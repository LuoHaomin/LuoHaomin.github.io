{"/about/":{"data":{"":"","关于本博客#关于本博客":"欢迎来到我的个人博客！这是一个记录技术思考、学习笔记和项目经验的地方。\n本博客由 Hugo + Hextra 主题驱动，提供快速、优雅的阅读体验。","内容分类#内容分类":"博客: 技术文章、经验分享和思考 笔记: 学习记录、知识总结 维基: 参考资料、项目文档、知识库","联系方式#联系方式":"敬请期待…"},"title":"关于"},"/blog/":{"data":{"":"博客文章集合"},"title":"博客"},"/blog/%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2/":{"data":{"":"我开始重新维护这个博客了。\n希望能在这里记录一些有趣的想法和见解，记录一些技术上的探索和学习。"},"title":"写在前面"},"/blog/hexo%E4%B8%BB%E9%A2%98-stellar/":{"data":{"":"本博客使用的是Hexo搭建的，使用了Hexo主题中的Stellar主题。\nStellar主题是一个功能极其丰富的综合型 Hexo 主题，包含博客系统、知识库系统、专栏系统、笔记系统，内置海量的标签和动态数据组件。它不仅支持传统的博客写作，还提供了文档管理、知识库、专栏系统等高级功能，特别适合技术博客、知识分享和个人品牌建设。","1-安装主题#1. 安装主题":"# 在 Hexo 根目录下安装主题 npm install hexo-theme-stellar","2-启用主题#2. 启用主题":"在 _config.yml 中设置主题：\ntheme: stellar","3-创建主题配置文件#3. 创建主题配置文件":"创建 _config.stellar.yml 文件来配置主题：\n# 复制主题默认配置 cp node_modules/hexo-theme-stellar/_config.yml _config.stellar.yml","algolia-搜索#Algolia 搜索":"search: service: algolia algolia: appId: your_app_id apiKey: your_api_key indexName: your_index_name","beaudar-配置#Beaudar 配置":"# _config.stellar.yml comments: service: beaudar beaudar: repo: username/repo issue_term: pathname theme: github-light","box-标签#Box 标签":"{% box 标题 %} 正文，也可以指定[color:color] [child:codeblock/tabs] {% endbox %}","giscus-配置#Giscus 配置":"comments: service: giscus giscus: repo: username/repo repo_id: repo_id category_id: category_id mapping: pathname theme: light","grid#grid":"{% grid %} 一个单元格 另一个单元格 {% endgrid %} {% grid %}\n一个单元格\n另一个单元格 {% endgrid %}","katex-配置#KaTeX 配置":"# _config.stellar.yml plugins: katex: enable: true copy_tex: true mhchem: true 在文章中使用：\n--- katex: true ---","mathjax-配置#MathJax 配置":"plugins: mathjax: enable: true config: tex2jax: inlineMath: [['$','$'], ['\\\\(','\\\\)']] displayMath: [['$$','$$'], ['\\\\[','\\\\]']]","menubar-配置#Menubar 配置":"在 _config.stellar.yml 中配置菜单：\nmenubar: columns: 4 # 一行显示多少个菜单项 items: # 菜单项列表 - id: post # 页面中高亮的 menu_id theme: '#1BCDFC' # 高亮时的颜色 icon: solar:documents-bold-duotone # 图标 title: 博客 # 标题 url: / # 跳转链接 - id: wiki theme: '#3DC550' icon: solar:document-2-bold-duotone title: 文档 url: /wiki/ - id: notes theme: '#FA6400' icon: solar:notebook-bookmark-bold-duotone title: 笔记 url: /notebooks/ - id: 关于 theme: '#F44336' icon: solar:backpack-bold-duotone title: 关于 url: /about","mermaid-图表#Mermaid 图表":"plugins: mermaid: enable: true theme: neutral 使用：\ngraph TD A[开始] --\u003e B{判断} B --\u003e|是| C[执行A] B --\u003e|否| D[执行B] C --\u003e E[结束] D --\u003e E","note-标签#Note 标签":"{% note 标题 正文，颜色有这些：red/orange/yellow/green/cyan/blue/purple/light/dark/warning/error，通过[color:color]指定 %}","tab#tab":"{% tabs active:2 align:center %}\n{% image /assets/wiki/stellar/photos/hello@1x.png width:300px %}\nlet x = 123 print(\"hello world\") a b c a1 b1 c1 a2 b2 c2 {% endtabs %}","timeline#timeline":"{% timeline 标题 %} 事件描述1 事件描述2 {% endtimeline %} {% box 小提示 color:blue %} 实际上，你如果用VSCode作为编辑器，你可以使用代码片段来快速插入标签。 以下是一个代码片段的示例： {% folding codesnippets open:false %}\n{ \"Stellar Note\": { \"scope\": \"markdown\", \"prefix\": \"/note\", \"body\": [ \"{% note ${1:标题} ${2:正文} [color:${3:blue}] %}\" ], \"description\": \"Stellar Note 标签\" }, \"Stellar Box\": { \"scope\": \"markdown\", \"prefix\": \"/box\", \"body\": [ \"{% box ${1:标题} [color:${2:blue}] %}\", \"${3:正文内容}\", \"{% endbox %}\" ], \"description\": \"Stellar Box 标签\" }, \"Stellar Folding\": { \"scope\": \"markdown\", \"prefix\": \"/folding\", \"body\": [ \"{% folding ${1:标题} ${2:[open:true]} ${3:[color:cyan]} %}\", \"${4:折叠内容}\", \"{% endfolding %}\" ], \"description\": \"Stellar Folding 折叠标签\" }, \"Stellar Folders\": { \"scope\": \"markdown\", \"prefix\": \"/folders\", \"body\": [ \"{% folders %}\", \"\", \"${2:这是答案1}\", \"\", \"${4:这是答案2}\", \"{% endfolders %}\" ], \"description\": \"Stellar Folders 折叠组标签\" }, \"Stellar Grid\": { \"scope\": \"markdown\", \"prefix\": \"/grid\", \"body\": [ \"{% grid %}\", \"\", \"${1:一个单元格}\", \"\", \"${2:另一个单元格}\", \"{% endgrid %}\" ], \"description\": \"Stellar Grid 网格标签\" }, \"Stellar Tabs\": { \"scope\": \"markdown\", \"prefix\": \"/tabs\", \"body\": [ \"{% tabs ${1:active:1} ${2:align:center} %}\", \"\", \"\", \"${4:内容1}\", \"\", \"\", \"${6:内容2}\", \"\", \"{% endtabs %}\" ], \"description\": \"Stellar Tabs 标签页\" } } {% endfolding %} {% endbox %}","utterances-配置#Utterances 配置":"comments: service: utterances utterances: repo: username/repo issue_term: pathname theme: github-light","wiki-系统工作原理#Wiki 系统工作原理":"Wiki 系统通过以下机制工作：\n项目配置管理：在 source/_data/wiki/ 目录下创建项目配置文件 页面关联：通过页面的 wiki 字段关联到具体项目 自动生成：通过 wiki.js generator 自动生成 Wiki 列表页面 项目分类：支持通过标签对项目进行分类 页面树构建：根据配置的 tree 结构构建页面导航","wiki-系统特性#Wiki 系统特性":"项目卡片展示：在 Wiki 首页以卡片形式展示所有上架项目 标签分类：支持通过标签对项目进行分类筛选 页面树导航：根据配置的 tree 结构生成页面导航 自动首页：未指定 homepage 时，自动选择 TOC 第一页作为首页 相关项目推荐：基于标签推荐相关项目 注意：\n页面路径匹配：确保页面文件路径与 base_dir + tree 配置匹配 # 配置 base_dir: wiki/my-project/ tree: '基础': ['index', 'getting-started'] # 对应的页面文件 source/wiki/my-project/index.md source/wiki/my-project/getting-started.md 多个页面：Tree 组件只有在项目有多个页面时才会显示，单个页面不会显示导航树","wiki-页面结构示例#Wiki 页面结构示例":"source/ ├── _data/ │ ├── wiki/ │ │ └── my-project.yml # 项目配置 │ └── wiki.yml # Wiki 上架配置 └── wiki/ └── my-project/ ├── index.md # 项目首页 ├── getting-started.md # 基础页面 └── advanced.md # 高级页面","wiki文档系统使用#Wiki文档系统使用":"Wiki 系统是 Stellar 主题的核心功能之一，适合构建知识库和项目文档。根据源码分析，Wiki 系统通过数据文件配置和页面关联来实现项目管理。","专栏系统使用#专栏系统使用":"专栏系统适合系列文章管理，通过 topic 配置实现文章分组。","专栏系统工作原理#专栏系统工作原理":"专栏系统通过以下机制工作：\n专栏配置：在 source/_data/topic/ 目录下配置专栏 文章关联：通过 topic 字段关联文章到专栏 专栏页面：自动生成专栏列表页面 文章分组：在专栏页面中按时间或分类显示文章","专栏系统特性#专栏系统特性":"文章分组：自动将同专栏文章分组显示 专栏导航：在专栏页面显示所有相关文章 系列标识：在文章页面显示所属专栏信息 统计信息：显示专栏文章数量等统计信息","主题基础配置#主题基础配置":"在 _config.stellar.yml 中配置主题：\n# Logo 配置 logo: avatar: '[{config.avatar}](/about/)' title: '[{config.title}](/)' subtitle: '{config.subtitle}' # 样式配置 style: prefers_theme: auto # auto / light / dark smooth_scroll: true font-size: root: 16px body: 17px code: 85%","主题色配置#主题色配置":"# _config.stellar.yml style: color: theme: 'hsl(192 98% 55%)' # 主题色 accent: 'hsl(14 100% 57%)' # 强调色 link: 'hsl(207 90% 54%)' # 链接色","侧边栏组件#侧边栏组件":"Stellar 提供了丰富的侧边栏组件：","侧边栏配置#侧边栏配置":"","创建-wiki-文档系统#创建 Wiki 文档系统":"","创建专栏系统#创建专栏系统":"","创建博客文章#创建博客文章":"使用 Hexo 命令创建新文章：\nhexo new post \"文章标题\"","创建普通页面#创建普通页面":"hexo new page \"about\" 页面 Front-matter：\n--- title: 关于我 date: 2025-01-01 12:00:00 layout: page menu_id: 关于 # 高亮的菜单项 ---","创建笔记本系统#创建笔记本系统":"","博客系统使用#博客系统使用":"","可用组件列表#可用组件列表":"组件名 功能 说明 welcome 欢迎信息 个性化欢迎组件 recent 最近更新 显示最新文章 related 相关文章 智能推荐文章 tagtree 标签树 层级标签展示 tagcloud 标签云 可视化标签 toc 目录 文章目录导航 tree 页面树 上下篇文章 ghrepo GitHub 仓库 仓库信息展示 ghuser GitHub 用户 用户信息展示 timeline 时间线 动态时间线 author 作者信息 作者卡片","右侧栏组件#右侧栏组件":"site_tree: post: rightbar: toc, ghrepo # 博客文章右侧栏 wiki: rightbar: toc, ghrepo # 文档页面右侧栏","圆角配置#圆角配置":"style: border-radius: card-l: 24px # 侧边栏、文章横幅 card: 16px # 文章内卡片 card-s: 12px # 小型卡片 bar: 8px # 横条元素 image-l: 24px # 非技术类文章插图 image: 16px # 技术类文章插图","基础配置#基础配置":"","字体配置#字体配置":"style: font-family: body: 'system-ui, \"Microsoft Yahei\", \"Segoe UI\", Arial, sans-serif' code: 'Menlo, Monaco, Consolas, system-ui, monospace, sans-serif' font-size: root: 16px body: 17px code: 85%","安装配置#安装配置":"","左侧栏组件#左侧栏组件":"# _config.stellar.yml site_tree: post: leftbar: recent, related, tagtree # 博客文章左侧栏 wiki: leftbar: tree, related, recent # 文档页面左侧栏","折叠#折叠":"{% folding title [codeblock:bool] [open:bool] [color:color] %} content {% endfolding %} 就像这样：\n{% folding 标题 codeblock:true open:true color:cyan %}\n# 这里是代码块 def hello(): print(\"Hello, World!\") {% endfolding %}\n{% folders %}\n这是答案1\n这是答案2\n这是答案3 {% endfolders %}","插件功能#插件功能":"","搜索功能#搜索功能":"","数学公式支持#数学公式支持":"","文章-front-matter-配置#文章 Front-matter 配置":"Stellar 主题支持丰富的 Front-matter 配置选项：\n--- # 基本信息 title: 文章标题 date: 2025-01-01 12:00:00 tags: [标签1, 标签2] # 文章的标签 categories: [分类1, 分类2] # 文章的分类 description: 文章描述 # 或使用 excerpt # 封面和横幅 cover: /images/cover.jpg # 封面小图 banner: /images/banner.jpg # 文章顶部大图 # 海报（可选） poster: topic: 专栏名称 # 标题上方的小字 headline: 大标题 # 必选 caption: 标题下方的小字 # 可选 color: '#FF6B35' # 标题颜色 # 功能开关 sticky: 1 # 置顶，数字越大越靠前 comments: true # 是否允许评论 indexing: true # 是否被搜索索引 breadcrumb: true # 是否显示面包屑导航 # 页面布局 type: tech # tech: 技术类文章, story: 故事类文章 leftbar: recent, related # 左侧栏组件 rightbar: toc, ghrepo # 右侧栏组件 h1: 文章标题 # 设置为 '' 隐藏标题 # 专栏和作者 topic: blogtool # 专栏 id author: author_name # 作者 id # 数学公式和图表 mermaid: true # 启用 Mermaid 图表 katex: true # 启用 KaTeX 数学公式 mathjax: true # 启用 MathJax 数学公式 --- 文章摘要，会显示在列表页面。 文章正文内容...","文章类型说明#文章类型说明":"Stellar 支持两种文章类型：\ntech：技术类文章，适合代码和技术文档，代码块样式更突出 story：故事类文章，文字间距更大，适合阅读体验","本地搜索#本地搜索":"# _config.stellar.yml search: service: local local: enable: true path: search.json field: post,page content: true format: html","标签树结构使用#标签树结构使用":"笔记本系统支持层级标签，使用 / 分隔符：\ntags: [Hexo/基础/安装, Hexo/配置/主题, JavaScript/ES6/箭头函数] 这会生成如下的标签树结构：\nHexo ├── 基础 │ └── 安装 ├── 配置 │ └── 主题 JavaScript └── ES6 └── 箭头函数","标签组件#标签组件":"","环境要求#环境要求":"在开始使用 Stellar 主题之前，请确保您的环境满足以下要求：\nHexo: 6.3.0 ~ latest hexo-cli: 4.3.0 ~ latest node: 14.17.3 ～ latest LTS # 建议选择 LTS 版本 npm: 6.14.13 ~ latest","站点基本信息#站点基本信息":"在 _config.yml 中配置站点基本信息：\n# Site title: 我的博客 subtitle: '一行字|A line of code' description: 这是我的个人博客 author: 您的名字 language: zh-CN timezone: 'Asia/Shanghai' # URL url: https://your-domain.com permalink: :year/:month/:day/:title/ permalink_defaults: pretty_urls: trailing_index: true trailing_html: true","笔记本系统使用#笔记本系统使用":"笔记本系统适合管理学习笔记和知识整理，通过标签树结构实现层级化管理。","笔记本系统工作原理#笔记本系统工作原理":"笔记本系统通过以下机制工作：\n笔记本配置：在 source/_data/notebooks/ 目录下配置笔记本 标签树管理：使用层级标签实现笔记分类 自动生成：通过 generator 自动生成笔记本列表页面 标签云展示：自动生成标签云和标签树","笔记本系统特性#笔记本系统特性":"层级标签：支持多级标签分类 标签云：自动生成可视化标签云 标签树：侧边栏显示层级标签树 笔记统计：显示每个标签下的笔记数量","第一优先级页面-front-matter#第一优先级：页面 Front-matter":"--- title: 我的文章 menu_id: wiki # 直接指定高亮哪个菜单 ---","第一步创建专栏配置#第一步：创建专栏配置":"在 source/_data/topic/ 目录下创建专栏配置文件，例如 blogtool.yml：\ntitle: 博客工具 description: 博客相关工具使用教程 icon: solar:documents-bold-duotone color: '#1BCDFC' menu_id: post leftbar: recent, related rightbar: toc","第一步创建笔记本配置#第一步：创建笔记本配置":"在 source/_data/notebooks/ 目录下创建笔记本配置文件，例如 hexo.yml：\ntitle: Hexo 学习笔记 description: Hexo 相关学习笔记 icon: solar:notebook-bookmark-bold-duotone color: '#FA6400' menu_id: notes leftbar: tagtree, recent rightbar: toc","第一步创建项目配置文件#第一步：创建项目配置文件":"在 source/_data/wiki/ 目录下创建项目配置文件，例如 my-project.yml：\ntitle: 我的项目 description: 项目文档 icon: solar:document-2-bold-duotone color: '#3DC550' tags: [前端, 教程] # 项目标签，用于分类 sort: 1 # 排序权重，数字越大越靠前 base_dir: wiki/my-project/ # 项目页面基础路径 tree: # 页面树结构配置 \"基础\": [\"index\", \"getting-started\"] \"高级\": [\"advanced\", \"deployment\"] homepage: index # 指定首页，可选","第三优先级页面类型自动判断#第三优先级：页面类型自动判断":"博客文章 → post 专栏文章 → post 文档页面 → wiki 笔记页面 → notebooks 笔记本列表 → notebooks 作者页面 → post 404页面 → post","第三步配置笔记-front-matter#第三步：配置笔记 Front-matter":"在笔记的 Front-matter 中指定笔记本：\n--- title: Hexo 基础教程 notebook: hexo tags: [Hexo/基础, Hexo/教程] ---","第三步配置页面-front-matter#第三步：配置页面 Front-matter":"每个 Wiki 页面需要配置相应的 Front-matter：\n--- title: 快速开始 wiki: my-project # 关联到项目配置 layout: wiki # 使用 wiki 布局 ---","第二优先级笔记本配置#第二优先级：笔记本配置":"# 在笔记本配置中指定 notebook: menu_id: notes","第二步创建-wiki-页面#第二步：创建 Wiki 页面":"在 source/wiki/my-project/ 目录下创建页面文件：\n# 创建项目页面 hexo new page \"wiki/my-project/index\" hexo new page \"wiki/my-project/getting-started\" hexo new page \"wiki/my-project/advanced\"","第二步创建专栏文章#第二步：创建专栏文章":"创建文章时在 Front-matter 中指定专栏：\n--- title: Hexo 主题配置 topic: blogtool layout: post ---","第二步创建笔记文章#第二步：创建笔记文章":"使用标准的 Hexo 命令创建文章：\nhexo new post \"Hexo 基础教程\"","第四步配置-wiki-上架#第四步：配置 Wiki 上架":"在 source/_data/wiki.yml 中配置要显示的项目：\n# 上架的项目列表，只有在此列表中的项目才会在 Wiki 首页显示 - my-project - another-project","组件配置示例#组件配置示例":"# _config.stellar.yml widgets: recent: layout: recent limit: 10 # 显示数量 rss: /atom.xml # RSS 源 tagcloud: layout: tagcloud title: 标签云 min_font: 12 max_font: 24 amount: 100 color: true # 使用颜色 timeline: layout: timeline title: 近期动态 api: https://api.github.com/repos/user/repo/issues limit: 20","自定义-css#自定义 CSS":"创建 source/css/_custom.styl 文件：\n// 自定义样式 .custom-class color: var(--theme) font-weight: bold // 覆盖主题样式 .nav-item border-radius: 12px","自定义图标#自定义图标":"在 source/_data/icons.yml 中定义自定义图标：\n# 自定义图标 custom:my-icon: 图标要求：\n尺寸：width=\"32\" height=\"32\" 颜色：使用 fill=\"currentColor\" 以支持主题色 移除硬编码的颜色属性","自定义样式#自定义样式":"","自定义页面布局#自定义页面布局":"--- title: 自定义页面 layout: page leftbar: recent rightbar: toc ---","菜单配置#菜单配置":"菜单栏是 Stellar 主题的核心导航组件，位于左侧边栏顶部。","菜单高亮逻辑#菜单高亮逻辑":"Stellar 主题的菜单高亮遵循以下优先级：","评论系统#评论系统":"支持多种评论服务：","页面管理#页面管理":""},"title":"Hexo Stellar 主题使用指南"},"/blog/hexo%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5%E8%A1%A8/":{"data":{"":"","1-初始化和安装#1. 初始化和安装":"npm install -g hexo-cli 全局安装 Hexo 命令行工具。 hexo init 初始化一个新的 Hexo 项目。 npm install 安装项目依赖。 配置：在_config.yml中可以修改博客的配置。","2-生成和预览#2. 生成和预览":"hexo g 或 hexo generate 生成静态文件。 hexo s 或 hexo server 启动本地开发服务器预览博客。","3-部署#3. 部署":"npm install hexo-deployer-git --save 安装 Git 部署插件。 hexo d 或 hexo deploy 部署博客到远程仓库。","4-主题管理#4. 主题管理":"git clone \u003c主题仓库URL\u003e themes/\u003c主题名\u003e 克隆主题到项目主题目录。 cd themes/\u003c主题名\u003e \u0026\u0026 npm install 进入主题目录并安装主题依赖。","5-项目维护#5. 项目维护":"npm ls --depth 0 查看项目依赖树。 npm audit fix 修复项目依赖的安全漏洞。 hexo clean 清理生成的文件和缓存。如果修改了配置，需要先清理缓存才生效。","6-页面和文章管理#6. 页面和文章管理":"hexo new page \u003c页面名\u003e 创建新页面。 hexo new post \u003c文章名\u003e 创建新文章。","7-其他实用命令#7. 其他实用命令":"npm cache clean --force 清理 npm 缓存。 rm -rf node_modules \u0026\u0026 rm package-lock.json 删除 node_modules 目录和 package-lock.json 文件，用于重新安装依赖。"},"title":"Hexo使用速查表"},"/blog/hugo%E4%B8%BB%E9%A2%98-hextra/":{"data":{"":"Hextra 是一个专注文档与博客体验的 Hugo 主题，支持全文搜索、暗色模式、文档侧边栏、短代码等“开箱即用”的功能，非常适合用来搭建知识库 + 博客的组合站点。\n本文结合我自己的博客实践，按“从安装到上线”的顺序梳理使用 Hextra 的关键步骤。","1-准备一个-hugo-站点#1. 准备一个 Hugo 站点":"如果你还没有 Hugo 站点，可以先创建一个：\nhugo new site my-site cd my-site 建议 Hugo 使用扩展版（extended），方便处理 Tailwind / PostCSS 等相关功能。","2-获取-hextra-主题#2. 获取 Hextra 主题":"一般有两种常见方式：","21-作为-git-子模块引入#2.1 作为 Git 子模块引入":"git init git submodule add https://github.com/imfing/hextra.git themes/hextra 然后在 hugo.toml 或 hugo.yaml 中指定主题：\ntheme: hextra","22-使用-hugo-modules推荐#2.2 使用 Hugo Modules（推荐）":"如果你熟悉 Go Modules / Hugo Modules，可以在项目中启用模块支持，将 Hextra 作为远程模块引入。好处是升级主题和管理依赖更方便。","3-基础配置示例#3. 基础配置示例":"下面是一个精简过的 hugo.yaml 示例，展示与 Hextra 配合时常用的全局配置：\nbaseURL: https://example.com/ languageCode: en-us title: 我的 Hugo 站点 theme: hextra enableRobotsTXT: true enableGitInfo: true hasCJKLanguage: true outputs: home: [html] page: [html, markdown] section: [html, rss, markdown] params: navbar: displayTitle: true displayLogo: true width: wide theme: default: system displayToggle: true search: enable: true type: flexsearch flexsearch: index: content tokenize: forward blog: list: displayTags: true sortBy: date sortOrder: desc article: displayPagination: true 可以根据自己的需求再添加 footer、editURL、comments 等配置。","4-组织内容博客区与文档区#4. 组织内容：博客区与文档区":"Hextra 对“文档型内容”和“博客型内容”都有良好支持：\n博客区：通常使用 content/blog/ 目录，文章有 date、tags、description 和 摘要分隔。 文档区：推荐使用 _index.md + 子页面 的结构，并在 front matter 中设置 type: docs 或通过 cascade 继承。","41-博客文章示例#4.1 博客文章示例":"--- title: 我的第一篇 Hugo 文章 date: 2026-02-07T20:00:00+08:00 tags: - Hugo - 随笔 description: 用 Hugo + Hextra 写下的第一篇文章 --- 这里是文章的开头内容，会出现在博客列表摘要中。 这里是正文的剩余部分。","42-文档章节示例#4.2 文档章节示例":"--- title: Bevy 完整教程 cascade: type: docs --- 欢迎来到教程首页，这里可以作为整个文档系列的入口说明。 子页面只需要正常写内容，Hextra 会自动在左侧生成侧边栏导航，并在右侧生成小标题目录。","5-自定义导航栏与侧边栏#5. 自定义导航栏与侧边栏":"导航栏菜单通过 menu.main 配置，例如：\nmenu: main: - name: 博客 pageRef: /blog weight: 1 - name: 笔记 pageRef: /notes weight: 2 - name: 关于 pageRef: /about weight: 3 - name: 搜索 weight: 4 params: type: search 侧边栏的主要内容会根据目录结构自动生成，你也可以通过：\n在 _index.md 中设置 weight 控制顺序； 使用 menu.sidebar 添加额外链接（例如跳转到特定文档或外部参考）。","6-常用增强功能#6. 常用增强功能":"全文搜索：开启 params.search 后，Hextra 默认使用 FlexSearch 在前端实现全文检索。 代码高亮与复制按钮：通过 markup.highlight 和 params.highlight.copy 进行配置。 暗色模式：params.theme.default 设置为 system 或 dark，并启用 displayToggle。 短代码：如 callout、cards、tabs 等，可以让文档更美观易读。","7-本地预览与部署#7. 本地预览与部署":"本地开发通常用：\nhugo server --buildDrafts --disableFastRender 确认一切正常后，使用：\nhugo 在 public/ 目录中得到最终的静态站点，然后部署到 GitHub Pages、Netlify 之类的平台即可。\n总体体验下来，Hextra 对“文档 + 博客”这种混合场景非常友好：\n博客区：列表清晰、支持标签与全文搜索； 文档区：侧边栏导航、右侧目录、短代码都很顺手； 配置上手成本不高，用少量 YAML 就能获得不错的默认效果。 如果你已经在用 Hugo，希望站点更适合写长期文档和教程，非常推荐尝试一下 Hextra。"},"title":"Hugo主题——Hextra"},"/blog/hugo%E4%BD%BF%E7%94%A8%E9%80%9F%E6%9F%A5%E8%A1%A8/":{"data":{"":"这是一份围绕 Hugo 日常使用场景整理的速查表，适合已经安装好 Hugo、想要快速查命令和常见配置的你。","1-安装与创建站点#1. 安装与创建站点":"","11-安装-hugo推荐扩展版#1.1 安装 Hugo（推荐扩展版）":"macOS（Homebrew）： brew install hugo # 或指定扩展版 brew install hugo --HEAD 验证版本： hugo version","12-创建新站点#1.2 创建新站点":"hugo new site my-blog cd my-blog 常见目录：\ncontent/：文章内容 layouts/：自定义模板 static/：静态资源（图片、js、css） hugo.toml|yaml|json：站点配置","2-常用命令速查#2. 常用命令速查":"","21-本地开发与预览#2.1 本地开发与预览":"hugo server --buildDrafts --disableFastRender # 简写 hugo server -D -D / --buildDrafts：包含 draft: true 的文章 默认监听 http://localhost:1313","22-生成静态文件#2.2 生成静态文件":"hugo # 指定输出目录 hugo -d public 生成后的静态站点位于 public/ 目录，可直接部署到任意静态托管平台。","23-新建内容#2.3 新建内容":"# 新建一篇博客文章 hugo new blog/my-first-post.md # 新建一篇笔记 hugo new notes/my-note.md 新建的文章会带有默认 front matter，通常初始为 draft: true。","3-front-matter-速记#3. Front Matter 速记":"Hugo 支持 YAML / TOML / JSON 形式的 front matter，以下为 YAML 示例：\n--- title: 我的第一篇文章 date: 2026-02-07T20:00:00+08:00 tags: - 随笔 - Hugo categories: - Blog draft: false --- 常见字段：\ntitle：文章标题 date：创建/发布日期 lastmod：最后修改时间（配合 enableGitInfo 使用更佳） tags / categories：标签与分类 draft：草稿标记","4-多环境配置要点#4. 多环境配置要点":"","41-基本配置示例hugoyaml#4.1 基本配置示例（hugo.yaml）":"baseURL: https://example.com/ title: 我的博客 theme: hextra enableRobotsTXT: true enableGitInfo: true hasCJKLanguage: true 常见问题：\n本地预览 baseURL 无所谓，但部署到生产环境时应设置为真实网址，否则 RSS / Canonical URL 可能异常。","42-输出格式与-rss#4.2 输出格式与 RSS":"outputs: home: [html, rss] section: [html, rss] page: [html]","5-常见调试与排错#5. 常见调试与排错":"","51-查看所有页面列表#5.1 查看所有页面列表":"hugo list all 可以快速确认某篇文章是否被 Hugo 识别、是否为 draft。","52-检查草稿--未来文章#5.2 检查草稿 / 未来文章":"hugo list drafts hugo list future 如果线上站点看不到某篇文章，优先排查：\n是否 draft: true date 是否在未来 是否在 content/ 下的正确子目录","6-与主题协同使用的小贴士#6. 与主题协同使用的小贴士":"大部分主题会在文档中给出推荐的 front matter 字段，可以直接参照。 对于文档型内容，优先使用 type: docs 和 _index.md + 子页面 的方式组织。 熟悉 params 配置（如导航栏、搜索、评论系统等）能极大提升 Hugo 的使用体验。","7-进一步学习#7. 进一步学习":"官方文档：https://gohugo.io/documentation/ 主题站点示例与配置：在所用主题仓库的 exampleSite/ 目录中寻找"},"title":"Hugo使用速查表"},"/glossary":{"data":{},"title":"Glossary"},"/notes/":{"data":{"":"学习笔记与碎片整理"},"title":"笔记"},"/notes/fragment/%E7%A2%8E%E7%89%87/":{"data":{"":"在这个碎片中，我记录了一些零散的想法和灵感，可能并不完整，但希望能够为将来的创作提供一些启发。\n知识管理 卡片笔记法简介 卡片笔记法（Zettelkasten）是一种将知识拆分成小块、并通过链接构建知识网络的笔记方法。\n核心思想是：\n将每个想法、概念、问题拆分成独立的“卡片”。 通过链接将相关卡片连接起来，形成知识网络。 不追求完美的结构，而是通过不断整理和重组，让知识网络自发涌现结构。 原子化意味着一张卡片只记录一个知识点，这有助于降低记忆难度和认知负荷。\n{% quot 关键在于链接与群聚 %}","知识管理#知识管理":"","笔记分类#笔记分类":"闪念笔记（Fleeting Note）：捕捉想法。\n闪念卡片，旨在快速记录脑海中瞬间出现的想法，讲究的就是一个“快”字。\n文献笔记（Literature Note）：简短，使用自己的语言。 文献卡片，主要记录那些给我们带来启示和帮助的信息，以便我们在需要时能找到原文，并结合上下文进行复习。\n渐进式处理包括四个步骤：原文摘录、重点加粗、要点标注和摘要小结。\n**用自己的话来描述。**必要难度。\n尊重原始数据，意味着找到原始数据来源，且不在原始数据上直接修改。\n永久笔记（Permanent Note）：思考与已有信息的关联。发现新想法和创造新知识\n项目笔记（Project Note）：","链接#链接":"主题概述链接： 相邻集群链接 逻辑前后链接 {% endfolding %}"},"title":"碎片"},"/notes/learn/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96/":{"data":{"":"本系列文档系统整理了智能计算与 MLSys 相关的基础知识与工程实践，包括：\n机器学习与神经网络基础 深度学习在实际系统中的应用 分布式 MLSys 与大模型训练系统 推理服务、微调优化与 GPU/系统加速 典型架构案例（如 DeepSeek 等） 建议通过左侧目录按顺序阅读，或根据具体主题跳转到对应章节。"},"title":"智能计算软件优化"},"/notes/learn/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96/%E5%88%86%E5%B8%83%E5%BC%8Fmlsys/":{"data":{"":"","1-引言大模型发展的挑战与趋势#1. 引言：大模型发展的挑战与趋势":"本章节旨在介绍当前大模型发展的宏观背景、驱动因素以及所面临的系统性挑战，特别是计算硬件发展与模型规模增长之间的矛盾，从而引出分布式训练系统的重要性。","11-scaling-law模型性能与规模的关系#1.1 Scaling Law：模型性能与规模的关系":"核心定律：Scaling Law 指出，在其他条件不变的情况下，模型越大、数据越多、计算越久，模型的表现就越好。 这意味着通过简单地增加模型的参数量、训练数据集的大小以及训练时间，可以系统性地提升神经网络模型的性能。 重要参考文献：这一观察结果在神经网络语言模型领域得到了广泛验证，其中一篇里程碑式的论文是 Kaplan 等人发表的《Scaling Laws for Neural Language Models》（https://arxiv.org/pdf/2001.08361.pdf）。 深远影响：Scaling Law 是推动当前大模型浪潮（尤其是大型语言模型LLM）发展的重要理论基础。它为研究人员和工程师提供了明确的优化方向，即通过规模化来实现性能突破。","12-llm维度增长上下文大小的扩展#1.2 LLM维度增长：上下文大小的扩展":"关键维度：除了模型参数量的增长，增加模型的上下文大小（Context Size） 是LLM性能提升的另一个关键维度。 上下文大小决定了模型在进行预测或生成文本时能够考虑的历史信息量。更大的上下文意味着模型可以理解更长距离的依赖关系，处理更复杂的语境，从而在长文本理解、对话连贯性、代码生成等任务中表现更优。 重要参考文献：Brown 等人发表的《Language Models are Few-Shot Learners》（https://arxiv.org/pdf/2005.14165.pdf）展示了大型语言模型在具备足够上下文时所展现出的强大的“少样本学习”（Few-Shot Learning）能力。","13-计算硬件发展与模型规模增长的矛盾#1.3 计算硬件发展与模型规模增长的矛盾":"现状：当前大模型的模型规模增长速度远远超过了计算硬件性能的提升速度，二者之间存在显著的“剪刀差”。 GPU性能增长：GPU 的 FLOPS（每秒浮点运算次数）性能大约每 2.5年翻一番。 LLM规模增长：然而，大型语言模型的规模（参数量）却以每年约10倍的速度增长。 影响：这种巨大的差距意味着，即使拥有最先进的单个计算设备，也难以满足训练和部署超大规模模型的需求。 重要参考文献：Hobbhahn 和 Besiroglu 在《Trends in GPU Price-Performance》（https://epochai.org/blog/trends-in-gpu-price-performance）中对这一趋势进行了详细分析。此外，Smith 等人关于训练 Megatron-Turing NLG 530B 的论文《Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model》（https://arxiv.org/pdf/2201.11990.pdf）也侧面反映了应对这种规模挑战所需的系统级努力。 结论：为了弥合硬件能力与模型需求之间的鸿沟，分布式系统成为了承载和加速大模型计算的必然选择。","14-大模型参数规模演变图#1.4 大模型参数规模演变图":"该部分原始材料中包含一张展示大模型参数规模随时间演变趋势的图表。以下是对该图表的详细描述和解读：\n图表内容描述： 图表横轴代表年份，从2014年（经典机器学习模型）一直延伸到2024年（预留发展空间）。 图表纵轴代表模型参数规模（Scale of parameters），从数千万到数万亿。 图表上标记了多个里程碑式的模型，展示了它们在不同年份的参数量。 图表下方还列举了为了支持更大模型训练而引入的各种分布式并行技术。 关键信息提取： 2014年及以前：标记为“Classic ML models”，参数规模相对较小，通常在百万级。 2018年：ELMo (94M) - 参数量达到亿级。 2019年：BERT-L (340M), GPT-2 (1.5B) - 参数量进入十亿级。 2020年：Megatron-LM (8.3B), Turing-NLG (17.2B), GPT-3 (175B) - 参数量迅速增长，GPT-3达到千亿级。 2021年：Switch-C (1.6T), GShard (400B) - Switch-C首次将参数量推向万亿级别（稀疏模型）。 2022年：Megatron-Turing (530B) - 继续在千亿级规模发展。 2023年：图表指示参数规模继续增长。 分布式技术的重要性： 随着模型参数的爆炸式增长，单设备已无法满足存储和计算需求。图表下方列出的分布式并行技术正是应对这一挑战的关键。 Data Parallel (数据并行)：最早且最常用的并行策略，通过在不同设备上复制模型并分配不同批次的数据来加速训练。 Pipeline Parallel (管道并行)：将模型的层（layers）分布到不同的设备上，形成一个处理流水线，以减少单设备的内存占用。 Tensor Parallel (张量并行)：将模型内部的张量（如权重矩阵）切分到不同设备上，实现层内的并行计算。 Sequence Parallel (序列并行)：在序列维度上对输入进行切分，以减少激活内存的消耗。 Expert Parallel (专家并行)：主要用于稀疏激活模型（如MoE），将不同的“专家”模型分配到不同设备上，只激活部分专家进行计算。 总结：这张图生动地展示了**“Scaling Law”**的实践结果，以及在模型规模不断攀升的背景下，分布式训练系统和多样化的并行策略从“需要”变为“必须”的发展历程。这些并行策略的组合使用使得训练万亿参数规模的大模型成为可能。","2-通讯原语与通讯机制#2. 通讯原语与通讯机制":"在分布式机器学习训练中，数据需要在多个计算设备（如GPU）之间高效地传输和同步。为了实现这一目标，需要依赖一系列底层的通讯原语和机制。本节将详细介绍这些核心概念。","21-集合通讯-collective-communication#2.1 集合通讯 (Collective Communication)":"","211-定义与作用#2.1.1 定义与作用":"定义：集合通讯（Collective Communication）指的是一组参与进程（或设备）之间协作完成的通信操作。它们需要共同完成某种“整体性”的数据传递或计算任务。 作用：在大规模并行计算中（如多GPU训练），许多操作具有全局性质，例如聚合所有设备的梯度或分发相同的模型参数。这些操作无法简单地通过点对点通信（即两个设备之间的直接通信）高效完成，因此需要更高级别的集合通讯操作来协调多个设备。集合通讯提供了一种抽象，使得开发者无需关心复杂的点对点通信细节。","212-通讯抽象层与实现层#2.1.2 通讯抽象层与实现层":"分布式深度学习框架通常采用分层设计，将复杂的通信操作进行抽象：\n上层通信抽象层： 提供给用户友好的API，如 torch.distributed (PyTorch), Horovod, DeepSpeed。 这些框架封装了底层的通信细节，允许开发者以更高级别的语义（例如“同步梯度”、“广播模型”）来组织分布式训练逻辑。 下层通信实现层： 负责具体的网络数据传输，提供高性能的通信后端。 常见的实现包括： NCCL (NVIDIA Collective Communications Library)：NVIDIA专门为GPU优化的高性能集合通信库，广泛用于多GPU和多节点GPU集群。 MPI (Message Passing Interface)：通用的并行计算通信协议，可在CPU和GPU集群上使用。 Gloo：Facebook开源的CPU通信库，也可以在GPU上运行。 RCCL (ROCm Collective Communication Library)：AMD为自家GPU平台提供的集合通信库。 UCX (Unified Communication X)：一个高性能的通用通信框架，支持多种网络硬件和传输协议。 SHARP (Scalable Hierarchical Aggregation and Reduction Protocol)：Mellanox InfiniBand网络提供的硬件加速集合通信技术。 RDMA (Remote Direct Memory Access)：一种允许直接访问远程内存而无需CPU参与的技术，能够显著降低通信延迟和CPU开销。 TCP (Transmission Control Protocol)：标准的网络传输协议，但通常用于低带宽或广域网场景，性能不如专门的并行通信协议。","213-常见的集合通讯操作#2.1.3 常见的集合通讯操作":"以下是分布式训练中常用的几种集合通讯操作的列表，它们将在2.3节中详细讲解：\nAllReduce Broadcast Reduce AllGather ReduceScatter","22-基于点对点通讯实现的通讯原语#2.2 基于点对点通讯实现的通讯原语":"除了上述直接由底层库提供的集合通讯原语，许多更复杂的通信模式可以通过基本的点对点通讯（如 ncclSend() 和 ncclRecv()）进行构建和实现。这些原语描述了数据如何在特定发送方和接收方之间一对一地传输。基于点对点通讯，可以构建出：\nScatter (One-to-all)：将一个设备的数据分散到所有其他设备。 Gather (All-to-one)：将所有设备的数据收集到一个设备。 All-to-all：每个设备都向其他所有设备发送数据，并从其他所有设备接收数据。","23-各类通讯原语详解#2.3 各类通讯原语详解":"","231-allreduce#2.3.1 AllReduce":"定义与功能： Reduce 指的是在某个或某些维度上对数据进行归约处理（如求和 sum、求最小值 min、求最大值 max、求平均 avg 等操作）。 AllReduce 则是在完成归约处理后，将最终的归约结果分发（复制）给所有参与集合通讯的GPU（或进程）。 典型应用：在数据并行训练中，每个GPU会计算各自子批次数据的梯度，然后使用AllReduce操作将所有GPU计算出的梯度进行求和（或求平均），并将最终的平均梯度同步到所有GPU上，以便每个GPU都能用相同的梯度更新模型。 实现优化：并行传输，管道传输： 为了提高效率，AllReduce的实现通常会采用并行传输（例如同时在多个链路上发送数据）和管道传输（将数据分成小块，在前一块数据传输的同时，后一块数据进行计算或准备发送，形成流水线效应）等技术。 Ring-based AllReduce: Reduce-Scatter + Allgather： 环形AllReduce是一种非常高效且常用的AllReduce实现算法，尤其适用于大规模集群。 它将一个完整的AllReduce操作分解为两个阶段： Reduce-Scatter：每个设备将自己的数据与环上的下一个设备的数据进行归约，并将归约结果的一部分（slice）发送给下一个设备。这个过程在环上进行N-1次，直到每个设备都获得了所有设备数据的一个归约后的“片段”（slice）。最终，每个设备都拥有一个完整的归约结果的不同片段，且这些片段已经包含了所有设备对应部分的数据。 Allgather：在Reduce-Scatter完成后，每个设备都拥有归约结果的一个片段。Allgather阶段则通过在环上传输这些片段，使得每个设备最终都能收集到所有片段，从而得到完整的归约结果。 优点：环形AllReduce能够有效地利用网络带宽，并通过流水线操作隐藏通信延迟，使得通信流量在所有设备上相对均衡。","232-broadcast#2.3.2 Broadcast":"定义与功能： Broadcast 操作是将一个设备（源设备）上的数据完全复制并发送到所有其他参与集合通讯的设备上。 典型应用：在分布式训练中，通常用于将主设备（或某个特定设备）上的模型参数、超参数或配置信息分发给所有worker设备。 实现优化：并行传输，管道传输： 与AllReduce类似，Broadcast的实现也可以通过并行传输和管道传输来优化效率。例如，可以使用树形结构进行广播，以减少传播时间。","233-reduce#2.3.3 Reduce":"定义与功能： Reduce 操作是将所有设备上的数据进行归约，并将最终的归约结果只存储到其中一个指定的设备上。 与AllReduce的区别：“没有All前缀”意味着归约结果只在一个位置（通常是根节点）可见，而不会像AllReduce那样分发到所有设备。 典型应用：收集所有worker设备的日志信息、统计量或汇总某些特定的中间结果到主设备进行统一处理。","234-scatter-one-to-all#2.3.4 Scatter (One-to-all)":"定义与功能： Scatter 操作是将一个设备上的数据分割成多个不重叠的片段（chunks），然后将这些不同的片段分发给不同的参与设备。 典型应用：将一个大的数据集或一个大型批次的数据分割成多个小批次，分发给不同的worker设备进行独立处理。 与Broadcast的区别： Broadcast 发送给所有设备的数据是完全相同的副本。 Scatter 发送给所有设备的数据是不同且不重叠的片段。","235-reducescatter#2.3.5 ReduceScatter":"定义与功能： ReduceScatter 操作结合了Reduce和Scatter的功能。它首先将所有设备的数据进行归约，同时在归约过程中，将归约结果的不同片段直接分散到不同的设备上。 换句话说，每台设备都有自己的数据。在将每个设备的数据分割分发的过程当中同时完成归约操作。 典型应用：在环形AllReduce算法的第一阶段中用到，每个设备将自身数据与环上下一个设备的数据归约，并将归约结果的一个片段发送出去。","236-gather-all-to-one#2.3.6 Gather (All-to-one)":"定义与功能： Gather 操作是将所有参与设备上的数据收集到其中一个指定的设备上。这些数据通常是来自不同设备的，收集后会在目标设备上按照特定顺序组合起来。 可以形象地理解为将分散在不同设备上的数据“行变列”或“拼接到一起”。 典型应用：在模型训练中，每个设备可能处理了不同的数据片段并生成了对应的结果。Gather可以将这些结果收集到一起进行后续处理，例如在主设备上对所有worker的输出进行统一评估。 与Scatter的逆操作关系： Gather和Scatter互为逆操作。Scatter将一个完整的数据源分散到多个目标，而Gather则将多个分散的数据源收集回一个完整的目的地。","237-allgather#2.3.7 AllGather":"定义与功能： AllGather 操作是在Gather收集数据的基础上，将最终收集到的完整结果（所有设备的数据组合而成）复制并分发给所有参与集合通讯的设备。 典型应用：在需要所有设备都拥有完整信息（例如所有设备的输出特征，或在张量并行中需要组合完整的张量）的场景。","238-all-to-all#2.3.8 All-to-All":"定义与功能： All-to-All 是一种更通用的通信模式，可以理解为Scatter和Gather同时发生。 每个设备将其本地数据分割成多个块，并将每个块发送给不同的目标设备。同时，每个设备也从所有其他设备接收数据块，并组合成其最终的输出数据。 形象地说，如果将所有设备的数据看作一个矩阵，All-to-All操作相当于对这个矩阵进行“行列互换”（转置），即每一列是某个设备Scatter的结果，每一行是某个设备Gather的结果。 典型应用：在张量并行和专家混合模型（MoE）中，经常需要进行All-to-All通信，以实现数据或模型参数的复杂重排和交换。例如，MoE中将tokens路由到不同的专家，每个专家处理一部分tokens，然后将处理结果再路由回来。","31-数据并行-data-parallelism-dp#3.1 数据并行 (Data Parallelism, DP)":"","311-定义与基本原理#3.1.1 定义与基本原理":"数据并行 (Data Parallelism, DP) 是一种分布式训练策略，它通过将大规模训练数据的批次（batch）切分为多个子批次（mini-batch），然后将这些子批次分发到不同的计算设备（如GPU）上并行处理。每个设备都拥有模型的一个完整副本，独立地对分配到的数据子集进行前向传播和反向传播，计算出各自的梯度。最后，这些设备上的梯度会被聚合（通常是求平均），并用于更新所有设备上的模型副本。这个过程与在单个设备上对原始大批次数据进行梯度计算是等价的，从而加速了训练过程。","312-dp的计算流程#3.1.2 DP的计算流程":"数据并行的核心思想是“数据切分，模型复制，梯度聚合”。其计算流程可以概括为：\n数据分发：一个批次（batch）的数据被分割成 NNN 个子批次（mini-batch），每个子批次被分发到一个独立的GPU上。 独立计算： 在每个GPU上，进行独立的前向传播计算，产生损失。 接着进行反向传播，为该GPU上分配的子批次数据计算出梯度。 梯度聚合：在完成反向传播后，所有GPU上计算出的梯度会被收集起来进行聚合操作。最常见的是 求平均，以确保所有GPU上的模型副本能基于全局批次的平均梯度进行更新。这个聚合过程通常通过 All-reduce 操作实现。 模型更新：聚合后的梯度被用于更新每个GPU上的模型副本。由于所有GPU接收到相同的平均梯度，它们的模型副本将保持同步。 图片内容描述： 原始文档中有一张名为“数据并行”的示意图，展示了数据并行的计算流程。图中包含四个并行的GPU设备（GPU 0, GPU 1, GPU 2, GPU 3），每个GPU接收一个数据子批次（B0, B1, B2, B3）。图示箭头表明数据子批次首先进入各自的GPU进行前向传播和反向传播，然后每个GPU独立计算梯度。最后，这些梯度通过箭头汇聚，表示进行聚合操作（如All-reduce），最终统一更新所有GPU上的模型。这形象地说明了每个GPU独立计算并最终聚合梯度的过程。 【若需查看原始图片详情，请参考原文中的“数据并行”示意图】","313-ps-parameter-server-架构#3.1.3 PS (Parameter Server) 架构":"Parameter Server (PS) 架构 是一种经典的数据并行分布式机器学习框架，由Google在2014年提出。它将分布式系统的角色分为两类：\nServer (参数服务器)： 负责存储机器学习模型的所有参数。 接收来自Worker的梯度。 根据接收到的梯度对本地存储的参数进行更新 (update)。 将最新参数分发给Worker。 Worker (工作节点)： 从Server端获取 (pull) 当前最新的模型参数。 使用本地或者远程节点的数据以及从Server获取的参数，计算关于训练参数的梯度 (compute)。 将计算出的梯度发送 (push) 给Server端。 问题：in-cast的数据拥塞 PS架构的一个主要缺点是可能导致 in-cast数据拥塞。当大量Worker同时将各自计算的梯度“push”给Server时，Server端可能会因为接收带宽或处理能力的限制而成为瓶颈，导致数据传输拥塞，降低整体训练效率。这就像很多水流同时涌向一个细小的管道口，会造成堵塞。","314-ring-all-reduce的数据并行架构#3.1.4 Ring-all-reduce的数据并行架构":"为了解决PS架构可能存在的单点瓶颈和in-cast拥塞问题，Ring-all-reduce 成为一种更高效的梯度聚合方式，尤其适用于GPU集群。\n原理：Ring-all-reduce 将梯度聚合和广播的过程分解为一系列点对点通信操作，数据在设备之间形成一个“环形”拓扑结构进行传输。每个设备既发送数据也接收数据，以分段的方式完成所有数据的归约和广播。 优势： 去中心化：没有中心服务器，避免了单点故障和瓶颈。 负载均衡：每个设备在通信过程中都承担相似的工作量，使得流量传输更容易满足均衡需求。 高效率：通过重叠计算和通信，以及优化带宽利用率，Ring-all-reduce 通常比PS架构在梯度聚合上更高效。 实现方式：梯度聚合（pull）和传播（push）的过程本质上就是 AllReduce 的过程。Ring-all-reduce 通过将AllReduce拆解为 Reduce-Scatter 和 All-Gather 两个阶段来实现。","315-multiple-ring-allreduce架构#3.1.5 Multiple Ring-AllReduce架构":"进一步优化数据并行中的梯度聚合，可以利用网络拓扑的特性。\n思想：由于数据并行的流量只是在所有设备上执行“加和”的操作（满足结合律和交换律），因此可以利用光交换机设计多个互质网络环。 优势：通过在多个环形网络上并行传输，可以实现传输分流，显著增加传输效率，进一步降低梯度聚合的时间。这就像修建多条环形公路来分散交通流量。 【若需查看原始图片详情，请参考原文中的“Multiple Ring-AllReduce的数据并行架构”示意图，该图通常会展示多个交错的环形连接】","316-同步策略#3.1.6 同步策略":"在数据并行训练中，不同Worker之间参数更新的同步方式是影响训练效率和模型收敛行为的关键。\nBSP (Bulk Synchronous Parallel) 同步：\n这是最严格的同步方式。每轮迭代（iteration），所有计算设备必须全部完成梯度计算、梯度聚合、更新模型、分发更新后的模型之后，才能够进行下一个iteration的梯度计算。 优点：保证模型参数的一致性，收敛行为与单机训练一致，调试相对简单。 缺点：存在木桶效应，整个训练速度受限于最慢的Worker（“短板”）。 ASP (Asynchronous Parallel) 完全异步：\n每个Worker独立异步地计算梯度，并更新参数服务器上的模型参数，然后立即获取最新参数并进行下一轮的梯度计算，无需等待其他Worker。 优点：充分利用计算资源，避免木桶效应，在Worker之间传输代价较高时（如Geo-Distributed，广域网环境）尤其适用。 缺点： 模型参数不一致性：Worker可能基于过时的参数计算梯度，导致“梯度陈旧”问题。 收敛速度和准确度影响：陈旧梯度可能导致训练震荡，收敛速度变慢，甚至无法收敛到最优解，或导致最终模型准确度下降。 SSP (Staleness Synchronous Parallel) 有限程度的异步：\nSSP是BSP和ASP之间的一种折衷方案。它允许Worker使用略微过时的模型参数进行计算，但会限制这种“陈旧度（staleness）”在一定阈值之内。 如果某个Worker的参数版本落后超过预设的阈值，它会被暂停，直到参数版本追上为止。 优点：在提高训练速度的同时，通过限制陈旧度来缓解ASP的收敛问题，兼顾效率和准确性。 缺点：需要精心选择陈旧度阈值，过大的阈值会影响收敛，过小的阈值会重新引入部分同步开销。 异步性对训练速度与准确度的影响：\n训练速度：异步性越高（从BSP到ASP），Worker之间的等待时间越少，理论上训练速度越快，因为没有等待其他Worker的开销。 准确度/收敛性：异步性越高，模型参数的不一致性越大，训练过程中梯度可能越陈旧。这会导致： 收敛速度下降：模型可能需要更多的迭代才能收敛，甚至无法收敛到相同质量的解。 模型准确度下降：最终训练出的模型性能可能不如同步训练。 “训练越快，训练越慢！”：这句看似矛盾的话，深刻地揭示了异步训练的一个核心问题。虽然单步迭代可能更快（物理时间），但由于参数更新的混乱，模型可能需要更多的迭代才能达到相同的精度（迭代次数更多），或者无法达到同样高的精度，从有效收敛的角度看，反而“慢”了。","317-数据并行的优缺点#3.1.7 数据并行的优缺点":"优点： 实现简单：相对于模型并行，数据并行的实现和调试通常更直接。 加速训练：通过并行处理数据，可以显著减少单个Epoch的训练时间。 高效率：在计算密集型任务中，数据并行能够有效利用多设备资源。 缺点： 模型内存没有下降：每个GPU上都需要存放模型的完整副本。这意味着如果模型本身过大，单个GPU内存无法容纳，数据并行就无法直接使用。它主要用于加速计算任务，而非解决模型内存限制问题。 批次大小限制：虽然总的有效批次大小可以很大，但单个GPU上的迷你批次大小可能受限于可用内存，这会影响模型训练的稳定性或收敛性。 通讯开销：梯度的聚合（All-reduce）会引入可观的通信开销，尤其是在设备数量众多或网络带宽有限的情况下。 【“3.2 模型并行 (Model Parallelism)” 和 “3.3 管道并行 (Pipeline Parallelism, PP)“的学习笔记：】","32-模型并行-model-parallelism#3.2 模型并行 (Model Parallelism)":"模型并行 (Model Parallelism) 是一种分布式训练技术，其核心思想是将一个过大的模型在不同的计算设备（如GPU）之间进行切分，而不是像数据并行那样复制模型。它主要用于解决以下问题：\n核心原因 1：模型在一个计算设备上放不下。 随着深度学习模型规模的爆炸式增长（如GPT-3、Switch-C等），单个GPU的内存往往不足以容纳整个模型的参数、激活值、梯度和优化器状态。模型并行通过将模型拆分到多个设备上，使得每个设备只需存储模型的一部分，从而克服了单设备内存限制。 核心原因 2：在batch_size之外进一步切分计算粒度：hiddensize上切分的可能性。 除了数据（batch_size）维度上的并行，模型并行还可以在模型内部的维度（如隐藏层大小 hiddensize 或序列长度 sequence length）上进行切分，以实现更细粒度的并行化。 主要类型： 模型并行根据切分方式可以分为两种主要类型：\n层间切分 (Inter-layer Parallelism)：也被称为管道并行 (Pipeline Parallelism)。它将模型的不同层分配到不同的设备上。例如，GPU A处理模型的第1-3层，GPU B处理第4-6层，以此类推。 层内切分 (Intra-layer Parallelism)：也被称为张量并行 (Tensor Parallelism)。它在一个模型层内部进行切分，例如将一个大型矩阵乘法操作分解成多个较小的矩阵乘法，分别在不同的设备上执行。这在Transformer架构中对MLP和自注意力模块的矩阵运算尤为常见。","33-管道并行-pipeline-parallelism-pp#3.3 管道并行 (Pipeline Parallelism, PP)":"","331-定义与原理层间切分#3.3.1 定义与原理：层间切分":"管道并行 (Pipeline Parallelism, PP) 是一种模型并行策略，通过垂直切分模型（即按层切分），将模型的不同层或一组连续的层分配到不同的计算设备（通常是不同的GPU）上。\n原理：每个设备只负责模型的一部分层。数据（通常是mini-batch）在这些设备之间按顺序流动，如同流水线一样。当一个设备完成其负责层的计算后，将中间结果（激活值）传递给下一个设备。 目标： 减少模型内存占用：这是PP最直接的好处。与数据并行每个GPU都需要完整的模型副本不同，管道并行将模型拆分到不同的GPU/主机之间，显著减少了每个设备上的模型内存占用。 允许训练超大模型：使得内存无法容纳在单个设备上的巨大模型得以训练。","332-pp与dp的结合ppdp#3.3.2 PP与DP的结合：PP+DP":"管道并行（PP）和数据并行（DP）可以结合使用，形成一种混合并行策略（如GPipe等）。\nDP的内存占用：每个GPU上都要放置完整的模型副本，因此DP在“模型层面上”并不会降低内存占用。 PP的内存占用：模型被拆分到不同的GPU/主机之间，从而减少了每个设备的模型内存占用。 PP+DP：在DP的基础上，每个DP副本（即每个DP组）内部再使用PP来切分模型。这样，既能利用DP扩展到更大批次数据，又能利用PP承载更大的模型。这意味着对于每个DP副本，其内部的各个GPU之间会交换梯度更新信息。","333-pipeline概念与microbatch#3.3.3 Pipeline概念与Microbatch":"为了解决简单的层间切分可能导致的GPU空闲问题（当前设备计算完其部分后，需要等待下一设备完成计算才能继续反向传播），管道并行引入了微批次（Microbatch） 的概念和流水线调度机制。\nMicrobatch的定义与作用：\nMicrobatch 是比普通迷你批次（Mini-batch）更小的批处理运算块。 它将一个Mini-batch进一步拆分成若干个Microbatch。 作用：这些Microbatch分块进入模型管道，使得每个GPU可以同时处理不同Microbatch在不同阶段的计算。例如，当GPU 1处理Microbatch 1的前向传播时，GPU 0可能已经在处理Microbatch 2的前向传播，或者处理Microbatch 0的反向传播。这种方式提高了GPU的利用率，减少了空闲时间。 Batch size, Mini-batch size, Micro-batch size：\nBatch size：机器学习算法要求的一个完整批次的大小（例如，整个模型的有效训练批次大小可能是2048）。 Mini-batch size：通过数据并行（DP）后，每个模型副本分到的批处理大小（例如，如果DP=2，则mini-batch_size = 2048 / 2 = 1024）。 Micro-batch size：继续通过管道并行（PP）后，每个GPU设备在单个计算阶段实际运行的批处理大小（例如，如果mini-batch_size = 1024，PP切分了4个阶段，micro-batch_size = 1024 / 4 = 256）。 Stage number与Microbatch数量：\n我们把模型拆分的划分数量称为 stage number（K）。 Microbatch的数量（M）可以不等于 stage number，通常M会远大于K，以减少“气泡”（bubble）。 图片内容描述：原始文档中有一张“Pipeline in PP”示意图，展示了minibatch被拆分成microbatches，并在GPU之间以流水线方式处理的过程。图中清晰地描绘了不同GPU在不同时间点处理不同microbatch的前向传播（FP）和反向传播（BP）阶段。其中有一些“气泡（Bubble）”表示GPU的空闲时间。图示下方文字说明“层间通讯开销隐藏在计算开销之后”，并且“当网络状况极差时可能需要特别的并行调度设计”。 【若需查看原始图片详情，请参考原文中的“Pipeline in PP”示意图】","334-系统性能分析#3.3.4 系统性能分析":"管道并行虽然提高了GPU利用率，但仍存在其固有的性能开销。\nBubble时间（空闲时间比例）：\n定义：在管道并行中，由于设备间的依赖性（例如，一个设备必须等待前一个设备完成前向传播才能开始自己的前向传播，或者等待后一个设备完成反向传播才能开始自己的反向传播），会出现GPU空闲的时间段，这被称为“气泡”（Bubble）。 影响：Bubble越大，GPU的利用率越低，训练效率越差。 分析：理论上，气泡最长处近似于一个microbatch的前向传播（FP）和反向传播（BP）的时间之和。对于K个阶段和M个microbatch，Bubble time（idletime/idea time） 可以近似表示为 O(K−1M)O(\\frac{K-1}{M})O(MK−1​)。 优化：当K（阶段数）较小，M（microbatch数）足够大的时候，bubble time的比例会变得可以忽略不计。 权衡：然而，M过大（意味着micro-batch size = N/M太小）会导致GPU计算资源无法充分利用，因为小批次数据可能无法有效地填充GPU的计算单元。好的实践是选择能够刚好让加速设备计算满载的microbatch size。 Peak activation memory（峰值激活内存）：\n激活值是前向传播的中间结果，在反向传播时需要重新计算梯度。为了节省计算，通常会将激活值存储起来。 在管道并行中，峰值激活内存包括： 当前正在运行的microbatch的反向传播（BP）展开部分，其内存开销约为 O(L/K⋅N/M)O(L/K \\cdot N/M)O(L/K⋅N/M)，其中L是总层数，K是阶段数，N是minibatch size，M是microbatch数量。 其他microbatch尚未展开的部分，其内存开销约为 O(N)O(N)O(N)。","335-pipedream进阶的pipeline设计#3.3.5 PipeDream：进阶的Pipeline设计":"PipeDream 是一种更进一步的管道并行设计，其核心特点是在管道并行的层面上进行异步的更新，从而最大化GPU的利用率和运行时间。 这与传统的同步管道并行（如GPipe）有显著区别。\nPipeDream与GPipe的对比：\nGPipe (Google Pipeline)：所有microbatch在通过整个管道完成前向和反向传播后，才进行一次梯度更新（pipeline Flush）。这种同步更新确保了模型参数的一致性，但会引入较大的气泡。 PipeDream：每个microbatch完成其反向传播后就马上更新模型梯度，而不是等待整个minibatch所有microbatch都完成。这意味着没有“Flush”的情况，模型是异步更新的。例如，当microbatch #5进入管道时，它可能会使用已经被microbatch #1的梯度更新过的新模型参数。 Per stage调度策略：\nPipeDream每个stage计算哪个microbatch的前向传播（FP）还是反向传播（BP）的优先级由其当前活跃的microbatch决定。 存在一个最优的活跃microbatch数量：理想情况下，所有worker都正在处理所有的microbatch，这样刚好不浪费memory。 当管道达到稳态后，每个FP操作会为管道带来一个新的microbatch，而每个BP操作会从管道送走一个完成的microbatch。 如果所有worker都在忙，处理速度为 O(workers)O(\\text{workers})O(workers)。 最优工作microbatch数量：如果每个stage只有一个device工作，对于一个input stage来说，最优的工作microbatch数量等于 (# workers)。例如，stage 2的最优处理数量取决于它往后所有worker的处理能力。 1F1B调度模式 (One-Forward-One-Backward)：\nPipedream在各个stage进入稳态后，会采用1F1B调度模式。这意味着在释放一个microbatch（BP完成）后，会立即处理下一个microbatch（FP开始），以保持活跃microbatch数量为最优大小。 图片内容描述：原文提供了一个示例，展示了worker 3在等待3个microbatches的BP完成后，才接收下一个microbatch，以确保其运行中的microbatch数量不超过2。 【若需查看原始图片详情，请参考原文中的“Example：worker 3等到BP3个microbatches出去再接受一个，保证在运行的microbatch不超过2！”】 Weight Stashing：\n必要性：由于PipeDream每个microbatch会马上更新模型参数，而反向传播（BP）需要对应前向传播（FP）时的激活值和模型权重。为了解决这个问题，PipeDream需要“Weight Stashing”，即存储了每个microbatch在前向传播时所使用的模型参数副本。 代价：这会增加内存开销。 Vertical Sync：\n由于异步更新，不同microbatch在前向和反向传播过程中可能使用了不同版本的模型参数，这被称为模型版本不一致性。 Vertical Sync 旨在要求一个microbatch在不同阶段（stages）使用的是一个相同时间版本的模型。 实现：例如，通过n-bounded SSP（Staleness Synchronous Parallel）限制模型版本差异。 代价：这可能意味着更大的存储需求或引入额外的同步开销。 图片内容描述：原文中“5-FP在各个stage分别面对的是1、2、3、4BP之后的模型参数。使用vertical sync则一直使用1BP之后之后模型参数，但是意味着更大的存储需求。”展示了异步更新可能导致的不同模型版本使用情况，并说明了Vertical Sync如何通过牺牲存储来保持版本一致性。 【若需查看原始图片详情，请参考原文中的“PP上异步的更新方式”示意图】 PipeDream的优缺点：\n优势： 高效并行机制：相比于数据并行，通常具有更低的机间通讯量，因为它传输的是激活值而非梯度。 高GPU利用率：通过异步更新和流水线调度，最大化GPU的运行时间，减少气泡。 问题/缺点： 异步训练破坏训练语义：由于模型参数的异步更新，可能导致“梯度陈旧”问题，从而影响模型的收敛速度和最终准确性。这与数据并行中的ASP相似。","336-pipedream-flush#3.3.6 PipeDream-FLUSH":"PipeDream-FLUSH 是PipeDream的一个变种，旨在解决PipeDream的两个主要问题：\n问题1：Weight Stashing：PipeDream为每一个microbatch提供自己的Weight Stashing，增加了内存负担。 问题2：异步训练的准确性损失：异步更新可能导致模型收敛困难或准确度下降。 核心思想：PipeDream-FLUSH 采用了1F1B调度的FLUSH版本，即在一个minibatch的所有microbatch都通过管道完成FP和BP后，才进行一次梯度更新。 优点： 不需要Weight Stashing：因为模型参数在整个minibatch的反向传播完成后才更新，所以所有BP阶段都使用相同的模型版本，无需存储FP时的参数副本。 无需考虑model version：解决了异步更新导致的模型版本不一致问题，保证了训练语义的同步性。 节约内存：中间结果保存开销逐级下降，最多不超过stage数量（第一个stage），最少为1（最后一个stage）。而原始的Pipeline Parallelism（如GPipe）每个stage的中间结果都为 num_microbatch。Less micro-batch size -\u003e less peak memory consumption. Micro-batches no longer consume memory after BP, with more micro-batches, the number of active micro-batches in the pipeline decrease. 缺点： 不减少Bubbletime：PipeDream-FLUSH虽然解决了异步问题，但其本质上回到了同步更新，因此并没有减少GPipe那样的气泡时间，其Bubble time开销仍然是 O(K−1M)O(\\frac{K-1}{M})O(MK−1​)。 Bubbletime分析：看最后一个Device计算。其总时间为 M×(FP+BP)+(K−1)×FP+(K−1)×BPM \\times (FP + BP) + (K-1) \\times FP + (K-1) \\times BPM×(FP+BP)+(K−1)×FP+(K−1)×BP。 【若需查看原始图片详情，请参考原文中的“Bubbletime分析”公式】","337-1f1b-with-interleaved-stages#3.3.7 1F1B with interleaved stages":"针对管道并行中高额的Bubble time（有时甚至占比高达50%）的问题，1F1B with interleaved stages 被提出作为一种解决方案。\n问题回顾：\nPipeline FLUSH (如GPipe, PipeDream-FLUSH)：同步更新，确保准确性，但Bubble time占比非常大。 不做FLUSH (如PipeDream)：异步更新，训练效率高，但会影响收敛速度和模型准确性。 增加microbatch number：可以减少Bubble time，但可能导致GPU利用率下降（因为micro-batch size过小）。 解决方案：1F1B with interleaved stages 的核心思想是让每个设备负责多个逻辑阶段（stages）。\n原理：如果逻辑上的Stage数量（K）多于物理设备数量（GPUs），那么可以将多个Stage分配给同一个物理设备。例如，模型有8个逻辑Stage，但只有4个GPU，那么每个GPU将负责2个Stage。这样，一个microbatch会在同一个物理设备上反复运行多次，处理其负责的多个逻辑Stage。 图片内容描述：原文图示“Stage多于设备，每个设备负责多个stages，因此每个microbatch会反复跑各个设备多次。” 例如，FP逻辑上有8个stage，要在4个device上面循环两次。 【若需查看原始图片详情，请参考原文中的“1F1B with interleaved stages”示意图】 Bubble time分析：\n假设每个Device分配 vvv 个stage。 一个microbatch在一个设备上每次花费的时间为 (FP+BP)/v(FP + BP) / v(FP+BP)/v。 新的Bubble time 可以显著降低，约为 O(K−1vM)O(\\frac{K-1}{vM})O(vMK−1​)。相比于 O(K−1M)O(\\frac{K-1}{M})O(MK−1​) 减少了 vvv 倍。 【若需查看原始图片详情，请参考原文中的“Bubble time分析”公式】 优缺点：\n优点： 减少 vvv 倍的Bubble time：显著提高了GPU的利用率。 对GPU利用率影响不大：由于拆分的是串行运算序列，只要microbatch size设置得当，可以保持较高的GPU利用率。 缺点： 增加 vvv 倍的通讯开销：由于一个microbatch在同一个物理设备上可能需要多次进行stage间的输入输出，这会增加设备内部或设备之间的通讯频率和总量。 适用场景：当网络带宽大、而计算利用率不高时，采用此方案可以有效提升整体效率。 【“3.4 张量并行 (Tensor Parallelism, TP)\"、“4. 分布式大模型训练系统 - 2”、“4.1 序列并行 (Sequence Parallel, SP)\"、“4.2 3D并行 (PTD-P: PP + TP + DP)“的学习笔记：】","34-张量并行-tensor-parallelism-tp#3.4 张量并行 (Tensor Parallelism, TP)":"","341-定义与原理层内切分#3.4.1 定义与原理：层内切分":"定义： 张量并行（Tensor Parallelism, TP）是一种层内并行（Intra-layer Parallelism）的分布式训练策略。它的核心思想是对模型中的单个层（例如，Transformer模型中的线性层或自注意力模块）的权重张量进行切分，并将这些切分后的张量分布到不同的计算设备（如GPU）上进行计算。 与数据并行（DP）复制整个模型不同，也与管道并行（PP）按层切分模型不同，TP是在一个层的内部进行细粒度的并行化。\n原理： TP通过对模型权重矩阵进行分块，使得每个设备只负责计算部分矩阵乘法。由于张量并行需要在层内进行切分和计算，因此它通常需要非常频繁的设备间通信来聚合中间结果或同步梯度，这意味着它对网络连接的速度要求极高。目前主流的TP实现是专门针对Transformer架构优化的，主要应用于其核心组件：MLP（多层感知机）和自注意力模块。","342-mlp的张量并行#3.4.2 MLP的张量并行":"MLP层通常由两个线性变换（矩阵乘法）和一个非线性激活函数组成，例如 Y=G(XA1)A2Y = G(XA_1) A_2Y=G(XA1​)A2​。在TP中，我们可以选择不同的方式来切分这些矩阵。","3421-按行切分与按列切分#3.4.2.1 按行切分与按列切分":"假设一个矩阵 AAA 需要与输入 XXX 相乘。\n按列切分 (Column Parallel)：\n将矩阵 AAA 按列切分成 A1,A2,…,APA_1, A_2, \\dots, A_PA1​,A2​,…,AP​ (其中 PPP 是并行设备数量)，每个设备 iii 存储 AiA_iAi​。 每个设备 iii 计算 XAiXA_iXAi​。 所有设备的计算结果 XA1,XA2,…,XAPXA_1, XA_2, \\dots, XA_PXA1​,XA2​,…,XAP​ 可以直接拼接得到完整的 XAXAXA。 优点： 在第一个矩阵乘法 XA1XA_1XA1​ 后，可以分别对 XAiXA_iXAi​ 的结果应用非线性函数，而无需进行聚合通信。 在Transformer的MLP中： 通常第一个线性层会采用列并行，因为其输出 XA1XA_1XA1​ 往往会作为激活函数的输入，各部分的计算可以独立进行，最后再聚合。 对应图示（如原始资料中所示）： “按照列分，然后组合”。 按行切分 (Row Parallel)：\n将矩阵 AAA 按行切分成 A1,A2,…,APA_1, A_2, \\dots, A_PA1​,A2​,…,AP​，每个设备 iii 存储 AiA_iAi​。 输入 XXX 需要在所有设备上复制。 每个设备 iii 计算 XAiXA_iXAi​。 所有设备的计算结果 XA1,XA2,…,XAPXA_1, XA_2, \\dots, XA_PXA1​,XA2​,…,XAP​ 需要**进行聚合（通常是求和或Reduce操作）**才能得到完整的 XAXAXA。 优点： 减少了每个设备存储的参数量。 在Transformer的MLP中： 通常第二个线性层会采用行并行。由于其输入通常是前一个层（可能已经聚合或在每个设备上复制）的输出，并且需要聚合才能得到最终结果，所以需要进行Reduce操作。 对应图示（如原始资料中所示）： “按照行分，然后加和”。 在两层MLP中： 为了减少通信开销，一个常见的策略是：\n第一个矩阵乘法（例如，输入到隐层的转换）采用按列切分。 第二个矩阵乘法（例如，隐层到输出的转换）采用按行切分。 通过这种方式，可以在两个线性层之间巧妙地安排通信，使得只在关键点进行一次通信。","3422-forward与backward的通讯过程#3.4.2.2 Forward与Backward的通讯过程":"以一个简单的两层MLP为例 Z=NonLinear(XA)BZ = \\text{NonLinear}(XA)BZ=NonLinear(XA)B，其中 AAA 采用列并行， BBB 采用行并行。\nForward Pass (前向传播)：\n输入 XXX 的分发： 对于TP的第一层，输入 XXX 需要拷贝到所有Worker（GPU）上，以便每个Worker能够独立计算其负责的部分。 第一个矩阵乘法 (XAXAXA)： 假设 AAA 被列切分成 A1,A2,…,APA_1, A_2, \\dots, A_PA1​,A2​,…,AP​。 每个Worker iii 计算 Zi=XAiZ_i = XA_iZi​=XAi​。 此时，每个Worker iii 得到了 XAXAXA 的一部分。为了应用非线性函数，这些部分需要被组合起来。然而，如果非线性函数是元素级的（如ReLU），我们可以推迟聚合，让每个Worker先对自己本地的部分 ZiZ_iZi​ 应用非线性函数得到 NonLinear(Zi)\\text{NonLinear}(Z_i)NonLinear(Zi​)。 通讯（若有）： 通常这里会进行一次All-Gather来聚合所有 ZiZ_iZi​。但如果是非线性函数，有时可以直接进行下一步的计算，再考虑聚合。原始资料中提到 “g的forward：每个worker上的forward的计算完毕，取得Z1和Z2后，GPU间做一次all-reduce，相加结果产生Z”，这里假设的 ggg 是第二个线性层，而 fff 是第一个线性层。这暗示了两个线性层之间的通信模式。 第二个矩阵乘法 (ZBZBZB)： 假设 BBB 被行切分成 B1,B2,…,BPB_1, B_2, \\dots, B_PB1​,B2​,…,BP​。 每个Worker iii 计算 ZBiZ B_iZBi​。 由于 BBB 是按行切分的，每个Worker iii 存储 BiB_iBi​。为了得到完整的 ZBZBZB，每个Worker计算完 ZBiZB_iZBi​ 后，需要进行一次All-Reduce（求和操作），将所有Worker的 ZBiZB_iZBi​ 加起来，以得到完整的 ZBZBZB。这个聚合的结果会在所有Worker上可用。 Backward Pass (反向传播)：\n梯度 dZdZdZ 的分发： 反向传播开始时，梯度 dZdZdZ（来自后续层）会作为输入。 第二个矩阵乘法（BBB 的梯度计算）： 计算 dBdBdB（相对于 BBB 的梯度）和 dX′dX'dX′（传递给前一层的梯度）。 由于 BBB 是按行切分的，每个Worker只负责其本地 BiB_iBi​ 的梯度计算。对于传递给前一层的梯度，需要聚合。 通讯： 通常会进行一次All-Reduce来聚合所有Worker计算的梯度 dX′dX'dX′，确保每个Worker拥有完整的梯度，以便其计算第一层 AAA 的梯度。 第一个矩阵乘法（AAA 的梯度计算）： 计算 dAdAdA（相对于 AAA 的梯度）。 由于 AAA 是按列切分的，每个Worker只负责其本地 AiA_iAi​ 的梯度计算。 通讯（若有）： 对于传递给更前一层的梯度，同样可能需要All-Reduce。 总结： 当多个张量并行模块连接时，前向传播和反向传播中，通常涉及两次All-Reduce操作。例如，在一个Transformer层中，自注意力模块和MLP模块都会有各自的TP通信，通常整体包含Forward的两次All-Reduce和Backward的两次All-Reduce。","343-self-attention的张量并行#3.4.3 Self-Attention的张量并行":"自注意力机制也包含多个线性变换（用于计算Q、K、V），因此同样可以应用张量并行。\n基于不同注意力头 (K_i, Q_i, V_i) 的切分： 在自注意力机制中，通常有多个注意力头（Multi-Head Attention）。TP可以沿着注意力头的维度或隐藏维度进行切分。 例如，可以将Q、K、V矩阵按列切分，使得每个设备只负责计算部分注意力头的Q、K、V。 GEMMs (General Matrix Multiplications)： 这些切分操作最终都会归结为通用矩阵乘法，可以高效地并行执行。 输出Y的连续性： 自注意力模块的输出 YYY 通常是完整的子矩阵部分，这意味着它可以直接作为下一个模块（例如MLP的第一个线性层）的输入，并继续进行按行切分的张量并行，无需额外的通信。 通讯： 与MLP类似，自注意力模块的张量并行通常也需要总共两次All-Reduce操作（一次在前向，一次在反向）来聚合中间结果。","344-张量并行的优缺点#3.4.4 张量并行的优缺点":"优点：\n减少每个GPU所需的内存量： 由于模型权重被切分，每个GPU只需存储部分权重，从而显著降低了单个GPU的模型内存占用，使得训练超大模型成为可能。 GPU利用率保持较高 (无Bubble)： 与管道并行不同，张量并行通常不会引入“气泡时间”（bubble time），因为它是在层内部进行并行计算，且通信通常可以与计算重叠，因此GPU的利用率可以保持较高水平。 缺点：\n非常频繁的同步 (AllReduce)： 张量并行需要在层内进行多次All-Reduce操作来聚合中间结果或梯度。这意味着它对网络带宽和延迟要求极高。 高吞吐量的网络连接： 为了保持高吞吐量，需要极快的网络连接，例如NVLink或InfiniBand等高速互联技术，通常这限制了TP只能在单个节点内部或高速集群的“超节点”之间使用。如果网络带宽较低，频繁的通信会导致明显的性能瓶颈。","4-分布式大模型训练系统---2#4. 分布式大模型训练系统 - 2":"这个部分将深入探讨更高级和复合的分布式训练策略，以应对大模型训练中内存和计算效率的进一步挑战。","41-序列并行-sequence-parallel-sp#4.1 序列并行 (Sequence Parallel, SP)":"","411-激活内存开销问题#4.1.1 激活内存开销问题":"背景：\n管道并行 (PP) 的局限性： 即使使用了PP，每个Stage（尤其是靠前的Stage）仍然需要存储大量的前向传播 (FP) 临时结果（即激活值 Activation），以便在反向传播 (BP) 时进行梯度计算。这些激活值是内存消耗的大户。 PP切分过多： 虽然切分更多的PP Stage可以减少每个Stage的模型内存占用，但相对地，激活值的内存开销占比会变得更高，这成为新的内存瓶颈。 挑战： 如何进一步减少激活值的内存占用，尤其是在Transformer模型中？","412-tp与sp结合的提出#4.1.2 TP与SP结合的提出":"原始的张量并行 (TP) 方案通常只关注矩阵乘法本身的切分，而忽略了Transformer模型中其他重要的操作，如层归一化 (Layer Normalization, LayerNorm) 和 Dropout。\n原始TP的局限性： 在原始的TP中，这些操作通常并没有被拆分，而是在所有TP设备中重复进行计算和存储。虽然这些操作的计算量不大，但它们需要消耗大量的激活内存。 解决方案： 提出将层归一化和Dropout的计算和存储工作也在TP的设备之间进行分割，这就是序列并行 (Sequence Parallelism, SP) 的核心思想。","413-sp的原理层归一化与dropout的切分#4.1.3 SP的原理：层归一化与Dropout的切分":"核心观察 (Observation)：\n层归一化和Dropout的操作是独立的针对每个Token/样本进行的。这意味着对一个Token进行LayerNorm/Dropout不会影响其他Token的计算。 它们需要Token/样本的完整向量才能完成操作，而不是像矩阵乘法那样对特征维度进行分解。 核心思想 (Idea)： 既然LayerNorm/Dropout是针对每个Token独立的，我们可以利用这一点，在TP的机器之间引入SP，让每个TP设备只处理一部分Token的LayerNorm/Dropout操作。\n具体做法：拆解All-reduce操作 为了实现这种Token维度的并行，SP将TP中通常用于聚合的All-Reduce操作进行拆解和重新设计：\nForward Pass (前向传播)： 在TP计算之前，进行 Token-level Reduce-scatter (或类似操作) 将不同Token的数据分发到不同的TP设备上。 在TP计算之后，进行 All-gather 将所有TP设备的输出重新聚合，以便后续操作或输出。 Backward Pass (反向传播)： 在梯度计算之前，进行 All-gather。 在梯度计算之后，进行 Reduce-scatter 将梯度分发给负责不同Token的设备。 更具体的转换：\n原TP：All-Reduce in FP, no operation in BP. (这里可能是指TP的一种变体，或者强调其核心通信点) SP的引入： all-gather in the FP, and reduce-scatter in the BP. (一种实现方式，用于聚合输入或分发梯度) reduce-scatter in FP, and all-gather in BP. (另一种实现方式，用于分发输入或聚合梯度) 理解 g 聚合 token 的作用：\n原始资料中提到 g 负责收集所有的token，然后执行TP的子矩阵运算 和 g 负责在做reduce的时候，让每个TP的机器只拿去一部分tokens的reduce结果，然后进行各自独立的中间操作。这表明在TP+SP的组合中，可能存在一个“门控”或聚合/分发机制 g，它在FP阶段聚合所有Token以便进行TP的矩阵运算（因为矩阵运算需要整个特征维度），而在BP阶段只将一部分Token的Reduce结果分发给TP设备，以便各自独立处理。","414-tp--sp在mlp中的应用#4.1.4 TP + SP在MLP中的应用":"SP在Token维度上聚合/分割： 每个TP设备负责处理输入序列中一部分Token。 TP在特征维度上聚合/分割： 每个TP设备负责处理模型权重矩阵中一部分特征。 结合效果： 通过这种结合，可以同时在Token维度和特征维度上进行并行，进一步降低单个设备的内存负担。","415-activations-memory分析#4.1.5 Activations memory分析":"通过SP，可以将LayerNorm/Dropout等操作的激活值也分布到不同的TP设备上，从而显著减少每个设备存储的激活值总量。这意味着：\nTP解决模型权重本身的内存问题。 SP解决TP之外的、在每个设备上重复存储的激活值内存问题。 总结： SP是对TP的一种补充，它通过并行化LayerNorm和Dropout等操作来减少Transformer模型中的激活内存开销，使得在有限内存的设备上训练更大的模型成为可能。","42-3d并行-ptd-p-pp--tp--dp#4.2 3D并行 (PTD-P: PP + TP + DP)":"","421-引入更多并行策略的原因#4.2.1 引入更多并行策略的原因":"背景： 随着大模型规模的指数级增长，单一的并行策略往往会遇到瓶颈，无法满足训练需求。\n只使用DP (数据并行)： 优点： 擅长分割计算任务，理论上可以无限扩展，对模型本身内存占用无影响。 缺点： 不擅长分割模型以减少内存开销。每个GPU都需要存储完整的模型副本，当模型过大时，单卡内存会成为瓶颈。 只使用TP (张量并行)： 优点： 擅长分割模型/计算，可以显著降低单个GPU的模型内存占用。 缺点： 需要非常大量的设备间通信开销（频繁的All-Reduce），在低带宽或高延迟的网络环境下会导致明显的性能瓶颈。通常限制在高速互联的节点内部。 只使用PP (管道并行)： 优点： 擅长分割模型/计算，可以显著降低单个GPU的模型内存占用。 缺点： 存在“气泡时间” (bubble time)，导致GPU利用率降低，并行效率稍弱。 结论： 单一并行方式的扩展能力存在上限，受限于不同的维度（如 batch_size, hidden_size, layer_size）。\n3D并行的提出： 将数据并行 (DP)、张量并行 (TP) 和 管道并行 (PP) 结合起来，可以独立扩展每个维度的并行度，从而在训练上百或上千个GPU的超大模型时实现更灵活、更强的可扩展性。","422-3d并行组合示例#4.2.2 3D并行组合示例":"3D并行可以根据具体的模型、集群资源和训练需求，灵活地组合DP、TP和PP的并行度。\nDP=2, TP=2, PP=2： 假设有8个GPU，可以分成2个DP组，每个DP组有4个GPU，这4个GPU又分成2个TP组，每个TP组的2个GPU再进行2层的PP。 DP=4, TP=4, PP=4： 这代表了极高的并行度，通常需要大规模的GPU集群。 DP=4, TP=2, PP=4 或 DP=2, TP=4, PP=4： 这些都是不同的组合方式，用于在特定场景下优化性能。 关键问题： 如何确定在给定GPU数量下，各个并行策略的程度是多少？这通常需要复杂的搜索和优化。","423-通讯开销分析#4.2.3 通讯开销分析":"在3D并行中，通信开销是性能的关键影响因素，需要对PP和TP的通信量进行量化分析。 假设：\nMMM: microbatch size（微批次大小） SSS: sequence length（序列长度） hhh: embedding/activation size（嵌入/激活维度） PTPP_{TP}PTP​: TP并行度（TP replicas数量） PPPP_{PP}PPP​: PP并行度（PP stages数量） 管道并行 (PP) 通讯：\n对于每对连续的设备（在PP流水线中相邻的Stage），在前向传播和反向传播中，每次Microbatch传输的通信量大约为 M⋅S⋅hM \\cdot S \\cdot hM⋅S⋅h。 这个通信量是传输激活值（中间结果）。 计算： 每对连续设备每次微批次的前向+反向通信量为 2×(M⋅S⋅h)2 \\times (M \\cdot S \\cdot h)2×(M⋅S⋅h)。 特点： PP的通信量主要取决于输入/输出的激活值大小，相对较少。 张量并行 (TP) 通讯：\n在TP中，涉及模型参数或梯度的All-Reduce操作。 对于每个Transformer层，需要对大小为 M⋅S⋅hM \\cdot S \\cdot hM⋅S⋅h 的张量在 PTPP_{TP}PTP​ 个模型副本（TP组内的设备）之间进行两次All-Reduce操作（一次在前向，一次在反向）。 每次All-Reduce的通信量大约是 2×(M⋅S⋅h)×PTP−1PTP2 \\times (M \\cdot S \\cdot h) \\times \\frac{P_{TP}-1}{P_{TP}}2×(M⋅S⋅h)×PTP​PTP​−1​ (这通常被简化为 2×(M⋅S⋅h)2 \\times (M \\cdot S \\cdot h)2×(M⋅S⋅h)，因为All-Reduce的理论最优通信量是 2×data_size×N−1N2 \\times \\text{data\\_size} \\times \\frac{N-1}{N}2×data_size×NN−1​ 或 2×data_size2 \\times \\text{data\\_size}2×data_size ）。 在一个层中，前向和反向各两次All-Reduce，总共是 4×2×(M⋅S⋅h)4 \\times 2 \\times (M \\cdot S \\cdot h)4×2×(M⋅S⋅h)。 计算： 每个Microbatch在每个TP组内的每个设备，每个层，总通信量约为 8⋅M⋅S⋅h⋅PTP−1PTP8 \\cdot M \\cdot S \\cdot h \\cdot \\frac{P_{TP}-1}{P_{TP}}8⋅M⋅S⋅h⋅PTP​PTP​−1​。 影响： 如果一个设备负责 kkk 层模型（例如在PP中一个Stage负责多层），那么TP的通信量将增加 kkk 倍。而PP的通信量则不受 kkk 的影响（因为只发生在Stage之间）。 总结：\nTP的通信量通常远大于PP，且对 PTPP_{TP}PTP​ 敏感。 PP的通信量相对较小，但会引入气泡时间。","424-各并行策略在3d并行中的作用#4.2.4 各并行策略在3D并行中的作用":"TP + PP 的核心作用： 它们主要用于切分模型本身，以使模型能够被装载到有限内存的设备上，并允许训练得以正常进行。 DP 的核心作用： 在TP+PP已经切分好模型的基础上，DP可以不断增加模型副本（在DP组之间），从而扩展到更大规模的分布式训练上，提高整体吞吐量。DP并不直接降低单卡模型内存，但其通信效率相对较高。 GPU利用率与并行细粒度：\nGPU本身是大规模并行计算设备。 如果分布式切分做得过于细致，导致 microbatch size 过低，即使可以降低气泡时间（如PP优化），也可能导致GPU利用率不足。这是因为过小的 microbatch 无法充分填充GPU的计算单元，导致计算效率下降。 因此，在实际应用中，需要在内存节省、通信开销和GPU利用率之间找到一个最佳平衡点。","43-全切片数据并行-fully-sharded-data-parallel-fsdp--zero#4.3 全切片数据并行 (Fully Sharded Data Parallel, FSDP / ZeRO)":"","431-引入背景现有并行策略的局限性#4.3.1 引入背景：现有并行策略的局限性":"在处理大规模模型训练时，传统的并行策略会遇到各自的局限性：\n管道并行 (Pipeline Parallelism, PP)：虽然能有效切分模型以减少单个设备的内存占用，但其存在“bubble”问题（即部分GPU空闲时间），降低了计算效率。 张量并行 (Tensor Parallelism, TP)：擅长在层内切分模型，但需要非常大量的设备间通讯开销。在低带宽（如跨节点）的网络条件下，这会导致明显的传输延迟，因此通常仅适用于高速连接的计算设备之间（如单机内的NVLink）。 数据并行 (Data Parallelism, DP)：通讯量相对适中，并且可以通过按层传输等技术隐藏大量传输开销，不存在PP的“bubble”问题。然而，DP的缺点在于每个设备都需要存放完整的模型副本，这导致存储资源大量重复，无法有效减少单个模型副本所需的内存。当模型参数巨大时，即使是DP也可能因模型本身无法放入单个设备内存而失效。 因此，需要一种新的并行策略，它既能像DP一样高效利用计算资源，又能像模型并行一样分担模型的内存占用。","432-zero-zero-redundancy-optimizer-核心思想#4.3.2 ZeRO (Zero Redundancy Optimizer) 核心思想":"ZeRO（零冗余优化器）是一种旨在消除数据并行中内存冗余的优化技术，其核心思想是让DP的各个副本之间也能均摊模型状态的内存负担。它通过**“按需收集，迅速分发 (On-demand gather, immediate scatter)”的策略实现。 具体而言，每个设备只保存一部分参数、梯度或优化器状态**。当需要进行计算（如前向或反向传播）时，设备会按需从其他设备收集所需的完整部分；一旦计算完成，便立即丢弃这些临时收集到的数据，只保留自己负责的“切片（slice）”，并将计算结果（如梯度）分发给负责保存对应参数的设备。","433-训练内存开销分析model-states与residual-states#4.3.3 训练内存开销分析：Model states与Residual states":"在大模型训练中，所需的内存远大于模型参数本身的大小。内存开销主要分为两大部分：\nModel states（模型状态）： 模型参数 (Model Parameters)：即模型权重。 模型梯度 (Model Gradients)：反向传播计算出的参数更新方向。 优化器参数 (Optimizer Parameters)：例如，Adam优化器需要存储动量（momentum）和方差（variance）两个状态，通常各占用与模型参数相同大小的内存。 Residual states（残余状态）： 中间激活值 (Intermediate Activations)：前向传播过程中每一层输出的激活值，在反向传播时需要重新计算或存储。 临时缓存 (Temporary Buffers)：各种临时计算和存储所需空间。 未使用的内存片段 (Unused Memory Fragments)：内存碎片等。 混合精度训练下的内存占用：\n假设模型参数有NNN个值。 模型参数和梯度通常以FP16（半精度浮点数）保存，各占2N2N2N字节。 优化器参数是内存占用的大头：Adam优化器需要存储FP32（单精度浮点数）的模型参数副本（4N4N4N字节），以及FP32的动量（momentum, 4N4N4N字节）和方差（variance, 4N4N4N字节）。 总计：2N2N2N (FP16参数) + 2N2N2N (FP16梯度) + 4N4N4N (FP32参数副本) + 4N4N4N (动量) + 4N4N4N (方差) = 16N16N16N 字节（原始资料中提到的是12N12N12N字节，可能是忽略了FP16参数本身，但核心在于优化器状态占据了绝大部分）。 例如，一个15亿参数的GPT-2模型，即使参数本身仅需要3GB（FP16），也无法在32GB内存的单个GPU上训练，因为优化器状态等会迅速耗尽内存。","434-zero的partition类型与阶段#4.3.4 ZeRO的Partition类型与阶段":"ZeRO根据模型状态切分的程度，分为三个阶段（ZeRO-1, ZeRO-2, ZeRO-3）：\nZeRO-1: Optimizer State Partitioning 切分内容：只切分优化器状态（如Adam的动量和方差）。 通信模式： 前向：无额外通信。 反向：通过Reduce-Scatter操作分发梯度到负责对应优化器状态的设备。 参数更新后：通过All-Gather将更新后的参数分发给所有设备。 ZeRO-2: Optimizer State Partitioning + Gradient Partitioning 切分内容：切分优化器状态和梯度。 通信模式： 前向：无额外通信。 反向：按需逐层Reduce-Scatter分发梯度给负责的设备。 参数更新后：通过All-Gather将更新后的参数分发给所有设备。 ZeRO-3: Optimizer State Partitioning + Gradient Partitioning + Parameter Partitioning 切分内容：切分优化器状态、梯度和模型参数。这是最激进的切分策略，也是FSDP的基础。 通信模式： 前向：按需All-Gather收集参数到当前GPU进行计算，计算完成后即丢弃非本设备负责的参数。 反向：按需逐层All-Gather收集参数，按需逐层Reduce-Scatter分发梯度给负责的设备。 参数更新后：无额外通信，因为每个设备只更新自己负责的参数切片，无需再分发。","435-zero-3详细示例#4.3.5 ZeRO-3详细示例":"假设一个线性层权重矩阵 WWW 是 1024×40961024 \\times 40961024×4096，在4个GPU上进行ZeRO-3分配。\n每个GPU只保存 WWW 的一个切片 (slice)：\nGPU0: W[:,0:1024]W[:, 0:1024]W[:,0:1024] GPU1: W[:,1024:2048]W[:, 1024:2048]W[:,1024:2048] GPU2: W[:,2048:3072]W[:, 2048:3072]W[:,2048:3072] GPU3: W[:,3072:4096]W[:, 3072:4096]W[:,3072:4096] 前向计算时：\n每个GPU先进行All-Gather操作，临时从其他GPU收集它们负责的切片，从而在本地得到完整的 WWW 矩阵 (1024×40961024 \\times 40961024×4096)。 使用完整的 WWW 进行计算。 完成计算后，丢弃临时组合的完整 WWW，只保留自己负责的 WWW 切片。 反向计算时：\n每个GPU再次进行All-Gather操作，临时在本地得到完整的 WWW 矩阵。 完成反向传播计算。 每个GPU只保留自己负责的梯度切片。对于非自己负责的梯度切片，通过Reduce-Scatter操作发送给对应的GPU。 梯度更新：\n每个GPU只更新自己负责的参数切片。","436-内存下降效果#4.3.6 内存下降效果":"ZeRO-3带来的内存下降是惊人的。通过将模型参数、梯度和优化器状态全部进行切分，每个GPU的内存占用显著降低，从而使得训练超大模型成为可能。","437-zero的额外通讯开销分析#4.3.7 ZeRO的额外通讯开销分析":"自然地，将模型状态切分到不同副本之间必然会导致更多的通信。然而，ZeRO的设计目标是尽量将这些通信开销隐藏或最小化。\n数据并行的通讯开销回顾：\n传统数据并行中，在每个minibatch的梯度计算完成后，会使用AllReduce操作将不同GPU上的梯度聚合并分发。 AllReduce通常通过Reduce-Scatter + All-Gather实现（如Ring AllReduce）。 对于模型大小为 NNN 的参数，其通信开销通常为 2N/B~2N/B 2N/B（BBB 为带宽）。 ZeRO-1与ZeRO-2的通讯开销：\n对于每一个层的梯度，ZeRO-1和ZeRO-2会使用Scatter-Reduce从所有模型副本处聚合各切片的梯度到对应的本地副本（开销 N/B~N/B N/B）。 随后，在梯度收集、更新模型并分发时，会使用All-Gather将更新后的参数收集到每一个模型副本上（开销 N/B~N/B N/B）。 可见，ZeRO-1和ZeRO-2的传输开销本质上是原始AllReduce的分阶段完成，与原始DP的传输开销近似。ZeRO-2进一步将这些操作均摊到整个训练的各层反向传播中，逐层按需完成。 ZeRO-3的通讯开销：\n由于模型参数也被切分，前向和反向传播过程都需要从其他副本All-Gather拉取模型参数。每次All-Gather一个完整模型参数的开销为 N/B~N/B N/B。由于“按需收集，迅速分发”原则，FP完成后即丢弃非本设备参数，BP时需要再次All-Gather。因此，All-Gather整个模型两次，开销 2N/B~2N/B 2N/B。 反向传播结束时，需要Scatter-Reduce整个模型梯度一次，开销 N/B~N/B N/B。 总开销约为 3N/B3N/B3N/B。 因此，ZeRO-3的总通信时间开销约为原始DP的1.5倍。这是一个可以接受的开销，尤其是在内存限制是主要瓶颈时。","438-superlinearity#4.3.8 Superlinearity":"通过ZeRO，每个GPU释放出大量的内存。这些内存可以被用来增加Batch Size。在很多情况下，Batch Size越大，计算利用率越高，这可以带来**Superlinearity（超线性）**的性能提升，即系统性能的提升超过了硬件资源的线性叠加。","439-zero与模型并行的关系对比#4.3.9 ZeRO与模型并行的关系对比":"ZeRO和模型并行（MP）虽然都涉及将模型状态分布式存储在不同GPU上，但它们的核心侧重点和数据流动方式有所不同：\n模型并行：通常是“模型不动，数据动”。即模型被固定地切分到不同设备上，数据（或激活值）在设备之间流动。 ZeRO：更像是“数据不动，模型动”。即数据并行中，每个设备处理独立的数据子集，但为了减少冗余，模型的各个部分在需要时才被“召唤”到特定设备，使用完后即“送走”。 更高效的部分：\n模型可以提前移动 (Pipeline)：在计算N−1N-1N−1层的输出时，可以提前传输NNN层的模型参数，为NNN层的计算做准备。 PP必须等待数据：管道并行（PP）必须等到N−1N-1N−1层的计算完成，将计算结果（激活值）发送给NNN层的设备后，才能进行后续计算。 传输量对比：PP的传输量通常是层间中间结果（激活值），而ZeRO的传输量是模型大小。激活值的大小可能小于或大于模型参数大小，具体优劣需结合模型、训练算法、GPU性能和网络拓扑具体考量。在实践中需要进行性能测试来选择。 与张量并行的结合：\n张量并行（TP）和ZeRO切分的是不同维度：TP通常切分隐藏层维度（hidden_size），而ZeRO主要切分Batch Size维度上的模型冗余。 在有限的Batch Size（如2048）下，两者结合可以获得更大的并行能力，从而扩展到成千上万个GPU上进行训练（例如，TP与FSDP结合）。 3D并行 + ZeRO：\n在TP组内可以继续使用FSDP（ZeRO-3）进行数据并行，即每个GPU只保存张量的一个切片。 前向/反向传播在TP组内部使用3D并行的传输（TP、PP），同时在DP副本之间使用FSDP的All-Gather / Scatter-Reduce来收集和分发参数和梯度。这种组合能够最大化并行度，应对极端规模的模型训练。 【若需查看原始图片详情，请参考原文中的“3D并行+Zero”示意图】","44-混合专家模型-mixture-of-experts-moe#4.4 混合专家模型 (Mixture of Experts, MOE)":"","441-定义与核心思想稀疏模型架构#4.4.1 定义与核心思想：稀疏模型架构":"混合专家模型（MoE）是一种稀疏模型架构，旨在进一步增加大模型的规模，同时控制计算成本。其核心思想是：\n将一个大模型拆分成多个独立的小型模型，称为专家 (expert)。 在每次运行一个输入（如一个Token或一个Batch）时，只有部分的模型参数参与工作。 通过这种方式，在维持模型巨大容量的同时，实际激活的计算量保持在可控范围，从而达到节省计算资源的效果。","442-switchtransformer中的moe应用-ffn#4.4.2 SwitchTransformer中的MoE应用 (FFN)":"在许多MoE模型中，例如Google的SwitchTransformer，MoE层通常被应用于前馈网络 (Feed-Forward Network, FFN) 部分。\nTransformer模型中的FFN层是计算密集型部分，将其替换为MoE层可以显著增加模型容量，同时通过稀疏激活控制计算量。 【若需查看原始图片详情，请参考原文中的“SwitchTransformer: MOE in FFN”示意图】","443-门的计算与专家选择#4.4.3 门的计算与专家选择":"MoE模型引入了一个可训练的门 (gate) 机制，以确保稀疏性并根据输入动态选择专家：\n门的计算：对于给定的输入 xxx，门会类似于分类过程，为不同的专家分配不同的概率或分数。这通常通过一个小型的前馈网络加上Softmax函数实现。 专家选择：门会根据这些分数，选择前 kkk 个得分最高的专家来处理当前的输入。通常 kkk 值很小（例如 k=1k=1k=1 或 k=2k=2k=2）。 结果组合：选定的专家独立地对输入进行处理。最终的输出是这些选定专家的输出的加权和，权重通常就是门计算出的专家分数。","444-专家并行中的all-to-all通讯#4.4.4 专家并行中的All-to-all通讯":"当MoE模型进行分布式训练时，通常会采用专家并行 (Expert Parallelism) 策略。这意味着不同的专家被放置在不同的设备上。在这种设置下：\n通信需求：每个输入需要被路由到其被选中的专家所在的设备。而每个设备可能需要处理来自不同输入的Tokens，这些Tokens被路由到其本地的专家。 All-to-all通信：这种路由过程通常通过All-to-all集合通信操作来实现。 在前向传播 (FP) 时，通常有两次All-to-all通信：一次将Tokens路由到它们选定的专家，另一次将专家处理后的结果路由回原始Tokens的设备。 在反向传播 (BP) 时，也有两次All-to-all通信，处理梯度流的路由。 总共四次All-to-all通信：每个MoE层在FP和BP时各发生两次All-to-all通信，用于传输Tokens及其梯度。","445-load-balancing-loss#4.4.5 Load Balancing Loss":"在MoE模型中，一个常见的问题是负载不均衡：某些专家可能被过度选择，而另一些专家则很少被使用（“starving experts”）。这导致资源浪费和训练效率下降。为了解决这个问题，通常会在损失函数中增加一个负载均衡损失 (Load Balancing Loss) 项。\n原理：该损失项旨在鼓励门机制将Tokens均匀地分配给所有专家，防止少数专家过度活跃。 计算方式： Load Balancing Loss=∑i=1NFreq(i)⋅Prob(i)\\text{Load Balancing Loss} = \\sum_{i=1}^{N} \\text{Freq}(i) \\cdot \\text{Prob}(i)Load Balancing Loss=∑i=1N​Freq(i)⋅Prob(i) 其中，Freq(i)\\text{Freq}(i)Freq(i) 是专家 iii 被选中的频率（或“出头鸟”的次数，代表其被分配到的Tokens数量），Prob(i)\\text{Prob}(i)Prob(i) 是门函数给专家 iii 的平均概率值。 通过最小化这个损失，模型会倾向于让所有专家被选中的概率相似，并且每个专家处理的Tokens数量也相对均匀。 效果：降低损失的结果是让所有专家都“不做出头鸟”，最终达到负载均衡。这有助于提高所有专家的利用率，并稳定训练过程。 稀疏程度与训练时间：MoE模型的目标是实现高稀疏度，即在每次计算时激活最少的专家。虽然计算量减少了，但由于复杂的通信（All-to-all）和负载均衡问题，MoE模型的训练时间仍然可能面临挑战。","45-并行的自动化搜索#4.5 并行的自动化搜索":"","451-挑战搜索空间与硬件考量#4.5.1 挑战：搜索空间与硬件考量":"在实际的大模型训练中，面对多种并行策略（数据并行DP、管道并行PP、张量并行TP、序列并行SP、混合专家模型MoE等）及其组合，如何选择最优的并行策略是一个巨大的挑战。\n组合爆炸的搜索空间：即使是相对简单的3D并行（DP+TP+PP），当面对多达24个GPU时，其并行度（例如，DP×TP×PP=24DP \\times TP \\times PP = 24DP×TP×PP=24）就有多种组合，如 2×4×32 \\times 4 \\times 32×4×3、 2×2×62 \\times 2 \\times 62×2×6、 1×1×241 \\times 1 \\times 241×1×24 或 2×1×122 \\times 1 \\times 122×1×12 等。每种组合又可能对应不同的放置策略，使得搜索空间呈组合爆炸式增长。 硬件异构性与网络拓扑：最优的并行策略不仅取决于模型结构，还与具体的硬件环境（如GPU型号、内存大小）以及网络拓扑结构（如NVLink直连、InfiniBand交换机、以太网）紧密相关。例如，张量并行需要极快的网络连接，通常适用于单机内GPU间的NVLink连接，而跨机通信则更倾向于数据并行或管道并行。因此，在选择并行策略时，需要同时考虑网络拓扑和计算设备的能力。 试错成本高昂：在数百或数千个GPU的规模上，手动尝试不同的并行化策略是极其缓慢和昂贵的。每次实验都需要耗费大量计算资源和时间。 鉴于这些挑战，研究人员提出了一个核心问题：我们能否自动执行给定模型和集群的并行化过程？ 这促使了自动化并行策略搜索技术的发展。","452-alpa自动化inter-和intra-operator并行#4.5.2 Alpa：自动化Inter-和Intra-Operator并行":"Alpa是一个旨在自动化Inter-Operator（操作符间）并行和Intra-Operator（操作符内）并行以实现分布式深度学习的系统。\nInter-Operator Parallelism (操作符间并行)：主要指管道并行 (PP)，即将模型的不同层（或一组操作符）放置在不同的设备上，形成一个流水线。 Intra-Operator Parallelism (操作符内并行)：主要指张量并行 (TP) 和数据并行 (DP)，即将单个操作符（如矩阵乘法）或其内部的数据进行切分，分布到多个设备上并行计算。 Alpa的工作原理和特点：\n多样化的策略选择和并行方式：Alpa能够综合考虑多种并行策略，并根据模型的特性和硬件资源进行选择和组合。 网络拓扑决定Device Placement：Alpa会分析网络拓扑结构，以智能地决定设备（GPU）的放置策略，例如哪些GPU应该组成一个张量并行组，哪些应该用于数据并行，从而最小化通信开销。 API层次搜索：Alpa通过在API层进行抽象和搜索，避免了直接在低级代码层面操作，从而大大简化了并行策略的表示和搜索过程。 规划方法进行搜索：Alpa采用了一种分阶段的规划方法 (planning method) 来解决复杂的并行搜索问题： Inter-op Pass (操作符间通行)：这个阶段主要搜索管道并行 (PP) 策略。它关注如何将模型层间进行切分并放置到不同的设备或设备组上。通过设备放置（Device Placement）的决策，确定PP的拓扑结构。 【若需查看原始图片详情，请参考原文中的“Inter-op pass: Device placement”示意图】：该图展示了Inter-op pass如何将模型（如一个Transformer block）划分为多个阶段，并分配给不同的设备或设备组。 Intra-op Pass (操作符内通行)：在确定了Inter-op并行策略后，这个阶段在每个设备组内部搜索张量并行 (TP) 和数据并行 (DP) 策略。它关注如何将单个操作符（如矩阵乘法）或Batch数据在设备组内部进行切分。 Cost Function (成本函数)：在Intra-op pass中，Alpa会使用一个成本函数来评估不同TP/DP策略的性能（例如，通信开销、计算时间、内存占用）。通过最小化这个成本函数，Alpa能找到给定设备组内的最优Intra-op并行策略。 示例：Wide-ResNet Partition on 16 GPUs Alpa通过其自动化并行化能力，能够有效地为复杂的模型（如Wide-ResNet）在特定数量的GPU（如16个）上找到高效的并行策略。\n【若需查看原始图片详情，请参考原文中的“Example: Wide-ResNet Partition on 16 GPUs”和“Automatic Parallelization with Alpa”示意图】：这些图示展示了Alpa如何为Wide-ResNet模型在16个GPU上进行自动化的并行切分和设备放置，包括结合Inter-op和Intra-op并行，以达到最佳性能。这种可视化有助于理解自动化并行策略是如何在实际模型中应用的。 通过这种分层和自动化的方式，Alpa极大地降低了分布式训练中并行策略选择的复杂性，使得开发者能够更高效地训练大规模深度学习模型。"},"title":"分布式MLSYS"},"/notes/learn/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/":{"data":{"":"","1-智能计算系统基础概述#1 智能计算系统基础概述":"","11-概念层次关系#1.1 概念层次关系":"在智能计算领域，人工智能 (AI)、机器学习 (ML)、神经网络 (NN) 和 深度学习 (DL) 之间存在着清晰的层次结构和包含关系。这种关系可以理解为一个由广到深、由抽象到具体的演进过程。\n人工智能 (AI)：是最大的概念，是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新的技术科学。其目标是使机器能够像人一样思考、学习、理解和解决问题。人工智能包含多个子领域，如智能代理与规划、知识表示与推理等，而机器学习是其重要的一个分支。\n机器学习 (ML)：是实现人工智能的一种核心方法。它允许计算机系统通过数据而非显式编程来学习，从而识别模式、做出决策或预测。机器学习涉及各种算法，如线性回归、逻辑回归、支持向量机、决策树等，这些算法旨在通过数据训练出模型，使其能够从经验中“学习”并改进性能。\n神经网络 (NN)：是机器学习领域中的一个重要模型类别，灵感来源于人脑的神经元结构。它由相互连接的节点（或称神经元）组成，这些节点分层排列，通过权重和激活函数处理信息。神经网络是深度学习的基础。\n深度学习 (DL)：是机器学习的一个子领域，它特指使用包含多个隐藏层（即“深度”）的神经网络进行学习的方法。深度学习模型的特点是能够自动从原始数据中学习和提取多层次的、抽象的特征表示，从而在图像识别、语音处理和自然语言处理等复杂任务中取得了突破性进展。","12-典型机器学习过程#1.2 典型机器学习过程":"机器学习的定义： 机器学习是通过数据和机器学习方法，对数据内在规律（假设）进行优化与验证，从而获得对数据/任务模式最为准确的函数建模。这意味着机器通过分析大量数据，自主发现数据中的模式和规律，并构建一个能够解释或预测这些规律的模型。\n典型机器学习过程图示描述：\n训练数据 (Training Data)：这是机器学习过程的起点，是带有已知输入和输出对的数据集，用于训练模型。 机器学习方法 (Machine Learning Method)：选择合适的算法（如线性回归、决策树、神经网络等），这些算法将根据训练数据学习模式。 模型/函数 (Model/Function)：通过机器学习方法在训练数据上学习得到的结果，它是一个能够捕获数据内在规律的数学表达式或结构。 新数据 (New Data)：当模型训练完成后，会引入模型从未见过的新数据。 预测值 (Prediction)：模型利用学习到的函数对新数据进行处理，生成预测结果。 示例：认识天鹅 这个过程可以用“认识天鹅”的例子来形象说明：\n训练数据：给机器看大量的图片，其中一些是天鹅的图片（标注为“天鹅”），另一些不是（标注为“不是天鹅”）。这些图片是数据，图片上的特征（如颜色、形状、大小、行为等）是输入，图片是否为天鹅是输出（标签）。 机器学习方法：采用一个分类算法（例如，神经网络），让算法分析这些图片中的像素信息和标签。 模型/函数：算法通过学习，建立起一个“天鹅识别”模型，这个模型能够根据图片的特征来判断它是否是天鹅。 新数据：给模型一张它以前没看过的图片。 预测值：模型会根据其学习到的规律，给出这张图片是“天鹅”或“不是天鹅”的预测结果。","2-线性回归#2 线性回归":"","21-问题引入与概念#2.1 问题引入与概念":"","211-房屋销售预测案例#2.1.1 房屋销售预测案例":"在现实世界的许多场景中，我们常常需要根据已知的信息来预测某个数值。一个典型的例子是房屋销售价格预测。假设一个房屋销售中心拥有大量的历史交易数据，这些数据包含了房屋的各种属性（如面积、楼层、朝向等）以及对应的最终销售价格。\n特征 (Features)：影响房屋价格的属性。 例如，x1x_1x1​表示房屋面积（单位可能为平方米）。 例如，x2x_2x2​表示房屋楼层。 标签/目标 (Label/Target)：我们希望预测的数值。 例如，yyy表示房屋售价（单位可能为万元）。 面对这样的数据，我们的核心问题是：如何设计一个“回归程序”来预测新房屋的售价？","212-寻找特征与售价关系#2.1.2 寻找特征与售价关系":"为了预测新房屋的售价，我们不能仅仅依靠销售记录中已有的数据。例如，如果销售记录中没有面积为 65 平方米的房屋，那么我们如何预测一间 65 平方米的房屋的售价yyy呢？\n解决这个问题的关键在于：寻找特征 x1x_1x1​ (房屋面积) 和售价yyy之间的内在关系。这个关系一旦被“学习”或“发现”，我们就可以用它来对任何给定面积的房屋进行售价预测。线性回归就是一种用于发现这种数值型特征与数值型目标之间线性关系的方法。","22-线性回归模型#2.2 线性回归模型":"线性回归旨在找到一个最佳的直线（或超平面），能够“拟合”给定数据集中的点，从而揭示这些点背后的规律。","221-单变量线性回归模型-一元回归模型#2.2.1 单变量线性回归模型 (一元回归模型)":"当只有一个特征（例如，只有房屋面积xxx）来预测目标（售价yyy）时，我们称之为单变量线性回归或一元回归模型。\n核心思想：我们假设xxx和yyy之间存在一个近似的线性关系，可以用一条直线来表示。 模型假设函数 (Hypothesis Function)： Hw(x)=w0+wxH_w(x) = w_0 + wxHw​(x)=w0​+wx xxx：表示特征 (Feature)，即自变量（如房屋面积）。 Hw(x)H_w(x)Hw​(x)：表示假设 (Hypothesis)，是模型对给定xxx的预测值。 w0w_0w0​和www：表示模型的参数 (Parameters)，也称为权重或系数。 w0w_0w0​是截距 (Intercept)，表示当x=0x=0x=0时的预测值。 www是斜率 (Slope)，表示xxx每增加一个单位，Hw(x)H_w(x)Hw​(x)的变化量。 目标：通过训练数据找到最佳的w0w_0w0​和www，使得这条直线能够最好地代表数据点的分布规律。","222-多变量线性回归模型#2.2.2 多变量线性回归模型":"在实际问题中，影响目标变量的特征往往不止一个。例如，房屋售价yyy不仅受面积x1x_1x1​影响，还可能受楼层x2x_2x2​、朝向x3x_3x3​等多个特征xnx_nxn​的影响。\n模型假设函数 (多特征)： Hw(x)=w0+w1x1+w2x2+⋯+wnxnH_w(x) = w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_nHw​(x)=w0​+w1​x1​+w2​x2​+⋯+wn​xn​ x1,x2,…,xnx_1, x_2, \\dots, x_nx1​,x2​,…,xn​：表示nnn个不同的特征。 w0,w1,…,wnw_0, w_1, \\dots, w_nw0​,w1​,…,wn​：是模型对应的参数。 向量化表示 (更简洁)： 为了方便计算和表示，我们通常使用向量形式来表达多变量线性回归模型。 定义参数向量：w^=[w0;w1;… ;wn]\\hat{\\mathbf{w}} = [w_0; w_1; \\dots; w_n]w^=[w0​;w1​;…;wn​] 定义特征向量（在特征前添加一个常数x0=1x_0=1x0​=1用于与w0w_0w0​相乘）：x=[x0;x1;… ;xn]\\mathbf{x} = [x_0; x_1; \\dots; x_n]x=[x0​;x1​;…;xn​]，其中x0=1x_0=1x0​=1。 则模型假设函数可以写为：Hw(x)=w^TxH_w(\\mathbf{x}) = \\hat{\\mathbf{w}}^T \\mathbf{x}Hw​(x)=w^Tx 意义：不同的权重w^\\hat{\\mathbf{w}}w^向量意味着不同的模型假设，反映了各个特征对目标变量影响的强度和方向。","23-损失函数均方误差-mse#2.3 损失函数：均方误差 (MSE)":"为了衡量我们拟合的线性函数（即模型）与实际数据点之间的契合程度，我们需要一个损失函数 (Loss Function)。损失函数越小，说明模型的预测越接近真实值，拟合效果越好。","231-定义与目标#2.3.1 定义与目标":"对于线性回归，最常用的损失函数是均方误差 (Mean Squared Error, MSE)。\n数据表示：我们有一组观测数据，包含mmm个样本。每个样本iii由其特征值x(i)\\mathbf{x}^{(i)}x(i)和对应的真实目标值y(i)y^{(i)}y(i)组成。 对于单变量：{(x(1),y(1)),(x(2),y(2)),…,(x(m),y(m))}\\{ (\\mathbf{x}^{(1)}, y^{(1)}), (\\mathbf{x}^{(2)}, y^{(2)}), \\dots, (\\mathbf{x}^{(m)}, y^{(m)}) \\}{(x(1),y(1)),(x(2),y(2)),…,(x(m),y(m))} 对于多变量：x(i)=(xi1;xi2;… ;xid)\\mathbf{x}^{(i)} = (x_{i1}; x_{i2}; \\dots; x_{id})x(i)=(xi1​;xi2​;…;xid​)，其中ddd是特征的数量，yi∈Ry_i \\in \\mathbb{R}yi​∈R。 均方误差定义 (针对单变量模型)： MSE(ω0,ω)=1m∑i=1m(y(i)−(ω0+ωx(i)))2MSE(\\omega_0, \\omega) = \\frac{1}{m} \\sum_{i=1}^{m} (y^{(i)} - (\\omega_0 + \\omega x^{(i)}))^2MSE(ω0​,ω)=m1​∑i=1m​(y(i)−(ω0​+ωx(i)))2 其中y(i)y^{(i)}y(i)是第iii个样本的真实值，(ω0+ωx(i))(\\omega_0 + \\omega x^{(i)})(ω0​+ωx(i))是模型对第iii个样本的预测值Hw(x(i))H_w(x^{(i)})Hw​(x(i)). 均方误差定义 (针对多变量模型)： L(w^)=12∑j=1m(Hw(x(j))−y(j))2=12∑j=1m(w^Tx(j)−y(j))2L(\\hat{\\mathbf{w}}) = \\frac{1}{2} \\sum_{j=1}^{m} (H_w(\\mathbf{x}^{(j)}) - y^{(j)})^2 = \\frac{1}{2} \\sum_{j=1}^{m} (\\hat{\\mathbf{w}}^T \\mathbf{x}^{(j)} - y^{(j)})^2L(w^)=21​∑j=1m​(Hw​(x(j))−y(j))2=21​∑j=1m​(w^Tx(j)−y(j))2 这里的12\\frac{1}{2}21​是为了求导时方便，不影响最小化结果。 目标：通过最小化这个损失函数L(w^)L(\\hat{\\mathbf{w}})L(w^)，来找到最优的参数w^\\hat{\\mathbf{w}}w^，使得模型的预测值尽可能接近实际值。这能使模型更好地拟合数据，提高预测的准确性。","232-误差与权重修正#2.3.2 误差与权重修正":"误差 (ϵ\\epsilonϵ)：模型预测值y^\\hat{y}y^​与真实值yyy之间的差异，即ϵ=y−y^=y−w^Tx\\epsilon = y - \\hat{y} = y - \\hat{\\mathbf{w}}^T \\mathbf{x}ϵ=y−y^​=y−w^Tx。 修正机制：机器学习的核心思想就是通过不断修正模型的权重向量w^\\hat{\\mathbf{w}}w^，以使这种误差ϵ\\epsilonϵ尽可能地减小。这个修正过程就是模型的训练过程。","24-线性回归的求解方法#2.4 线性回归的求解方法":"找到了衡量模型好坏的损失函数后，下一步就是找到能够使损失函数最小化的参数w^\\hat{\\mathbf{w}}w^。","241-解析解-正规方程#2.4.1 解析解 (正规方程)":"对于均方误差 (MSE) 这种形式的损失函数，由于它是关于参数的二次函数，我们可以通过微积分的方法直接求解其最小值。\n方法原理： 对损失函数L(w^)L(\\hat{\\mathbf{w}})L(w^)关于每个参数wjw_jwj​求偏导数。 将所有偏导数组成的梯度向量设为零向量。 解这个线性方程组，得到的参数值即为最优解。 正规方程 (Normal Equation)： 通过上述过程，可以直接得到参数w^\\hat{\\mathbf{w}}w^的解析表达式： w∗=(XTX)−1XTy\\mathbf{w}^* = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}w∗=(XTX)−1XTy X\\mathbf{X}X：被称为设计矩阵 (Design Matrix)，它的每一行代表一个训练样本的特征向量（包括x0=1x_0=1x0​=1）。 y\\mathbf{y}y：是所有训练样本真实目标值组成的列向量。 (XTX)−1(\\mathbf{X}^T \\mathbf{X})^{-1}(XTX)−1：是矩阵XTX\\mathbf{X}^T \\mathbf{X}XTX的逆。 特点与优势： 闭式解 (Closed-form Solution)：可以直接通过一次计算（矩阵运算）得到全局最优解，无需迭代过程。 全局最优：对于均方误差，解析解保证找到的是全局最小值。 局限性： 计算成本：当特征数量nnn非常大时（例如几十万甚至上百万），计算(XTX)−1(\\mathbf{X}^T \\mathbf{X})^{-1}(XTX)−1的逆矩阵的计算成本非常高（通常为O(n3)O(n^3)O(n3)），这使得解析解在大规模数据集上变得不可行。 矩阵可逆性：要求矩阵XTX\\mathbf{X}^T \\mathbf{X}XTX必须可逆。如果不可逆（例如特征之间存在高度相关性或样本数量小于特征数量），则需要使用伪逆。 除了解析解，线性回归也可以通过梯度下降法或牛顿法等迭代优化方法求解，这些方法将在后续章节中详细介绍。","25-线性假设的偏差与局限性#2.5 线性假设的偏差与局限性":"尽管线性回归模型简洁且易于理解，但它也有其固有的局限性。\n模型假设：线性回归模型最核心的假设是：特征xxx与标签yyy之间存在线性关系，即y=w^Tx+by = \\hat{\\mathbf{w}}^T \\mathbf{x} + by=w^Tx+b。 局限性：当真实世界的数据模式过于复杂，是非线性的时，线性回归模型就无法准确捕捉这些复杂的非线性关系。 后果：在这种情况下，即使找到了最优的线性拟合，模型也会产生明显的系统性误差 (Systematic Error)，这被称为高偏差 (High Bias)。这意味着模型过于简化，未能充分学习数据中的真实模式，导致拟合不足 (Underfitting)。例如，如果数据点呈现出抛物线或S形曲线的趋势，用一条直线去拟合将始终存在很大的偏差。","3-逻辑回归#3 逻辑回归":"","31-线性分类概念#3.1 线性分类概念":"在某些机器学习任务中，我们的目标不是预测一个连续的数值（如房屋价格），而是将输入数据分到不同的类别中，这被称为分类问题 (Classification Problem)。","311-直线超平面分割#3.1.1 直线/超平面分割":"最简单的线性分类方法是尝试找到一个线性边界来区分不同的类别。\n二维空间示例：\n考虑二维空间中的数据点，每个点由特征x=(x1,x2)x = (x_1, x_2)x=(x1​,x2​)表示。 我们可以定义一个线性方程：wTx=w1x1+w2x2=0w^T x = w_1x_1 + w_2x_2 = 0wTx=w1​x1​+w2​x2​=0。 这条直线wTx=0w^T x = 0wTx=0能够将二维平面分割成两个区域：wTx\u003e0w^T x \u003e 0wTx\u003e0和wTx\u003c0w^T x \u003c 0wTx\u003c0。 我们可以将属于不同区域的点分到不同的类别。例如，如果一个点的wTx\u003e0w^T x \u003e 0wTx\u003e0，则将其分类为类别 A；如果wTx\u003c0w^T x \u003c 0wTx\u003c0，则分类为类别 B。 向量w=(w1,w2)w = (w_1, w_2)w=(w1​,w2​)决定了这条分割线的方向，而截距项（如果包含的话）决定了其位置。 高维空间（n维）：\n在nnn维空间中，线性方程wTx=0w^T x = 0wTx=0定义的是一个超平面 (Hyperplane)。 这个超平面将nnn维空间分割成两个半空间：wTx\u003e0w^T x \u003e 0wTx\u003e0和wTx\u003c0w^T x \u003c 0wTx\u003c0。 通过超平面，我们可以实现对高维数据的线性分类。","312-线性分类中损失函数的挑战#3.1.2 线性分类中损失函数的挑战":"对于线性分类问题，直接尝试将线性回归的均方误差 (MSE) 损失函数应用于分类标签（例如，标签为 1 和 -1）时，会遇到一些问题：\n标签的意义：在分类问题中，我们希望区分类别，而不是精确预测一个数值。MSE 衡量的是预测值与真实值之间的“距离”，这在分类任务中不一定是最合适的度量。 不可导函数：一种直观的分类损失是 0/1 损失（预测正确得 0 分，错误得 1 分）。然而，0/1 损失函数在很多点上是不可导的，这使得基于梯度的优化方法（如梯度下降法）难以应用。 对离群点的敏感性：如果使用 MSE，模型对远离决策边界的、被错误分类的点会非常敏感，会付出很大的“代价”，从而可能导致模型整体性能下降。 因此，研究者们倾向于采用近似的、可导的、并且能够用概率来解释的平滑损失函数来替代 0/1 损失。","32-逻辑回归#3.2 逻辑回归":"逻辑回归 (Logistic Regression) 是一种广泛使用的、用于解决二分类问题的统计模型。尽管名字中带有“回归”，它实际上是一个分类算法。","321-从线性回归到逻辑回归的引入#3.2.1 从线性回归到逻辑回归的引入":"线性回归模型直接输出一个连续的数值，这不适合表示类别概率（概率值应在 [0, 1] 之间）。逻辑回归通过引入一个激活函数来解决这个问题。\n局限性：线性回归在处理非线性可分数据时表现不佳；其输出是连续值，难以直接解释为分类概率。 改进思路：将线性模型的输出通过一个函数映射到(0,1)(0, 1)(0,1)的区间，这个输出可以被解释为样本属于某个特定类别的概率。","322-sigmoid-函数及其特性#3.2.2 Sigmoid 函数及其特性":"Sigmoid 函数（也称为 Logistic 函数）是逻辑回归中常用的激活函数。\n数学形式： σ(z)=11+e−z\\sigma(z) = \\frac{1}{1 + e^{-z}}σ(z)=1+e−z1​\n其中zzz通常是线性组合的结果，即z=wTx+bz = \\mathbf{w}^T \\mathbf{x} + bz=wTx+b(或w^Tx\\hat{\\mathbf{w}}^T \\mathbf{x}w^Tx，如果包含截距项)。 可视化中的良好特性：\n类似于阶跃函数：当zzz变化时，σ(z)\\sigma(z)σ(z)会迅速从接近 0 变化到接近 1。这使得它能够有效地将输入区分开。 对离群值的影响较小：相比于直接使用线性模型的输出，Sigmoid 函数将较大的正数映射到接近 1，将较大的负数映射到接近 0，一定程度上“压缩”了输出范围，使其对离群点的敏感性降低。 连续的：Sigmoid 函数处处可导，方便使用梯度下降等基于梯度的优化方法进行模型训练。 输出范围：其输出始终在(0,1)(0, 1)(0,1)之间，非常适合表示概率。","323-逻辑回归模型形式#3.2.3 逻辑回归模型形式":"逻辑回归模型将原始特征的线性组合z=wTx+bz = \\mathbf{w}^T \\mathbf{x} + bz=wTx+b通过 Sigmoid 函数进行转换，得到样本属于正类（类别 1）的概率。\n模型输出： P(y=1∣x;w,b)=σ(wTx+b)=11+e−(wTx+b)P(y=1 | \\mathbf{x}; \\mathbf{w}, b) = \\sigma(\\mathbf{w}^T \\mathbf{x} + b) = \\frac{1}{1 + e^{-(\\mathbf{w}^T \\mathbf{x} + b)}}P(y=1∣x;w,b)=σ(wTx+b)=1+e−(wTx+b)1​ 这意味着，给定输入特征x\\mathbf{x}x，模型预测该样本属于类别 1 的概率是P(y=1∣… )P(y=1|\\dots)P(y=1∣…)。 同理，属于类别 0（或 -1，取决于标签定义）的概率是： P(y=0∣x;w,b)=1−P(y=1∣x;w,b)=1−σ(wTx+b)=σ(−(wTx+b))P(y=0 | \\mathbf{x}; \\mathbf{w}, b) = 1 - P(y=1 | \\mathbf{x}; \\mathbf{w}, b) = 1 - \\sigma(\\mathbf{w}^T \\mathbf{x} + b) = \\sigma(-(\\mathbf{w}^T \\mathbf{x} + b))P(y=0∣x;w,b)=1−P(y=1∣x;w,b)=1−σ(wTx+b)=σ(−(wTx+b)) 决策规则：通常，如果P(y=1∣… )\u003e0.5P(y=1|\\dots) \u003e 0.5P(y=1∣…)\u003e0.5，则将样本分类为类别 1；否则，分类为类别 0。","33-损失函数交叉熵损失-cross-entropy-loss#3.3 损失函数：交叉熵损失 (Cross-Entropy Loss)":"为了训练逻辑回归模型，我们需要选择一个合适的损失函数。对于逻辑回归，交叉熵损失 (Cross-Entropy Loss) 是最常用的选择。","331-定义#3.3.1 定义":"交叉熵损失衡量的是模型预测的概率分布与真实的概率分布之间的差异。对于一个二分类问题，假设有mmm个样本，标签yyy只能是 0 或 1。\n交叉熵损失函数： L(w,b)=−1m∑i=1m[y(i)log⁡(y^(i))+(1−y(i))log⁡(1−y^(i))]L(\\mathbf{w}, b) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]L(w,b)=−m1​∑i=1m​[y(i)log(y^​(i))+(1−y(i))log(1−y^​(i))] 其中： y(i)y^{(i)}y(i)是第iii个样本的真实标签 (0 或 1)。 y^(i)=P(y=1∣x(i);w,b)=σ(wTx(i)+b)\\hat{y}^{(i)} = P(y=1 | \\mathbf{x}^{(i)}; \\mathbf{w}, b) = \\sigma(\\mathbf{w}^T \\mathbf{x}^{(i)} + b)y^​(i)=P(y=1∣x(i);w,b)=σ(wTx(i)+b)是模型预测的第iii个样本属于类别 1 的概率。 1−y^(i)1 - \\hat{y}^{(i)}1−y^​(i)是模型预测的第iii个样本属于类别 0 的概率。 直观解释： 如果y(i)=1y^{(i)} = 1y(i)=1，损失变为−log⁡(y^(i))-\\log(\\hat{y}^{(i)})−log(y^​(i))。为了最小化损失，y^(i)\\hat{y}^{(i)}y^​(i)需要接近 1。 如果y(i)=0y^{(i)} = 0y(i)=0，损失变为−log⁡(1−y^(i))-\\log(1 - \\hat{y}^{(i)})−log(1−y^​(i))。为了最小化损失，y^(i)\\hat{y}^{(i)}y^​(i)需要接近 0（即1−y^(i)1 - \\hat{y}^{(i)}1−y^​(i)需要接近 1）。","332-与最大似然估计-mle-的关系#3.3.2 与最大似然估计 (MLE) 的关系":"交叉熵损失函数与最大似然估计 (Maximum Likelihood Estimation, MLE) 密切相关。\n似然函数：假设我们有一组训练数据{(x(i),y(i))}i=1m\\{(\\mathbf{x}^{(i)}, y^{(i)})\\}_{i=1}^m{(x(i),y(i))}i=1m​。给定模型参数w\\mathbf{w}w和bbb，我们希望找到一组参数，使得观测到的训练数据的似然函数最大化。\n对于二分类问题，似然函数可以写为： L(w,b)=∏i=1mP(y(i)∣x(i);w,b)L(\\mathbf{w}, b) = \\prod_{i=1}^{m} P(y^{(i)} | \\mathbf{x}^{(i)}; \\mathbf{w}, b)L(w,b)=∏i=1m​P(y(i)∣x(i);w,b) 根据模型定义，P(y(i)∣x(i);w,b)P(y^{(i)} | \\mathbf{x}^{(i)}; \\mathbf{w}, b)P(y(i)∣x(i);w,b)可以写成y^(i)\\hat{y}^{(i)}y^​(i)(如果y(i)=1y^{(i)}=1y(i)=1) 或1−y^(i)1-\\hat{y}^{(i)}1−y^​(i)(如果y(i)=0y^{(i)}=0y(i)=0)。 更统一地，我们可以写成：P(y(i)∣x(i);w,b)=(y^(i))y(i)(1−y^(i))1−y(i)P(y^{(i)} | \\mathbf{x}^{(i)}; \\mathbf{w}, b) = (\\hat{y}^{(i)})^{y^{(i)}} (1 - \\hat{y}^{(i)})^{1 - y^{(i)}}P(y(i)∣x(i);w,b)=(y^​(i))y(i)(1−y^​(i))1−y(i) 则似然函数为：L(w,b)=∏i=1m(y^(i))y(i)(1−y^(i))1−y(i)L(\\mathbf{w}, b) = \\prod_{i=1}^{m} (\\hat{y}^{(i)})^{y^{(i)}} (1 - \\hat{y}^{(i)})^{1 - y^{(i)}}L(w,b)=∏i=1m​(y^​(i))y(i)(1−y^​(i))1−y(i) 最大化似然等价于最小化负对数似然： 由于直接最大化连乘形式的似然函数在计算上很困难（容易溢出，且求导复杂），我们通常取其对数（对数函数是单调递增的，最大化对数似然等价于最大化似然），并将其变为最小化问题。\n对数似然：log⁡L(w,b)=∑i=1m[y(i)log⁡(y^(i))+(1−y(i))log⁡(1−y^(i))]\\log L(\\mathbf{w}, b) = \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]logL(w,b)=∑i=1m​[y(i)log(y^​(i))+(1−y(i))log(1−y^​(i))] 最小化负对数似然： −log⁡L(w,b)=−∑i=1m[y(i)log⁡(y^(i))+(1−y(i))log⁡(1−y^(i))]-\\log L(\\mathbf{w}, b) = -\\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]−logL(w,b)=−∑i=1m​[y(i)log(y^​(i))+(1−y(i))log(1−y^​(i))] 如果我们再取平均值（除以mmm），就得到了我们之前定义的交叉熵损失函数！ Cross-Entropy Loss=−1m∑i=1m[y(i)log⁡(y^(i))+(1−y(i))log⁡(1−y^(i))]\\text{Cross-Entropy Loss} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]Cross-Entropy Loss=−m1​∑i=1m​[y(i)log(y^​(i))+(1−y(i))log(1−y^​(i))] 因此，最小化逻辑回归的交叉熵损失函数，本质上就是通过最大似然估计来寻找最能拟合训练数据的模型参数。","34-逻辑回归的求解#3.4 逻辑回归的求解":"","341-非解析解特性#3.4.1 非解析解特性":"与线性回归可以通过正规方程（解析解）直接求解参数不同，逻辑回归的损失函数（交叉熵损失）在经过 Sigmoid 函数转换后，其关于参数w\\mathbf{w}w和bbb的表达式是非线性的。\n尝试求解：如果我们尝试直接对交叉熵损失函数求导并令导数为零，会得到一个非线性超越方程。 结果：这类方程通常没有简单的解析解（闭式解），意味着我们无法像线性回归那样通过一步矩阵运算直接得到最优参数。 因此，求解逻辑回归模型参数（即找到使交叉熵损失最小化的w\\mathbf{w}w和bbb）需要依赖迭代优化方法，最常见的是梯度下降法 (Gradient Descent) 及其变体。","35-分类问题的激活函数选择#3.5 分类问题的激活函数选择":"在神经网络的语境下，激活函数的作用是在线性组合的输出后引入非线性，从而增强模型的表达能力。对于分类问题，输出层的激活函数选择尤为重要，它决定了模型的输出形式。","351-sigmoid-函数-二分类#3.5.1 Sigmoid 函数 (二分类)":"用途：当处理二分类问题时，Sigmoid 函数是输出层常用的激活函数。 输出：将线性组合的输出zzz映射到(0,1)(0, 1)(0,1)区间，表示样本属于正类 (类别 1) 的概率。","352-softmax-函数-多分类#3.5.2 Softmax 函数 (多分类)":"用途：当处理多分类问题（即类别数量大于 2）时，Softmax 函数是输出层常用的激活函数。 输出：对于一个KKK类的分类问题，Softmax 函数将一个KKK维的向量（通常是线性组合的输出）转换为一个概率分布。输出的每个元素表示样本属于对应类别的概率，所有输出元素的和为 1。 假设线性组合的输出为z=(z1,z2,…,zK)z = (z_1, z_2, \\dots, z_K)z=(z1​,z2​,…,zK​)。 Softmax 函数的输出y^i\\hat{y}_iy^​i​（表示属于类别iii的概率）为： y^i=Softmax(z)i=ezi∑j=1Kezj\\hat{y}_i = \\text{Softmax}(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}y^​i​=Softmax(z)i​=∑j=1K​ezj​ezi​​ ∑i=1Ky^i=1\\sum_{i=1}^{K} \\hat{y}_i = 1∑i=1K​y^​i​=1 注意：在神经网络中，隐含层通常使用 Sigmoid、ReLU 等激活函数来引入非线性，而输出层的激活函数选择则取决于具体的任务（回归、二分类、多分类）。\n【“2.4 神经网络训练方法”的学习笔记已生成】","4-神经网络训练方法#4 神经网络训练方法":"神经网络的训练核心目标是调整模型参数（权重W\\mathbf{W}W和偏置b\\mathbf{b}b），使得模型的输出y^\\hat{\\mathbf{y}}y^​尽可能地逼近真实值y\\mathbf{y}y。这个过程通常通过最小化一个损失函数L(W)L(\\mathbf{W})L(W)来实现，该损失函数衡量了模型预测值与真实值之间的差异。","41-参数寻优迭代法-梯度下降法#4.1 参数寻优：迭代法 (梯度下降法)":"","411-原理与更新公式#4.1.1 原理与更新公式":"梯度下降法 (Gradient Descent, GD) 是一种最常用的迭代优化算法，用于寻找损失函数最小值的参数。\n核心原理：\n损失函数L(W)L(\\mathbf{W})L(W)是关于模型参数W\\mathbf{W}W的一个函数。 负梯度方向是损失函数下降最快的方向。 因此，通过沿着损失函数负梯度的方向更新参数，可以逐步减小损失函数的值，直到达到局部最小值（或全局最小值）。 更新公式： W←W−η∂L(W)∂W\\mathbf{W} \\leftarrow \\mathbf{W} - \\eta \\frac{\\partial L(\\mathbf{W})}{\\partial \\mathbf{W}}W←W−η∂W∂L(W)​\nW\\mathbf{W}W：表示模型参数（可以是单个权重，也可以是权重向量或矩阵）。 η\\etaη(eta)：称为学习率 (Learning Rate) 或步长 (Step Size)。它控制了每次参数更新的幅度。 如果η\\etaη过大，可能导致参数更新过快，跳过最小值点，甚至发散。 如果η\\etaη过小，会导致收敛速度过慢，训练时间过长。 ∂L(W)∂W\\frac{\\partial L(\\mathbf{W})}{\\partial \\mathbf{W}}∂W∂L(W)​：表示损失函数L(W)L(\\mathbf{W})L(W)关于参数W\\mathbf{W}W的梯度 (Gradient)。梯度是一个向量，其每个分量是损失函数对相应参数的偏导数。 迭代过程：\n初始化参数：随机或使用特定策略（如全零向量）初始化模型参数W\\mathbf{W}W。 计算梯度：在当前参数W\\mathbf{W}W处，计算损失函数L(W)L(\\mathbf{W})L(W)对所有参数的梯度。 更新参数：按照上述更新公式，沿着梯度的负方向调整参数。 重复：重复步骤 2 和 3，直到损失函数收敛（变化非常小）或达到预设的最大迭代次数。","412-梯度下降的可视化与示例#4.1.2 梯度下降的可视化与示例":"概念可视化： 想象损失函数C(x1,x2)C(x_1, x_2)C(x1​,x2​)是一个三维曲面（一个碗状），我们要找到碗底的最低点。\n当前点：我们站在曲面上的某个位置(x1,x2)(x_1, x_2)(x1​,x2​)。 梯度：梯度向量指向曲面上坡度最陡峭的方向。 负梯度：负梯度向量指向曲面下降最陡峭的方向。 更新：每次迭代，我们沿着负梯度方向走一小步（步长由学习率控制），从而逐步接近最低点。 数学示例：\n目标函数：f(x1,x2)=x12+3x22+x1x2f(x_1, x_2) = x_1^2 + 3x_2^2 + x_1x_2f(x1​,x2​)=x12​+3x22​+x1​x2​ 初始点：(x1,x2)=(3,3)(x_1, x_2) = (3, 3)(x1​,x2​)=(3,3) 学习率：η=0.2\\eta = 0.2η=0.2 解答过程：\n计算梯度： ∇f(x1,x2)=(∂f∂x1,∂f∂x2)=(2x1+x2,x1+6x2)\\nabla f(x_1, x_2) = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\right) = (2x_1 + x_2, x_1 + 6x_2)∇f(x1​,x2​)=(∂x1​∂f​,∂x2​∂f​)=(2x1​+x2​,x1​+6x2​)\n第 1 轮迭代：\n当前点：(x1,x2)=(3,3)(x_1, x_2) = (3, 3)(x1​,x2​)=(3,3) 梯度：∇f(3,3)=(2×3+3,3+6×3)=(9,21)\\nabla f(3, 3) = (2 \\times 3 + 3, 3 + 6 \\times 3) = (9, 21)∇f(3,3)=(2×3+3,3+6×3)=(9,21) 更新： (x1,x2)←(3,3)−0.2×(9,21)(x_1, x_2) \\leftarrow (3, 3) - 0.2 \\times (9, 21)(x1​,x2​)←(3,3)−0.2×(9,21) (x1,x2)←(3−1.8,3−4.2)=(1.2,−1.2)(x_1, x_2) \\leftarrow (3 - 1.8, 3 - 4.2) = (1.2, -1.2)(x1​,x2​)←(3−1.8,3−4.2)=(1.2,−1.2) 第 2 轮迭代：\n当前点：(x1,x2)=(1.2,−1.2)(x_1, x_2) = (1.2, -1.2)(x1​,x2​)=(1.2,−1.2) 梯度：∇f(1.2,−1.2)=(2×1.2+(−1.2),1.2+6×(−1.2))=(2.4−1.2,1.2−7.2)=(1.2,−6)\\nabla f(1.2, -1.2) = (2 \\times 1.2 + (-1.2), 1.2 + 6 \\times (-1.2)) = (2.4 - 1.2, 1.2 - 7.2) = (1.2, -6)∇f(1.2,−1.2)=(2×1.2+(−1.2),1.2+6×(−1.2))=(2.4−1.2,1.2−7.2)=(1.2,−6) 更新： (x1,x2)←(1.2,−1.2)−0.2×(1.2,−6)(x_1, x_2) \\leftarrow (1.2, -1.2) - 0.2 \\times (1.2, -6)(x1​,x2​)←(1.2,−1.2)−0.2×(1.2,−6) (x1,x2)←(1.2−0.24,−1.2−(−1.2))=(0.96,0)(x_1, x_2) \\leftarrow (1.2 - 0.24, -1.2 - (-1.2)) = (0.96, 0)(x1​,x2​)←(1.2−0.24,−1.2−(−1.2))=(0.96,0) 第 3 轮迭代：\n当前点：(x1,x2)=(0.96,0)(x_1, x_2) = (0.96, 0)(x1​,x2​)=(0.96,0) 梯度：∇f(0.96,0)=(2×0.96+0,0.96+6×0)=(1.92,0.96)\\nabla f(0.96, 0) = (2 \\times 0.96 + 0, 0.96 + 6 \\times 0) = (1.92, 0.96)∇f(0.96,0)=(2×0.96+0,0.96+6×0)=(1.92,0.96) 更新： (x1,x2)←(0.96,0)−0.2×(1.92,0.96)(x_1, x_2) \\leftarrow (0.96, 0) - 0.2 \\times (1.92, 0.96)(x1​,x2​)←(0.96,0)−0.2×(1.92,0.96) (x1,x2)←(0.96−0.384,0−0.192)=(0.576,−0.192)(x_1, x_2) \\leftarrow (0.96 - 0.384, 0 - 0.192) = (0.576, -0.192)(x1​,x2​)←(0.96−0.384,0−0.192)=(0.576,−0.192) 经过三次迭代，参数(x1,x2)(x_1, x_2)(x1​,x2​)的值更新为(0.576,−0.192)(0.576, -0.192)(0.576,−0.192)。 【若需查看原始图片详情，请参考原文中的“GD可视化”等高线图，它展示了迭代路径如何逐步接近最小值点。】","42-梯度下降算法的变体#4.2 梯度下降算法的变体":"机器学习模型的损失函数通常具有以下形式： L=1N∑if(xi,yi,w)L = \\frac{1}{N} \\sum_{i} f(x_i, y_i, \\mathbf{w})L=N1​∑i​f(xi​,yi​,w) 其中NNN是训练样本的总数，fff是单个样本的损失贡献。","421-批量梯度下降-batch-gradient-descent-bgd#4.2.1 批量梯度下降 (Batch Gradient Descent, BGD)":"原理：在每次参数更新时，BGD 会计算所有训练样本的梯度，然后根据这些梯度的平均值来更新参数。 wt+1=wt−η×∇L(wt)=wt−η×1N∑i=1N∂f(xi,yi,wt)∂wt\\mathbf{w}_{t+1} = \\mathbf{w}_t - \\eta \\times \\nabla L(\\mathbf{w}_t) = \\mathbf{w}_t - \\eta \\times \\frac{1}{N} \\sum_{i=1}^{N} \\frac{\\partial f(x_i, y_i, \\mathbf{w}_t)}{\\partial \\mathbf{w}_t}wt+1​=wt​−η×∇L(wt​)=wt​−η×N1​∑i=1N​∂wt​∂f(xi​,yi​,wt​)​ 特点： 计算精度高：每次更新都使用了全部样本的信息，因此梯度估计更准确，收敛路径更平滑，通常能收敛到全局最小值（对于凸函数）或较好的局部最小值。 计算复杂度高：对于超大规模数据集，每次迭代都需要遍历整个数据集，计算成本极高，导致训练速度非常慢，甚至不可行。 内存需求大：需要将整个数据集加载到内存中。","422-随机梯度下降-stochastic-gradient-descent-sgd#4.2.2 随机梯度下降 (Stochastic Gradient Descent, SGD)":"原理：与 BGD 相反，SGD 在每次参数更新时随机抽取一个样本来计算梯度，并以此样本的梯度来近似整个数据集的梯度。 wt+1=wt−η×∇f(xi,yi,wt)\\mathbf{w}_{t+1} = \\mathbf{w}_t - \\eta \\times \\nabla f(x_i, y_i, \\mathbf{w}_t)wt+1​=wt​−η×∇f(xi​,yi​,wt​) 其中(xi,yi)(x_i, y_i)(xi​,yi​)是随机选取的单个样本。 特点： 计算复杂度低：每次更新只处理一个样本，计算速度快。 随机性强：由于每次只使用一个样本，梯度估计具有较高的方差，导致损失函数在下降过程中会伴随显著的震荡。 可能跳出局部最优：这种震荡有时能帮助模型跳出浅的局部最小值或鞍点，找到更好的解。 优化效率低：虽然单次迭代快，但由于梯度估计不准确，可能需要更多次的迭代才能收敛，且可能收敛到次优解。","423-mini-batch-随机梯度下降-mini-batch-stochastic-gradient-descent-mbgd#4.2.3 Mini-batch 随机梯度下降 (Mini-batch Stochastic Gradient Descent, MBGD)":"原理：MBGD 介于 BGD 和 SGD 之间。它在每次参数更新时随机抽取一个固定大小的“小批量” (mini-batch) 样本来计算梯度。 g←1p∑i∈batch∇f(xi,yi,wt)\\mathbf{g} \\leftarrow \\frac{1}{p} \\sum_{i \\in \\text{batch}} \\nabla f(x_i, y_i, \\mathbf{w}_t)g←p1​∑i∈batch​∇f(xi​,yi​,wt​) mathbfwt+1=wt−η×gmathbf{w}_{t+1} = \\mathbf{w}_t - \\eta \\times \\mathbf{g}mathbfwt+1​=wt​−η×g 其中ppp是 mini-batch 的大小，g\\mathbf{g}g是当前 mini-batch 的平均梯度。 特点： 目前深度学习领域 SGD 通常指的就是 Mini-batch SGD。 平衡效率与准确性：它结合了 BGD 的稳定性和 SGD 的效率。每次更新的计算量适中，梯度估计相对稳定，且能够有效利用现代并行计算的优势。 计算复杂度适中：比 BGD 快，比 SGD 每次迭代更稳定。 更好的泛化能力：引入的适度随机性可以帮助模型避免过拟合，提高泛化能力。 小批量的选择：mini-batch 的大小 (ppp) 是一个重要的超参数，需要仔细调整。它控制着估计误差（学习方向的发散）和每个周期（epoch）的步数之间的权衡。 Batch size 过小，更新频繁，收敛路径震荡，但可能跳出局部最优。 Batch size 过大，更新平稳，但计算开销增加，可能陷入局部最优。","424-sgd变体的优缺点与收敛过程#4.2.4 SGD变体的优缺点与收敛过程":"SGD和MBGD需要更多步骤才能收敛：相较于 BGD，SGD 和 MBGD 在每个训练周期（对整个训练数据集的一次遍历）中执行的更新步骤更多（因为每次只处理一小部分数据）。 实现更快的收敛：尽管步数多，但由于每次更新的计算量大大减少，所以在相同时间内，SGD 和 MBGD 通常能更快地达到一个可接受的收敛水平，尤其是在训练前期。 SGD的缺点： 学习率选择困难：由于梯度估计的随机性，选择合适的学习率变得非常关键和困难。 容易收敛到局部最优点或困在鞍点：虽然随机性有助于跳出浅层局部最小值，但在复杂的非凸损失函数中，SGD 仍可能被困在质量不佳的局部最优解或鞍点附近。 收敛过程中的山谷震荡：在损失函数表面存在狭长山谷区域时，SGD 由于其梯度估计的方差大，容易在山谷两侧来回震荡，而不是直接沿谷底向下，这会显著减慢收敛速度。 【若需查看原始图片详情，请参考原文中的“收敛过程中的山谷震荡”图示，它直观地展示了SGD在狭长山谷区域的低效震荡。】","43-梯度下降面临的挑战与解决方案#4.3 梯度下降面临的挑战与解决方案":"","431-山谷震荡问题#4.3.1 山谷震荡问题":"问题描述：在多维参数空间中，损失函数通常不是球形的，而是可能存在狭长的山谷。在这种区域中，损失函数在某个维度上变化剧烈（陡峭），而在另一个维度上变化缓慢（平坦）。 SGD 的表现：由于 SGD 采用小批量样本的梯度估计，存在显著的方差。这种估计偏差导致更新方向偏离最优下降路径，从而在峡谷壁间反复振荡。这种震荡使得模型无法沿主曲率方向高效下降，进而引发收敛过程不稳定和收敛速率降低的问题。 步长影响： 步长设置过小时，收敛过程将十分缓慢。 步长设置过大时，梯度可能会在最小值附近来回震荡，甚至发散。","432-动量-momentum#4.3.2 动量 (Momentum)":"动量 (Momentum) 是一种常用的优化技术，旨在加速 SGD 在相关方向上的收敛，并抑制不相关方向上的震荡。\n目的：通过积累历史梯度信息，减小梯度方向的改变，抑制梯度的震荡，从而加速收敛速度。 核心思想：引入一个“速度”或“动量”项，使参数更新不仅依赖于当前的梯度，还依赖于之前梯度的加权平均。 更新公式： 计算梯度：g←1p∑i∈batch∇f(xi,yi,wt)\\mathbf{g} \\leftarrow \\frac{1}{p} \\sum_{i \\in \\text{batch}} \\nabla f(x_i, y_i, \\mathbf{w}_t)g←p1​∑i∈batch​∇f(xi​,yi​,wt​)(Mini-batch 梯度) 更新动量：v←μ×v−η×g\\mathbf{v} \\leftarrow \\mu \\times \\mathbf{v} - \\eta \\times \\mathbf{g}v←μ×v−η×g 更新参数：w←w+v\\mathbf{w} \\leftarrow \\mathbf{w} + \\mathbf{v}w←w+v μ\\muμ(mu)：动量因子 (Momentum Factor)，通常是一个接近 1 的值（如 0.9）。它决定了上一次更新对当前更新的影响程度。 v\\mathbf{v}v：累计动量 (Accumulated Momentum)，可以看作是参数更新的速度向量。 直观解释： 如果连续多个梯度方向相同，动量项会不断累积，使得参数更新加速。这有助于快速穿过平坦区域。 如果梯度方向频繁变化（如在山谷震荡），动量项会因正负梯度的抵消而减小，从而抑制震荡。 可以类比为一个球从山坡滚下：球不仅会受当前坡度的影响，还会因为惯性（动量）而保持之前的运动趋势。","433-adam-优化器#4.3.3 Adam 优化器":"Adam (Adaptive Moment Estimation) 是一种结合了动量和自适应学习率的优化算法，它在实际应用中非常流行且表现出色。Adam 通过计算梯度的一阶矩（均值）和二阶矩（未中心化方差）的指数加权移动平均来辅助参数更新。","4331-一阶矩估计-均值#4.3.3.1 一阶矩估计 (均值)":"作用：跟踪梯度的方向历史信息，表达了**“动量”或平均梯度方向**。 公式： mt=β1mt−1+(1−β1)gt\\mathbf{m}_t = \\beta_1 \\mathbf{m}_{t-1} + (1 - \\beta_1) \\mathbf{g}_tmt​=β1​mt−1​+(1−β1​)gt​ mt\\mathbf{m}_tmt​：当前时刻的一阶矩估计向量。 β1\\beta_1β1​：衰减率超参数（通常为 0.9），控制着历史梯度的影响程度。 gt\\mathbf{g}_tgt​：当前时刻的梯度向量。","4332-二阶矩估计-未中心化方差#4.3.3.2 二阶矩估计 (未中心化方差)":"作用：跟踪梯度大小的历史信息，表达了**“平均学习率”或自适应步长**。 公式： vt=β2vt−1+(1−β2)gt⊙gt\\mathbf{v}_t = \\beta_2 \\mathbf{v}_{t-1} + (1 - \\beta_2) \\mathbf{g}_t \\odot \\mathbf{g}_tvt​=β2​vt−1​+(1−β2​)gt​⊙gt​ vt\\mathbf{v}_tvt​：当前时刻的二阶矩估计向量。 β2\\beta_2β2​：衰减率超参数（通常为 0.999），控制着历史平方梯度的影响程度。 ⊙\\odot⊙：表示元素级别的乘法（哈达玛积）。","4333-adam-解决的问题与泛化能力#4.3.3.3 Adam 解决的问题与泛化能力":"Adam 在参数更新时会对一阶矩和二阶矩进行偏差修正 (Bias Correction)，特别是在训练初期，以抵消初始化时m0\\mathbf{m}_0m0​和v0\\mathbf{v}_0v0​通常为零的偏差。修正后的公式如下： m^t=mt1−β1t\\hat{\\mathbf{m}}_t = \\frac{\\mathbf{m}_t}{1 - \\beta_1^t}m^t​=1−β1t​mt​​ v^t=vt1−β2t\\hat{\\mathbf{v}}_t = \\frac{\\mathbf{v}_t}{1 - \\beta_2^t}v^t​=1−β2t​vt​​ 然后，参数更新公式为： wt←wt−1−ηm^tv^t+ϵ\\mathbf{w}_t \\leftarrow \\mathbf{w}_{t-1} - \\eta \\frac{\\hat{\\mathbf{m}}_t}{\\sqrt{\\hat{\\mathbf{v}}_t} + \\epsilon}wt​←wt−1​−ηv^t​​+ϵm^t​​ 其中ϵ\\epsilonϵ是一个很小的常数（防止分母为零）。\nAdam 的优势： 结合动量：通过一阶矩估计，Adam 继承了动量的优点，加速在相关方向上的收敛。 自适应学习率：通过二阶矩估计，Adam 为每个参数维护了一个独立的学习率。 对于频繁出现大幅梯度的参数，vt\\mathbf{v}_tvt​值会增大，从而在更新时缩小其学习率。 对于梯度较小的参数，则会相对放大学习率。 这种机制使得 Adam 能够自动适应不同参数的尺度差异，且对稀疏梯度数据处理效果好。 解决 SGD 挑战：Adam 基本解决了之前提到的梯度下降的一系列问题： 随机小样本：通过动量和平滑处理减少了 SGD 的震荡。 自适应学习率：无需手动为每个参数调整学习率。 容易卡在梯度较小点（鞍点）：自适应学习率和动量机制有助于更好地越过或逃离鞍点。 更好的泛化能力、提高训练稳定性、适应稀疏数据和大规模分布式训练场景。","4334-adam-在nlp任务上的效果对比#4.3.3.4 Adam 在NLP任务上的效果对比":"【若需查看原始图片详情，请参考原文中的“NLP任务上的效果对比”图示】 在一项关于 LSTM 模型在 NLP 任务上的训练实验中，观察到 Adam 优化器在训练前期比 SGD with Momentum (SGDM) 具有显著更快的收敛速度。这表明 Adam 能够更快地找到一个较好的解，从而缩短模型训练的周期。","434-梯度消失梯度爆炸局部最小值问题#4.3.4 梯度消失、梯度爆炸、局部最小值问题":"虽然 Adam 等优化器在很大程度上缓解了梯度下降的一些问题，但对于深度神经网络，依然存在一些挑战：\n梯度消失问题 (Vanishing Gradients)：\n描述：在深层神经网络中，反向传播过程中梯度会逐层传递。如果激活函数的导数（例如 Sigmoid 函数在饱和区的导数）很小，或者权重很小，那么梯度在反向传播时会呈指数级减小。 后果：越靠近输入层的隐藏层，其权重更新会变得非常缓慢甚至停滞，导致网络无法有效学习浅层特征。 梯度爆炸问题 (Exploding Gradients)：\n描述：与梯度消失相反，如果激活函数的导数很大，或者权重很大，梯度在反向传播时可能会呈指数级增大。 后果：导致参数更新幅度过大，模型训练不稳定，权重值剧烈震荡，甚至溢出为 NaN (Not a Number)。 陷入局部最小值（或鞍点）：\n描述：神经网络的损失函数通常是非凸的，存在多个局部最小值和鞍点。 后果：梯度下降算法（包括其变体）可能收敛到局部最小值，而非全局最小值，或者被困在鞍点（在某个方向是最小值，在另一个方向是最大值的点），这会影响模型的最终性能。 这些问题需要通过更深层次的网络架构设计（如残差网络）、恰当的激活函数选择（如 ReLU 及其变体）、参数初始化策略、批量归一化 (Batch Normalization) 以及梯度裁剪 (Gradient Clipping) 等方法来解决。","5-神经网络设计基础#5 神经网络设计基础":"","51-神经网络与线性逻辑回归的联系#5.1 神经网络与线性/逻辑回归的联系":"神经网络（Neural Networks）是机器学习领域中一种强大的模型，它的基本构建块和核心思想与前面介绍的线性回归和逻辑回归有着深厚的渊源。可以说，神经网络是在这些基本模型的基础上，通过堆叠、组合和引入非线性而发展起来的。","511-神经网络与线性回归#5.1.1 神经网络与线性回归":"线性回归模型的局限：线性回归模型的核心假设是特征与标签之间存在线性关系。这种模型假设过于简单，导致其高偏差 (high bias)，无法很好地建模和捕获复杂问题中的非线性模式。当真实数据关系是非线性的时，线性回归模型会产生明显的系统性误差，即拟合不足 (underfitting)。 神经网络的演进：为了克服这一局限，研究者们从线性回归的基本操作——权重加权求和——出发，通过不断叠加这种操作，并引入非线性激活函数，构建了能够近似任意复杂函数的神经网络。 单一神经元：一个简单的神经元，其输出可以看作是输入特征的加权和，这与线性回归的假设函数Hw(x)=∑wixi+w0H_w(x) = \\sum w_i x_i + w_0Hw​(x)=∑wi​xi​+w0​非常相似。 多层连接：通过将多个这样的神经元组织成层，并将层与层之间连接起来，网络的表达能力得到了极大的提升。","512-神经网络与逻辑回归#5.1.2 神经网络与逻辑回归":"逻辑回归模型的局限：逻辑回归模型虽然引入了 Sigmoid 函数来处理二分类问题，但它本质上仍然是基于线性决策边界进行分类的。这意味着它模型假设相对单一，仅适用于线性可分的问题。面对现实世界中复杂的非线性分类任务时，逻辑回归模型的表现会受到限制。 神经网络的突破：在逻辑回归的基础上，通过引入多层结构和非线性激活函数，可以构建出具有强大非线性拟合能力的神经网络。 单层感知机：带有 Sigmoid 激活函数的单层神经网络，其行为与逻辑回归模型非常相似。 多层感知机 (MLP)：通过堆叠多个这样的层，并使用非线性激活函数，神经网络能够学习和表示复杂的非线性决策边界。这使其能够有效处理复杂分类问题，显著提升模型的泛化性能和预测精度。 从线性到非线性：通过多层非线性变换，神经网络能够将原始输入数据映射到一个更高维度的特征空间，在这个空间中，原本非线性可分的数据可能变得线性可分。 总结：神经网络可以看作是线性回归和逻辑回归的通用化和扩展。通过增加层次结构和引入非线性激活函数，神经网络能够克服单一线性/逻辑模型在处理复杂模式时的限制，从而具备学习和近似任意复杂函数的能力。","52-神经网络的结构与表示#5.2 神经网络的结构与表示":"神经网络通常由输入层、一个或多个隐藏层以及输出层组成。信息在这些层之间流动，经过一系列的计算和转换。","521-正向传播-forward-propagation#5.2.1 正向传播 (Forward Propagation)":"正向传播是神经网络在给定输入后，通过权重、偏置和激活函数逐层计算，直到得到最终输出结果的过程。它描述了信息流如何从输入层经过隐藏层到达输出层。\n过程描述： 输入层接收输入：接收原始特征向量x\\mathbf{x}x。 隐藏层计算： 每个隐藏层中的神经元接收前一层（或输入层）的输出。 对这些输入进行加权求和（线性变换），加上一个偏置项b\\mathbf{b}b。 将结果通过一个激活函数GGG (如 Sigmoid, ReLU 等) 进行非线性变换。 例如，对于第一个隐藏层：h=G(W(1)Tx+b(1))\\mathbf{h} = G(\\mathbf{W}^{(1)T} \\mathbf{x} + \\mathbf{b}^{(1)})h=G(W(1)Tx+b(1))。 输出层计算： 输出层接收最后一个隐藏层的输出。 同样进行加权求和和偏置项的添加。 再通过一个输出激活函数G′G'G′（例如，二分类用 Sigmoid，多分类用 Softmax，回归用线性激活）。 例如，对于输出层：y^=G′(W(2)Th+b(2))\\hat{\\mathbf{y}} = G'(\\mathbf{W}^{(2)T} \\mathbf{h} + \\mathbf{b}^{(2)})y^​=G′(W(2)Th+b(2))。 示例图解： 【若需查看原始图片详情，请参考原文中的“正向传播”图示】 图示展示了一个简单的三层神经网络（输入层、一个隐藏层、一个输出层）。 输入x\\mathbf{x}x：例如(x1,x2,x3)(\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{x}_3)(x1​,x2​,x3​)。 隐藏层h\\mathbf{h}h：例如(h1,h2,h3)(\\mathbf{h}_1, \\mathbf{h}_2, \\mathbf{h}_3)(h1​,h2​,h3​)。 输出y^\\hat{\\mathbf{y}}y^​：例如(y^1,y^2)(\\hat{\\mathbf{y}}_1, \\hat{\\mathbf{y}}_2)(y^​1​,y^​2​)。 权重矩阵：W(1)\\mathbf{W}^{(1)}W(1)连接输入层到隐藏层，W(2)\\mathbf{W}^{(2)}W(2)连接隐藏层到输出层。 偏置向量：b(1)\\mathbf{b}^{(1)}b(1)对应隐藏层，b(2)\\mathbf{b}^{(2)}b(2)对应输出层。 参数数量计算：图示中的例子需要3×33 \\times 33×3个权重和333个偏置（第一层），以及3×23 \\times 23×2个权重和222个偏置（第二层），共9+3+6+2=209+3+6+2 = 209+3+6+2=20个参数。如果按照 PPT 的例子，第一层是3×33 \\times 33×3权重，第二层是3×23 \\times 23×2权重，偏置向量是和神经元数量对应的，所以W(1)W^{(1)}W(1)是3×33 \\times 33×3加上b(1)b^{(1)}b(1)是333个，W(2)W^{(2)}W(2)是3×23 \\times 23×2加上b(2)b^{(2)}b(2)是222个，共9+3+6+2=209+3+6+2=209+3+6+2=20个参数。 更复杂的例子：一个包含两个隐藏层的神经网络，其参数数量会进一步增加（例如，PPT中给出 29 个参数的例子，计算方式为2×3+3+3×2+2=6+3+6+2=172 \\times 3 + 3 + 3 \\times 2 + 2 = 6+3+6+2 = 172×3+3+3×2+2=6+3+6+2=17参数，如果按照图示的连接方式，第二层权重3×33 \\times 33×3加上偏置 3 个，第三层权重3×23 \\times 23×2加上偏置 2 个，总共是2×3+3+3×3+3+3×2+2=6+3+9+3+6+2=292 \\times 3 + 3 + 3 \\times 3 + 3 + 3 \\times 2 + 2 = 6+3+9+3+6+2 = 292×3+3+3×3+3+3×2+2=6+3+9+3+6+2=29个参数）。这说明了神经网络的参数数量可以非常庞大，是其强大表达能力的基础。","522-多层神经网络的特征抽象能力#5.2.2 多层神经网络的特征抽象能力":"层层抽象：随着神经网络层数（特别是隐藏层）的增加，每一层神经元学习到的都是前一层神经元输出的更抽象、更高层次的表示。 信息提炼：输入特征从低级、原始的表示（如像素值）逐步提取为更高级、更具语义的抽象特征。 示例（图像识别）： 【若需查看原始图片详情，请参考原文中的“多层神经网络”图像特征提取图示】 在一个图像识别任务中： 第一个隐层：可能学习到图像的**“边缘”特征**（如水平边缘、垂直边缘）。 第二个隐层：可能将边缘特征组合成**“形状”特征**（如圆形、方形）。 第三个隐层：可能进一步抽象出**“图案”特征**（如眼睛、鼻子）。 第四个隐层：可能识别出更复杂的**“目标”特征**（如人脸、汽车）。 意义：通过这种多层级的抽象，神经网络能够从原始数据中自动学习到具有区分性的特征，从而实现对复杂事物的识别、分类或理解，并获得更好的区分与分类能力。","523-多层神经网络的非线性拟合能力#5.2.3 多层神经网络的非线性拟合能力":"核心原因：引入非线性激活函数是多层神经网络能够拟合非线性关系的关键。如果所有层都只进行线性变换（即使层数再多），其整体效果仍然等同于一个单层的线性模型，因为线性函数的组合仍然是线性函数。 从单层到多层： 单层感知机：只能解决线性可分问题。 两层神经网络：通过引入一个隐藏层和非线性激活函数，原则上可以拟合任何连续函数，例如，解决异或 (XOR) 这样的非线性可分问题。 多层神经网络 (MLP)：随着网络层数的增加，以及激活函数的恰当选择，神经网络拟合非线性分界的能力不断增强。这使其能够学习高度复杂的输入-输出映射，处理各种非线性问题。 交互性演示：例如 TensorFlow Playground（http://playground.tensorflow.org/）等工具可以直观展示多层神经网络如何通过非线性激活函数逐步构建复杂的决策边界。","53-神经网络模型训练过程#5.3 神经网络模型训练过程":"","531-训练目的与核心思想#5.3.1 训练目的与核心思想":"训练目的：神经网络模型训练的最终目的，就是调整模型的所有参数（包括权重W\\mathbf{W}W和偏置b\\mathbf{b}b），使得模型的计算输出y^\\hat{\\mathbf{y}}y^​尽可能地与真实值y\\mathbf{y}y逼近。 核心思想：通过衡量预测输出与真实值之间的差异（损失函数），并利用优化算法（如梯度下降）迭代地更新参数，以最小化这个差异。","532-反向传播-backpropagation-bp#5.3.2 反向传播 (Backpropagation, BP)":"反向传播 (BP) 是训练多层神经网络最核心的算法。它是一种高效计算梯度的方法，使得梯度下降算法能够应用于拥有多个隐藏层的神经网络。","5321-原理与链式法则#5.3.2.1 原理与链式法则":"基本思想： 正向传播：首先进行正向传播，计算网络的输出和损失。 反向计算误差：根据损失函数，计算输出层与真实值之间的误差。 误差反向传播：将这个误差从输出层逐层向后（即向输入层方向）传播，计算每一层神经元的误差贡献。 计算梯度：利用各层的误差贡献和链式法则，计算损失函数对每个权重和偏置的梯度。 更新参数：根据计算出的梯度，使用梯度下降法更新权重和偏置。 链式法则 (Chain Rule)：反向传播算法的核心数学工具。它允许我们计算复合函数（如神经网络）的导数。 示例：如果z=f(g1(x)+g2(x))z = f(g_1(x) + g_2(x))z=f(g1​(x)+g2​(x))，那么∂z∂x=∂z∂g1∂g1∂x+∂z∂g2∂g2∂x\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial g_1} \\frac{\\partial g_1}{\\partial x} + \\frac{\\partial z}{\\partial g_2} \\frac{\\partial g_2}{\\partial x}∂x∂z​=∂g1​∂z​∂x∂g1​​+∂g2​∂z​∂x∂g2​​。 在神经网络中，损失函数LLL是关于输出y^\\hat{\\mathbf{y}}y^​的函数，y^\\hat{\\mathbf{y}}y^​是关于隐藏层输出h\\mathbf{h}h的函数，h\\mathbf{h}h又是关于输入x\\mathbf{x}x和权重W\\mathbf{W}W的函数。为了计算∂L∂W\\frac{\\partial L}{\\partial \\mathbf{W}}∂W∂L​，我们需要从LLL开始，一步步地“链式”求导，直到所需的权重W\\mathbf{W}W。","5322-bp-示例-详细计算过程#5.3.2.2 BP 示例 (详细计算过程)":"我们将通过一个具体的数值例子来理解反向传播的计算过程。 【若需查看原始图片详情，请参考原文中的“链式传导示例”图示，该图示展示了一个带有三个输入神经元、三个隐藏神经元和两个输出神经元的神经网络结构。】\n网络结构： 输入层：x=[x1,x2,x3]T\\mathbf{x} = [x_1, x_2, x_3]^Tx=[x1​,x2​,x3​]T 隐藏层：h=[h1,h2,h3]T\\mathbf{h} = [h_1, h_2, h_3]^Th=[h1​,h2​,h3​]T 输出层：y^=[y^1,y^2]T\\hat{\\mathbf{y}} = [\\hat{y}_1, \\hat{y}_2]^Ty^​=[y^​1​,y^​2​]T 给定值： 输入数据：x1=0.02,x2=0.04,x3=0.01x_1=0.02, x_2=0.04, x_3=0.01x1​=0.02,x2​=0.04,x3​=0.01 偏置：b(1)=[0.4;0.4;0.4]\\mathbf{b}^{(1)}=[0.4; 0.4; 0.4]b(1)=[0.4;0.4;0.4],b(2)=[0.7;0.7]\\mathbf{b}^{(2)}=[0.7; 0.7]b(2)=[0.7;0.7] 期望输出：y=[0.9,0.5]T\\mathbf{y} = [0.9, 0.5]^Ty=[0.9,0.5]T 初始权重： W(1)=(0.250.150.300.250.200.350.100.250.15)\\mathbf{W}^{(1)} = \\begin{pmatrix} 0.25 \u0026 0.15 \u0026 0.30 \\\\ 0.25 \u0026 0.20 \u0026 0.35 \\\\ 0.10 \u0026 0.25 \u0026 0.15 \\end{pmatrix}W(1)=​0.250.250.10​0.150.200.25​0.300.350.15​​ W(2)=(0.400.250.350.300.010.35)\\mathbf{W}^{(2)} = \\begin{pmatrix} 0.40 \u0026 0.25 \\\\ 0.35 \u0026 0.30 \\\\ 0.01 \u0026 0.35 \\end{pmatrix}W(2)=​0.400.350.01​0.250.300.35​​ 激活函数：所有层都使用 Sigmoid 函数σ(z)=11+e−z\\sigma(z) = \\frac{1}{1 + e^{-z}}σ(z)=1+e−z1​。 损失函数：均方误差 (MSE)L(W)=12∑k(yk−y^k)2L(\\mathbf{W}) = \\frac{1}{2} \\sum_k (y_k - \\hat{y}_k)^2L(W)=21​∑k​(yk​−y^​k​)2 1. 正向传播：\n输入到隐层计算：\n线性组合v\\mathbf{v}v： v=W(1)Tx+b(1)=(0.250.250.100.150.200.250.300.350.15)(0.020.040.01)+(0.40.40.4)=(0.005+0.01+0.0010.003+0.008+0.00250.006+0.014+0.0015)+(0.40.40.4)=(0.0160.01350.0215)+(0.40.40.4)=(0.41600.41350.4215)\\mathbf{v} = \\mathbf{W}^{(1)T} \\mathbf{x} + \\mathbf{b}^{(1)} = \\begin{pmatrix} 0.25 \u0026 0.25 \u0026 0.10 \\\\ 0.15 \u0026 0.20 \u0026 0.25 \\\\ 0.30 \u0026 0.35 \u0026 0.15 \\end{pmatrix} \\begin{pmatrix} 0.02 \\\\ 0.04 \\\\ 0.01 \\end{pmatrix} + \\begin{pmatrix} 0.4 \\\\ 0.4 \\\\ 0.4 \\end{pmatrix} = \\begin{pmatrix} 0.005+0.01+0.001 \\\\ 0.003+0.008+0.0025 \\\\ 0.006+0.014+0.0015 \\end{pmatrix} + \\begin{pmatrix} 0.4 \\\\ 0.4 \\\\ 0.4 \\end{pmatrix} = \\begin{pmatrix} 0.016 \\\\ 0.0135 \\\\ 0.0215 \\end{pmatrix} + \\begin{pmatrix} 0.4 \\\\ 0.4 \\\\ 0.4 \\end{pmatrix} = \\begin{pmatrix} 0.4160 \\\\ 0.4135 \\\\ 0.4215 \\end{pmatrix}v=W(1)Tx+b(1)=​0.250.150.30​0.250.200.35​0.100.250.15​​​0.020.040.01​​+​0.40.40.4​​=​0.005+0.01+0.0010.003+0.008+0.00250.006+0.014+0.0015​​+​0.40.40.4​​=​0.0160.01350.0215​​+​0.40.40.4​​=​0.41600.41350.4215​​ 隐层输出h\\mathbf{h}h (经过 Sigmoid 激活)： h=σ(v)=(1/(1+e−0.4160)1/(1+e−0.4135)1/(1+e−0.4215))≈(0.60250.60190.6038)\\mathbf{h} = \\sigma(\\mathbf{v}) = \\begin{pmatrix} 1 / (1 + e^{-0.4160}) \\\\ 1 / (1 + e^{-0.4135}) \\\\ 1 / (1 + e^{-0.4215}) \\end{pmatrix} \\approx \\begin{pmatrix} 0.6025 \\\\ 0.6019 \\\\ 0.6038 \\end{pmatrix}h=σ(v)=​1/(1+e−0.4160)1/(1+e−0.4135)1/(1+e−0.4215)​​≈​0.60250.60190.6038​​ 隐层到输出层计算：\n线性组合z\\mathbf{z}z： z=W(2)Th+b(2)=(0.400.350.010.250.300.35)(0.60250.60190.6038)+(0.70.7)=(0.2410+0.2107+0.00600.1506+0.1806+0.2113)+(0.70.7)=(0.45770.5425)+(0.70.7)=(1.15771.2425)\\mathbf{z} = \\mathbf{W}^{(2)T} \\mathbf{h} + \\mathbf{b}^{(2)} = \\begin{pmatrix} 0.40 \u0026 0.35 \u0026 0.01 \\\\ 0.25 \u0026 0.30 \u0026 0.35 \\end{pmatrix} \\begin{pmatrix} 0.6025 \\\\ 0.6019 \\\\ 0.6038 \\end{pmatrix} + \\begin{pmatrix} 0.7 \\\\ 0.7 \\end{pmatrix} = \\begin{pmatrix} 0.2410 + 0.2107 + 0.0060 \\\\ 0.1506 + 0.1806 + 0.2113 \\end{pmatrix} + \\begin{pmatrix} 0.7 \\\\ 0.7 \\end{pmatrix} = \\begin{pmatrix} 0.4577 \\\\ 0.5425 \\end{pmatrix} + \\begin{pmatrix} 0.7 \\\\ 0.7 \\end{pmatrix} = \\begin{pmatrix} 1.1577 \\\\ 1.2425 \\end{pmatrix}z=W(2)Th+b(2)=(0.400.25​0.350.30​0.010.35​)​0.60250.60190.6038​​+(0.70.7​)=(0.2410+0.2107+0.00600.1506+0.1806+0.2113​)+(0.70.7​)=(0.45770.5425​)+(0.70.7​)=(1.15771.2425​) 输出层输出y^\\hat{\\mathbf{y}}y^​ (经过 Sigmoid 激活)： y^=σ(z)=(1/(1+e−1.1577)1/(1+e−1.2425))≈(0.76090.7760)\\hat{\\mathbf{y}} = \\sigma(\\mathbf{z}) = \\begin{pmatrix} 1 / (1 + e^{-1.1577}) \\\\ 1 / (1 + e^{-1.2425}) \\end{pmatrix} \\approx \\begin{pmatrix} 0.7609 \\\\ 0.7760 \\end{pmatrix}y^​=σ(z)=(1/(1+e−1.1577)1/(1+e−1.2425)​)≈(0.76090.7760​) 计算总误差：\n预测输出y^=[0.7609,0.7760]T\\hat{\\mathbf{y}} = [0.7609, 0.7760]^Ty^​=[0.7609,0.7760]T 期望输出y=[0.9,0.5]T\\mathbf{y} = [0.9, 0.5]^Ty=[0.9,0.5]T 总损失L(W)=12(y1−y^1)2+12(y2−y^2)2L(\\mathbf{W}) = \\frac{1}{2} (y_1 - \\hat{y}_1)^2 + \\frac{1}{2} (y_2 - \\hat{y}_2)^2L(W)=21​(y1​−y^​1​)2+21​(y2​−y^​2​)2 L(W)=12(0.9−0.7609)2+12(0.5−0.7760)2=12(0.1391)2+12(−0.2760)2≈0.00967+0.03809≈0.04776L(\\mathbf{W}) = \\frac{1}{2} (0.9 - 0.7609)^2 + \\frac{1}{2} (0.5 - 0.7760)^2 = \\frac{1}{2} (0.1391)^2 + \\frac{1}{2} (-0.2760)^2 \\approx 0.00967 + 0.03809 \\approx 0.04776L(W)=21​(0.9−0.7609)2+21​(0.5−0.7760)2=21​(0.1391)2+21​(−0.2760)2≈0.00967+0.03809≈0.04776 注：PPT中显示的损失为 0.0478，与精确计算略有差异，可能为舍入误差。 由于计算值与真实值之间存在差距，我们需要通过反向传播来修改权重。 2. 反向传播（以更新w2,1(2)w^{(2)}_{2,1}w2,1(2)​为例）：\n我们将计算损失函数L(W)L(\\mathbf{W})L(W)对权重w2,1(2)w^{(2)}_{2,1}w2,1(2)​（即h2h_2h2​到y^1\\hat{y}_1y^​1​的权重，在 PPT 中表示为www）的偏导数∂L∂w2,1(2)\\frac{\\partial L}{\\partial w^{(2)}_{2,1}}∂w2,1(2)​∂L​。\n应用链式法则： ∂L∂w2,1(2)=∂L∂y^1⋅∂y^1∂z1⋅∂z1∂w2,1(2)\\frac{\\partial L}{\\partial w^{(2)}_{2,1}} = \\frac{\\partial L}{\\partial \\hat{y}_1} \\cdot \\frac{\\partial \\hat{y}_1}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w^{(2)}_{2,1}}∂w2,1(2)​∂L​=∂y^​1​∂L​⋅∂z1​∂y^​1​​⋅∂w2,1(2)​∂z1​​\n逐项计算：\n∂L∂y^1\\frac{\\partial L}{\\partial \\hat{y}_1}∂y^​1​∂L​： L=12(y1−y^1)2+12(y2−y^2)2L = \\frac{1}{2} (y_1 - \\hat{y}_1)^2 + \\frac{1}{2} (y_2 - \\hat{y}_2)^2L=21​(y1​−y^​1​)2+21​(y2​−y^​2​)2 ∂L∂y^1=−(y1−y^1)=y^1−y1=0.7609−0.9=−0.1391\\frac{\\partial L}{\\partial \\hat{y}_1} = -(y_1 - \\hat{y}_1) = \\hat{y}_1 - y_1 = 0.7609 - 0.9 = -0.1391∂y^​1​∂L​=−(y1​−y^​1​)=y^​1​−y1​=0.7609−0.9=−0.1391 ∂y^1∂z1\\frac{\\partial \\hat{y}_1}{\\partial z_1}∂z1​∂y^​1​​： 由于y^1=σ(z1)=11+e−z1\\hat{y}_1 = \\sigma(z_1) = \\frac{1}{1 + e^{-z_1}}y^​1​=σ(z1​)=1+e−z1​1​，Sigmoid 函数的导数是σ(z)(1−σ(z))\\sigma(z)(1 - \\sigma(z))σ(z)(1−σ(z))。 ∂y^1∂z1=y^1(1−y^1)=0.7609×(1−0.7609)=0.7609×0.2391≈0.1819\\frac{\\partial \\hat{y}_1}{\\partial z_1} = \\hat{y}_1 (1 - \\hat{y}_1) = 0.7609 \\times (1 - 0.7609) = 0.7609 \\times 0.2391 \\approx 0.1819∂z1​∂y^​1​​=y^​1​(1−y^​1​)=0.7609×(1−0.7609)=0.7609×0.2391≈0.1819 ∂z1∂w2,1(2)\\frac{\\partial z_1}{\\partial w^{(2)}_{2,1}}∂w2,1(2)​∂z1​​： z1=w1,1(2)h1+w2,1(2)h2+w3,1(2)h3+b1(2)z_1 = w^{(2)}_{1,1} h_1 + w^{(2)}_{2,1} h_2 + w^{(2)}_{3,1} h_3 + b^{(2)}_1z1​=w1,1(2)​h1​+w2,1(2)​h2​+w3,1(2)​h3​+b1(2)​ 所以，∂z1∂w2,1(2)=h2=0.6019\\frac{\\partial z_1}{\\partial w^{(2)}_{2,1}} = h_2 = 0.6019∂w2,1(2)​∂z1​​=h2​=0.6019 整合计算梯度： ∂L∂w2,1(2)=(−0.1391)×(0.1819)×(0.6019)≈−0.0152\\frac{\\partial L}{\\partial w^{(2)}_{2,1}} = (-0.1391) \\times (0.1819) \\times (0.6019) \\approx -0.0152∂w2,1(2)​∂L​=(−0.1391)×(0.1819)×(0.6019)≈−0.0152\n更新权重w2,1(2)w^{(2)}_{2,1}w2,1(2)​： 假设学习率η=1.0\\eta = 1.0η=1.0(PPT中未明确给出，但从0.35−(−0.0152)=0.36520.35 - (-0.0152) = 0.36520.35−(−0.0152)=0.3652推断)。 w2,1(2)←w2,1(2)−η×∂L∂w2,1(2)=0.35−(1.0×(−0.0152))=0.35+0.0152=0.3652w^{(2)}_{2,1} \\leftarrow w^{(2)}_{2,1} - \\eta \\times \\frac{\\partial L}{\\partial w^{(2)}_{2,1}} = 0.35 - (1.0 \\times (-0.0152)) = 0.35 + 0.0152 = 0.3652w2,1(2)​←w2,1(2)​−η×∂w2,1(2)​∂L​=0.35−(1.0×(−0.0152))=0.35+0.0152=0.3652\n通过这个更新，权重w2,1(2)w^{(2)}_{2,1}w2,1(2)​从 0.35 变为 0.3652。 对所有其他权重和偏置项也进行类似的梯度计算和更新。","5323-bp-的向量化表示#5.3.2.3 BP 的向量化表示":"为了高效地实现反向传播，通常使用向量化运算。\n使用 Sigmoid 作为激活函数：\nSigmoid 导数特性：σ′(z)=σ(z)(1−σ(z))\\sigma'(z) = \\sigma(z)(1-\\sigma(z))σ′(z)=σ(z)(1−σ(z))。 前向传输（向量形式）：\n输入到隐层： v=W(1)Tx+b(1)\\mathbf{v} = \\mathbf{W}^{(1)T} \\mathbf{x} + \\mathbf{b}^{(1)}v=W(1)Tx+b(1) h=σ(v)\\mathbf{h} = \\sigma(\\mathbf{v})h=σ(v) 隐层到输出层： z=W(2)Th+b(2)\\mathbf{z} = \\mathbf{W}^{(2)T} \\mathbf{h} + \\mathbf{b}^{(2)}z=W(2)Th+b(2) y^=σ(z)\\hat{\\mathbf{y}} = \\sigma(\\mathbf{z})y^​=σ(z) 反向传播（向量形式）：\n计算输出层误差项δ(2)\\boldsymbol{\\delta}^{(2)}δ(2)： 衡量输出层的误差对线性组合z\\mathbf{z}z的影响。 假设损失函数为均方误差L=12∑(yk−y^k)2L = \\frac{1}{2} \\sum (\\mathbf{y}_k - \\hat{\\mathbf{y}}_k)^2L=21​∑(yk​−y^​k​)2，则∂L∂y^=y^−y\\frac{\\partial L}{\\partial \\hat{\\mathbf{y}}} = \\hat{\\mathbf{y}} - \\mathbf{y}∂y^​∂L​=y^​−y。 δ(2)=(y^−y)⊙σ′(z)=(y^−y)⊙y^(1−y^)\\boldsymbol{\\delta}^{(2)} = (\\hat{\\mathbf{y}} - \\mathbf{y}) \\odot \\sigma'(\\mathbf{z}) = (\\hat{\\mathbf{y}} - \\mathbf{y}) \\odot \\hat{\\mathbf{y}}(1 - \\hat{\\mathbf{y}})δ(2)=(y^​−y)⊙σ′(z)=(y^​−y)⊙y^​(1−y^​) 这里的⊙\\odot⊙是元素级别的乘法。\n计算隐藏层误差项δ(1)\\boldsymbol{\\delta}^{(1)}δ(1)： 输出层误差反向传播到隐藏层。 δ(1)=(W(2)δ(2))⊙σ′(v)=(W(2)δ(2))⊙h(1−h)\\boldsymbol{\\delta}^{(1)} = (\\mathbf{W}^{(2)} \\boldsymbol{\\delta}^{(2)}) \\odot \\sigma'(\\mathbf{v}) = (\\mathbf{W}^{(2)} \\boldsymbol{\\delta}^{(2)}) \\odot \\mathbf{h}(1 - \\mathbf{h})δ(1)=(W(2)δ(2))⊙σ′(v)=(W(2)δ(2))⊙h(1−h)\n计算权重和偏置的梯度：\n输出层权重梯度：∂L∂W(2)=h(δ(2))T\\frac{\\partial L}{\\partial \\mathbf{W}^{(2)}} = \\mathbf{h} (\\boldsymbol{\\delta}^{(2)})^T∂W(2)∂L​=h(δ(2))T 输出层偏置梯度：∂L∂b(2)=δ(2)\\frac{\\partial L}{\\partial \\mathbf{b}^{(2)}} = \\boldsymbol{\\delta}^{(2)}∂b(2)∂L​=δ(2) 隐藏层权重梯度：∂L∂W(1)=x(δ(1))T\\frac{\\partial L}{\\partial \\mathbf{W}^{(1)}} = \\mathbf{x} (\\boldsymbol{\\delta}^{(1)})^T∂W(1)∂L​=x(δ(1))T 隐藏层偏置梯度：∂L∂b(1)=δ(1)\\frac{\\partial L}{\\partial \\mathbf{b}^{(1)}} = \\boldsymbol{\\delta}^{(1)}∂b(1)∂L​=δ(1) 更新参数： W←W−η∂L∂W\\mathbf{W} \\leftarrow \\mathbf{W} - \\eta \\frac{\\partial L}{\\partial \\mathbf{W}}W←W−η∂W∂L​ b←b−η∂L∂b\\mathbf{b} \\leftarrow \\mathbf{b} - \\eta \\frac{\\partial L}{\\partial \\mathbf{b}}b←b−η∂b∂L​","5324-bp-算法的本质与迭代过程#5.3.2.4 BP 算法的本质与迭代过程":"本质：标准 BP 算法本质上是梯度下降法的一种应用，它提供了一种系统高效地计算神经网络中所有参数梯度的方法。 作用：反向传播的作用是将神经网络的输出误差反向传播到网络的输入端，并以此来更新网络中各个连接的权重和偏置。 迭代训练： 完成第一次反向传播后，网络的模型参数得到更新。 网络进行下一轮的正向传播过程。 如此反复地迭代进行训练，从而不断缩小计算值与真实值之间的误差，使模型性能逐步提升。","5325-bp-算法的缺陷#5.3.2.5 BP 算法的缺陷":"尽管 BP 算法在神经网络训练中非常有效，但它也存在一些固有的局限性，尤其是在训练深层网络时：","53251-梯度消失问题-vanishing-gradients#5.3.2.5.1 梯度消失问题 (Vanishing Gradients)":"描述：由于深层神经网络包含较多的隐藏层，在反向传播过程中，如果激活函数的导数（例如 Sigmoid 或 Tanh 函数在饱和区的导数很小）或者权重过小，那么梯度在通过多层链式乘法时会呈指数级减小。 后果：越靠近输入层（网络前端）的隐藏层，其梯度将变得越小，导致这些层的权重更新缓慢或停滞。这意味着浅层特征难以学习，模型训练效率低下。","53252-梯度爆炸问题-exploding-gradients#5.3.2.5.2 梯度爆炸问题 (Exploding Gradients)":"描述：与梯度消失相反，如果激活函数的导数很大（例如 ReLU 导数始终为 1）或者权重过大，梯度在反向传播时可能会呈指数级增大。 后果：导致神经网络不稳定，权重更新过大，在训练过程中参数值迅速变得非常大，甚至溢出为 NaN (Not a Number)，使得模型无法从训练数据中很好地学习。","53253-局部最小值鞍点问题-local-minima--saddle-points#5.3.2.5.3 局部最小值/鞍点问题 (Local Minima / Saddle Points)":"描述：神经网络的损失函数通常是非凸的，在多维空间中存在大量的局部最小值和鞍点。 后果：BP 算法（作为梯度下降的一种应用）可能收敛到局部最小值而非全局最小值。在鞍点处，虽然某个方向梯度为零，但并非真正的最小值，模型可能会被困在这些点，导致无法找到最优解。","54-神经网络训练参数的选择与优化#5.4 神经网络训练参数的选择与优化":"为了提升神经网络的训练效果和模型性能，除了 BP 算法本身，还需要关注其他关键设计和优化方面。当模型训练结果不尽如人意（不准确）时，可以从以下几个方面进行调整：","541-机器学习基本组件-data-model-optimizer-loss-metric#5.4.1 机器学习基本组件 (Data, Model, Optimizer, Loss, Metric)":"训练一个机器学习模型可以看作是一个系统工程，涉及以下几个核心组件：\nData (数据)：模型的输入，包括训练数据、验证数据和测试数据。数据质量、数量和预处理对模型性能至关重要。 Model (模型)：即神经网络的架构，包括层数、每层神经元数量、连接方式等。 Optimizer (优化器)：用于调整模型参数以最小化损失函数的算法（如 SGD、Adam 等）。 Loss (损失函数)：衡量模型预测与真实值之间差异的函数。例如，Loss=∑i=1n(predicted−truth)2Loss = \\sum_{i=1}^n (predicted - truth)^2Loss=∑i=1n​(predicted−truth)2。这个函数是关于模型参数的函数。 Metric (评估指标)：用于评估模型性能的量化标准，可能与损失函数不同（例如准确率、F1-score 等）。 这五个组件共同构成了一个机器学习项目的核心要素，任何一个环节的问题都可能影响最终结果。","542-选择合适的激活函数#5.4.2 选择合适的激活函数":"","5421-激活函数的作用#5.4.2.1 激活函数的作用":"引入非线性：在神经元中，输入数据经过加权求和后，还会通过一个非线性函数GGG，这个函数就是激活函数 (Activation Function)。激活函数是多层神经网络能够学习和拟合复杂非线性模式的关键。如果没有激活函数或只使用线性激活函数，无论堆叠多少层，整个网络最终都等效于一个简单的线性模型。 特征变换：激活函数将神经元的输入信号转换成输出信号，这个输出信号将作为下一层神经元的输入。","5422-激活函数应具备的性质#5.4.2.2 激活函数应具备的性质":"一个好的激活函数通常需要具备以下性质：\n可微性 (Differentiability)：这是最重要的性质之一。当优化方法是基于梯度（如反向传播）时，激活函数必须是可微的，以便能够计算梯度并更新参数。 输出值的范围： 有限范围：当激活函数的输出值是有限的时候（如 Sigmoid、Tanh），基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著。这有助于避免梯度爆炸。 无限范围：当激活函数的输出是无限的时候（如 ReLU），模型的训练会更加高效，但也可能更容易导致梯度爆炸，因此在这种情况下通常需要更小的学习率。 非线性：使多层网络能够学习复杂的模式。 单调性：保证损失函数是凸函数，使得梯度下降更容易收敛。 计算效率：激活函数的计算应该尽可能高效，因为在每次正向和反向传播中都会被大量调用。","5423-常用激活函数示例-relu-leaky-relu#5.4.2.3 常用激活函数示例 (ReLU, Leaky ReLU)":"ReLU (Rectified Linear Unit) 函数：\n公式：f(x)=max⁡(0,x)f(x) = \\max(0, x)f(x)=max(0,x) 特点： 解决了 Sigmoid 和 Tanh 在正区间饱和导致的梯度消失问题，因为它在x\u003e0x \u003e 0x\u003e0时导数恒为 1。 计算效率高，只需判断大小。 但可能导致“死亡 ReLU”问题，即当x≤0x \\le 0x≤0时神经元不再激活，梯度为 0，无法更新。 Leaky ReLU 函数：\n公式：f(x)=max⁡(αx,x)f(x) = \\max(\\alpha x, x)f(x)=max(αx,x)，其中α∈(0,1)\\alpha \\in (0, 1)α∈(0,1)是一个很小的正数（例如 0.01）。 特点： 解决了 ReLU 的“死亡 ReLU”问题，因为它在x\u003c0x \u003c 0x\u003c0时依然有一个小的非零梯度α\\alphaα，允许信息通过。 保持了 ReLU 的计算效率。","543-选择恰当的损失函数#5.4.3 选择恰当的损失函数":"定义：损失函数L=f(y^,y)L = f(\\hat{\\mathbf{y}}, \\mathbf{y})L=f(y^​,y)，其中y^\\hat{\\mathbf{y}}y^​是模型预测值，y\\mathbf{y}y是真实值。模型预测值y^\\hat{\\mathbf{y}}y^​是神经网络模型参数W\\mathbf{W}W的函数，记作y^=HW(x)\\hat{\\mathbf{y}} = H_W(\\mathbf{x})y^​=HW​(x)。因此，从参数W\\mathbf{W}W的角度看，损失函数可以记为L(W)=f(HW(x),y)L(\\mathbf{W}) = f(H_W(\\mathbf{x}), \\mathbf{y})L(W)=f(HW​(x),y)。 作用：损失函数用于评价网络模型的好坏。损失函数值越小，说明模型及其参数越符合训练样本(x,y)(\\mathbf{x}, \\mathbf{y})(x,y)所反映的真实数据模式。 选择依据：选择何种损失函数取决于具体的任务类型： 回归任务：常用均方误差 (MSE)、平均绝对误差 (MAE) 等。 二分类任务：常用二元交叉熵损失 (Binary Cross-Entropy Loss)。 多分类任务：常用类别交叉熵损失 (Categorical Cross-Entropy Loss)。"},"title":"机器学习基础"},"/notes/learn/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8/":{"data":{"":"","1-引言#1. 引言":"","11-深度学习基础与应用概览#1.1 深度学习基础与应用概览":"本章的学习目标是将前一章中获得的神经网络基础知识（如多层感知机的正反向计算过程，以及基础优化方法）应用到实际场景中。通过分析经典深度学习算法，学习如何将基础神经网络应用于实际场景，并逐步优化以实现工业级应用，最终目标是使机器能更好地理解和服务人类。","12-输入类型与任务匹配#1.2 输入类型与任务匹配":"人类获取的信息可以分为两大主要类型，深度学习模型根据这些类型及其对应的任务，采用不同的神经网络结构：\n图像信息： 任务：理解图像内容（例如，识别图像中的物体、场景等）。 方法：主要通过卷积神经网络 (CNN) 来处理这类任务。 序列信息： 任务：理解语音、文字或视频内容（这些数据具有时间或逻辑上的序列依赖性）。 方法：主要通过循环神经网络 (RNN) 来处理这类任务。","13-归纳偏置-inductive-bias#1.3 归纳偏置 (Inductive Bias)":"","131-定义与哲学渊源#1.3.1 定义与哲学渊源":"定义：归纳偏置 (Inductive Bias) 是指模型结构本身所蕴含的限制、假设和偏向。它决定了模型在面对未知数据时，倾向于做出哪种类型的预测，或者说，它对学习任务设定了一种“先验”的约束。 哲学渊源： 洛克 (John Locke) 的《人类理解论》中的经验主义：洛克认为人的心灵初始状态像一块“白板”，精神内容完全来源于经验。这可以类比于一个模型，如果没有归纳偏置，它将完全依赖从数据中学习到的模式。 康德 (Immanuel Kant) 的《纯粹理性批判》中的综合先验判断：康德认为存在不来源于感官经验、而是来源于心智的先天结构的知识（如时空、逻辑、数学等）。他提出，我们通过结合先天知识和经验来认识世界。这可以类比于归纳偏置，即模型内置的结构（先天知识）使其能够更好地处理某些类型的数据（经验），从而更有效地学习。康德认为，正是因为我们先天具备了认识三维时空、逻辑和数学的大脑结构，我们才能更好地认识世界。","132-神经网络模型与归纳偏置#1.3.2 神经网络模型与归纳偏置":"正如康德所言，大脑的先天结构决定了其认识世界的方式，不同的神经网络模型结构也具有不同的归纳偏置。这意味着：\n每种模型结构都对输入数据和学习任务做出了特定的假设。 这些假设使得模型在处理特定类型的数据或解决特定类型的问题时效率更高、性能更好。 例如，卷积神经网络 (CNN) 具有局部连接和权重共享的归纳偏置，这使其天然适合处理具有空间局部性和平移不变性的图像数据。而循环神经网络 (RNN) 的循环结构使其适合处理具有时间依赖性的序列数据。因此，选择合适的神经网络模型结构对于解决特定任务至关重要，因为它能够利用与任务匹配的归纳偏置来更有效地学习。","2-适合图像处理的卷积神经网络#2. 适合图像处理的卷积神经网络":"","21-卷积神经网络概述#2.1 卷积神经网络概述":"","211-发展历史#2.1.1 发展历史":"对卷积神经网络 (CNN) 的研究可以追溯到日本学者福岛邦彦在 1979 和 1980 年提出的 Neocognition 模型。这个模型参照了生物的视觉皮层 (visual cortex) 设计，是现代CNN的早期雏形。 AlexNet 在 ILSVRC2012 (ImageNet Large Scale Visual Recognition Challenge 2012) 图像分类竞赛中取得巨大成功。它显著提高了图像分类的准确率，并标志着卷积神经网络在图像分类领域获得快速发展，成为主流方法。","212-全连接网络的挑战#2.1.2 全连接网络的挑战":"问题背景： 对于计算机视觉任务，例如识别图像中的物体，传统的多层感知机 (MLP) 或全连接网络 (Fully Connected Network, FCN) 会面临巨大的参数量挑战。 示例分析 (原始资料第7页和第8页图示的文字描述): 小图像示例 (32x32x3): 输入图像大小：32x32 像素，通道数 RGB 为 3。 输入数据量：32×32×3=307232 \\times 32 \\times 3 = 307232×32×3=3072 个特征。 如果第一层隐层神经元有 100 个，那么连接输入层和第一层隐层的权重数量将是 3072×100=3072003072 \\times 100 = 3072003072×100=307200。这已经是相当大的参数量。 大图像示例 (1024x1024x3): 实际场景中，图像尺寸往往更大，例如 1024×10241024 \\times 10241024×1024 像素，通道数 3。 如果第一层隐层神经元有 1000 个 (这还是一个相对较小的数字)，那么仅仅是第一层的权重数量将达到 1024×1024×3×1000≈3×1091024 \\times 1024 \\times 3 \\times 1000 \\approx 3 \\times 10^91024×1024×3×1000≈3×109 (即 30 亿) 的量级。 挑战总结： 参数量过大： 如此庞大的权重数量会导致模型训练困难，计算资源消耗巨大。 过拟合 (Overfitting)： 过多的参数使得模型容易过度学习训练数据中的噪声和特定模式，导致在新数据上泛化能力差。 解决方案： 卷积神经网络通过其特有的 局部连接 和 权重共享 机制，可以有效减少权重数量，从而解决全连接网络在处理高维图像数据时面临的挑战，并为构建更深的网络结构提供了可能。","22-卷积层-convolutional-layer#2.2 卷积层 (Convolutional Layer)":"","221-核心特征#2.2.1 核心特征":"卷积层是CNN的核心组成部分，其引入的两个重要特征极大地优化了图像处理：\n局部连接 (Local Connectivity)： 传统全连接： 每个神经元都与前一层的所有神经元连接。 卷积层： 卷积层中的每个神经元（即输出特征图上的一个点）只与其输入特征图（或原始图像）的局部区域相连接。这个局部区域的大小由滤波器 (filter/kernel) 的尺寸决定。 优势： 这种设计模仿了生物视觉系统对局部特征的感知，例如边缘、纹理等，并且大大减少了连接数量。 权重共享 (Weight Sharing)： 传统全连接： 不同的连接使用不同的权重。 卷积层： 一个滤波器（即一组权重）在输入特征图上滑动，对所有局部区域执行相同的卷积操作。这意味着同一组权重被输入特征图的所有局部区域共享。 优势： 这种共享机制使得模型能够检测到图像中任何位置的相同特征（例如，无论一只猫的眼睛出现在图像的左上角还是右下角，都可以被同一个滤波器检测到）。同时，它进一步减少了模型的总参数量，有效避免过拟合，并使得构建更深层次的网络成为可能。","222-卷积运算#2.2.2 卷积运算":"本质： 卷积运算在神经网络中实际是计算输入矩阵与滤波器矩阵之间的内积 (相关系数)，用于提取特征。","2221-数学定义#2.2.2.1 数学定义":"在数学上，一维离散卷积的定义为： y[n]=∑i=−∞∞x[i]h[n−i]=x[n]∗h[n]y[n] = \\sum_{i=-\\infty}^{\\infty} x[i]h[n-i] = x[n] * h[n]y[n]=∑i=−∞∞​x[i]h[n−i]=x[n]∗h[n] 其中，x[n]x[n]x[n] 是输入信号，h[n]h[n]h[n] 是卷积核 (滤波器)，y[n]y[n]y[n] 是输出信号。 在卷积神经网络中，这个概念被推广到二维图像，通常是输入数据与一个小的矩阵 (滤波器) 进行元素乘积求和的操作，然后滑动到下一个区域。","2222-多输入单输出#2.2.2.2 多输入单输出":"过程描述 (原始资料第13页图示的文字描述): 假设输入是一个 6×6×36 \\times 6 \\times 36×6×3 的特征图 (例如，RGB 图像，6x6 像素，3 个颜色通道)。 使用一个 3×3×33 \\times 3 \\times 33×3×3 的滤波器 (这里，滤波器的深度必须与输入特征图的通道数相匹配)。 这个滤波器在输入特征图的每个通道上分别进行卷积操作，然后将三个通道的卷积结果相加，得到一个单一的输出特征图（例如 4×44 \\times 44×4）。 关键点： 尽管输入有多个通道，但一个滤波器最终只生成一个输出通道。这意味着，如果我们需要多个输出特征图 (检测多种特征)，就需要使用多个不同的滤波器。 【若需查看原始图片详情，请参考原文中的“多输入特征图单输出特征图卷积运算示意图”】","2223-边缘检测示例#2.2.2.3 边缘检测示例":"核心思想： 不同的滤波器 (卷积核) 可以用来检测图像中的不同特征，例如垂直边缘、水平边缘、对角线边缘等。这是因为滤波器中的权重可以被训练成特定的模式，当与图像中的对应模式进行内积运算时，会产生较高的激活值。 示例一：垂直边缘检测 (原始资料第16页图示的文字描述): 滤波器示例： 1 0 -1 1 0 -1 1 0 -1 这个滤波器左右两侧是正负对称的，中间为零。 输入图像示例： 图像左侧是高亮度区域 (例如 10)，右侧是低亮度区域 (例如 0)，中间是过渡区域。 卷积结果： 当这个滤波器滑动到垂直边缘 (亮度从高到低变化) 时，其输出值会显著增大，从而“检测”到垂直边缘。例如，当滤波器跨越一个亮到暗的垂直边界时，它会将左侧亮区乘以正值，右侧暗区乘以负值，求和后产生较大的绝对值。 示例二：对角线边缘检测 (原始资料第16页图示的文字描述): 滤波器示例： 1 1 0 1 0 -1 0 -1 -1 这个滤波器呈现对角线的正负值分布。 卷积结果： 类似地，当这个滤波器滑动到图像中的对角线边缘时，会产生较高的响应，实现对角线边缘的检测。 【若需查看原始图片详情，请参考原文中的“垂直边缘检测与对角线边缘检测示例图”】","223-边界扩充-padding-与卷积步长-stride#2.2.3 边界扩充 (Padding) 与卷积步长 (Stride)":"这两个参数是卷积层中控制输出特征图尺寸和信息保留的关键。\n边界扩充 (Padding)： 定义： 在进行卷积操作之前，在输入图像或特征图的边界周围添加额外的像素。这些像素通常填充为 0 或边缘像素的重复值。 目的： 防止特征图持续减小： 随着多层卷积，特征图的尺寸会逐渐缩小。Padding 可以保持特征图的尺寸不变或减缓其缩小速度，从而允许构建更深的网络。 强化边缘信息： 图像边缘的像素点在没有Padding的情况下，只参与少数几次卷积计算。通过Padding，边缘像素也能被充分利用，避免边缘信息丢失，因为边缘信息往往对图像识别很重要。 卷积步长 (Stride)： 定义： 滤波器在输入特征图上滑动时，每次移动的像素点个数。 影响： 控制输出尺寸： 步长越大，滤波器跳过的区域越多，输出特征图的尺寸就越小。 下采样： 当步长大于 1 时，实际上执行了一种形式的下采样 (down-sampling)，减少了计算量，但可能损失一些细节。 输出特征图尺寸计算公式： 给定输入尺寸 Wi×HiW_i \\times H_iWi​×Hi​，滤波器尺寸 K×KK \\times KK×K，Padding ppp，步长 sss。 输出特征图的尺寸 Wo×HoW_o \\times H_oWo​×Ho​ 为： Wo=Wi+2p−Ks+1W_o = \\frac{W_i + 2p - K}{s} + 1Wo​=sWi​+2p−K​+1 Ho=Hi+2p−Ks+1H_o = \\frac{H_i + 2p - K}{s} + 1Ho​=sHi​+2p−K​+1 示例 (原始资料第17页图示的文字描述): 输入 5×55 \\times 55×5，滤波器 3×33 \\times 33×3，Padding p=1p=1p=1，步长 s=2s=2s=2。 Wo=(5+2×1−3)/2+1=(5+2−3)/2+1=4/2+1=2+1=3W_o = (5 + 2 \\times 1 - 3)/2 + 1 = (5+2-3)/2 + 1 = 4/2 + 1 = 2+1=3Wo​=(5+2×1−3)/2+1=(5+2−3)/2+1=4/2+1=2+1=3 Ho=(5+2×1−3)/2+1=3H_o = (5 + 2 \\times 1 - 3)/2 + 1 = 3Ho​=(5+2×1−3)/2+1=3 因此，输出特征图尺寸为 3×33 \\times 33×3。 【若需查看原始图片详情，请参考原文中的“卷积步长与Padding示例图”】","224-多输入多输出#2.2.4 多输入多输出":"过程描述 (原始资料第18页图示的文字描述): 如果输入是 Wi×Hi×CiW_i \\times H_i \\times C_iWi​×Hi​×Ci​ (高、宽、输入通道数)。 我们使用多个滤波器。每个滤波器 (例如 K×K×CiK \\times K \\times C_iK×K×Ci​) 作用于输入特征图，生成一个输出通道 (如前所述)。 如果我们有 CoC_oCo​ 个不同的滤波器，那么它们会分别生成 CoC_oCo​ 个输出通道。 最终的输出特征图尺寸将是 Wo×Ho×CoW_o \\times H_o \\times C_oWo​×Ho​×Co​ (高、宽、输出通道数)。 关键点： 不同的滤波器可以检测不同的特征。例如，一个滤波器可能检测垂直边缘，另一个检测水平边缘，第三个检测特定颜色模式。 【若需查看原始图片详情，请参考原文中的“多输入特征图多输出特征图卷积运算示意图”】","225-参数总结#2.2.5 参数总结":"输入： Wi×Hi×CiW_i \\times H_i \\times C_iWi​×Hi​×Ci​ (宽度、高度、输入通道数) 输出： Wo×Ho×CoW_o \\times H_o \\times C_oWo​×Ho​×Co​ (宽度、高度、输出通道数) Wo=Wi+2p−Ks+1W_o = \\frac{W_i + 2p - K}{s} + 1Wo​=sWi​+2p−K​+1 Ho=Hi+2p−Ks+1H_o = \\frac{H_i + 2p - K}{s} + 1Ho​=sHi​+2p−K​+1 滤波器 (Filter/Kernel)： 可训练参数。每个滤波器的大小通常为 K×K×CiK \\times K \\times C_iK×K×Ci​。 卷积层中共有 CoC_oCo​ 个这样的滤波器，它们共同生成输出的 CoC_oCo​ 个通道。 因此，一个卷积层中滤波器的总参数量为 Co×K×K×CiC_o \\times K \\times K \\times C_iCo​×K×K×Ci​。 偏置 (Bias)： 可训练参数。每个输出通道通常对应一个偏置项。 总偏置参数量为 1×1×Co1 \\times 1 \\times C_o1×1×Co​ (每个输出通道一个偏置)。 作用： 偏置项允许分类器偏离激活函数原点，增加模型的灵活性，使其能够更好地拟合数据。 激活函数 (Activation Function)： 卷积操作后通常会接着一个非线性激活函数 (如 ReLU)，为网络引入非线性能力，使其能够学习更复杂的模式。 超参数： 步长 (stride)： 滤波器滑动的步长。 填充 (pad)： 边界填充的大小。 滤波器尺寸 (K)： 滤波器的高度和宽度。 输出通道数 (Co)： 卷积层生成的特征图通道数，也代表了滤波器/特征的数量。","23-池化层-pooling-layer#2.3 池化层 (Pooling Layer)":"","231-作用与类型#2.3.1 作用与类型":"作用： 池化层的主要功能是主动减小特征图的尺寸，从而： 减少参数的数量和计算量： 降低网络的复杂度。 控制过拟合 (Overfitting)： 通过减少特征维度，使模型对输入的变化更具鲁棒性。 提取主要特征： 保留最重要的信息。 特点： 池化层不引入额外的参数，因为它执行的是固定的统计操作 (如取最大值、平均值)。 主要类型： 最大池化 (Max Pooling)： 从池化区域中选择最大的元素作为输出。 平均池化 (Average Pooling)： 计算池化区域中所有元素的平均值作为输出。 L2 池化 (L2 Pooling)： 计算池化区域中元素平方和的平方根作为输出。","232-max-pooling-特点#2.3.2 Max Pooling 特点":"过程描述 (原始资料第20页图示的文字描述): 假设有一个 6×66 \\times 66×6 的输入特征图。 使用一个 2×22 \\times 22×2 的滤波器 (这里称为池化窗口)。 设置 Padding p=0p=0p=0，步长 s=2s=2s=2。 Max Pooling 在每个 2×22 \\times 22×2 的窗口内，选择最大的数值作为输出。 例如，在输入特征图的左上角 2×22 \\times 22×2 区域 [2, 3; 7, 4] 中，最大值是 7，所以输出为 7。 输出特征图尺寸将变为 3×33 \\times 33×3。 优势： Max Pooling 能够保留特征的最大值，这意味着它主要关注每个区域中响应最强的特征。这有助于提高提取特征的鲁棒性，使其对特征在输入中的微小位置变化不那么敏感 (即平移不变性)。 【若需查看原始图片详情，请参考原文中的“Max Pooling 示例图”】","24-全连接层-fully-connected-layer#2.4 全连接层 (Fully Connected Layer)":"","241-作用#2.4.1 作用":"在卷积神经网络中，卷积层和池化层主要充当特征提取器，它们从原始输入中学习并提取出抽象的、高层次的特征表示。 全连接层 (FC) 则作为网络的分类器。它将前一层 (通常是最后一个池化层或卷积层) 提取到的高维特征图展平 (flatten) 成一维特征向量。 这个一维特征向量包含了图像中所有重要的特征信息，然后被全连接层进一步处理，最终映射到各个类别的概率。","242-softmax-激活函数#2.4.2 Softmax 激活函数":"位置： Softmax 函数通常作为网络的最后一层，尤其是在执行多类别分类任务时。 作用： 它将全连接层输出的原始分数 (logits) 转换成一个概率分布。这个概率分布的所有元素都在 0 到 1 之间，并且它们的和为 1。 特点： 归一化： 将任意实数值归一化为概率值。 凸显最大值： Softmax 函数的指数特性会凸显其中最大的值，同时抑制远低于最大值的其他分量。这意味着，模型对某个类别的置信度越高，该类别的输出概率就越接近 1，而其他类别的概率则趋近于 0。 公式： 对于输入向量 z=[z1,z2,…,zn]z = [z_1, z_2, \\dots, z_n]z=[z1​,z2​,…,zn​]，Softmax 函数的输出 f(z)jf(z)_jf(z)j​ (即第 jjj 个类别的概率) 为： f(z)j=ezj∑i=0nezif(z)_j = \\frac{e^{z_j}}{\\sum_{i=0}^{n} e^{z_i}}f(z)j​=∑i=0n​ezi​ezj​​ 其中 nnn 是类别的总数。","25-卷积神经网络总体结构#2.5 卷积神经网络总体结构":"","251-层排列规律#2.5.1 层排列规律":"典型的卷积神经网络由以下几种层构成： 卷积层 (Conv Layer)： 负责特征提取。 激活函数 (ReLU)： 通常紧跟在卷积层之后，引入非线性。 池化层 (Pool Layer)： 负责下采样和特征聚合。 全连接层 (FC Layer)： 负责分类。 Softmax 层： 通常是网络的最后一层，输出分类概率。 常见排列方式 (原始资料第22页图示的文字描述): 一个常见的模式是重复组合 Conv + ReLU，然后接一个 Pool 层。 在特征提取部分完成后，通常会接一个或多个 FC + ReLU 层。 最后是一个 FC 层，然后是 Softmax 层，输出最终的分类结果。 示例： 如果设置重复次数 N=3, M=1, P=2 (N次 Conv+ReLU，M次Pool，P次FC+ReLU)，那么网络结构可能为： Input → (Conv + ReLU) x3 → Pool → (FC + ReLU) x2 → FC → Softmax (Output) 【若需查看原始图片详情，请参考原文中的“卷积神经网络层排列规律示意图”】","252-经典网络示例-vgg16#2.5.2 经典网络示例 (VGG16)":"VGG16 结构概览 (原始资料第23页图示的文字描述): VGG16 是一个经典的深度卷积神经网络，以其简洁和深度而闻名。 输入： 224x224 像素的 RGB 图像。 特征提取部分 (由多个卷积层和池化层组成)： Conv1 (2层): 两个 3×33 \\times 33×3 卷积层，输出 64 个通道。 Maxpool1: 最大池化层，尺寸减半 (112x112)。 Conv2 (2层): 两个 3×33 \\times 33×3 卷积层，输出 128 个通道。 Maxpool2: 最大池化层，尺寸减半 (56x56)。 Conv3 (3层): 三个 3×33 \\times 33×3 卷积层，输出 256 个通道。 Maxpool3: 最大池化层，尺寸减半 (28x28)。 Conv4 (3层): 三个 3×33 \\times 33×3 卷积层，输出 512 个通道。 Maxpool4: 最大池化层，尺寸减半 (14x14)。 Conv5 (3层): 三个 3×33 \\times 33×3 卷积层，输出 512 个通道。 Maxpool5: 最大池化层，尺寸减半 (7x7)。 分类部分 (由全连接层组成)： FC1: 4096 个神经元的全连接层。 FC2: 4096 个神经元的全连接层。 FC3: 1000 个神经元的全连接层 (对应 ImageNet 的 1000 个类别)。 Softmax: 最后一层，输出 1000 个类别的概率。 VGG 的设计哲学： VGG 网络大量使用了小尺寸 (3×33 \\times 33×3) 的卷积核，通过堆叠多个这样的卷积层来增加网络的深度，从而学习到更复杂的特征，同时保持较小的感受野。 【若需查看原始图片详情，请参考原文中的“VGG16网络结构图”】","253-神经网络可视化-浅层与深层特征#2.5.3 神经网络可视化 (浅层与深层特征)":"概念： 神经网络可视化技术可以帮助我们理解网络内部各层学习到的特征。 观察结果： 浅层 (例如 VGG16 的 Conv1)： 倾向于学习到局部、通用、低级的特征，例如边缘 (水平、垂直、对角线)、颜色斑块、纹理等。这些特征在不同的图像中是通用的。 深层 (例如 VGG16 的 Conv5 或更深层)： 学习到的是整体、抽象、高级的特征，这些特征更接近于人类可以理解的语义概念。例如，它们可能检测到眼睛、鼻子、车轮、建筑物的特定部分等。这些特征通常是任务特定的，并且与最终的分类目标密切相关。 意义： 这种由浅入深的特征学习过程是卷积神经网络强大的原因之一。 【若需查看原始图片详情，请参考原文中的“神经网络可视化示意图”】","26-应用于图像分类的卷积神经网络#2.6 应用于图像分类的卷积神经网络":"图像分类是深度学习最早取得突破性进展的应用之一，以下是一些经典的卷积神经网络模型，它们在图像分类任务上表现出色，并推动了该领域的发展： AlexNet： 开创性的工作，证明了深度CNN在大型数据集上的有效性。 VGG： 以其深而统一的结构 (大量堆叠 3×33 \\times 33×3 卷积核) 闻名，提供了深入理解网络深度的基础。 Inception 系列 (如 GoogLeNet)： 引入了 Inception 模块，通过多尺度卷积核并行处理，有效地捕捉不同尺度的特征，同时控制了参数量。 ResNet (Residual Network)： 引入了残差连接 (residual connection)，解决了深度网络训练中的梯度消失和退化问题，使得网络可以训练得非常深。","27-应用于目标检测的卷积神经网络#2.7 应用于目标检测的卷积神经网络":"目标检测是计算机视觉的核心任务之一，它不仅要识别图像中的物体类别，还要准确地标定出它们的位置。","271-任务对比-分类-vs-定位分类#2.7.1 任务对比 (分类 vs. 定位+分类)":"特征 图像分类 (Image Classification) 目标检测 (Object Detection) 输入 单一大型物体图像 (single and big object) 包含多个小型物体的图像 (multi and small object) 任务 理解图像内容 (识别图像的整体类别) 理解图像内容 + 定位图像中的物体 (识别物体类别并给出边界框) 输出 类别标签 (label) 类别标签 \u0026 边界框 (label \u0026 bounding box) 评价指标 准确率 (precision, top-1/top-5 accuracy) IoU (交并比), mAP (Mean Average Precision) 核心问题 图像中有什么？ 图像中有什么？在哪里？有多少个？","272-评测指标#2.7.2 评测指标":"","2721-iou-交并比#2.7.2.1 IoU (交并比)":"定义： IoU (Intersection over Union) 是用于衡量定位准确度的指标。它计算预测边界框 (predicted bounding box) 与真实边界框 (ground truth bounding box) 之间交集面积与并集面积的比值。 计算公式： IoU=Area of OverlapArea of UnionIoU = \\frac{\\text{Area of Overlap}}{\\text{Area of Union}}IoU=Area of UnionArea of Overlap​ 判断标准： 通常，当 IoU 大于或等于 0.5 时，我们认为预测的边界框是成功的定位 (true detection)。不同的数据集和任务可能会有不同的 IoU 阈值要求，例如 COCO 数据集通常使用 0.5 到 0.95 之间多个 IoU 阈值的平均值来评估。 图示说明 (原始资料第27页图示的文字描述): IoU 的计算涉及到两个矩形框，一个表示模型的预测，另一个表示真实的标注。交集是两个框重叠的部分，并集是两个框覆盖的总面积。 【若需查看原始图片详情，请参考原文中的“IoU示意图”】","2722-map-mean-average-precision-平均精度均值#2.7.2.2 mAP (Mean Average Precision 平均精度均值)":"定义： mAP 是计算机视觉领域用于衡量模型在测试集上检测精度优劣程度的关键指标。它综合考虑了检测结果的召回率 (recall) 和精度 (precision)。 特点： mAP 值越高表示检测结果越好，因为它反映了模型在不同置信度阈值下的综合性能。","27221-召回率与精度#2.7.2.2.1 召回率与精度":"召回率 / 查全率 (Recall)： 定义： 在所有真实的正样本中，模型成功检测到的正样本的比例。 公式： Recall=TPTP+FNRecall = \\frac{TP}{TP + FN}Recall=TP+FNTP​ TP (True Positives)： 被模型正确识别为正样本的真实正样本。 FN (False Negatives)： 未被模型识别为正样本的真实正样本 (漏检)。 直观理解： 模型“找出了多少个”它应该找出来的东西。 精度 / 查准率 (Precision)： 定义： 在所有模型预测为正样本的样本中，真实为正样本的比例。 公式： Precision=TPTP+FPPrecision = \\frac{TP}{TP + FP}Precision=TP+FPTP​ FP (False Positives)： 被模型错误识别为正样本的真实负样本 (误报)。 直观理解： 模型“找出来的东西有多少是正确的”。 召回率与精度的权衡： 召回率和精度之间通常存在此消彼长的关系。 提高召回率： 通过降低置信度阈值，模型会检测出更多的样本，包括更多的真实正样本，从而提高召回率。但这通常也会导致更多的误报，从而降低精度。 提高精度： 通过提高置信度阈值，模型只会保留最确信的预测结果，减少误报，从而提高精度。但这可能导致漏检一些真实正样本，从而降低召回率。","27222-map-计算原理与示例#2.7.2.2.2 mAP 计算原理与示例":"计算步骤： 对每个类别 (class) 分别计算平均精度 (Average Precision, AP)。 将所有类别的 AP 值求平均，得到 mAP。 AP 计算原理 (VOC2012 标准，原始资料第30页和第31页图示的文字描述): 准备数据： 假设对某个类别 A 进行检测。我们有 100 张测试图像，其中共有 25 个真实标注为 A 的物体。模型检测出了 20 个分类为 A 的候选框，每个候选框都有一个置信度分数 (confidence score) 和一个标记 (label，表示该预测是否正确，通常通过 IoU 阈值判断)。 排序： 首先，将所有预测框按照置信度分数从高到低排序。 计算 Precision 和 Recall 曲线： 逐个遍历排序后的预测框。每增加一个预测框，就重新计算当前的 TP、FP、FN，并更新 Precision 和 Recall 值。 例如，在原始资料的示例中： 当置信度阈值设置为 0.5 时，有 4 个预测框被认为是正样本 (score \u003e 0.5)。其中 3 个是 True Positive (TP)，1 个是 False Positive (FP)。那么此时 Precision = 3/4，Recall = 3/25 (总共有 25 个真实正样本)。 当置信度阈值设置为 0.2 时，有 12 个预测框被认为是正样本 (score \u003e 0.2)。其中 5 个是 TP。那么此时 Precision = 5/12，Recall = 5/25。 PR 曲线： 绘制 Precision-Recall 曲线，横轴为 Recall，纵轴为 Precision。 AP 计算 (VOC2012)： 对于 PR 曲线上的每个 Recall 值 (从 0 到 1)，取其对应的最大 Precision 值 (即在该 Recall 值及更高的 Recall 值中，Precision 的最大值)，然后对这些最大 Precision 值进行插值求平均。 更直观的看法： AP 相当于 PR 曲线下面的面积。这个面积越大，表示模型在该类别上的检测性能越好。 【若需查看原始图片详情，请参考原文中的“mAP计算示例表格和PR曲线图”】","273-基于cnn的目标检测算法分类#2.7.3 基于CNN的目标检测算法分类":"目前，基于深度学习的目标检测算法大致可以分为两大类：","2731-两阶段-two-stage-算法#2.7.3.1 两阶段 (Two-stage) 算法":"核心思想： 这类算法首先生成候选区域 (Region Proposals)，然后再对这些候选区域进行分类和边界框回归。 过程： 阶段一： 通过一个独立的子网络 (例如 RPN, Region Proposal Network) 快速地在图像中生成一系列可能包含物体的候选框。 阶段二： 对这些候选框进行特征提取 (通常通过 RoI Pooling/Align 等操作)，然后送入分类器判断物体类别，并进一步进行边界框的精细调整 (回归)。 代表算法： R-CNN 系列 (R-CNN, SPP-Net, Fast R-CNN, Faster R-CNN, Mask R-CNN, Cascade R-CNN 等)。 特点： 通常具有较高的检测精度，但速度相对较慢。","2732-一阶段-one-stage-算法#2.7.3.2 一阶段 (One-stage) 算法":"核心思想： 这类算法直接在输入图像上同时预测物体的类别和边界框，无需生成单独的候选区域步骤。 过程： 通过单个神经网络直接从输入图像中预测所有物体的边界框和对应的类别概率。 代表算法： YOLO (You Only Look Once) 系列 (YOLO, YOLOv2, YOLOv3, YOLOv4, YOLOv5, YOLOv6, YOLOv7, YOLOv8, YOLOX, YOLOR), SSD (Single Shot MultiBox Detector) 系列 (SSD, DSSD, DSOD, FSSD), RetinaNet, EfficientDet 等。 特点： 通常具有更快的检测速度，但精度可能略低于两阶段算法 (近年来差距正在缩小)。","2733-发展图谱#2.7.3.3 发展图谱":"详细分类 (原始资料第34页图示的文字描述): Two-stage (两阶段)： R-CNN 家族： R-CNN, SPP-Net, Fast R-CNN, Faster R-CNN (更好的特征网络如 HyperNet, MS-CNN, PVANet, Light-Head R-CNN; 更精确的 RPN 如 MR-CNN, FPN, CRAFT; 更完善的 ROI 分类如 R-FCN, CoupleNet, Mask R-CNN, Cascade R-CNN)。 目标后处理： OHEM (Online Hard Example Mining), Soft-NMS。 其他： A-Fast-RCNN。 One-stage (一阶段)： YOLO 家族： YOLO, YOLOv2, YOLOv3, YOLOv4, YOLOv5, YOLOv6, YOLOv7, YOLOv8, YOLOX, YOLOR。 SSD 家族： SSD, R-SSD, DSSD, DSOD, FSSD。 其他： OverFeat, RetinaNet, EfficientDet。 【若需查看原始图片详情，请参考原文中的“目标检测算法发展图谱”】","28-应用于图像生成的卷积神经网络#2.8 应用于图像生成的卷积神经网络":"","281-生成模型与判别模型#2.8.1 生成模型与判别模型":"在深度学习中，模型可以大致分为两类：\n判别模型 (Discriminative Model)： 任务： 主要用于图像识别、分类、分割等任务。 学习目标： 学习输入数据 x 到输出标签 y 的映射关系 P(y∣x)P(y|x)P(y∣x)，即判别输入数据属于哪个类别。 示例： 输入一张猫的图片，判别模型会输出“猫”这个标签，或者猫的概率为 0.9，狗的概率为 0.1。它只回答“是猫还是不是猫”，不关心猫本身是如何生成的。 直观理解： “Cat √ / Dog ×” (是猫，不是狗)。 生成模型 (Generative Model)： 任务： 主要用于图像生成、数据合成、数据分布学习等任务。 学习目标： 学习数据本身的模式或特征，甚至是整个数据分布 P(x)P(x)P(x) 或联合分布 P(x,y)P(x,y)P(x,y)。一旦学习到数据的分布，就可以从这个分布中生成新的样本。 示例： 通过学习大量猫的图片，生成模型可以生成一张全新的、逼真的猫的图片。 直观理解： 一类图像本质上是一组概率分布。生成模型的目标是找到一个模型分布 PθP_\\thetaPθ​ 来近似真实数据分布 PdataP_{data}Pdata​。一旦找到 PθP_\\thetaPθ​，就可以从中采样生成新数据。 【若需查看原始图片详情，请参考原文中的“生成模型学习数据分布示意图”】","282-生成对抗网络-gan#2.8.2 生成对抗网络 (GAN)":"","2821-概述与核心思想#2.8.2.1 概述与核心思想":"提出者： Ian Goodfellow 在 2014 年 提出了生成式对抗网络 (Generative Adversarial Networks, GAN)。 重要性： 被 Yann LeCun (深度学习三巨头之一) 誉为“20年来机器学习领域最酷的想法”。 解决问题： 从训练样本中学习出新的、逼真的样本。为无监督学习和预测学习提供了强大的算法框架。 核心思想： 借鉴了博弈论的思想，通过让两个神经网络 (生成器和判别器) 相互对抗学习，从而达到共同进步的目的。这与苏格拉底的反诘法有异曲同工之妙。","2822-模型组成-生成器与判别器#2.8.2.2 模型组成 (生成器与判别器)":"GAN 由两个核心部分组成，它们相互竞争：\n生成器 G (Generator) - “伪装者/造假者”： 输入： 随机噪声 z (通常是高斯噪声)。 任务： 找出观测数据内部的统计规律，并尝试生成能够以假乱真的样本 (G(z))。 目标： 尽可能愚弄判别器，使判别网络输出接近 0.5 (即判别器难以区分真假样本)。 判别器 D (Discriminator) - “警察/鉴别者”： 输入： 真实样本 x 或生成器生成的假样本 G(z)。 任务： 判断输入数据是来自真实样本集 (real data) 还是生成样本集 (fake data)。 目标： 如果输入是真样本 x，输出接近 1 (表示“真”)。 如果输入是生成样本 G(z)，输出接近 0 (表示“假”)。 关系： 生成器和判别器构成一个动态的零和博弈：生成器努力生成更好的假样本，判别器努力区分真假，两者在对抗中不断提升性能，直到生成器能够生成与真实数据难以区分的样本，此时判别器将无法做出准确判断（输出 0.5）。 【若需查看原始图片详情，请参考原文中的“生成对抗网络结构示意图”】","2823-训练过程#2.8.2.3 训练过程":"GAN 的训练是一个交替迭代的优化过程：\n训练判别器 D： 目标： 使判别器能够准确地区分真实样本和生成样本。 输入： 一批真实样本 x (标签为 1) 和一批生成样本 G(z) (标签为 0)。 优化： 更新判别网络的权重参数，使其在输入真实样本时输出接近 1，在输入生成样本时输出接近 0。 训练生成器 G： 目标： 使生成器能够生成足以欺骗判别器的假样本。 输入： 随机噪声 z，通过生成器生成假样本 G(z)。 优化： 更新生成网络的权重参数，使其生成的假样本 G(z) 被判别器判断为接近 1 (即判别器认为它是真的)。这意味着生成器要最小化 1−D(G(z))1 - D(G(z))1−D(G(z))。 交替迭代： 这两个步骤交替进行，形成一个极小极大博弈 (Minimax Game) 或零和博弈。理想情况下，最终达到纳什均衡，此时生成器能生成完美的假样本，判别器对任何输入都输出 0.5。 图示说明 (原始资料第39页图示的文字描述): 展示了判别网络和生成网络在训练过程中参数更新的方向和目标。 【若需查看原始图片详情，请参考原文中的“GAN训练过程示意图”】","2824-条件gan-conditional-gan-cgan#2.8.2.4 条件GAN (Conditional GAN, cGAN)":"问题： 原始 GAN 的生成器输入是纯随机噪声，这意味着它生成的样本模式是不可控的。我们无法指定生成器生成特定类别或具有特定属性的图像。 解决方案： 条件 GAN (cGAN) 通过在生成器和判别器的输入中增加额外的条件信息 (category condition) 来解决这个问题。 实现： 生成器： 输入随机噪声 z 和条件信息 c (例如，一个类别的 one-hot 编码向量)。生成器学习生成符合条件 c 的样本 G(z, c)。 判别器： 输入样本 (真实样本或生成样本) 和条件信息 c。判别器学习判断输入的样本和条件信息是否匹配 (例如，判断输入图像是否真的是一只狗，并且与条件“狗”相符)。 效果： cGAN 能够实现对生成过程的控制，例如生成指定数字的图像、生成具有特定属性的人脸等。 【若需查看原始图片详情，请参考原文中的“条件GAN输入输出示例图”】","2825-常见gan结构与应用#2.8.2.5 常见GAN结构与应用":"GAN 结构演变： DCGAN (Deep Convolutional GAN)： 将 GAN 中的全连接神经网络扩展到卷积神经网络，使得 GAN 能够处理图像数据。 ResGAN： 结合残差网络 (ResNet) 思想的 GAN，常用于图像恢复等任务。 SRGAN： 用于超分辨率重建的 GAN，同样利用了 ResNet 结构。 CycleGAN： 能够实现图像风格转换，无需成对的训练数据。 CGAN (Conditional GAN)： 如前所述，引入条件信息实现可控生成。 InfoGAN： 学习可解释的、解耦的表示，使得生成的图像在某些维度上可控。 集成推断模型的 GAN (如 BiGAN)： 尝试学习数据的逆映射，即从数据推断出潜在编码。 对抗自编码器 (如 VAE-GAN)： 结合变分自编码器 (VAE) 和 GAN 的优势。 GAN 应用示例： 人脸生成： 生成逼真的人脸图像，例如不存在的人脸。 风格转换： 将一张图片的风格应用到另一张图片上，或将一种图像类型转换为另一种 (如将风景照转换为梵高风格画作)。 超分辨率 (Super Resolution)： 将低分辨率图像提升到高分辨率。 图像修复 (Inpainting)： 填充图像中缺失的部分。 数据增强： 生成额外的训练数据来扩充数据集。 文本到图像生成： 根据文本描述生成图像 (例如 DALL-E 早期版本)。 资源合集： GAN zoo：https://deephunt.in/the-gan-zoo-79597dc8c347 GAN 代码合集：https://github.com/zhangqianhui/AdversarialNetsPapers GAN 应用合集：https://github.com/nashory/gans-awesome-applications","283-扩散模型-diffusion-models#2.8.3 扩散模型 (Diffusion Models)":"","2831-概述与ddpm#2.8.3.1 概述与DDPM":"兴起： 扩散模型是一种相对较新的生成模型，2020 年提出的 DDPM (Denoising Diffusion Probabilistic Models) 在图像合成方面击败了 GAN，显示出强大的潜力。 核心思想： 破坏训练数据： 通过连续添加高斯噪声来逐步破坏训练数据，使其最终变为纯噪声。 学习恢复： 模型学习反转噪声过程，即学习如何从噪声中逐步去除噪声，从而恢复出原始数据。 测试时生成： 在生成新数据时，首先从随机采样的纯高斯噪声开始，然后通过模型学习到的去噪过程逐步将其转化为清晰的数据。","2832-标准过程-正向扩散与逆向扩散#2.8.3.2 标准过程 (正向扩散与逆向扩散)":"扩散模型的核心是两个相互对称的过程：\n正向扩散过程 (Forward Diffusion Process)： 目的： 帮助神经网络训练逆向过程。 机制： 这是一个固定的马尔可夫链过程。从原始数据 x0x_0x0​ 开始，在每个时间步 ttt，都向当前数据 xt−1x_{t-1}xt−1​ 逐步添加少量高斯噪声，生成 xtx_txt​。 结果： 经过足够多的时间步长 T 后，xTx_TxT​ 将完全变成纯高斯噪声，与原始数据几乎无关。 反向逆扩散过程 (Reverse Diffusion Process)： 目的： 这是模型需要学习的过程，用于从噪声中生成数据。 机制： 这是一个可训练的马尔可夫链过程。从一张纯高斯噪声图片 xTx_TxT​ 开始，通过一个可训练的神经网络 (例如 U-net 或去噪自编码器)，在每个时间步预测并去除噪声，逐步生成最终的清晰结果 x0x_0x0​。 核心： 神经网络需要学习每个时间步的噪声分布，以便能够准确地“去噪”。 【若需查看原始图片详情，请参考原文中的“扩散模型正向/逆向过程示意图”】","2833-扩散过程#2.8.3.3 扩散过程":"描述： 正向扩散过程是将数据从清晰状态逐步过渡到完全噪声状态。 细节： 它采用一个固定的马尔可夫链，这意味着每个时间步 xtx_txt​ 只依赖于前一个时间步 xt−1x_{t-1}xt−1​。在每个时间步，都会向 xt−1x_{t-1}xt−1​ 添加少量预定义的高斯噪声。 最终状态： 最终，当时间步 ttt 达到 TTT 时，xTx_TxT​ 将成为一个纯粹的高斯噪声，与原始图像失去了所有可识别的联系。","2834-逆扩散过程#2.8.3.4 逆扩散过程":"描述： 逆扩散过程是从纯噪声开始，逐步恢复原始数据的过程。 细节： 从一张标准高斯噪声图片 xTx_TxT​ 开始。 通过一个可训练的网络 (如 U-net 或者去噪自编码器等)，该网络被训练来预测并减去每个时间步添加的噪声。 这个过程也是一个马尔可夫链，可以被定义为 Pθ(xt−1∣xt)P_\\theta(x_{t-1}|x_t)Pθ​(xt−1​∣xt​)，其中 θ\\thetaθ 是网络的参数。 通过逐步迭代这个去噪过程，最终可以从 xTx_TxT​ 生成出高质量的 x0x_0x0​。","2835-扩散模型-vs-gans#2.8.3.5 扩散模型 vs. GANs":"扩散模型与生成对抗网络 (GANs) 在生成能力和训练稳定性上存在显著差异：\n生成对抗网络 (GAN) 存在的问题： 生成图像缺乏多样性： 判别器可能会引导生成器收敛到数据分布的一个子集，导致生成样本缺乏多样性。 模式崩溃 (Mode Collapse)： 这是多样性缺乏的极端表现，生成器可能只生成少数几种模式的样本，而忽略了数据分布中的其他模式。例如，在生成人脸时，可能只生成特定表情或特定肤色的人脸。 对抗性带来的难以训练： GAN 的训练是一个不稳定的对抗过程，需要精心调整超参数，容易出现梯度消失、梯度爆炸或模式崩溃，导致训练难以收敛。 扩散模型的优势： 训练更容易： 扩散模型的训练过程没有对抗，其优化目标通常更稳定，更容易收敛。 不会受到模式崩溃的影响： 由于扩散模型通过学习整个噪声分布来逐步去噪，它能够更好地覆盖整个数据分布，从而避免了模式崩溃的问题，生成样本的多样性更高。 能够产生多样化图像： 相较于 GAN，扩散模型在生成图像的多样性和质量方面往往表现更出色。","3-适合语音文本处理的循环神经网络#3. 适合语音/文本处理的循环神经网络":"","31-循环神经网络概述#3.1 循环神经网络概述":"","311-任务特点与能力要求#3.1.1 任务特点与能力要求":"传统的神经网络（如前馈神经网络）在处理序列数据时存在局限性，因为它们假设输入是相互独立的。然而，在语音、文本等序列数据中，数据点之间往往存在时序上的相关性，即前一个数据点会影响后一个数据点。\n因此，处理这类任务的网络必须具备以下能力：\n捕捉时序依赖：能够理解和利用序列中不同时间步之间的关联性。 记忆信息：网络需要有“存储”信息的能力，以便在处理当前输入时能够回顾和利用之前时间步的信息。","312-主要应用场景#3.1.2 主要应用场景":"循环神经网络 (RNN) 因其处理序列数据的能力，在多种领域得到了广泛应用：\n机器翻译：将一种语言的句子序列翻译成另一种语言的句子序列。 图片描述 (Image Captioning)：根据输入的图片生成描述性文本序列。 视频标注 (Video Annotation)：对视频中的连续帧进行分析并生成对应的文本描述或标签序列。 视觉问答 (Visual Question Answering)：结合图像内容和自然语言问题，生成自然语言答案。 文本生成：如聊天机器人、代码生成等。 情感分析 (Sentiment Analysis)：分析文本序列（如评论）以判断其情感倾向。 语音识别：将语音信号序列转换为文本序列。 进一步了解RNN及其应用，可参考GitHub项目：Awesome Recurrent Neural Networks。","32-循环神经网络结构#3.2 循环神经网络结构":"","321-核心原理#3.2.1 核心原理":"循环神经网络通过引入带自反馈的神经元来处理任意长度的序列数据。其核心思想是，隐藏状态 h(t) 不仅与当前时刻的输入 x(t) 相关，还与上一时刻的隐藏状态 h(t-1) 相关。这种循环连接使得网络能够将信息从序列的前面部分传递到后面部分，从而实现对序列数据的记忆。\n时序 (Sequence)：RNN能够建模序列数据，即前、后输入数据 x(t) 和 x(t+1) 之间不是相互独立的，而是相互影响的。 循环 (Recurrent)：对每个输入时间步执行的操作是相同的，循环往复地重复这些操作。这意味着在不同时间步，网络会共享相同的参数 W 和 U。 记忆 (Memory)：隐藏层 h(t) 捕捉了所有时刻 t 之前的信息。理论上，h(t) 记忆的内容可以无限长，但实际上受限于梯度问题，其记忆能力是有限的。 数学表达式为： h(t)=f(Wh(t−1)+Ux(t)+b)h^{(t)} = f(W h^{(t-1)} + U x^{(t)} + b)h(t)=f(Wh(t−1)+Ux(t)+b) 其中，fff 是非线性激活函数，常用 tanh 或 ReLU。\n[原始文档中的“unfold”示意图]： 原始的RNN结构（左侧）在时间维度上可以展开（右侧），形成一个多层前馈网络，每一层代表序列中的一个时间步。 【若需查看原始图片详情，请参考原文中的“循环神经网络结构”示意图】。","322-多种输入-输出结构#3.2.2 多种输入-输出结构":"RNN可以根据任务需求，设计不同的输入-输出结构：\n一对多 (One-to-many)： 输入：一个单一的输入（如图片）。 输出：一个序列（如图片描述）。 示例：Image Captioning (图片描述)。 多对一 (Many-to-one)： 输入：一个序列（如电影评论）。 输出：一个单一的输出（如情感分类）。 示例：Sentiment Analysis (情感分析)。 多对多 (Many-to-many, 序列长度不同)： 输入：一个序列（如源语言句子）。 输出：一个不同长度的序列（如目标语言句子）。 示例：Machine Translation (机器翻译)。 多对多 (Many-to-many, 同步)： 输入：一个序列（如视频帧）。 输出：一个相同长度的序列，每个输出对应一个输入。 示例：Video Classification (视频分类，标注每一帧)。 多对多 (Many-to-many, 延迟)： 输入：一个序列。 输出：一个序列，但输出相对于输入有延迟（如视频标注，先看完部分视频再开始输出）。 示例：Video Caption (视频字幕)。 值得注意的是，RNN对输入序列的长度没有预先定义的要求，可以处理任意长度的序列。","323-正向计算过程#3.2.3 正向计算过程":"RNN的正向计算是从序列的第一个时间步到最后一个时间步依次进行的。\n初始时刻： 通常将初始隐藏状态 h(0)h^{(0)}h(0) 设为一个全零向量。 一般时刻 ttt： 计算隐藏状态： h(t)=f(Wh(t−1)+Ux(t)+b)h^{(t)} = f(W h^{(t-1)} + U x^{(t)} + b)h(t)=f(Wh(t−1)+Ux(t)+b) 其中，fff 是激活函数 (如 tanh 或 ReLU)。 计算输出： o(t)=Vh(t)+co^{(t)} = V h^{(t)} + co(t)=Vh(t)+c 计算预测值： y^(t)=softmax(o(t))\\hat{y}^{(t)} = \\text{softmax}(o^{(t)})y^​(t)=softmax(o(t)) （对于分类任务，softmax 函数将输出归一化为概率分布）。 在整个时间序列上，参数 WWW (连接 h(t−1)h^{(t-1)}h(t−1) 到 h(t)h^{(t)}h(t))、UUU (连接 x(t)x^{(t)}x(t) 到 h(t)h^{(t)}h(t))、VVV (连接 h(t)h^{(t)}h(t) 到 o(t)o^{(t)}o(t)) 和偏置 bbb, ccc 都是共享的。这意味着网络在处理序列的不同部分时使用相同的“转换规则”。\n[原始文档中的“RNN cell”示意图]： 该图展示了RNN在单个时间步内的计算流程。输入 xtx_txt​ 和前一时刻隐藏状态 ht−1h_{t-1}ht−1​ 分别通过权重 UUU 和 WWW 进行线性变换，然后与偏置 bbb 相加，经过激活函数 fff 得到当前时刻隐藏状态 hth_tht​。hth_tht​ 接着通过权重 VVV 和偏置 ccc 生成输出 oto_tot​，最终通过 softmax 得到预测输出 y^t\\hat{y}_ty^​t​。 【若需查看原始图片详情，请参考原文中的“RNN cell”示意图】。","324-反向传播-bptt---back-propagation-through-time#3.2.4 反向传播 (BPTT - Back-Propagation Through Time)":"RNN的训练通常采用BPTT算法，它是标准反向传播算法在时间维度上的扩展。由于RNN在时间维度上展开成一个深层网络，BPTT就是在这个展开的网络上执行反向传播。\n单个时刻 ttt 的损失函数： L(t)=−∑jyj(t)ln⁡y^j(t)L^{(t)} = -\\sum_{j} y_j^{(t)} \\ln \\hat{y}_j^{(t)}L(t)=−∑j​yj(t)​lny^​j(t)​ （这里以交叉熵损失为例，yj(t)y_j^{(t)}yj(t)​ 是真实标签的one-hot编码）。 整个序列的总损失函数： L=∑t=1τL(t)=−∑t=1τ∑jyj(t)ln⁡y^j(t)L = \\sum_{t=1}^{\\tau} L^{(t)} = -\\sum_{t=1}^{\\tau} \\sum_{j} y_j^{(t)} \\ln \\hat{y}_j^{(t)}L=∑t=1τ​L(t)=−∑t=1τ​∑j​yj(t)​lny^​j(t)​ 其中 τ\\tauτ 是序列的长度。 BPTT的关键在于计算损失函数 LLL 对网络参数 (如 WWW, UUU, VVV) 的梯度。例如，对参数 WWW 的偏导数需要考虑 WWW 对所有时刻的损失 L(t)L^{(t)}L(t) 的影响，并且每个时刻 ttt 的隐藏状态 h(t)h^{(t)}h(t) 都依赖于前一时刻的隐藏状态 h(t−1)h^{(t-1)}h(t−1)，这种依赖关系会沿着时间反向传播。\n计算 WWW 的梯度时，需要将所有时间步的梯度贡献进行累加： ∂L∂W=∑t=1τ∂L(t)∂W\\frac{\\partial L}{\\partial W} = \\sum_{t=1}^{\\tau} \\frac{\\partial L^{(t)}}{\\partial W}∂W∂L​=t=1∑τ​∂W∂L(t)​ 其中，∂L(t)∂W\\frac{\\partial L^{(t)}}{\\partial W}∂W∂L(t)​ 需要通过链式法则沿着时间步反向展开，这导致了导数的递归展开： ∂L(t)∂W=∑k=1t∂L(t)∂y^(t)∂y^(t)∂h(t)∂h(t)∂h(k)∂h(k)∂W\\frac{\\partial L^{(t)}}{\\partial W} = \\sum_{k=1}^{t} \\frac{\\partial L^{(t)}}{\\partial \\hat{y}^{(t)}} \\frac{\\partial \\hat{y}^{(t)}}{\\partial h^{(t)}} \\frac{\\partial h^{(t)}}{\\partial h^{(k)}} \\frac{\\partial h^{(k)}}{\\partial W}∂W∂L(t)​=k=1∑t​∂y^​(t)∂L(t)​∂h(t)∂y^​(t)​∂h(k)∂h(t)​∂W∂h(k)​ 由于 h(t)h^{(t)}h(t) 依赖于 h(t−1)h^{(t-1)}h(t−1)，这个链式法则中会包含多个 ∂h(j)∂h(j−1)\\frac{\\partial h^{(j)}}{\\partial h^{(j-1)}}∂h(j−1)∂h(j)​ 因子。\n[原始文档中的“BPTT”示意图]： 此图展示了BPTT的原理。损失 L(t)L^{(t)}L(t) 不仅受当前时刻的 y^(t)\\hat{y}^{(t)}y^​(t) 影响，也间接地受 h(t)h^{(t)}h(t) 乃至更早的 h(t−1),h(t−2)h^{(t-1)}, h^{(t-2)}h(t−1),h(t−2) 的影响。因此，在计算梯度时，误差会沿着时间步反向传播，从 L(τ)L^{(\\tau)}L(τ) 传导到 L(1)L^{(1)}L(1)，并且每个时刻的梯度都会累加到共享参数上。 【若需查看原始图片详情，请参考原文中的“反向传播BPTT”示意图】。","325-梯度消失与梯度爆炸问题#3.2.5 梯度消失与梯度爆炸问题":"","3251-问题描述与影响#3.2.5.1 问题描述与影响":"由于RNN的递归结构和BPTT算法，导致在训练过程中梯度消失和梯度爆炸现象比普通深度前馈网络更为明显。\n梯度消失 (Vanishing Gradient)： 在BPTT计算梯度时，由于链式法则中包含多个雅可比矩阵的乘积 (如 ∂h(j)∂h(j−1)\\frac{\\partial h^{(j)}}{\\partial h^{(j-1)}}∂h(j−1)∂h(j)​)，如果这些矩阵的范数很小（例如，激活函数（如 sigmoid 或 tanh）的导数在饱和区接近于零），梯度就会随着时间步的增加呈指数级衰减，导致远离输出层的早期时间步的梯度变得非常小，几乎为零。 影响：网络难以学习长期依赖关系。例如，在一个语言模型中，预测“I grew up in Italy… I speak fluent Italian.”中的“Italian.”时，需要记住很久之前的“Italy”。如果梯度消失，网络就无法将“Italy”的信息有效地传导到后面，从而无法正确预测“Italian.”。这使得RNN在处理长序列时效果不佳。 梯度爆炸 (Exploding Gradient)： 与梯度消失相反，如果雅可比矩阵的范数很大，梯度就会随着时间步的增加呈指数级增长，导致梯度变得非常大。 影响：这会导致模型参数在训练过程中更新过大，使得网络训练不稳定，甚至出现NaN值，模型无法收敛。","3252-改进方法#3.2.5.2 改进方法":"解决梯度爆炸问题： 梯度截断 (Gradient Clipping)：这是一种相对简单且有效的技术，当梯度向量的范数超过某个预设阈值时，将其按比例缩放，使其范数回到阈值以内。这可以有效防止梯度过大，稳定训练过程。 解决梯度消失问题： 模型结构上的改进：这是更根本的解决方案，通过设计特殊的循环单元结构来缓解梯度消失问题，如长短期记忆网络 (LSTM) 和 门控循环单元 (GRU) 算法。这些结构通过引入“门”机制来更好地控制信息的流动，从而能够有效地学习和记忆长期依赖关系。","33-长短期记忆模型-lstm#3.3 长短期记忆模型 (LSTM)":"","331-核心思想与组件#3.3.1 核心思想与组件":"为了解决传统RNN的长期依赖问题（即梯度消失），长短期记忆网络 (Long Short-Term Memory networks, LSTM) 在1997年由 Hochreiter 和 Schmidhuber 提出。\nLSTM的核心在于其特殊的循环单元结构，它引入了单元状态 (Cell State) 和门限 (Gate) 机制，使得信息可以在单元状态中长期保存，并且可以通过门来精确控制信息的流动、添加或移除。\n隐藏状态 (Hidden State)：与传统RNN类似，但它更多地作为当前时间步的输出，并捕获短期信息。 单元状态 (Cell State)：这是LSTM的关键创新。它像一条信息传送带，贯穿整个链条，能够非常容易地让信息以不变的方式向下流动。它在长时间序列中保持相关信息的能力非常强大。 门限机制 (Gate Mechanism)：LSTM通过三个主要的“门”来管理信息，每个门都是一个sigmoid激活函数层和一个点乘操作的组合，输出一个0到1之间的数值，表示允许多少信息通过： 遗忘门 (Forget Gate)：决定从单元状态中“遗忘”哪些信息。 输入门 (Input Gate)：决定有多少新的信息应该被添加到单元状态中。 输出门 (Output Gate)：决定当前单元状态的哪些部分应该被“输出”到隐藏状态。","332-结构图与门限机制#3.3.2 结构图与门限机制":"[原始文档中的“LSTM”示意图]： 该图展示了一个LSTM单元在两个连续时间步 (ttt 和 t+1t+1t+1) 的内部结构。\n一个LSTM单元主要由以下几个部分组成：\n遗忘门 (ftf_tft​)：\n接收前一时刻的隐藏状态 ht−1h_{t-1}ht−1​ 和当前时刻的输入 xtx_txt​。 通过一个 sigmoid 函数输出一个介于0到1之间的向量，这个向量会与前一时刻的单元状态 ct−1c_{t-1}ct−1​ 进行逐元素相乘。值越接近0，表示遗忘越多；值越接近1，表示保留越多。 其计算公式为：ft=σ(Wf⋅[ht−1,xt]+bf)f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)ft​=σ(Wf​⋅[ht−1​,xt​]+bf​) 输入门 (iti_tit​) 和候选单元状态 (C~t\\tilde{C}_tC~t​)：\n输入门 (iti_tit​)：同样接收 ht−1h_{t-1}ht−1​ 和 xtx_txt​，通过一个 sigmoid 函数决定哪些新的信息需要更新到单元状态中。 候选单元状态 (C~t\\tilde{C}_tC~t​)：接收 ht−1h_{t-1}ht−1​ 和 xtx_txt​，通过一个 tanh 函数创建一个新的候选值向量，这些值可能会被添加到单元状态中。 其计算公式为： it=σ(Wi⋅[ht−1,xt]+bi)i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)it​=σ(Wi​⋅[ht−1​,xt​]+bi​) C~t=tanh(WC⋅[ht−1,xt]+bC)\\tilde{C}_t = \\text{tanh}(W_C \\cdot [h_{t-1}, x_t] + b_C)C~t​=tanh(WC​⋅[ht−1​,xt​]+bC​) 更新单元状态 (CtC_tCt​)：\n新的单元状态 CtC_tCt​ 是由旧的单元状态 Ct−1C_{t-1}Ct−1​ 经过遗忘门处理后，与输入门和候选单元状态的乘积相加而得到的。 其计算公式为：Ct=ft∗Ct−1+it∗C~tC_t = f_t * C_{t-1} + i_t * \\tilde{C}_tCt​=ft​∗Ct−1​+it​∗C~t​ 这个步骤是LSTM能够长期记忆信息的核心，它允许信息在时间步之间进行选择性地传递和更新。 输出门 (oto_tot​) 和隐藏状态 (hth_tht​)：\n输出门 (oto_tot​)：接收 ht−1h_{t-1}ht−1​ 和 xtx_txt​，通过一个 sigmoid 函数决定单元状态的哪些部分将作为当前隐藏状态输出。 隐藏状态 (hth_tht​)：通过将单元状态 CtC_tCt​ 经过 tanh 函数激活，再与输出门 oto_tot​ 进行逐元素相乘而得到。 其计算公式为： ot=σ(Wo⋅[ht−1,xt]+bo)o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)ot​=σ(Wo​⋅[ht−1​,xt​]+bo​) ht=ot∗tanh(Ct)h_t = o_t * \\text{tanh}(C_t)ht​=ot​∗tanh(Ct​) 图中的 WfW_fWf​, WiW_iWi​, WoW_oWo​, WcW_cWc​ 代表了连接不同输入（ht−1h_{t-1}ht−1​, xtx_txt​）到各个门的权重矩阵，它们是LSTM模型的可训练参数。\n【若需查看原始图片详情，请参考原文中的“长短期记忆模型”示意图】。","4-从深度学习到大模型#4. 从深度学习到大模型":"","41-注意力机制-attention-mechanism#4.1 注意力机制 (Attention Mechanism)":"","411-序列模型的问题与局限性#4.1.1 序列模型的问题与局限性":"在早期的序列模型，特别是基于循环神经网络 (RNN) 的 Seq2Seq 模型中，存在以下主要问题：\n固定长度的语义编码难以存储所有信息：编码器将输入序列编码成一个固定长度的语义向量（上下文向量）。当输入序列较长时，这个固定长度的向量很难捕获所有重要的信息，导致信息丢失，严重影响模型的性能。 语义编码中每个元素权重相同：传统的上下文向量对输入序列中的每个词或元素赋予相同的权重，模型无法区分不同部分的重要性，无法有选择性地关注与当前输出最相关的信息。","412-注意力机制的本质与优势#4.1.2 注意力机制的本质与优势":"为了解决上述问题，注意力机制被引入。\n本质：注意力机制的本质是分离特征的（重要性）和（内容）。它允许模型在处理序列数据时，动态地为输入序列的不同部分分配不同的权重，从而有选择性地关注最相关的信息。 工作方式：与串行整合特征不同，注意力机制通过权重加和特征来工作。它不强制将所有信息压缩到一个固定向量中，而是通过计算每个输入元素与当前任务的相关性，生成一个加权和表示。 优势： 抽取少量重要信息，忽略不重要信息：模型能够聚焦于对当前任务有用的少量关键信息，有效地过滤掉大量不重要的或冗余的信息。 归纳偏置：注意力机制的归纳偏置在于其任务需要的特征是轻重有别的，即并非所有输入元素都同等重要。 提升信息处理能力：它能有效提升基于 RNN（特别是 LSTM）的 Seq2Seq 模型的信息处理能力，使其能够更好地处理长序列并捕获长期依赖关系。 类比：注意力机制可以类比人类视觉神经系统的注意力机制。当人类观察一个场景时，并不会对场景中的每个像素都进行同等程度的加工，而是会根据任务需求（例如寻找特定物体）有选择性地将注意力集中在场景中的某些特定区域，从而更高效地获取所需信息。","413-自注意力机制-self-attention#4.1.3 自注意力机制 (Self-Attention)":"自注意力机制是注意力机制的一种特殊形式，其中查询（Query）、键（Key）和值（Value）都来源于同一组输入。它允许模型对输入序列内部的不同位置进行加权，从而更好地捕捉序列内部的相关性。\nTransformer Block：自注意力机制是 Transformer Block 的核心组成部分，而 Transformer Block 又是许多现代大型模型（如 GPT-2, GPT-3, BERT, RoBERTa, BART, T5 等）的基本构建单元。 文本特征表示：在自注意力机制中，文本特征的输入和输出仍然是序列长度 ×\\times× 词向量维度，不会发生压缩。 QKV 概念：对于输入序列中的每一个词或 token 的特征 XXX，通过线性变换生成三个部分： Q (Query)：查询向量，表示模型正在“寻找”或“提问”的信息。 K (Key)：键向量，表示每个 token “拥有”的信息。 V (Value)：值向量，表示每个 token “提供”的信息内容。 计算方法：自注意力机制的计算过程如下： 计算注意力分数：将查询向量 QQQ 与所有键向量 KKK 进行点积（内积）运算，得到一个注意力分数矩阵。这个分数衡量了查询与每个键的相似度。 缩放：为了防止点积结果过大导致 Softmax 梯度过小，将注意力分数除以 dk\\sqrt{d_k}dk​​ 进行缩放，其中 dkd_kdk​ 是键向量的维度。 归一化：对缩放后的分数应用 Softmax 函数，将其转化为概率分布，得到归一化的注意力权重。 加权和：将这些注意力权重与所有值向量 VVV 进行加权求和，得到最终的输出。 其数学表达式为： Attention(Q,K,V)=Softmax(QKTdk)VAttention(Q, K, V) = Softmax\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)VAttention(Q,K,V)=Softmax(dk​​QKT​)V 矩阵维度： QQQ (Query), KKK (Key), VVV (Value) 的维度通常为 [L,d][L, d][L,d]，其中 LLL 是序列长度， ddd 是向量维度。 QKTQK^TQKT 的维度为 [L,d]×[d,L]=[L,L][L, d] \\times [d, L] = [L, L][L,d]×[d,L]=[L,L]。这个矩阵表示序列中每个 token 对其他所有 token 的关注度。 最终输出的维度为 [L,L]×[L,d]=[L,d][L, L] \\times [L, d] = [L, d][L,L]×[L,d]=[L,d]。 优点与代价： 优点：自注意力机制擅长捕捉数据内部的相关性，能够有效地建模序列中任意两个位置之间的依赖关系。 代价：它会带来大量的计算和存储开销。注意力分数矩阵的维度为 [L,L][L, L][L,L]，这意味着计算复杂度和内存需求会随输入序列长度 LLL 的平方增加。 MASKED 机制：在某些场景（如生成式任务，如语言建模）中，为了防止模型在预测当前 token 时“偷看”未来的 token，会使用 MASKED 机制。这意味着在计算注意力时，每个 token 的向量计算只考虑自己和之前的 tokens，不需要每个 token 的生成都重新计算所有之前的 KV 内容，通过将未来 token 的注意力分数设置为负无穷（Softmax 后变为 0）来实现。","414-多头注意力-multi-head-attention#4.1.4 多头注意力 (Multi-Head Attention)":"多头注意力是对自注意力机制的扩展，旨在让模型能从不同的“表征子空间”（representation sub-spaces）中学习到不同的信息。\n原理：它通过并行运行多个独立的自注意力机制（称为“头”），每个头学习不同的方面或模式。最后将这些独立的注意力结果拼接起来，再经过一个线性变换，从而捕获更丰富、多样的信息。 计算过程： 线性变换：对原始的 Q,K,VQ, K, VQ,K,V 分别进行 hhh 组不同的线性变换，生成 hhh 组不同的 Qi,Ki,ViQ_i, K_i, V_iQi​,Ki​,Vi​。 并行计算注意力：对每一组 Qi,Ki,ViQ_i, K_i, V_iQi​,Ki​,Vi​ 并行计算一个自注意力结果 headihead_iheadi​。 拼接与线性映射：将 hhh 个 headihead_iheadi​ 结果拼接 (Concatenate) 起来，然后通过一个最终的线性变换 WOW^OWO 得到多头注意力的输出。 其数学表达式为： MultiHead(Q,K,V)=Concat(head1,...,headh)WOMultiHead(Q, K, V) = Concat(head_1, ..., head_h)W^OMultiHead(Q,K,V)=Concat(head1​,...,headh​)WO 其中，headi=Attention(QWiQ,KWiK,VWiV)head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)headi​=Attention(QWiQ​,KWiK​,VWiV​)。 这里，WiQ,WiK,WiVW_i^Q, W_i^K, W_i^VWiQ​,WiK​,WiV​ 是第 iii 个头的线性变换矩阵，WOW^OWO 是最终的线性变换矩阵。","42-transformer-架构#4.2 Transformer 架构":"","421-google-transformer-结构#4.2.1 Google Transformer 结构":"核心地位：Transformer 网络是自然语言处理 (NLP) 领域中常用且影响深远的模型之一。 与 Seq2Seq 类似：其宏观结构与传统的 Seq2Seq (Encoder-Decoder) 模型类似，都包括编码器 (Encoder) 和解码器 (Decoder) 两个主要部分。 组成单元：然而，Transformer 完全抛弃了循环和卷积结构，转而完全基于注意力机制（尤其是自注意力机制和多头注意力机制）来构建。 主要应用：它最初主要用于解决机器翻译等序列到序列的任务。 引用：该模型首次由 Ashish Vaswani 等人在 2017 年的论文 “Attention is All You Need” 中提出。","43-gpt-系列大型语言模型#4.3 GPT 系列大型语言模型":"","431-gpt-generative-pre-trained-transformer#4.3.1 GPT (Generative Pre-trained Transformer)":"结构与潜力：GPT 系列模型采用了 Transformer 解码器部分作为其主要架构。它通过单向的 Block 连接，使得模型在生成文本时只能依赖于其左侧（即之前）的上下文。这种设计展示了预训练模型在语言生成任务中的巨大潜力。 应用领域：GPT 模型被广泛应用于各种文本生成任务，例如文本自动完成、生成对话、文章摘要等。 LLM 的自回归特性： 目前的大型语言模型 (LLM) 主要以自回归 (autoregressive) 模型为主。 工作原理：给定之前生成或输入的 token 序列 x[1:i]x[1:i]x[1:i]，LLM 的核心任务是输出下一个 token x[i+1]x[i+1]x[i+1] 的概率分布。通过这种方式，模型可以递归地（一个接一个地）生成整个序列，从而完成推理过程。 计算方式：通常，模型会在最后一层、对最后一个 token 的输出特征应用 Softmax 函数来计算下一个 token 的概率分布。 GPT 的定义：GPT 代表着在大量原始数据上得到的生成语言模型。 架构特点：原始的 GPT 架构是一个 12 层的 Transformer。 学习目标：其主要学习目标是预测下一个 token，即通过观察大量文本数据来学习语言的统计规律和模式。","432-gpt-系列发展历程#4.3.2 GPT 系列发展历程":"GPT 系列模型的发展是大型语言模型领域进步的缩影，其核心思想是利用大规模预训练和模型规模化。\n4.3.2.1 GPT-1 (2018年6月)\n主要贡献：首次提出了预训练 (Pre-training) 和微调 (Fine-tuning) 的统一框架，奠定了后续大模型发展的基础。 架构：使用 Transformer 解码器结构。 数据与任务：在大规模规范化文本语料上进行预训练，之后通过微调适应具体的下游任务（如文本分类和标注性任务）。 规模：参数量为 1.17 亿，预训练数据量为 5GB。 4.3.2.2 GPT-2 (2019年2月)\n主要贡献：提出**“Language Models are Unsupervised Multitask Learners”**（语言模型是无监督的多任务学习器），强调模型通过无监督预训练就能解决各种不同的 NLP 任务，无需为每个任务单独微调。 核心观察：自然发生的任务演示，即所有 NLP 任务的示例都可以在自然文本中找到。 数据：引入了更大规模、更高质量的 WebText 数据集（包含 800 万个网页，大小约 40GB），极大地提升了模型的泛化能力。 规模：参数量大幅增加到 15 亿。 改进：还增加了词汇表大小和上下文窗口大小。 4.3.2.3 GPT-3 (2020年5月)\n主要贡献：提出了**“Language Models are Few-Shot Learners”（语言模型是少样本学习器），表明模型无需微调，仅通过与模型的文本交互（即提供少量任务相关的演示实例，称为in-context learning 或 few-shot learning**）就能指定和完成任务。 规模：参数量再次爆炸性增长至 1750 亿，是 GPT-2 的 100 多倍。 数据：预训练数据量达到惊人的 45TB。 In-context learning： 与梯度下降学习的区别： 梯度下降学习：提供特征和标签作为数据，模型通过优化算法自动学习它们之间的映射关系。 In-context learning：通过在输入文本中提供示例、描述问题、提供相关信息和定义答案格式来引导模型完成任务。 前提：当模型是一个元学习器 (meta-learner) 时，In-context learning 才成为可能。 4.3.2.4 GPT-1/2/3 对比\n模型 GPT-1 GPT-2 GPT-3 主要贡献 提出预训练和微调的统一框架 用无监督预训练模型做各种不同 NLP 任务 无需微调，利用少量演示指定任务 发布时间 2018年6月 2019年2月 2020年5月 参数量 1.17 亿 15 亿 1750 亿 数据量 5GB 40GB 45TB 4.3.2.5 CodeX (2021年8月)\n功能：一个能够输入自然语言，输出代码的模型。 训练方式：使用 GitHub 上的代码数据对 GPT-3 进行微调。 数据集：训练数据集为 159GB 从 GitHub 上筛选的代码数据。 能力：它“精通”Python、JavaScript、PHP、Swift、Shell 等多种编程语言。 4.3.2.6 InstructGPT (2022年3月)\n主要贡献：InstructGPT 提出并使用了来自人类反馈的强化学习 (Reinforcement Learning from Human Feedback, RLHF) 对预训练大模型进行微调，显著提升了模型遵循指令的能力和安全性。 三步微调流程： 监督方式微调 (Supervised Fine-Tuning, SFT)：收集人类标注的指令数据，以监督学习的方式微调 GPT-3 模型。 训练奖励模型 (Reward Model, RM)：利用人类对模型生成结果的偏好排序数据，训练一个奖励模型。这个奖励模型能够评估模型输出的质量。 强化学习微调 (Reinforcement Learning)：利用训练好的奖励模型提供 reward 信号，使用近端策略优化 (Proximal Policy Optimization, PPO) 算法对第一步微调的 GPT-3 模型进行强化学习微调。 4.3.2.7 ChatGPT (2022年11月)\n训练语料：其训练语料包含了多种主题的数据，使其能够处理各种不同任务，包括回答问题、撰写文章、多语种翻译、生成代码等。 连续对话：ChatGPT 能够主动记忆之前的对话内容，实现流畅的连续对话。 训练方法：与 InstructGPT 类似，ChatGPT 也使用了来自人类反馈的强化学习 (RLHF) 对预训练大模型进行微调。这提升了模型理解人类思维的准确性，并使其功能优于纯粹的 GPT-3。 与 InstructGPT 的关系：ChatGPT 和 InstructGPT 在训练流程上是相同的。主要区别在于 ChatGPT 在标注数据环节新增了大量的对话形式数据，并将原来的数据也全部改为了对话形式，使其更适合对话交互。 4.3.2.8 GPT-4 (2023年3月)\n多模态能力：GPT-4 是一款多模态模型，可以同时接收图像输入和文本输入。它在多种多模态任务上的 zero-shot (零样本) 效果达到了甚至超过了针对性训练的模型。 上下文长度：上下文长度大幅提升，可达 32768 tokens，相当于一次可以处理超过 50 页的内容，极大地扩展了模型的理解和生成能力。 训练与性能：GPT-4 沿用了与 ChatGPT 一致的训练方法 (RLHF)。但在文本总结和加工能力上有了明显的提升，能够根据指令给出更优质、更准确的答案。","44-大语言模型-llm-部署过程#4.4 大语言模型 (LLM) 部署过程":"大型语言模型从一个未经训练的神经网络到能够智能响应用户指令的完整系统，通常需要经过以下三个阶段：","441-预训练-pre-training#4.4.1 预训练 (Pre-Training)":"目标：通过大规模无监督学习，让模型在海量文本数据上学习语言的结构、知识和模式。 方法：通常通过语言建模任务（如预测下一个词）来训练模型，使其掌握通用的语言理解能力。 结果：预训练后的模型能够生成合理的文本段落，但对特定任务或指令的理解和执行能力仍然有限，可能无法直接用于与用户交互。","442-监督微调-supervised-fine-tuning-sft#4.4.2 监督微调 (Supervised Fine-Tuning, SFT)":"目标：通过监督学习，引导模型执行更为具体的任务，让其能够更好地理解和响应用户指令。 方法：使用高质量、标注好的指令-响应对数据来调整模型参数。这些数据可以是问答、代码生成、文本摘要等各种任务的示例。 作用：使模型能够更准确、更相关地执行特定任务。Instruct Tuning 和 InstructGPT 就是这种方法的典型代表。","443-偏好优化-preference-optimization#4.4.3 偏好优化 (Preference Optimization)":"目标：通过强化学习，进一步调整模型的生成行为，使其输出更符合人类的期望、偏好和价值观。 方法：这个阶段通常涉及人类反馈强化学习 (RLHF)。模型会生成多个响应，由人类标注者进行评估和排序，然后训练一个奖励模型来学习人类偏好。最后，利用奖励模型提供的 reward 信号，通过强化学习算法（如 PPO）来优化模型的策略，使其生成更受人类偏好的输出。 作用：经过偏好优化后的模型在对话、回答问题、生成内容时，其输出会更符合人类期望，减少不准确、有偏见或不合适的输出。ChatGPT 和 Claude 等模型都广泛采用了这一技术。"},"title":"神经网络应用"},"/notes/learn/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96/deepseek%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D/":{"data":{"":"","1-deepseek-项目概述与版本迭代#1. DeepSeek 项目概述与版本迭代":"DeepSeek 系列模型代表了在大规模语言模型 (LLM) 领域开放研究和技术进步的重要里程碑。该系列模型通过不断迭代，在模型架构、训练策略、并行技术和推理优化等方面取得了显著进展，旨在提供强大、经济且高效的语言模型。","11-deepseek-paper-系列#1.1 DeepSeek Paper 系列":"DeepSeek-AI 团队发布了一系列论文，详细介绍了其模型的演进和创新技术：\nDeepseek LLM: scaling open-source language models with longtermism：这篇论文可能侧重于 DeepSeek-V1 或其基础版本，强调了长期主义在开源大模型扩展中的作用。 Deepseek-V2: A strong, economical, and efficient mixture-of-experts language model：详细介绍了 DeepSeek-V2，特别是其作为混合专家模型 (MoE) 的特点，强调了其强大的性能、经济性和效率。 DeepSeek-V3：该版本在 V2 的基础上进一步优化，是当前课程主要介绍的重点。 DeepSeek-V3.2：V3 的进一步改进版本，通常在 V3 发布后进行小版本更新。 这些论文以及来自 Sebastian Raschka 的技术解析（https://magazine.sebastianraschka.com/p/technical-deepseek）共同构成了 DeepSeek 系列的技术背景。","12-deepseek-v3-核心特性概览#1.2 DeepSeek-V3 核心特性概览":"DeepSeek-V3 是 DeepSeek 系列中的一个重要版本，它集成了多项创新技术，旨在实现高性能、高效率和大规模。其核心特性包括：\n训练数据：在 14.8 万亿个多样化且高质量的 tokens 上进行训练。巨大的训练数据量是模型性能的基础。 训练阶段：采用 SFT (Supervised Fine-Tuning) + RL (Reinforcement Learning) 的两阶段训练。SFT 用于模型对指令的理解和遵循，而 RL（特别是通过 GRPO 等算法）则进一步优化模型行为，使其更好地对齐人类偏好。 训练效率：在 2048 块 H800 GPU 集群上，实现 3.7 天/万亿 tokens 的训练速度，总计耗费 2.788 百万 H800 GPU 小时。这表明了其高效的分布式训练能力。 开源性：DeepSeek-V3 已开源，代码可在 https://github.com/deepseek-ai/DeepSeek-V3 获取，这促进了其在社区中的应用和进一步研究。 模型结构： 层数：拥有 61 层 Transformer 结构，表示模型的深度。 隐藏层维度 (hidden dim)：7168，指每个 token 经过 Transformer 层后的表示维度。 MLA 注意力 (Multi-head Latent Attention)：采用 128 头 × 128 维 的 MLA，这是一种优化后的注意力机制，旨在减少缓存开销。 KV 压缩 (KV Compression)：dc=512d_c = 512dc​=512（KV 的压缩维度），dc′=1536d'_c = 1536dc′​=1536（Q 的压缩维度）。这意味着在 MLA 中，Key 和 Value 向量被压缩到 512 维，而 Query 向量被压缩到 1536 维，用于减少内存占用和计算。 解耦 Query/Key 头维度：64。这允许 Query 和 Key 使用不同的头维度，提供更大的灵活性。 FFN 结构：前 3 层使用 Dense FFN (Feed-Forward Network)，不使用 MoE。 MoE 结构：后 58 层使用 MoE (Mixture-of-Experts) 架构，包含 256 个专家 + 1 个共享专家，激活 8 个专家，并且限制专家调用在 4 个节点内。这是一种稀疏激活机制，能够在增加模型容量的同时，限制每个 token 的计算量。 专家 FFN 中间维度：2048，指 MoE 中每个专家内部 FFN 的中间层维度。 MTP 深度 (Multi-Token Prediction)：1（预测 next token + 额外一个 token）。MTP 是一种训练技术，通过预测多个未来的 token 来加速模型收敛。 训练精度：采用 FP8 混合精度训练，进一步提高训练效率和降低内存需求。 上下文长度：支持 128K 上下文，使其能够处理非常长的输入序列。 参数量：总参数量达 671B (十亿)，但每 token 激活的参数量仅为 37B，这是 MoE 架构带来的显著优势。","13-deepseek-v1-架构与优化#1.3 DeepSeek-V1 架构与优化":"DeepSeek-V1 是 DeepSeek 系列的起点，为后续版本奠定了基础。","131-训练数据与策略#1.3.1 训练数据与策略":"训练数据：在 2 万亿个 tokens 上进行训练，主要语言为中文和英文。 数据处理：为了确保数据的多样性、密度和代表性，采用了 去重 (deduplication)、过滤 (filtering) 和 重混合 (remixing) 三个阶段： 去重和重混合：确保数据集中独特实例的多样性表示，并通过重采样解决数据偏差。 过滤：增强信息密度，提高模型训练效率。 分词算法：采用 Byte-level Byte-Pair Encoding (BBPE)。 词汇表大小：102400 (100000 个常用 token + 15 个特殊 token)。 微调：采用 SFT (Supervised Fine-Tuning) 和 DRO (Direct Preference Optimization，一种基于人类反馈的强化学习算法)，使用 100 万个实例进行 SFT。 模型规模：67B 参数量。 性能目标：旨在超越 LLaMA-2 70B 和 ChatGPT。","132-架构特点#1.3.2 架构特点":"DeepSeek LLM (V1) 的微观设计主要遵循 LLaMA 架构 (Touvron et al., 2023a,b)，主要特点包括：\n预归一化结构 (Pre-Norm)：在 Transformer 块的每个子层输入前进行归一化。 RMSNorm 归一化函数 (Zhang and Sennrich, 2019)：一种高效的归一化方法。 SwiGLU 激活函数 (Shazeer, 2020)：作为 FFN 的激活函数，中间层维度为 8/3×dmodel8/3 \\times d_{model}8/3×dmodel​。 旋转位置编码 (Rotary Embedding, RoPE) (Su et al., 2024)：用于编码序列中的位置信息。 分组查询注意力 (Grouped Query Attention, GQA) (Ainslie et al., 2023)：为了优化推理成本，67B 模型使用了 GQA 而非传统的 MHA。GQA 共享 KV 投影，减少了缓存和带宽需求。","133-训练优化与并行策略#1.3.3 训练优化与并行策略":"DeepSeek-V1 采用了多种优化技术来提高训练效率和稳定性：\n优化器：使用 AdamW 优化器 (Loshchilov and Hutter, 2017)，超参数设置为：β1=0.9\\beta_1 = 0.9β1​=0.9, β2=0.95\\beta_2 = 0.95β2​=0.95, weight_decay = 0.1。 学习率调度器 (Step learner)：学习率在 2000 个 warmup 步骤后达到最大值，然后逐渐下降，在处理 80% 的 tokens 后降至最大值的 31.6%，在 90% 的 tokens 后降至最大值的 10%。 梯度裁剪：训练阶段的梯度裁剪设置为 1.0，以防止梯度爆炸。 训练框架：使用名为 HAI-LLM (High-flyer, 2023) 的高效轻量级训练框架。 分布式并行：集成了多种并行策略，与 Megatron 类似 (Korthikanti et al., 2023; Narayanan et al., 2021; Shoeybi et al., 2019)： 数据并行 (Data parallelism) 张量并行 (Tensor parallelism) 序列并行 (Sequence parallelism) 1F1B 流水线并行 (1F1B pipeline parallelism)：一种流水线并行策略，每个设备在计算前向和反向传播时，都只处理一个微批次。 Flash Attention (Dao, 2023; Dao et al., 2022)：用于提高硬件利用率。 ZeRO-1 (Rajbhandari et al., 2020)：用于在数据并行秩之间分割优化器状态，以减少显存占用。 计算与通信重叠：努力重叠计算和通信，以最小化额外等待开销，例如： 最后一个微批次的反向传播和 ZeRO-1 中的 reduce-scatter 操作。 GEMM (General Matrix Multiply) 计算和序列并行中的 all-gather/reduce-scatter 操作。 层/算子融合：融合了部分层和算子以加速训练，包括 LayerNorm、GEMM（尽可能）、Adam 更新。 混合精度训练：在 bf16 精度下训练模型，但使用 fp32 精度累积梯度，以提高模型训练稳定性。 In-place 交叉熵：为了减少 GPU 内存消耗，将 bf16 logits 实时转换为 fp32 精度，计算对应的 bf16 梯度，并用其覆盖 logits。","14-deepseek-v2-核心特性概览#1.4 DeepSeek-V2 核心特性概览":"DeepSeek-V2 在 V1 的基础上进行了扩展和优化。","141-预训练数据与微调#1.4.1 预训练数据与微调":"预训练数据：使用 8.1 万亿 tokens 进行预训练，数据量相比 V1 大幅增加，特别强调了中文数据的扩展和更高的数据质量。 监督微调 (SFT)：收集了 1.5M (150 万) 个对话会话，涵盖数学、代码、写作、推理、安全等多个领域，用于 DeepSeek-V2 Chat 的 SFT。","142-负载均衡辅助项#1.4.2 负载均衡辅助项":"在 DeepSeek-V2 中，为了解决 MoE 模型中专家负载不均衡的问题，引入了负载均衡辅助项到训练代价函数中。这一项的目的是鼓励模型在训练过程中均匀地使用各个专家。详细内容将在后续章节中讲解。","2-核心模型架构优化技术#2. 核心模型架构优化技术":"DeepSeek 系列模型在核心架构上进行了多项创新和优化，以提升性能、效率并支持更大规模的模型训练和推理。","21-注意力机制演进#2.1 注意力机制演进":"Transformer 架构的核心是自注意力机制，但其原始形式在效率和内存方面存在改进空间。DeepSeek 对注意力机制进行了多方面的优化。","211-标准多头注意力机制-mha#2.1.1 标准多头注意力机制 (MHA)":"基本原理：在标准的 Multi-Head Attention (MHA) 机制中，模型会将输入查询 (Query)、键 (Key)、值 (Value) 向量通过不同的线性变换矩阵（每个注意力头拥有自己独立的 WQ,WK,WVW_Q, W_K, W_VWQ​,WK​,WV​ 子矩阵）投影到不同的子空间。每个注意力头独立计算注意力分数并聚合值向量，最后将所有头的输出拼接并再次进行线性变换。 特点：每个注意力头使用自己的子矩阵对输入进行变换，生成自己特定的 Q、K、V 子向量。这使得模型可以从不同的“表示子空间”学习信息，捕捉不同的关系模式。","212-多查询注意力-mqa-与分组查询注意力-gqa#2.1.2 多查询注意力 (MQA) 与分组查询注意力 (GQA)":"为了优化推理时的内存和计算成本，尤其是在 KV 缓存方面，MHA 演变出了 MQA 和 GQA。\n多查询注意力 (MQA, Multi-Query Attention)： 特点：一个 token 的所有注意力头共享相同的 K/V 向量，即所有 Q 头都使用同一个 K 投影矩阵和同一个 V 投影矩阵。 优势：大幅减少了 KV 缓存的内存占用和从内存读取 KV 数据的带宽需求，显著降低了推理成本。 分组查询注意力 (GQA, Grouped-Query Attention)： 特点：介于 MHA 和 MQA 之间。它将查询头分为多个组，一个组内的所有注意力头共享相同的 K/V 向量。 优势：在 MQA 的推理效率提升和 MHA 的模型表达能力之间取得了平衡。DeepSeek-V1 的 67B 模型为了优化推理成本，就采用了 GQA。 总结：MQA 和 GQA 的核心思想都是通过减少需要存储和计算的 K/V 表达数量，从而在保持模型性能的同时，降低推理时的内存和带宽开销。","213-位置编码-position-encoding#2.1.3 位置编码 (Position Encoding)":"Transformer 的自注意力机制本身是完全无序的（对输入的排列不敏感），这意味着它无法区分序列中 token 的相对或绝对位置。为了让模型理解 token 之间的顺序信息，必须显式地引入位置信息。","2131-transformer-中的位置信息需求#2.1.3.1 Transformer 中的位置信息需求":"目的：让模型知道序列中每个 token 的位置信息，例如“第 1 个 token 在第 1 个位置，第 2 个 token 在第 2 个位置”等。 实现方式：位置编码可以将位置信息添加到输入词嵌入上（如 BERT 和 GPT-2），也可以在每一层的 QKV 计算中动态地融入位置信息（如 DeepSeek 中使用的 RoPE）。","2132-旋转位置编码-rope-rotary-position-embedding#2.1.3.2 旋转位置编码 (RoPE, Rotary Position Embedding)":"核心目标：RoPE 旨在让注意力计算能够表达两个 token 之间的相对距离。具体来说，当计算第 mmm 个 token 和第 nnn 个 token 之间的注意力时，希望它们的 QK 内积能够自然地受到其相对距离 (n−m)(n-m)(n−m) 的影响。 工作原理： 对于 Q 和 K 向量，RoPE 将向量每两个相邻的维度组成一个二维向量。 对这些二维向量进行逆时针旋转角度。每个二维向量的旋转角度不同，且随着维度索引的增加而减少。 旋转后生成的二维向量会替换回原始位置。 Value (V) 向量不做位置编码处理。 数学性质：通过这种旋转操作，两个带有 RoPE 编码的向量的内积，会自然地包含它们相对位置的旋转信息。形式上，两个旋转矩阵可以通过相乘融合，结果为旋转角度之和；转置则为反方向旋转。因此，QK 内积结果会带有一个与 (n−m)(n-m)(n−m) 相对位置关系相关的旋转项。 优势：RoPE 能够有效地将相对位置信息融入到注意力机制中，且具有外推性好的特点，被 DeepSeek 等许多现代 LLM 采用。","22-多头潜注意力-multi-head-latent-attention-mla#2.2 多头潜注意力 (Multi-head Latent Attention, MLA)":"MLA 是 DeepSeek-V3 引入的一种新型注意力机制，旨在进一步优化内存和计算效率。","221-目标与核心特征#2.2.1 目标与核心特征":"目标：在保持模型性能的同时，减少 KV 缓存的内存占用，特别是在处理长上下文时。 核心特征： 不同于传统的 MHA 或 GQA 直接缓存 K、V 向量，MLA 缓存的是输入向量的低维变换。 这些低维变换在推理时可以用于生成附加的矩阵乘法，从而按需构造 K、V 向量或其内积结果，而不是预先存储完整的 K、V 向量。","222-缓存策略缓存低维变换而非kv值#2.2.2 缓存策略：缓存低维变换而非KV值":"在 DeepSeek-V3 中，输入 token 的原始隐藏维度 d=7168d = 7168d=7168。 MLA 不直接缓存完整的 Key 和 Value 向量。相反，它缓存它们的低维表示 cKc_KcK​ 和 cVc_VcV​ (这里文本中都用 ccc 来表示，实际上是 cKc_KcK​ 和 cVc_VcV​ 两个不同的低维表示)。同时，Query 向量也通过低维变换得到 cQc_QcQ​。 DeepSeek-V3 中，KV 压缩维度 dc=512d_c = 512dc​=512，Query 压缩维度 dc′=1536d'_c = 1536dc′​=1536。这意味着缓存的 KV 表示的维度远小于原始 K、V 向量的维度（通常与隐藏维度相关），从而大幅减少了缓存需求。","223-mla-的计算开销与优化#2.2.3 MLA 的计算开销与优化":"MLA 带来的挑战是：如果不缓存完整的 KV 向量，每次解码生成新 token 时，是否需要对整个上下文进行计算来生成 KV？这开销是巨大的。DeepSeek 巧妙地利用了矩阵乘法的结合律来绕过这个问题。","2231-解码阶段计算量分析#2.2.3.1 解码阶段计算量分析":"问题：如果在解码（decoding）阶段，每次生成一个新 token 都需要重新计算所有历史 token 的 K、V 向量，其开销将是巨大的。 DeepSeek 的解决方案：利用矩阵乘法的结合律调整计算顺序，不先计算 K、Q 再相乘，而是直接通过降维向量 ccc 和 c′c'c′ 计算 QK 内积的结果。 传统解码计算量（缓存 K、V）：每次解码计算 QK 内积和加权求和 V，计算量为 O(L⋅dh)O(L \\cdot d_h)O(L⋅dh​)，其中 LLL 是上下文长度，dhd_hdh​ 是注意力头维度。 MLA 优化前的解码计算量（缓存 cK,cVc_K, c_VcK​,cV​ 但直接生成 K, V）：O(dc′⋅dh+L⋅dc⋅dh+dh⋅d)\\mathcal{O}(d'_c \\cdot d_h + L \\cdot d_c \\cdot d_h + d_h \\cdot d)O(dc′​⋅dh​+L⋅dc​⋅dh​+dh​⋅d)。因为需要从 cK,cVc_K, c_VcK​,cV​ 生成 K, V 再进行计算，引入了 LLL。 MLA 优化后的解码计算量（顺序计算）： 对于任意注意力头 sss，计算量约为 O(dc′⋅dh+dh⋅dc+L⋅dc)\\mathcal{O}(d'_c \\cdot d_h + d_h \\cdot d_c + L \\cdot d_c)O(dc′​⋅dh​+dh​⋅dc​+L⋅dc​)。 在 DeepSeek-V3 中，dh=128d_h=128dh​=128, 头数 Nh=128N_h=128Nh​=128, dc=512d_c=512dc​=512, dc′=1536d'_c=1536dc′​=1536, d=7168d=7168d=7168。 通过调整计算顺序， MLA 将解码计算量从 O(L⋅dh⋅(1+dc))\\mathcal{O}(L \\cdot d_h \\cdot (1 + d_c))O(L⋅dh​⋅(1+dc​)) 优化到 O(L⋅dc)\\mathcal{O}(L \\cdot d_c)O(L⋅dc​)，显著降低了与上下文长度 LLL 相关的计算开销。 合理性：在解码阶段，由于每次只生成一个 token，任务的计算密集度通常低于设备的计算密集度，瓶颈往往在于带宽（从 HBM 显存读取 KV 缓存）。因此，可以利用一些“多余”的算力来兑换缓存量和带宽需求的下降。","2232-预填充训练阶段计算量分析#2.2.3.2 预填充/训练阶段计算量分析":"预填充/训练阶段计算量： 传统计算方式（先计算 K, Q 再相乘）：O(L⋅dc′⋅dh+L⋅dc⋅dh+L⋅dh⋅d)\\mathcal{O}(L \\cdot d'_c \\cdot d_h + L \\cdot d_c \\cdot d_h + L \\cdot d_h \\cdot d)O(L⋅dc′​⋅dh​+L⋅dc​⋅dh​+L⋅dh​⋅d)。 顺序计算方式（结合律优化）：O(L⋅dc′⋅dh+L⋅dh⋅dc+L⋅dc⋅d)\\mathcal{O}(L \\cdot d'_c \\cdot d_h + L \\cdot d_h \\cdot d_c + L \\cdot d_c \\cdot d)O(L⋅dc′​⋅dh​+L⋅dh​⋅dc​+L⋅dc​⋅d)。 结论：由于 dcd_cdc​ (KV 压缩维度) 通常大于 dhd_hdh​ (注意力头维度)，在预填充/训练阶段，MLA 仍然按照传统的、先计算 K 和 Q 再相乘的方式来计算注意力，而不是采用解码时的结合律优化顺序。这是因为在处理整个序列时，传统方法更高效。","224-mla-图示与完整计算流程#2.2.4 MLA 图示与完整计算流程":"图示描述：原始文档中的图示展示了 MLA 如何为 Key/Value (KV) 和 Query (Q) 分别使用两组不同的低维表达 CKVC_{KV}CKV​ 和 CQC_QCQ​。 它将 Key 和 Query 的位置表达相关向量（如 RoPE 编码后的部分）和内容相关向量（即从输入 xxx 经过 WCW_CWC​ 线性变换得到的低维 ccc 向量）进行简单拼接。 在训练时，模型会同时学习得到生成低维表达的矩阵（例如 WCKVW_{CKV}WCKV​ 和 WCQW_{CQ}WCQ​）以及生成完整的 KVQ 向量的矩阵（例如 WKVQW_{KVQ}WKVQ​）。 核心思想：MLA 的完整计算流程涉及将输入 xxx 投影到低维内容表示 cQc_QcQ​ 和 cKc_KcK​（图中未明确 V 但原理相同），然后结合位置编码 RQ(pt)R_Q(p_t)RQ​(pt​) 和 RK(pt)R_K(p_t)RK​(pt​)，通过一系列矩阵乘法得到最终的 Q、K 向量。在推理阶段，通过调整矩阵乘法的结合律，可以直接计算注意力分数和加权值，而无需显式地构建和缓存完整的 K、V 向量。 缓存：缓存的是 CKVC_{KV}CKV​ 而非 K、V 向量本身，从而显著降低内存需求。","225-mla-的小技巧#2.2.5 MLA 的“小技巧”":"MLA 利用矩阵乘法的结合律来调整计算顺序，但这只能用于内容表达向量部分。通过这种计算顺序的调整，MLA 可以减少不缓存 KV 带来的计算代价。例如，在解码时对 score×V×dcscore \\times V \\times d_cscore×V×dc​ 也进行了类似的优化。","23-deepseek-混合专家模型-deepseekmoe#2.3 DeepSeek 混合专家模型 (DeepSeekMOE)":"DeepSeek-V3 采用了 MoE 架构，大幅增加了模型容量，同时通过稀疏激活保持了计算效率。","231-moe-类型共享专家与路由专家#2.3.1 MoE 类型：共享专家与路由专家":"DeepSeekMoE 包含两种类型的专家：\n共享专家 (Shared Expert)：一个或多个专家，它们一定会被调用，对所有 token 都进行处理。 路由专家 (Routing Experts)：多个专家组成的池，通过路由机制，只选择其中的 K 个专家进行激活和调用。","232-专家调用与权重计算#2.3.2 专家调用与权重计算":"假设有 NSN_SNS​ 个共享专家和 NRN_RNR​ 个路由专家。 每个 token 的处理流程如下： 共享专家：所有共享专家的输出会进行等权加和（或根据预设权重加和）。 路由专家：对于路由专家，模型会计算输入向量与每个专家门（gating）向量的内积，得到一个分数。 选择分数最高的前 KtopK_{top}Ktop​ 个专家。 将这 KtopK_{top}Ktop​ 个专家的分数经过 Sigmoid 函数处理后，作为权重进行归一化。 最终的输出是这些被激活专家的输出与归一化权重的加权和。 DeepSeek-V3 配置：后 58 层 MoE 结构包含 256 个路由专家 + 1 个共享专家，每个 token 激活 8 个路由专家。","233-专家并行-expert-parallelism#2.3.3 专家并行 (Expert Parallelism)":"在 MoE 模型中，专家并行 (EP) 是一种关键的分布式训练技术。\n原理：将 MLP 层的各个专家（及其参数）分配到不同的设备（GPU）上。 数据流： 每个 token 在进入 MoE 层时，其路由机制会决定调用哪些专家。 由于各个 token 调用的专家可能分布在不同的设备上，token 会被发送到其对应的专家所在设备进行计算。这通常涉及两次 All-to-All 通信：一次用于将 token 路由到专家，另一次用于将专家处理后的结果收集回原始设备。 与张量并行 (TP) 的对比： 张量并行：在矩阵内部进行划分，因此每个 token 在所有设备上都会运行，对所有矩阵进行均等分解。 专家并行：在专家维度上进行划分。在 MoE 场景下，由于每个 token 只激活少数专家，EP 比 TP 更高效，因为它避免了每个 token 在所有设备上进行不必要的计算。","2331-专家并行与数据并行结合#2.3.3.1 专家并行与数据并行结合":"结合方式：通常将专家并行与数据并行 (DP) 结合使用。 流程： 不同的 DP replica 处理不同的输入 tokens。 在 MoE 层，各个 token 会根据路由结果在不同的设备之间“串门”，寻找自己的专家进行计算。这个过程涉及跨设备的 All-to-All 通信。 计算完成后，每个 token 的处理结果会再次通过 All-to-All 通信回到其原始的 DP replica 进行聚合。","234-专家负载均衡-load-balancing#2.3.4 专家负载均衡 (Load Balancing)":"MoE 模型面临的一个重要挑战是专家负载不均衡 (load imbalance)。","2341-问题负载不均衡与路由崩溃#2.3.4.1 问题：负载不均衡与路由崩溃":"负载不均衡：某些专家可能被过度选择，导致“打爆”；而另一些专家可能很少被选择，导致“饿死”。 路由崩溃 (routing collapse)：在训练过程中，模型可能倾向于只使用少数几个专家，导致大部分专家形同虚设，无法充分利用模型容量。 推理问题：负载不均衡在推理时可能导致网络流量不均衡，造成网络拥塞，并使得在专家并行场景下计算设备无法充分利用。 目标：研究人员希望 MoE 模型除了高准确率之外，还能实现对不同专家的调用比例比较相近。","2342-deepseek-v2-的负载均衡损失-load-balancing-loss#2.3.4.2 DeepSeek-V2 的负载均衡损失 (Load Balancing Loss)":"方法：DeepSeek-V2 通过在训练代价函数中增加一个负载均衡辅助项来实现。 原理：这个辅助项旨在鼓励不同专家被选中的概率相似，从而实现负载均衡。 辅助项通常会惩罚那些被过度选择的专家，或者鼓励那些未被充分利用的专家。 其基本思想是让“出头鸟”的概率值下降，降低 loss 的结果是让所有专家都不做“出头鸟”，最终达到负载均衡。","2343-deepseek-v3-的负载均衡偏差-load-balancing-bias#2.3.4.3 DeepSeek-V3 的负载均衡偏差 (Load Balancing Bias)":"V3 的改进：V3 认为增加额外的训练项可能会影响训练效果，因此它虽然仍然使用 V2 的附加代价项，但将其权重设置得极低。 主要策略：V3 主要通过直接偏移训练过程中的专家路由权重来实现路由均衡。 在训练的路由过程中，V3 会给每个专家 iii 的门控分数（即输入与专家门向量的内积）增加一个偏移项 bib_ibi​。 如果某个路由专家 iii 被过多选择，则减少其对应的 bib_ibi​；反之，如果被选择不足，则增加 bib_ibi​。 关键点：增加的 bib_ibi​ 仅用于路由选择，用于决定激活哪些专家；而后续的输出权重加和仍然使用原始的门控分数（经过 Sigmoid 和归一化处理）。 效果：这种简单直接的方法在 DeepSeek-V3 中反而取得了更好的训练效果。 其他设计：V3 还引入了更复杂的设计，例如 Node-Limited Routing (节点限制路由)，限制专家的使用尽可能在 K 个节点内，以优化通信效率和减少跨节点流量。","24-多令牌预测-multi-token-prediction-mtp#2.4 多令牌预测 (Multi-Token Prediction, MTP)":"MTP 是一种在预训练阶段使用的技术，旨在加速模型的收敛速度。","241-mtp-目标与原理#2.4.1 MTP 目标与原理":"目标：在预训练时，与其一次只预测一个 token，一次预测多个 tokens 能够更快地收敛。这类似于多任务学习 (multi-task learning) 的思想，模型在预测下一个 token 的同时，也能预测更远的未来 token，从而从更丰富的信息中学习。 灵感来源：多任务学习表明，当多个相关任务一起学习时，模型往往能学得更好、更快。MTP 将预测多个未来 token 视为多个相关任务。","242-deepseek-v3-中的-mtp-实现#2.4.2 DeepSeek-V3 中的 MTP 实现":"串行 MTP：DeepSeek-V3 采用串行的 MTP 技术，一次推理输出未来的多个 tokens。 仅用于预训练：MTP 仅在预训练过程中使用，训练完成后，模型在推理时只使用主模型 (Main model) 部分，即仅预测下一个 token。 MTP 流程示例： Main Model：输入 token1234，预测 token5。 MTP Model 1：基于 token1234 输入 Main Model 的最后一层 Transformer 的输出，然后输入 token5，再经过额外一层 Transformer，预测 token6。 MTP Model 2：基于 token12345 (这里的 token5 是 MTP Model 1 的输入) 的 MTP Model 1 的最后一层 Transformer 的输出，然后输入 token6，再经过另一层 Transformer，预测 token7。 这个过程可以重复，形成一个链式预测结构，其中每个 MTP 模型预测下一个 token，并将其输出作为下一个 MTP 模型的输入的一部分。 通用 MTP 流程：对于上下文 [0,T−k][0, T-k][0,T−k] 内的每个 token iii，在第 kkk 个 MTP 模块中： 所有 [0,T−k][0, T-k][0,T−k] 的 tokens 进入 Transformer。 然后计算第 (i+k+1)(i+k+1)(i+k+1) 个 token 的采样概率。","243-mtp-对代价函数的影响#2.4.3 MTP 对代价函数的影响":"MTP 通过预测未来的多个 token，显著提升了训练的收敛速度和样本效率。 在 DeepSeek-V3 中，代价函数（loss function）被修改，为任意上下文增加了对未来更多 tokens (k=1,2,…,Dk=1, 2, \\ldots, Dk=1,2,…,D) 的预测项。这意味着模型不仅仅优化下一个 token 的预测，还同时优化多个后续 token 的预测。","3-分布式训练设计与基础设施#3. 分布式训练设计与基础设施":"DeepSeek-V3 的训练需要极其庞大的计算资源和高效的分布式系统支持。这部分将详细介绍 DeepSeek-V3 所依赖的硬件基础设施、网络优化以及其独特的并行训练策略。","31-deepseek-v3-训练基础设施#3.1 DeepSeek-V3 训练基础设施":"DeepSeek-V3 的训练环境是高性能计算集群，其设计旨在最大化 GPU 算力的利用率和通信效率。","311-硬件配置与互联技术#3.1.1 硬件配置与互联技术":"集群规模：DeepSeek-V3 在配备 2048 块 NVIDIA H800 GPU 的集群上进行训练。H800 是 NVIDIA 专为 AI 训练设计的高性能加速卡。 节点内部互联： 配置：集群中的每个节点包含 8 块 GPU。 互联技术：节点内部的 8 块 GPU 通过 NVLink 互联。 NVLink：这是 NVIDIA 自主研发的高带宽、低延迟 GPU 互联总线。它相当于 GPU 与 GPU 之间的“高速公路”，为同一节点内的 GPU 之间的数据交换提供高达 1280Gb/s 的带宽。NVLink 的核心作用是使多 GPU 能够像一个统一的计算单元一样协同工作，尤其是在张量并行和数据并行内部的数据同步中至关重要。 NVSwitch：为了在单个服务器内部将多个 GPU 互联成一个统一的大 GPU 集群，NVIDIA 设计了 NVSwitch 芯片。它通过 NVLink 连接所有 GPU，形成一个全连接的拓扑，进一步提升了节点内部的通信效率。【若需查看原始图片详情，请参考原文中的“节点内部互联”图】 节点间互联： 互联技术：不同节点之间使用 InfiniBand (IB) 互连，以实现跨节点通信。 InfiniBand (IB)：这是一种超高速数据中心网络的开放标准，专门用于服务器之间的高性能通信。它支持 RDMA (Remote Direct Memory Access) 技术，能够实现超低延迟、超高吞吐量和超低 CPU 开销的网络传输。在 DeepSeek-V3 的集群中，InfiniBand 提供 400Gb/s 的带宽。它是大规模大模型训练中不可或缺的互联技术，因为它允许 GPU 直接访问远程 GPU 的内存，而无需经过 CPU 的干预。 RDMA：不经过对方 CPU，直接读写远程内存的网络传输技术，大大降低了数据传输的延迟和 CPU 负载。 RoCE (RDMA over Converged Ethernet)：虽然理论上 RoCE 可以在以太网上实现 RDMA，并可能替代 InfiniBand，但目前要让 RoCE 稳定运行需要“无丢包以太网”，这在实际大规模训练中稳定性有限。因此，在 DeepSeek-V3 这样的大规模训练中，InfiniBand 仍然是首选。 NVIDIA 的垄断地位：目前，NVIDIA 通过收购 Mellanox（InfiniBand 商业成熟产品的主要供应商）主导并几乎垄断了 AI 计算卡的高速互联解决方案。NVIDIA GPU、NCCL (NVIDIA Collective Communications Library) 与 InfiniBand 深度绑定，共同实现了 GPUDirect RDMA，使得跨节点 GPU 到 GPU 的通信几乎达到零 CPU 开销和满带宽。【若需查看原始图片详情，请参考原文中的“节点间互联”图】 未来趋势：单块 NVIDIA Blackwell GPU 支持同时最多 18 条 NVLink 连接，每条带宽 100 GB/s，总带宽可达 1.8 TB/s，预示着未来高性能互联能力的进一步提升。","312-rail-optimized-network#3.1.2 Rail-optimized Network":"Rail-optimized Network 是一种专门为大规模分布式训练设计的网络拓扑结构，旨在优化特定通信模式的效率。\n原理：在分布式训练中，通常不同节点上相同序号的 GPU 会处理模型中的相同部分，导致这些 GPU 之间存在大量的梯度和参数传输。 结构： 多条并行 Rail：网络由多条平行的“Rail”组成，每条 Rail 连接不同节点机器上相同序号的 GPU。例如，所有节点上的 GPU 0 构成一条 Rail，所有节点上的 GPU 1 构成另一条 Rail，以此类推。 独立网卡：机内每个 GPU 都配备一张独立的物理网卡 (NIC)。 高速交换机：交换机负责在一个 Rail 内的 GPU 之间建立高速通信链路。 通信优化： Rail 内通信：在一个 Rail 内部，由于连接的是处理模型相同部分的 GPU，梯度/参数传输量通常较大。这种设计确保了 Rail 内通信的高效性。 跨 Rail 通信：当需要进行跨 Rail 通信时（例如在 DeepSeekMoE 的专家并行场景下，一个 token 可能需要访问不同 Rail 上的专家），通信会首先利用 NVSwitch/NVLink 在机内（同一个节点内）的高带宽和低延迟特性，将数据传输到同一个 Rail 上的 GPU，然后再进行 Rail 内的节点间传输。 避免多跳：这种设计可以避免传统两层交换机拓扑中可能出现的跳数过多和延迟较高的问题。【若需查看原始图片详情，请参考原文中的“Rail-optimized Network”图】","32-deepseek-v3-训练并行策略#3.2 DeepSeek-V3 训练并行策略":"为了有效利用 2048 块 H800 GPU 的集群，DeepSeek-V3 采用了复杂的混合并行策略。","321-hai-llm-训练框架#3.2.1 HAI-LLM 训练框架":"DeepSeek-V3 的训练是基于其内部工程师从头开始构建的名为 HAI-LLM 的高效轻量级训练框架。这表明 DeepSeek 在底层训练系统上具有高度定制化和优化的能力。","322-预训练中的并行组合#3.2.2 预训练中的并行组合":"DeepSeek-V3 在预训练中采用了以下并行策略的组合：\n流水线并行 (Pipeline Parallelism, PP)：16 路 PP。模型被切分成 16 个阶段，每个阶段部署到不同的设备上，数据在这些设备之间流水线式地流动。 专家并行 (Expert Parallelism, EP)：64 路 EP，跨越 8 个节点。这意味着 256 个路由专家被切分为 64 份，分布在 8 个节点上。由于每个节点有 8 块 GPU，这相当于每个节点处理 8 路专家，总计 8×8=648 \\times 8 = 648×8=64 路专家。 ZeRO-1 数据并行 (Data Parallelism, DP)：128 路 DP，横跨 2048 块 GPU (2048 GPUs/(16 PP ranks×8 EP partitions per node)=128 DP ranks2048 \\text{ GPUs} / (16 \\text{ PP ranks} \\times 8 \\text{ EP partitions per node}) = 128 \\text{ DP ranks}2048 GPUs/(16 PP ranks×8 EP partitions per node)=128 DP ranks)。ZeRO-1 是一种内存优化型数据并行策略，通过分区优化器状态来减少每块 GPU 的内存占用。 通讯与计算比：在 DeepSeek-V3 的分布式场景下，由于引入了专家并行，通信量和计算量的比例达到了接近 1:1。这意味着通信效率对整体训练速度有着至关重要的影响。","323-dualpipe-流水线并行优化#3.2.3 DualPipe 流水线并行优化":"DualPipe 是 DeepSeek-V3 中针对流水线并行引入的创新优化，旨在解决传统流水线并行中的“气泡”问题。","3231-目标消除气泡与隐藏通信开销#3.2.3.1 目标：消除气泡与隐藏通信开销":"气泡 (Bubble)：传统流水线并行（例如 1F1B，在前向传播 (FP) 和反向传播 (BP) 之间切换，每个设备只处理一个微批次）的一个主要问题是“气泡”。在启动阶段，流水线需要时间被填满，导致一部分设备在前向或反向阶段无事可做，产生计算资源的浪费。回顾 1F1B (Pipedream-Flush) 的主要气泡：启动阶段从一侧发起，因此另一侧设备无事可做。 DualPipe 目标： No Bubble (无气泡)：最大化 GPU 利用率，消除由于流水线填充和排空而产生的空闲时间。 完全隐藏 All-to-all 和管道并行的通信开销：通过巧妙的调度，使通信操作与计算操作完全重叠，从而在总训练时间内不增加通信的负担。","3232-dualpipe-工作原理#3.2.3.2 DualPipe 工作原理":"核心思想：DualPipe 将一个微批次序列分成两批（或更多批次，但通常是两批），并以完全镜像的方式从流水线设备阶段的两端同时开始处理。 调度： 一部分微批次从流水线的第一阶段开始前向传播。 同时，另一部分微批次从流水线的最后一个阶段开始反向传播（这要求在流水线被完全填充后才能进行）。 重叠效应：当存在一个设备在同一时间既有某个微批次的前向传播 (FP) 任务，又有另一个微批次的反向传播 (BP) 任务时，这些计算可以混合进行，相互覆盖。 优势：这种双向启动和交错执行的策略，有效地填充了传统流水线中的空闲时间，特别是解决了启动和排空阶段的气泡问题，从而提高了整体的硬件利用率。 示例：在 8 个 PP 秩和 20 个微批次的场景下，DualPipe 能显著提升效率。","33-fp8-混合精度训练#3.3 FP8 混合精度训练":"DeepSeek-V3 采用 FP8 (8-bit浮点数) 混合精度训练，这是在 FP16 混合精度训练基础上的进一步发展，旨在大幅减少内存占用并加速计算。","331-fp8-相较于-fp16-的挑战#3.3.1 FP8 相较于 FP16 的挑战":"表达能力有限：与 FP16 相比，FP8 的位数更少 (8 位)，其数值范围和精度都更低。这使得直接将所有数据都用 FP8 表示会面临更大的数值溢出和精度损失风险。 动态量化需求：由于 FP8 的表达能力有限，它必须像推理中进行 INT8 量化一样，采用更精细的动态量化策略。这意味着需要为模型权重和激活值计算合适的 scaling factors (缩放因子)，在每次计算前将高精度数据缩放到 FP8 范围，计算后再反量化回高精度。这种缩放操作需要每张量 (per-tensor) 甚至更细粒度的缩放，以确保数值稳定性。","332-deepseek-v3-中-fp8-的应用策略#3.3.2 DeepSeek-V3 中 FP8 的应用策略":"DeepSeek-V3 在 FP8 混合精度训练中采取了以下策略：\n矩阵乘法：在 FP/BP 过程中发生的矩阵乘法操作（这是 LLM 中最主要的计算负载）会实时地将输入数据 scale 转换成 FP8 进行运算。 高精度累积：为了保证精度，矩阵乘法计算后的行列求和过程则使用高精度 (FP32) 保存。这意味着即使计算在 FP8 中进行，中间结果的累积仍然在更高的精度中完成。 保留原始精度模块：为了避免精度损失，某些开销相对较低或对精度要求极高的模块和操作仍使用原始精度 (例如 BF16 或 FP32)： embedding 模块 (词嵌入层)。 output head (输出层，通常是分类或回归层)。 MoE gating modules (MoE 模型的门控模块，决定激活哪些专家)。 normalization operators (归一化操作，如 LayerNorm, RMSNorm)。 attention operators (注意力计算中的某些部分)。 Master weights (主权重，用于保存模型的最终高精度权重)。 梯度。 优化器状态。 优势：通过选择性地在计算密集型部分使用 FP8，DeepSeek-V3 在显著降低内存占用和加速计算的同时，最大程度地保持了模型的训练精度。","333-细粒度量化-fine-grained-scaling#3.3.3 细粒度量化 (Fine-Grained Scaling)":"DeepSeek-V3 在 FP8 量化中实现了极高的细粒度，这意味着它不会对整个矩阵应用单一的缩放因子。\n分段缩放：一个矩阵或向量内部可以分成不同的段，并为每个段使用不同的 scaling factors。 激活值量化：对于激活值（即每个 token 经过 Transformer 层后的向量表达），DeepSeek-V3 按照 1×1281 \\times 1281×128 的 tile（平铺块）进行分组和缩放。 权重值量化：对于权重，DeepSeek-V3 按照 128×128128 \\times 128128×128 的 block（块）进行分组缩放。 计算挑战：这意味着在矩阵乘法过程中，当进行反量化时，必须为每块的计算使用不同的 scaling factors。这要求底层硬件和软件框架能够高效地处理这种细粒度量化，增加了实现的复杂性。","334-其他-fp8-优化细节#3.3.4 其他 FP8 优化细节":"DeepSeek-V3 还包括其他一些优化细节，以充分发挥 FP8 的优势：\n激活值存储：激活值直接存储为 FP8 格式。这不仅节省内存，而且因为激活值后续也会用于计算权重梯度 (Wgrad)，以 FP8 形式存储可以避免额外的格式转换。 自注意力输出量化：自注意力模块的输出在分发到不同的 MoE 专家之前，会被量化成 FP8。这样做可以有效节省在 MoE 专家之间进行通信时的带宽，因为 MoE 模型的专家并行会产生大量的 All-to-All 通信。","4-后训练与推理#4. 后训练与推理":"DeepSeek 模型的开发不仅仅包括大规模的预训练，还涉及关键的后训练阶段，以使模型能更好地理解和遵循人类指令，并在实际应用中提供高效的推理服务。","41-后训练-post-training#4.1 后训练 (Post-Training)":"后训练阶段是模型从一个基础的语言理解器转变为一个有用的、能够执行特定任务的对话式 AI 的关键步骤。","411-监督式微调-sft#4.1.1 监督式微调 (SFT)":"目的：监督式微调 (Supervised Fine-Tuning, SFT) 旨在让预训练好的大语言模型能够理解并执行人类的指令请求。它通过在高质量、带有指令和对应回答的数据集上进行训练，使模型学会如何响应用户提示。 DeepSeek-V3 实践：DeepSeek-V3 使用了150 万条例子进行指令微调。这些例子涵盖了广泛的任务和领域，包括： 推理 (Reasoning) 编程 (Code) 逻辑题 (Logic Puzzles) 问答 (Question Answering) 创造性写作 (Creative Writing) 角色扮演 (Role Playing) 等等。 推理数据来源：其中，用于训练推理能力的数据是使用 DeepSeek-R1 模型生成的。这表明 DeepSeek-R1 具备强大的推理能力，其产出被用于增强 DeepSeek-V3 的 SFT 阶段。","412-知识蒸馏-knowledge-distillation#4.1.2 知识蒸馏 (Knowledge Distillation)":"目的：知识蒸馏 (Knowledge Distillation) 是一种将复杂“教师模型”的知识转移到更小、更简单的“学生模型”或改进现有模型的方法。 DeepSeek-V3 实践：DeepSeek-V3 从 DeepSeek-R1 模型中进行了知识蒸馏。 DeepSeek-R1 可能是一个专注于 Chain-of-Thought (COT) 或其他复杂推理策略的模型。 DeepSeek-V3 精妙地将 DeepSeek-R1 的验证 (verification) 和反思 (reflection) 模式融入其自身架构中。这意味着 DeepSeek-V3 不仅仅是简单地模仿 DeepSeek-R1 的输出，而是学习了其内在的推理和自我修正机制，从而在标准 LLM 中实现了更强的推理能力。","42-deepseek-v3-推理架构#4.2 DeepSeek-V3 推理架构":"DeepSeek-V3 的推理架构是针对大规模、高并发场景进行优化的，它将 Prefilling（预填充）和 Decoding（解码）阶段分离部署，并采用先进的并行策略和负载均衡机制。","421-推理基础设施#4.2.1 推理基础设施":"硬件：DeepSeek-V3 推理同样运行在高性能的 H800 GPU 集群上。 互联：与训练基础设施类似： 机内互联：NVLink interconnects 用于同一节点内的 GPU 之间的高速通信。 机间互联：Infiniband interconnects 用于不同节点之间的低延迟、高带宽通信。","422-prefilling-阶段部署与并行#4.2.2 Prefilling 阶段部署与并行":"Prefilling 阶段指的是处理输入提示词（prompt），生成第一个 token 之前的计算过程。这个阶段通常涉及较长的序列长度，但计算量相对固定。\n资源配置：每个 Prefill Stage 使用 4 个节点 × 8 块 GPU = 32 块 GPU。 并行策略： 自注意力模块：采用 张量并行 (TP=4)、序列并行 (Sequential Parallelism, SP) 和 数据并行 (DP=8)。 TP=4：将自注意力模块的矩阵计算分解到 4 块 GPU 上。 SP：序列并行处理长上下文，将序列长度维度切分到不同 GPU 上。 DP=8：数据并行将不同的输入提示词分配到 8 组 GPU 上并行处理。 MoE（原 MLP）模块：使用 32 路专家并行 (EP)。这意味着 256 个路由专家被切分成 32 份，分布在不同的 GPU 上。 具体而言，每个节点（8 块 GPU）上包含 8 个路由专家和 1 个共享专家。 DeepSeek 的前 3 层 FFN：这些层是 Dense FFN，不使用 MoE。它们在 Prefilling 阶段不进行并行 (TP=1)，通常是在单个 GPU 上独立计算。 优化：为了提高效率，Prefilling Stage 会同时运行两个批次 (batch)，从而实现计算和 All-to-All 通信操作的交叉进行和隐藏，减少等待时间。","423-decoding-阶段部署与并行#4.2.3 Decoding 阶段部署与并行":"Decoding 阶段指的是模型逐个生成后续 token 的过程。这个阶段的特点是序列长度动态增长，但每次生成一个 token 的计算量较小。\n资源配置：每个 Decoding Stage 使用 40 个节点 × 8 块 GPU = 320 块 GPU。解码阶段通常需要更多的计算资源来处理并发的用户请求和维持低延迟。 并行策略： 自注意力计算：使用 TP=4 + SP。与 Prefilling 类似，通过张量并行和序列并行来优化长序列的注意力计算。 数据并行 (DP=80)：用于处理大量的并行解码请求。 专家并行 (EP=320)：在 Decoding Stage，由于资源更多，每个 GPU 可以保存一个路由专家，以便更快地进行专家查找和计算。 其中多出来 64 块 GPU 用于保存冗余的路由专家和共享专家。 优化： 实时专家调整：根据实时专家负载动态调整保存哪些冗余专家。这样可以在某个专家负载过高时，将其副本分配给负载较低的 GPU，从而实现负载均衡。 双批次运行：同样，每个 replica 会同时运行两个批次来交叉通信与计算，进一步提升效率。","424-推理时的专家负载均衡#4.2.4 推理时的专家负载均衡":"在 MoE 模型的推理阶段，尽管训练时已经采取了负载均衡策略，但由于实际用户数据的动态性和随机性，仍然需要额外的机制来保持微观上的专家负载均衡。\n问题：DeepSeekMoE 会调用 1 个共享专家和 Top-8 个路由专家进行运算。训练时保证了宏观上的专家调用频率相似，但在推理阶段，具体的用户请求可能导致某个专家在短时间内被频繁调用，而其他专家空闲，从而造成计算设备负载不均衡。 DeepSeek-V3 的解决方案： 实时记录与重复部署：通过实时记录各个专家的调用情况，系统会周期性地（例如，每 10 分钟）将负载高的专家重复部署给同一节点上其他计算设备上的专家。这有助于尽可能地摊平负载，避免个别 GPU 过载。 冗余专家池：在 Decoding Stage，每块 GPU 上可以存放更多的冗余专家（例如，16 个而非训练时的 9 个）。 这使得每次推理选择专家时具有更大的灵活性。当一个 token 需要某个专家时，系统可以选择同样提供该专家服务但当前负载较低的 GPU 来处理，进一步优化负载分配。"},"title":"DeepSeek架构介绍"},"/notes/learn/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96/gpu%E6%9E%B6%E6%9E%84%E4%B8%8E%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96%E5%8A%A0%E9%80%9F/":{"data":{"":"","1-gpu架构概览#1. GPU架构概览":"","11-gpu-vs-cpu#1.1 GPU vs CPU":"CPU（中央处理器）和GPU（图形处理器）在设计理念和擅长任务上存在显著差异：\nCPU (Central Processing Unit): 拥有强大的控制单元和高效的上下文切换能力。 设计用于通用计算，能够灵活、高效地处理各种复杂且多样化的任务序列。 控制能力相对更重要，擅长处理串行任务和需要复杂逻辑判断的任务。 特点是低延迟，单个核心性能强大。 GPU (Graphics Processing Unit): 最初是为了游戏领域的图形渲染而发明，主要处理大量的矩阵运算。 是一种特化的计算处理器，设计目标是进行大规模并行计算。 并行计算能力相对更重要，擅长处理可高度并行化的任务。 特点是高吞吐量，拥有数千个小核心。 这种卓越的并行计算能力使其成为大规模机器学习应用的基础。","12-gpu硬件架构#1.2 GPU硬件架构":"GPU的硬件架构围绕着高效的并行计算设计，其核心是流式多处理器（Streaming Multiprocessor, SM）。","121-sm-streaming-multiprocessor#1.2.1 SM (Streaming Multiprocessor)":"SM 是 GPU 的核心计算单元。一个GPU通常包含多个SM。 每个SM能够调度多个warp并同时执行。 编程模型中的每一个Block必然在一个SM上执行，但一个SM可以执行多个Block（以时间片轮转等方式）。 A100 GPU拥有108个SM。 One SM in A100 的结构组成： 包含4个更小的计算单元。 包含128个FP32 / INT32 CUDA核心。 包含64个FP64 (double) CUDA核心。 包含4个Tensor Core。 拥有可配置的Shared Memory，通常为164 KB / SM。 拥有寄存器（Registers），通常为64K 32-bit registers / SM。","122-cuda-core#1.2.2 CUDA Core":"CUDA Core 是GPU中执行基本算术运算的执行单元。 它们处理诸如整数加法、浮点运算等指令。 每个SM包含多个CUDA核心，这些核心协同工作来执行线程的指令。","123-tensor-core#1.2.3 Tensor Core":"Tensor Core 是专门用于加速矩阵乘法和其他张量操作的硬件单元。 它们在深度学习任务中表现出色，尤其在处理大型矩阵运算时能提供显著的性能提升。 每个A100的SM包含4个Tensor Core。","13-gpu计算能力#1.3 GPU计算能力":"GPU的计算能力主要通过其执行融合乘加（FMA）操作的速度来衡量。","131-乘加操作-fma#1.3.1 乘加操作 (FMA)":"乘加操作（Fused Multiply-Add, FMA） 是一种在一个硬件指令中同时执行一次乘法和一次加法运算的操作。 它是现代神经网络中最频繁的操作，因为神经网络的核心计算大量涉及矩阵乘法（乘法）和累加（加法）。 FMA操作相比分开执行乘法和加法，具有更高的效率和精度。","132-算力评估指标#1.3.2 算力评估指标":"GPU的算力通常使用每秒FMA次数作为评估指标。 一次FMA操作被认为包含两个运算（一个乘法和一个加法）。 A100 GPU 的时钟频率（clock rate）为 1.41 GHz。 A100的理论峰值算力计算示例： 假设所有SM（108个）满载运算。 这个理论峰值在实际中无法达到，因为存在各种限制（如内存带宽、指令调度等）。 GPU计算能力的来源: Source: CUDA Programming Guide (说明这些概念和数据来源自NVIDIA官方文档)。","2-gpu编程模型与执行机制#2. GPU编程模型与执行机制":"","21-cuda编程模型核心概念#2.1 CUDA编程模型核心概念":"NVIDIA CUDA（Compute Unified Device Architecture）是一个并行计算平台和编程模型，它允许开发者使用C、C++、Fortran等语言编写程序，并在NVIDIA GPU上执行。","211-kernel#2.1.1 Kernel":"Kernel 是在GPU上执行的函数。 它类似于在CPU上运行的普通函数，但其执行是高度并行的，由数千个GPU线程同时执行。","212-grid#2.1.2 Grid":"Grid (网格) 是一次Kernel运行的执行范围。 它由多个Block（线程块） 组成，用于划分整个计算任务的执行规模。 Grid是最高层级的抽象，代表了所有参与计算的线程块的集合。","213-block#2.1.3 Block":"Block (线程块) 是线程的组织单位，也是GPU中并行计算的基本调度单元。 每个线程块包含一组线程（例如，最多1024个线程）。 一个Block内部的线程可以在Shared Memory中相互通信，并可以通过同步点（__syncthreads()）进行同步。 一个Block内部的线程保证在同一时间、同一SM上执行（但并非所有线程同时执行）。","214-thread#2.1.4 Thread":"Thread (线程) 是GPU执行的最基本计算单元。 每个线程执行Kernel代码的一个独立副本，但通常操作不同的数据。","215-shared-memory#2.1.5 Shared Memory":"Shared Memory 是一种位于片上、Block内线程之间共享的内存。 它的访问速度非常快，类似于CPU的L1缓存，是实现Block内线程高效协作的关键。","216-global-memory#2.1.6 Global Memory":"Global Memory 是所有线程（无论属于哪个Block）都可以访问的内存空间。 它位于GPU的主存储器（如HBM）上，容量最大，但访问延迟相对较高。","22-从编程模型到硬件执行simt#2.2 从编程模型到硬件执行：SIMT":"GPU的执行模型被称为SIMT，它将编程模型中的抽象概念（Grid、Block、Thread）映射到底层的硬件单元（SM、Warp）。","221-warp#2.2.1 Warp":"Warp 是GPU的基本执行单位，它由一组并行执行的线程组成。 NVIDIA GPU中一个warp通常包含32个线程。 这些线程会在同一时间被调度，并执行相同的指令（SIMT模式），但操作不同的数据。","222-simt-single-instruction-multiple-threads#2.2.2 SIMT (Single Instruction, Multiple Threads)":"SIMT（Single Instruction, Multiple Threads）类似于SIMD（Single Instruction, Multiple Data）。 SIMD 要求所有数据通道严格执行相同的指令。 SIMT 则更加灵活，它允许不同线程根据条件分支执行不同的路径（而SIMD必须通过掩码实现）。这意味着如果warp内的线程遇到分支，它们会串行执行分支的两部分，然后重新汇合。 SIMT是GPU实现大规模并行计算的核心机制。","223-线程块与sm的映射#2.2.3 线程块与SM的映射":"编程模型中的线程块（Block） 会被映射到GPU的SM上。 每个SM可以同时处理多个线程块（通过时间片轮转或多路复用）。 这些线程块会共享SM内的共享内存、L1缓存等资源。","224-warp调度#2.2.4 Warp调度":"SM内部有多个warp调度器，它们负责管理warp的执行。 调度器在多个warp之间进行切换，以隐藏内存访问延迟和其他计算瓶颈，从而提高SM的利用率。 A100 GPU的每个SM支持4个并发warp，并可以有64个在运行的warp。 它可以在一个时钟周期内进行快速、轻量级的上下文切换。","225-启动示例1000维向量相加#2.2.5 启动示例：1000维向量相加":"假设我们要实现一个1000维向量的相加操作：\nint N = 1000; int blockSize = 256; // 每个Block包含256个线程 int gridSize = (N + blockSize - 1) / blockSize; // 计算需要的Block数量 // Kernel启动语法：\u003c\u003c\u003e\u003e(args...) addKernel\u003c\u003c\u003cgridSize, blockSize\u003e\u003e\u003e(a, b, c, N); 在这个例子中，addKernel 将在GPU上执行，gridSize 决定了有多少个Block被创建，blockSize 决定了每个Block有多少个线程。","23-矩阵乘法kernel示例#2.3 矩阵乘法Kernel示例":"矩阵乘法是GPU上的一个典型并行计算任务。 它涉及大量的乘加操作，非常适合GPU的并行架构。 一个优化的矩阵乘法Kernel会充分利用GPU的内存层级结构（寄存器、共享内存、全局内存），并通过分块（tiling）等技术来提高数据复用率和带宽利用率。 示例链接: https://dlsyscourse.org/","3-gpu内存层级架构与访问模式#3. GPU内存层级架构与访问模式":"","31-内存层级结构#3.1 内存层级结构":"GPU的内存系统是一个复杂的层级结构，旨在平衡容量、带宽和延迟。物理上越靠近GPU计算核心的内存，其空间通常越小，但带宽越大，访问延迟也越低。\n示意图描述: 原始资料中提供了一张展示GPU内存层级结构的示意图，从最靠近计算核心（上部）到最远的（底部）排列，并标注了容量、带宽（相对值）和延迟（相对值）。\n该图从上到下展示了以下内存层级：\nRegister File: 位于最顶端，最接近计算核心。 L1 Cache \u0026 Shared Memory: 紧随其后。 L2 Cache: 位于L1/Shared Memory之下。 High Bandwidth Memory (HBM): GPU的主存储器，容量最大，但距离计算核心相对较远。 Host Memory (通过PCIE): 位于最底部，是CPU的主内存，通过PCIe总线与GPU连接，访问延迟最高，带宽最低。 图中标注了各层级内存的相对带宽和容量：\n256kB Register File per SM (27MB total)：每个SM 256KB，总共27MB。 192kB L1 Cache \u0026 Shared Memory per SM (20MB total)：每个SM 192KB，总共20MB。 40MB L2 cache shared across all SMs：所有SM共享40MB。 80GB High Bandwidth Memory：80GB，具有1,935GB/s的带宽（标注为1x）。 Host memory through PCIE：带宽标注为0.02x，显著低于HBM。 带宽的相对值表示，从Host Memory到HBM有约50倍的提升 (1/0.02)。从HBM到L2 Cache，再到L1/Shared Memory，乃至Register File，带宽呈指数级增长，同时延迟急剧降低。【若需查看原始图片详情，请参考原文中的“GPU内存层级架构图”】","311-register-file#3.1.1 Register File":"特性: 位于GPU核心内部，速度最快，容量最小。 作用: 用于存储线程的局部变量，每个线程拥有独立的寄存器。访问延迟极低，通常在一个时钟周期内完成。","312-l1-cache--shared-memory#3.1.2 L1 Cache \u0026amp; Shared Memory":"特性: 位于每个SM内部，速度非常快，容量适中。 作用: L1 Cache: 作为SM的局部缓存，用于加速对Global Memory的访问。 Shared Memory: 供同一个Block内的线程共享，实现快速的线程间通信和数据复用。其访问延迟远低于Global Memory。","313-l2-cache#3.1.3 L2 Cache":"特性: 通常由所有SM共享，容量比L1/Shared Memory大，速度介于L1/Shared Memory和HBM之间。 作用: 作为GPU的全局缓存，用于缓存Global Memory的数据，进一步减少对HBM的访问。","314-hbm-high-bandwidth-memory#3.1.4 HBM (High Bandwidth Memory)":"特性: GPU的主存储器，容量最大，带宽极高，但访问延迟相对较高。 作用: 存储大量的计算数据和模型参数，是GPU与CPU之间数据交换的主要介质。","315-host-memory-通过pcie#3.1.5 Host Memory (通过PCIE)":"特性: CPU的主内存，通过PCIe总线与GPU连接。 作用: GPU与CPU进行数据传输的通道。其带宽最低，延迟最高，是GPU计算中常见的性能瓶颈。","32-内存访问特性#3.2 内存访问特性":"","321-带宽与延迟关系#3.2.1 带宽与延迟关系":"物理限制: 物理上，光速上限决定了信息传输的最小延迟。因此，内存距离计算核心越远，访问延迟自然越高。 设计权衡: 内存层级的设计是容量、带宽和延迟之间的权衡。大容量、低成本的内存（如HBM）通常具有较高延迟，而小容量、高成本的内存（如寄存器、L1/Shared Memory）则具有极低延迟和极高带宽。","322-hbm访问模式与连续性#3.2.2 HBM访问模式与连续性":"高效利用HBM（和其他内存）的关键在于优化访问模式。\nHBM访问模式图示描述: 原始资料中提供了一张关于HBM访问模式的示意图，展示了从\"burst\"（突发）到\"one read per page\"（每页一次读取）的效率变化。\n该图可能演示了随着内存访问模式的变化，数据传输效率的差异：\nBurst模式: 当访问是连续的、对齐的，内存控制器能够一次性读取一大块数据（burst），效率最高。图中\"burst部分占大头\"可能指的是这种理想情况。 One read per burst with negligible page reads: 访问模式仍然较好，但可能不是完全对齐，或者存在一些小的间隙，但页内读取效率依然很高。 One read per page: 当访问变得稀疏，每次读取都需要访问一个新的内存页时，开销会显著增加，因为每次页访问都会引入额外的延迟。图中\"足够稀疏之后page read开销占大头，变成one read per page\"描述了效率最低的情况。【若需查看原始图片详情，请参考原文中的“HBM访问模式图”】 连续访问的重要性: 为了最大化HBM的利用率和降低访问延迟，应尽可能地进行连续访问，从而避免频繁的页交换（换页）和不必要的开销。\n大量并发的warp通过合并访存降低访问开销:\nCUDA硬件具备一种称为合并访存（coalesced access） 的机制。当一个warp中的32个线程同时访问Global Memory时，如果它们的内存地址是连续的，硬件能够将这些独立的访问请求合并成一个或少数几个大的内存事务，从而显著提高访存效率。 Example: 一个线程获取float2数据类型（包含两个浮点数）的向量元素，需要 2×4=82 \\times 4 = 82×4=8 字节。 一个warp（32个线程）如果连续访问，理论上会读取 8×32=2568 \\times 32 = 2568×32=256 字节。 一个SM中有4个同时运行的warp，如果它们的数据访问也是连续的，可能一次性读取 256×4=1024256 \\times 4 = 1024256×4=1024 字节。这个1024字节的量，通常与一个内存行（cache line或内存事务的基本单位）的字节数相匹配，从而实现了高效的内存合并访问。 结论: 我们需要确保跨线程束/线程的内存访问是连续的，这样CUDA才能更好地调度线程束，将多个线程的访存请求合并成高效的事务。 线程独立性:\n为了让并行度带来的收益最大化，一个重要的设计原则是：线程之间尽可能少同步，尽可能独立。 这意味着每个线程应尽可能地独立完成自己的计算任务，减少对其他线程的依赖和同步点。 通过将调度工作交给GPU（warp调度器），可以更好地隐藏延迟，提升并发效率。即“你忙你的，我忙我的”，让GPU调度器在不同warp之间快速切换，充分利用计算资源。","4-gpu计算系统优化思路#4. GPU计算系统优化思路":"","41-核心优化目标#4.1 核心优化目标":"GPU计算系统的优化是一个多维度的挑战，主要围绕以下四个核心目标展开：\n延迟 (Latency): 指完成一个操作所需的时间。在GPU中，特别是内存访问延迟，是影响性能的关键因素。 内存 (Memory): 指内存的容量、访问速度和访问模式。高效的内存使用能减少瓶颈。 带宽 (Bandwidth): 指单位时间内数据传输的量。高带宽是GPU处理大规模数据的基础。 算力 (Compute): 指GPU执行计算操作的原始能力（如FLOPS）。 重要提示: 在GPU优化中，一个普遍且至关重要的认知是：算力在上述问题中是最最不重要的部分！首先要充分利用算力——提高GPU利用率！\n这意味着，即使GPU拥有强大的原始计算能力，如果数据不能及时、有效地到达计算核心，或者计算任务不够并行化以充分利用所有核心，那么这些算力就无法被利用。因此，优化的重点往往是解决数据流问题（延迟、内存、带宽），以确保算力能够得到充分利用。","42-gpu利用率目标#4.2 GPU利用率目标":"GPU利用率 是衡量GPU计算资源被实际利用程度的指标。它表示GPU的计算单元在给定时间内处于繁忙状态的比例。 对于复杂的、内存密集型的通用GPU计算任务来说，达到高利用率是极具挑战性的。 实际表现: GPU利用率 ~50% = 表现不错！ 这表明即使是一半的利用率，对于许多工作负载来说也已经是相当好的结果。 GPU利用率 ~75% = 非常厉害！ 达到75%或更高的利用率通常意味着代码已经经过了高度优化，并且能够高效地利用GPU的并行处理能力和内存子系统。","5-具体优化目标与策略#5. 具体优化目标与策略":"","51-优化目标隐藏延迟#5.1 优化目标：隐藏延迟":"延迟 (Latency) 是指完成一个操作所需的时间。在GPU计算中，数据从全局内存（HBM）传输到计算核心的延迟是主要的瓶颈之一。为了克服这一瓶颈，GPU的设计和编程模型都强调通过大量的并发任务来隐藏延迟。","511-大量并发隐藏延迟#5.1.1 大量并发隐藏延迟":"基本原理: 当一个计算单元（如一个warp或SM）因为等待数据从慢速内存（如HBM）加载而停顿时，GPU调度器可以立即切换到另一个准备好执行的计算单元，从而避免处理器空闲。通过并行执行足够的任务，GPU可以确保总是有可执行的任务，从而“隐藏”掉数据加载的延迟。 例子: 文档中提到“这就是为什么执行4个却有64个wrap同时工作的原因”，这指的是在一个SM中，虽然可能只有少数（如4个）warp在同时进行计算，但调度器会管理更多（如64个）处于不同执行阶段的warp。当一个warp因内存访问而阻塞时，调度器可以快速切换到另一个就绪的warp，保持计算单元的忙碌。","512-线程块与sm的映射策略#5.1.2 线程块与SM的映射策略":"充分利用SM: “使用单个线程块启动函数只能将工作分配给一个SM（流处理器组）；为了充分利用具有多个SM的GPU，需要启动多个线程块。” 这强调了为了最大化GPU的计算能力，必须将任务分解为足够多的线程块（blocks），以便这些线程块能够并行地调度到GPU的多个SM上执行。 隐藏延迟: 即使在单个SM内部，启动多个线程块也很有益。当一个线程块的warp因为内存访问而阻塞时，SM可以切换到处理另一个线程块的warp，从而隐藏延迟。","513-warp调度机制#5.1.3 Warp调度机制":"快速上下文切换: GPU的warp调度器能够在单个时钟周期内从一个线程束切换到下一个。这种超快速的上下文切换是隐藏内存访问延迟的关键。当一个warp发起内存请求并进入等待状态时，调度器会立即选择另一个已就绪的warp来执行，从而避免SM的空闲。 并发量: A100 GPU的每个SM支持4个并发warp（即可以在任意时刻实际执行指令的warp数量），但可以同时管理64个在运行中的warp（处于不同状态，包括等待内存、计算等）。这种高并发度确保了在任何给定时间都有足够的warp可以被调度执行。","514-并行访存与合并访问#5.1.4 并行访存与合并访问":"HBM访问模式: 文本指出HBM访问模式应“尽可能的连续访问，从而避免换页！” 这意味着当多个线程访问内存时，如果它们的访问地址是连续的，GPU的内存控制器可以将其合并为一个大的突发访问（burst access），从而更高效地利用内存带宽。 图片描述 (HBM访问模式图示): 原始资料中HBM访问模式的图示可能展示了随着访问连续性（或稀疏性）的变化，内存访问开销的组成。在非常连续的情况下，突发传输（burst）占主导；在适度稀疏时，每次突发可能伴随少量页访问；而在高度稀疏时，页访问开销占大头，可能导致每次读取都需要一个独立的页访问。 合并访存: “大量并发的wrap通过合并访存降低访问开销！” 示例: 一个线程获取 float2 数据类型（8 bytes）。一个warp（32个线程）如果访问连续的内存，可以一次性获取 8 bytes/thread * 32 threads = 256 bytes。一个SM中有4个运行的warp，如果它们访问连续的内存，可以一次性获取 1024 bytes。如果这正好是一行的字节数，那么这将是一个非常高效的访问模式。 重要性: 确保跨线程束/线程的内存访问是连续的，这样CUDA才能更好地调度线程束，实现高效的内存合并（memory coalescing）。内存合并能够显著减少内存事务的数量，从而提高访存效率。","515-线程独立性#5.1.5 线程独立性":"最大限度利用并行度: “让并行度带来的收益最大化的另一个重要设计：threads之间尽可能少同步，尽可能独立！” 原理: 线程之间频繁的同步（例如，__syncthreads()）会引入额外的开销，并可能导致一些线程等待其他线程完成，从而降低并行度。理想情况下，每个线程应独立完成其任务，只在必要时进行同步或通信。将调度交给GPU，让其自由选择就绪的线程执行，可以最大化吞吐量。 示例: 基于CNN的物体识别通常涉及大量独立的卷积操作，每个卷积可以在不同的GPU线程上并行执行，且彼此之间依赖性较低，是并行计算的良好应用场景。","52-优化目标提升带宽利用率#5.2 优化目标：提升带宽利用率":"即使算力强大，如果数据传输速度跟不上，GPU的计算单元也会因为等待数据而空闲。这就是带宽瓶颈。","521-带宽与计算的trade-off#5.2.1 带宽与计算的Trade-off":"定义: TmemT_{mem}Tmem​：用于访问内存的时间。 TmathT_{math}Tmath​：用于执行数学运算的时间。 重叠与总时间: 如果不同线程的内存访问和数学运算可以重叠（即通过流水线（Pipelining） 技术），那么函数的总执行时间是 max(Tmem,Tmath)max(T_{mem}, T_{math})max(Tmem​,Tmath​)。 性能限制因素: 如果 Tmath\u003eTmemT_{math} \u003e T_{mem}Tmath​\u003eTmem​，则该函数是数学（计算）受限的。这意味着计算时间是瓶颈，提高计算能力会有更大收益。 如果 Tmem\u003eTmathT_{mem} \u003e T_{math}Tmem​\u003eTmath​，则该函数是内存（带宽）受限的。这意味着数据传输时间是瓶颈，提高内存带宽会有更大收益。","522-算法算术强度与设备计算密集度#5.2.2 算法算术强度与设备计算密集度":"为了量化这种Trade-off，我们引入算术强度（Arithmetic Intensity） 的概念。\n算术强度 (Arithmetic Intensity):\n算法相关的性质，定义为 #ops/#bytes\\#ops / \\#bytes#ops/#bytes。 表示每传输一个字节的数据，执行了多少次浮点运算（operations）。 设备计算密集度 (Device Compute Intensity):\n设备相关的性质，定义为 BWmath/BWmemBW_{math} / BW_{mem}BWmath​/BWmem​。 BWmathBW_{math}BWmath​ 是设备的峰值浮点运算能力（FLOP/s）。 BWmemBW_{mem}BWmem​ 是设备的峰值内存带宽（Byte/s）。 代表了充分利用设备算力所需的最低算术强度。例如，A100 GPU的设备计算密集度约为100，意味着每传输1字节数据，需要执行100次浮点运算才能完全利用其算力。 关系:\n当任务计算密集度（即算法的算术强度） \u003e 设备计算密集度时：任务是计算受限的。充分利用了设备算力，瓶颈在于计算单元的速度。 当任务计算密集度 \u003c 设备计算密集度时：任务是带宽受限的。未充分利用设备算力，瓶颈在于内存传输速度。 推导: 原始不等式：Tmath\u003eTmemT_{math} \u003e T_{mem}Tmath​\u003eTmem​ 等价于：#opsBWmath\u003e#bytesBWmem\\frac{\\#ops}{BW_{math}} \u003e \\frac{\\#bytes}{BW_{mem}}BWmath​#ops​\u003eBWmem​#bytes​ 通过代数运算，可以重构为：#ops#bytes\u003eBWmathBWmem\\frac{\\#ops}{\\#bytes} \u003e \\frac{BW_{math}}{BW_{mem}}#bytes#ops​\u003eBWmem​BWmath​​ 左侧是算法的算术强度，右侧是设备的计算密集度。","5223-roofline-plot模型#5.2.2.3 Roofline Plot模型":"图片描述 (Roofline Plot): 原始资料中的Roofline Plot是一个二维图表，横轴通常是算术强度 (Arithmetic Intensity)，纵轴是性能 (Performance) (通常以FLOP/s为单位)。 两条线: 一条是水平线 (Peak Performance)，代表设备的峰值计算能力（BWmathBW_{math}BWmath​），这是算力上限。 一条是斜线 (Memory Bandwidth Limit)，代表由内存带宽决定的性能上限，其斜率由设备的内存带宽（BWmemBW_{mem}BWmem​）决定。 交点: 两条线的交点即为设备计算密集度。 工作区域: 当算术强度小于交点时，性能受限于内存带宽（处于斜线部分）。 当算术强度大于交点时，性能受限于计算能力（处于水平线部分）。 目标: 理想情况下，我们希望算法的性能位于Roofline的“屋顶”部分，即达到计算或内存的理论峰值。","523-带宽瓶颈的解决方案#5.2.3 带宽瓶颈的解决方案":"问题: 如果你目前任务的处于带宽瓶颈，怎么办？\nA. 换用更大的显存：通常不能解决带宽瓶颈，因为更大的容量不一定意味着更快的传输速度。 B. 换用更快的显存：正确。更快的显存（如升级到更高带宽的HBM）直接增加了 BWmemBW_{mem}BWmem​，从而减少了设备计算密集度（BWmath/BWmemBW_{math} / BW_{mem}BWmath​/BWmem​），使得任务更容易达到计算受限区域。 C. 换用更快的计算芯片：如果已经是带宽瓶颈，意味着计算单元已经在等待数据，此时再提高计算能力（增加 BWmathBW_{math}BWmath​）只会让设备计算密集度更高，并不能解决瓶颈。 D. 使用更低的精度进行计算：正确。例如，从FP32降到FP16或BF16。这会增加任务计算密集度。因为同样的数据量（例如，一个16位浮点数只占2字节），可以进行更多的运算（如16位乘加），从而提高了 #ops / #bytes 的比值，使得任务更容易达到计算受限区域。 总结: 解决带宽瓶颈的根本方法是提高算法的算术强度（例如，通过降低精度、重用数据）或提高内存带宽。\n挑战: “对于FLOPs非常大的先进GPU，Arithmetic Intensity想达到其设备计算密集度（100 for A100）还是挺难的！”这意味着很多实际应用在A100上仍然是带宽受限的。 解决方案: “只有足够大的矩阵运算才能够满足”。大型矩阵运算通常具有很高的算术强度。 批处理 (Batch Processing): “因此批处理训练可以带来吞吐率提升。” 批处理通过一次处理更多的数据，可以有效地增加操作数与字节传输的比率，从而提高任务的算术强度，使其更接近计算受限。 图片描述 (Batch size vs. Throughput): 原始资料中可能包含一张图，展示了随着 (batch_size * dim_size) * (dim_size * 1024) 在GeForce RTX 3090上执行时，吞吐量如何随批处理大小增加而提升的例子。这图会说明，在较小的批处理大小下，性能受限于内存带宽，吞吐量较低；而随着批处理大小增加，算术强度提高，吞吐量也随之提升，直到达到计算能力的瓶颈。","53-优化目标高效内存使用#5.3 优化目标：高效内存使用":"高效利用内存是优化GPU性能的关键。\n与设备计算密集度关联: “数据传输越高效，任务越容易充分利用算力。” 通过减少实际传输的数据量，或者提高数据的复用率，可以有效地提高算法的算术强度，使其更接近或达到设备计算密集度，从而摆脱带宽瓶颈。","531-多级内存访问与复用#5.3.1 多级内存访问与复用":"策略: “增加片上内存/缓存的复用度，从而减少了实际的设备计算密集度！” GPU具有多级内存层级结构（寄存器、L1缓存、共享内存、L2缓存、HBM）。 片上内存（如寄存器、共享内存、L1/L2缓存）速度远快于片外内存（HBM）。 通过精心设计算法，使数据尽可能在片上内存中多次使用，可以大幅减少对慢速HBM的访问次数，从而降低平均内存访问延迟和带宽需求。","532-矩阵乘法的分块优化示例#5.3.2 矩阵乘法的分块优化示例":"矩阵乘法（C = A * B）是展示内存优化的经典案例。","5321-寄存器级别优化#5.3.2.1 寄存器级别优化":"原始矩阵乘法问题: 在最简单的实现中，对于结果矩阵 CCC 中的每一个元素 CijC_{ij}Cij​，都需要重新读取 AAA 矩阵的第 iii 行和 BBB 矩阵的第 jjj 列。 开销: 如果每次都重新读取，总的内存访问开销非常高，达到 2N32N^32N3（对于 N×NN \\times NN×N 的矩阵）。 寄存器分块 (Tiling): “当V = 1时候，该运算相当于原始矩阵乘法，对每一个C中的单元重新读取对应的行和列，因此开销为2*N^3.” (此处的 V=1 可能指的是没有在寄存器中进行分块复用。) 寄存器级别的优化就是将一小块数据（如矩阵 AAA 的一小行和矩阵 BBB 的一小列）加载到寄存器中，然后在寄存器中完成多次乘加操作，而不是每次都从全局内存中读取。","5322-寄存器-共享内存级别优化#5.3.2.2 寄存器-共享内存级别优化":"层级分块: 这是一个更高级的优化策略，结合了共享内存和寄存器。 思想: 将大矩阵 AAA 和 BBB 分割成若干个子块。 每个线程块负责计算 CCC 矩阵的一个子块。 为了计算 CCC 的一个子块，线程块会分批次地将 AAA 和 BBB 对应的子块从全局内存加载到共享内存 (Shared Memory)。 一旦数据进入共享内存，该线程块内的所有线程都可以高速访问这些数据。 每个线程再从共享内存中加载更小的数据块到自己的寄存器 (Registers) 中进行计算。 优势: 共享内存的访问速度远快于全局内存，且可以在一个线程块内高效复用。通过这种分层的数据移动和复用，可以显著减少对全局内存的访问次数，极大地提高内存访问效率，从而提升整体性能。 示例: “向量相乘生成累加矩阵 L\u003eV” (这可能是一个具体的矩阵乘法分块算法的命名或描述，例如 L 表示加载到共享内存的块大小，V 表示加载到寄存器的块大小，且 L 大于 V)。","6-flashattention案例分析#6. FlashAttention案例分析":"FlashAttention 是针对 Transformer 模型中的注意力（Attention）层在GPU上进行高效计算而提出的一系列优化方法，旨在解决标准Attention计算中由于内存访问模式不佳导致的性能瓶颈。","61-transformer-attention层问题#6.1 Transformer Attention层问题":"在 Transformer 模型中，Attention 机制的核心计算涉及 Q（Query）、K（Key）、V（Value）矩阵。对于一个上下文长度（context length）为 NNN 的序列，Attention 的计算公式通常包含 N×NN \\times NN×N 大小的中间矩阵 SSS 和 PPP： Attention(Q,K,V)=softmax(QKTdk)V\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})VAttention(Q,K,V)=softmax(dk​​QKT​)V\n其中，S=QKTS = QK^TS=QKT 是一个 N×NN \\times NN×N 的分数矩阵，P=softmax(QKTdk)P = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})P=softmax(dk​​QKT​) 是注意力权重矩阵。\n随着 NNN（上下文长度）的增大，主要问题如下：\n内存开销巨大：中间结果 SSS 和 PPP 矩阵的大小是 N×NN \\times NN×N，其存储和传输开销会随着 NNN 的平方增长，迅速消耗 GPU 的高带宽内存（HBM）。 HBM访存频率过高：标准Attention计算需要频繁地在HBM上读写 N×NN \\times NN×N 大小的中间矩阵，导致 HBM 成为性能瓶颈。 任务计算密集度低：由于大量的内存访问，导致实际的计算量相对于数据传输量较少，即任务计算密集度很低。 GPU利用率不高：在内存带宽限制下，GPU的算力无法得到充分利用，导致GPU利用率低下。","62-flashattention核心思想#6.2 FlashAttention核心思想":"FlashAttention 的核心在于避免显式地构建和存储完整的 N×NN \\times NN×N 大小的注意力矩阵 SSS 和 PPP，从而减少 HBM 的读写量。","621-分块思想-tiling#6.2.1 分块思想 (Tiling)":"核心策略：通过将注意力计算分解成更小的块（tile），并在 GPU 的片上内存（如 SRAM/Shared Memory）中进行计算。 跳过中间结果：在每个块的计算过程中，直接从输入的 Q、K、V 矩阵生成最终的输出 OOO 矩阵，而不显式地将 SSS 和 PPP 写入 HBM。这避免了 N×NN \\times NN×N 矩阵的存储和传输开销。 目的：减少对 HBM 的访问，提高数据局部性，充分利用片上内存的高带宽和低延迟特性。","622-重计算-recomputation#6.2.2 重计算 (Recomputation)":"策略：FlashAttention 在前向传播时不保存中间结果 SSS 和 PPP。 反向传播处理：在反向传播（BP）时，如果需要 SSS 和 PPP 来计算梯度，则选择重新计算这些中间结果，而不是从 HBM 中读取它们。 权衡：这种方法用额外的计算成本（重新计算 SSS 和 PPP）来换取显著的内存带宽节省，因为重新计算通常比从 HBM 读写更划算，尤其是在带宽受限的情况下。","63-flashattention具体实现#6.3 FlashAttention具体实现":"","631-partial-updates#6.3.1 Partial Updates":"FlashAttention通过分块（Tiling）的方式，将 Q、K、V 沿 token 维度切分，并在一个 GPU 块（block）内完成局部的注意力计算。\n图像描述（结合PPT内容）： 想象一个大的 QQQ 矩阵，它被水平切分成若干行，每一行代表一个 token 的查询向量。 同样，KKK 矩阵被水平切分，每个行代表一个 token 的键向量。 一个 GPU block 负责处理 QQQ 的一个“块”与 KKK 的所有“块”之间的注意力计算。 例如，一个 block 可能负责计算 QiQ_iQi​ （Q矩阵的第i个分块）对所有 KjK_jKj​ （K矩阵的所有分块）的注意力，并逐步累积输出 OiO_iOi​。 在计算过程中，每一个小分块的 QQQ 和 KKK 会被加载到片上内存（如 Shared Memory），计算出局部的注意力分数和输出，然后将这些局部结果合并。 token 维度切分：这意味着我们将序列长度 NNN 沿着某个维度（通常是行维度）进行切分，分配给不同的 GPU block 来并行处理。 目标：通过在片上内存中完成大部分计算，减少对慢速 HBM 的依赖，从而实现更高的吞吐量。","632-flashattention-on-gpt2#6.3.2 FlashAttention on GPT2":"FlashAttention在实际模型如GPT2上的应用表明，它可以显著提升训练速度和降低内存消耗，尤其是在处理长序列时。","64-flashattention的挑战#6.4 FlashAttention的挑战":"","641-block间同步问题#6.4.1 Block间同步问题":"在FlashAttention v1的设计中，一个 GPU block 可能需要读取 Q 的一个部分，然后遍历所有的 K 和 V 分块，逐一计算并更新输出。 这导致了Load/write synchronization issue（加载/写入同步问题）：不同的 Block 可能尝试写入输出矩阵的同一部分或需要协调对共享数据的访问，这会引入复杂的同步机制和潜在的竞争条件，从而影响效率。 图像描述（结合PPT内容）： ...... One block：PPT图示可能显示一个Block在处理 Q_i 时，需要与所有 K_j 交互。 这意味着一个 Block 的输出并非完全独立，它可能需要等待其他 Block 完成其对应的 K/V 分块的处理，或者在写入输出时与其他 Block 协调。 这种设计使得Block之间不能尽可能相互独立地写入，降低了并行度。","65-flashattention-v2的改进#6.5 FlashAttention v2的改进":"FlashAttention v2 主要解决了 FlashAttention v1 中的 Block 间同步和数据依赖问题，进一步提高了并行效率。","651-解决方案循环结构调整#6.5.1 解决方案：循环结构调整":"核心改进：FlashAttention v2 的主要优化在于交换了内外循环的顺序（“Just swap the outer/inner loop!\"）。 FlashAttention (v1)：每个 block 计算所有 tokens “询问部分上下文tokens” 的工作。这意味着所有 blocks 完成才能得到完整的 scores 以及输出 O 的任何子值。 FlashAttention v2：每个 block 计算部分 tokens “询问所有上下文tokens” 的工作。 目的：通过这种调整，每个 GPU block 负责计算输出矩阵 OOO 的不同部分（One block for one O_i），使得Block之间的数据写入尽可能地相互独立。 效果：减少了 Block 间的同步需求和潜在的写冲突，进一步提升了并行效率和 GPU 利用率。","652-flashattention-v2与flashattention的对比#6.5.2 FlashAttention v2与FlashAttention的对比":"FlashAttention v1：一个 block 可能负责处理 Q 的某一部分，然后它需要遍历 K 的所有分块。要得到最终的输出 OOO，需要将所有 block 的计算结果合并。这种模式下，所有 blocks 完成才能得到完整的 scores 以及输出 OOO 的任何子值。 FlashAttention v2：一个 block 负责计算输出 OOO 的某一部分 O_i。为了得到 O_i，这个 block 会读取 Q 的对应部分 Q_i，并遍历 K 和 V 的所有分块。因此，每个 block 处理输出矩阵 OOO 的不同部分。这种设计使各个 block 的输出计算更加独立。 总结：FlashAttention v2 的优化方向是让每个 block 独立地计算输出矩阵的特定部分，从而最小化 block 之间的依赖和同步开销。\n参考原始论文获取更多细节： FlashAttention: https://arxiv.org/abs/2205.14135 FlashAttention v2: https://arxiv.org/abs/2307.08691"},"title":"GPU架构与计算系统优化加速"},"/notes/learn/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96/mlsys%E5%BE%AE%E8%B0%83%E4%BC%98%E5%8C%96/":{"data":{"":"","1-大语言模型llm的部署过程#1. 大语言模型（LLM）的部署过程":"大语言模型（LLM）从基础的语言能力到能够理解并执行复杂任务，通常会经历一个多阶段的部署过程。这个过程涵盖了从模型学习通用知识到适应特定用户偏好的精细化调整。","11-预训练-pre-training#1.1 预训练 (Pre-Training)":"定义与目标： 预训练是LLM部署过程的第一步，通过大规模无监督学习进行。 模型在海量文本数据上进行训练，学习语言的结构、知识和模式。 核心目标是通过语言建模任务（例如，预测下一个词）使模型掌握通用的语言理解能力。 模型能力： 预训练后的模型能够生成合理的文本段落。 但此时模型对特定任务或用户指令的理解和响应能力仍然有限。它能“说”出通顺的语言，但还不懂得如何“做”任务。","12-监督微调-supervised-fine-tuning-sft#1.2 监督微调 (Supervised Fine-Tuning, SFT)":"定义与目标： 监督微调是LLM部署过程的第二步，它使用监督学习方法。 其目的是引导模型执行更为具体的任务，使其能够更好地理解和响应用户指令。 核心目标是让模型“学会做任务”、“变得像示范一样”。 训练过程： 通过监督学习调整模型参数，使其能更准确地执行特定任务。 应用示例： 如回答问题（Question Answering）、代码生成、文本摘要等。 相关的技术包括Instruct Tuning（指令微调）、InstructGPT等。","13-偏好优化-preference-optimization#1.3 偏好优化 (Preference Optimization)":"定义与目标： 偏好优化是LLM部署过程的第三步，通常通过强化学习或其他高级技术进行。 其目的是进一步调整模型的生成行为，使其更符合用户的期望和人类偏好。 核心目标是让模型“选择更好的回答”，即生成不仅正确，而且更“好”的输出。 模型能力： 经过偏好优化后的模型在对话、回答问题、内容生成时更符合人类期望。 它有助于减少不合适或不受欢迎的输出。 应用示例： 著名的应用包括RLHF (Reinforcement Learning from Human Feedback)、ChatGPT、Claude等。","2-指令微调-instruction-tuning#2. 指令微调 (Instruction Tuning)":"","21-指令微调的定义与目标#2.1 指令微调的定义与目标":"定义： 指令微调是指使用指令性数据对大语言模型进行微调的过程。 指令性任务数据包括各种明确的指令、提示和目标，这些数据要求模型执行特定的功能或生成特定的输出。 训练过程： 通过指令性任务数据，训练模型理解输入指令的含义，并生成相应的输出。 核心目标： 将模型从单纯的“吐字”（即生成语法正确但没有明确意图的文本）转变为“能够完成任务”（即根据指令执行特定功能）。 通过指令微调，可以增强模型的理解能力和执行能力，使其更好地适应各种实际应用场景。","22-指令微调数据示例#2.2 指令微调数据示例":"指令微调的数据通常是高质量的“指令-响应”对。这些数据可能来源于人工标注、现有数据集转换或自生成等方式。 值得注意的是，指令微调后的语言模型表现出**零样本学习（Zero-shot learning）**的能力。这意味着模型在没有见过特定任务的示例数据时，也能通过理解指令来完成该任务。 参考文献： “Finetuned language models are zero-shot learners.” (Wei, Bosma, Zhao, Guu, et. al, 2021) 进一步证实了指令微调对于实现零样本学习的重要性。","3-参数高效微调-parameter-efficient-fine-tuning-peft#3. 参数高效微调 (Parameter Efficient Fine-Tuning, PEFT)":"","31-全参数微调的挑战#3.1 全参数微调的挑战":"大语言模型（LLM）通常拥有数十亿甚至上千亿的参数。对这些模型进行全参数微调 (Full Fine-tuning) 意味着训练过程中需要更新模型的所有参数。虽然全参数微调通常能达到最好的效果，但它带来了显著的挑战：\n计算成本极高： 需要大量的计算资源（如GPU）和时间。 存储成本高： 每个微调任务都需要保存一份完整的模型副本，占用巨大的存储空间。 工作内存需求大： 训练过程中需要将整个模型参数加载到内存中，对显存要求极高。 部署复杂： 部署多个微调模型副本会带来巨大的基础设施开销。","32-peft-的目标与方法#3.2 PEFT 的目标与方法":"参数高效微调 (Parameter Efficient Fine-Tuning, PEFT) 的核心目标是：在只更新少量模型参数的情况下，实现与更新整个模型相近的微调性能。这意味着通过更少的计算、更少的工作内存和更少的存储，就能高效地将预训练模型适应到特定任务。\nPEFT 的主要方法包括：","321-soft-prompts#3.2.1 Soft Prompts":"Soft Prompts 方法通过在预训练模型的输入中添加可学习的部分 prompts（提示），用于指导模型生成特定于任务的输出。这种方法的优势在于，它只微调这些额外的、小部分的提示参数，而不是模型的原始权重，从而实现高效的适应。","3211-soft-prompt-方法原理#3.2.1.1 Soft Prompt 方法原理":"传统 Prompt 的局限： 传统的 Prompt 依赖人工设计，例如：“Classify the sentiment of this sentence: [输入文本]”。这种人工设计的提示效果可能不稳定，且需要领域专家经验。 Soft Prompt 的引入： Soft Prompt 方法定义了一组可训练的 Soft Prompt 嵌入向量，例如 P1,P2,...,PnP_1, P_2, ..., P_nP1​,P2​,...,Pn​。 拼接与输入： 这些 Soft Prompt 嵌入向量与输入文本的 Token 嵌入拼接后，一起输入到模型中，形成新的输入序列，例如：[P1, P2, ..., Pn, Token1, Token2, ...]。 训练机制： 在训练过程中，只优化这组 Soft Prompt 嵌入向量 P1,P2,...,PnP_1, P_2, ..., P_nP1​,P2​,...,Pn​，而不是模型本身的参数。模型的原始权重保持冻结。 效果： 经过训练的 Soft Prompt 会自动调整输入，使得模型更倾向于正确地识别和完成特定任务（如情感识别）。它让模型学会使用一种“模型语言”进行提示。","3212-prompt-tuning#3.2.1.2 Prompt Tuning":"机制： Prompt Tuning 是 Soft Prompts 的一种实现。它在输入侧增加一段可训练的 embedding。 输入结构： 模型的输入变为：[SOFT_PROMPT_1 ... SOFT_PROMPT_k] + original tokens。其中 SOFT_PROMPT_i 是可训练的嵌入向量。 特点： 这种方法简单，只在输入层进行修改，训练参数量极小。","3213-prefix-tuning#3.2.1.3 Prefix Tuning":"机制： Prefix Tuning 是一种在 Transformer 每一层的输入都增加一个“可训练的前缀 embedding”的方法。 前缀处理： 这个前缀 embedding（通常约几十个 token）会经过一个小的多层感知机（MLP）进行投影。 KV Cache： 投影后的结果会生成 Transformer 每一层 KV cache 的附加内容。重要的是，各层的前缀参数是独立不共享的。 输入结构： 模型的输入变为：[PREFIX...][x1 x2 x3 ...]。 KV Cache 结构： 经过 Prefix Tuning 后，Transformer 层的 KV cache 结构是 prefix + normal tokens。 特点： 相比 Prompt Tuning，Prefix Tuning 影响模型内部更深层的表示，可能带来更好的性能，但参数量略大。","322-frozen-layers#3.2.2 Frozen Layers":"迁移学习的基本思想： Frozen Layers 是迁移学习的一种基本方法，尤其在计算机视觉（CV）领域的多层卷积神经网络（CNN）中被广泛应用。 实现方式： 在微调过程中，冻结模型的前面几层参数（使其梯度不更新），只更新模型后面层的参数。 原理： 这种方法的理论基础是，模型的不同层学习到特征的抽象程度不同。通常，前面层学习到的是更通用的、低级的特征（如边缘、纹理），而后面层学习到的是更高级、任务特定的特征。因此，冻结通用特征层，只微调任务特定层，可以高效地适应新任务。 CV 经典模型借鉴： 类似于 CV 中冻结预训练的 ResNet 或 VGG 的大部分层，只微调顶部的分类器层。","323-adapters#3.2.3 Adapters":"机制： Adapter 方法通过在预训练模型的内部插入一个或多个轻量级的适配层（Adapter）来实现参数高效微调。 原始模型： 预训练模型的原始参数在微调过程中保持固定。 训练过程： 微调过程只更新 Adapter 部分的参数。 Adapter 结构： Adapter 通常是一个带有小隐藏层大小的多层感知机 (MLP)。它通常是一个残差连接结构，即 output = input + Adapter(input)。 【若需查看原始图片详情，请参考原文中的“Adapter: MLP with small hidden size”示意图】。该图展示了一个Adapter模块，它接收来自Transformer层的主路径输出，经过一个Down Projection、一个激活函数和一个Up Projection后，将结果通过残差连接加回到主路径。中间的隐藏层维度通常比主路径的维度小很多。 参数量： Adapter 的参数量通常只占模型总量的1%左右，因此非常高效。 局限性： 将 Adapter 串行地插入到模型的管道中，可能会导致信息瓶颈，从而在某些情况下影响模型的性能，尤其是在Adapter数量较多或设计不当时。","324-低秩适配-low-rank-adaptation-lora#3.2.4 低秩适配 (Low-Rank Adaptation, LoRA)":"","3241-lora-核心思想#3.2.4.1 LoRA 核心思想":"冗余观察： 大语言模型在完成训练之后，其模型参数常常存在巨大的冗余。 低秩分解： LoRA 的核心思想是，对大语言模型中的部分权重矩阵进行低秩分解。 只更新低秩矩阵： 通过这种方法，微调时只需要更新这些低秩矩阵，而无需更新整个权重矩阵。 插入适配层： 具体实现是在原始的预训练模型中，通过插入可训练的低秩适配层来调整模型，同时保持原始参数不变。 公式表示： 常规的前向传播是：h=Wxh = Wxh=Wx 带有 LoRA 的前向传播变为：h=Wx+BAx=(W+BA)xh = Wx + BAx = (W + BA)xh=Wx+BAx=(W+BA)x 这里 WWW 是原始的预训练权重矩阵（冻结），xxx 是输入。 BBB 和 AAA 是两个低秩矩阵，其中 AAA 的维度是 r×dinr \\times d_{in}r×din​，BBB 的维度是 dout×rd_{out} \\times rdout​×r，且 rrr (秩) 远小于 min(din,dout)min(d_{in}, d_{out})min(din​,dout​)。 【若需查看原始图片详情，请参考原文中的 LoRA 示意图】。该图展示了 WWW 矩阵与输入 xxx 相乘，同时有一个旁路分支，输入 xxx 先与 AAA 矩阵相乘，再与 BBB 矩阵相乘，最后将 BAxBAxBAx 的结果加到 WxWxWx 上。这形象地说明了 LoRA 如何通过在现有权重矩阵旁边增加一个低秩更新分支来工作。","3242-lora-初始化#3.2.4.2 LoRA 初始化":"保证初始状态： LoRA 的设计保证了在初始化时，微调后的模型与原模型功能一致。 初始化策略： 通常将矩阵 AAA 初始化为随机高斯分布的小值，而矩阵 BBB 初始化为零矩阵。 效果： 这样 BABABA 的乘积在训练开始时是零矩阵，即 WLoRA=W+BA=W+0=WW_{LoRA} = W + BA = W + 0 = WWLoRA​=W+BA=W+0=W，确保了初始状态与原始模型相同，避免了不必要的扰动。","3243-lora-的热替换能力#3.2.4.3 LoRA 的热替换能力":"灵活性： LoRA 的一个显著优点是其极高的灵活性，可以在一个预训练模型上轻松地替换不同的 Adapter。 多任务支持： 这使得一个基础大模型能够灵活支持多个不同的微调任务。例如，同一个基础模型可以加载针对问答、代码生成或文本摘要的不同 LoRA Adapter，而无需存储多个完整的模型副本。 部署优势： 这种能力极大简化了多任务模型的部署和管理。","3244-lora-对推理延迟和计算量的影响#3.2.4.4 LoRA 对推理延迟和计算量的影响":"训练完成后的合并： 当 LoRA 微调完成后，BABABA 的部分可以直接加回到原始参数矩阵 WWW 中，形成一个新的有效权重矩阵 WLoRA=W+BAW_{LoRA} = W + BAWLoRA​=W+BA。 推理阶段： 在推理阶段，只需要使用这个合并后的 WLoRAW_{LoRA}WLoRA​ 矩阵，与常规的 WWW 矩阵操作完全一致。 零影响： 因此，LoRA 在推理时不影响延迟和计算量。这与 Adapters 方法形成对比，Adapters 在推理时通常需要额外的计算步骤。","3245-lora-在-transformer-中的应用#3.2.4.5 LoRA 在 Transformer 中的应用":"可替换算子： LoRA 可以替换 Transformer 模型中任何线性矩阵运算算子 (Linear)。 常见应用位置： Attention 机制中的 Q (Query), K (Key), V (Value) projection 层。 Attention 机制中的 output projection 层。 前馈网络 (FFN) 或多层感知机 (MLP) 中的 linear1 / linear2 层。 Embedding 层（较少使用，因为 embedding 矩阵通常很大，低秩近似效果可能不佳）。 示例配置： 例如，LoraConfig(target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"]) 指示 LoRA 应用于 Q, K, V 投影层。","3246-mlora-基于管道并行化的多-lora-微调#3.2.4.6 mLoRA: 基于管道并行化的多 LoRA 微调":"mLoRA 是一种针对在多 GPU 环境下同时微调多个 LoRA 任务而设计的系统，旨在提高 GPU 利用率和吞吐量。\n多 LoRA 任务： mLoRA 允许多个 LoRA 任务在不同的 GPU 上同时进行微调。 内存复用： 由于所有 LoRA 任务共享同一个基础模型（预训练模型），因此可以通过在一个基础模型上微调来增加内存复用，从而提高效率。","32461-lorapp-优化#3.2.4.6.1 LoRAPP 优化":"管道并行挑战： 传统的管道并行（如 PipeDream）解决了管道并行中的“气泡时间 (Bubble time)”问题，但常常会导致异步更新，不适用于需要同步梯度的场景。 LoRA 的特殊性： 在 mLoRA 中，不同的 LoRA finetuning 任务更新的是各自不同的 LoRA 组件（即各自的 AAA 和 BBB 矩阵），这些组件之间相互没有影响。 LoRAPP 方案： 利用 LoRA 任务的这种独立性，LoRAPP 直接采用 PipeDream 的做法进行设备间的任务调度，将每个 LoRA 微调看作一个 “microbatch”。这允许在不同 GPU 上同时处理不同 LoRA 任务的不同阶段，实现高效的管道并行。","32462-batchlora-优化#3.2.4.6.2 BatchLoRA 优化":"基础模型复用： 不同的 LoRA 任务共享相同的基础模型参数。 Batching： 基于此，不同的 LoRA 任务的数据可以在基础模型部分组成一个大的Batch进行工作。这意味着在计算基础模型的共享前向/后向时，可以将来自不同 LoRA 任务的数据批量处理。 提高 GPU 利用率： 这种 BatchLoRA 机制显著增加了 GPU 的利用率，因为它减少了基础模型计算的重复开销。","32463-两者结合#3.2.4.6.3 两者结合":"mLoRA 将 LoRAPP 和 BatchLoRA 两种优化结合起来：\nMicrobatch 内： 每个 microbatch 使用 BatchLoRA 尽可能多地塞入任务数据，以增加内存和 GPU 利用率。 Microbatch 间： microbatch 之间采用 PipeDream 的 1F1B (One Forward One Backward) 方式进行更新，实现零气泡 (zero bubble)，进一步提高管道效率。","32464-lora-任务数量与吞吐量#3.2.4.6.4 LoRA 任务数量与吞吐量":"【若需查看原始图片详情，请参考原文中的“Throughput comparisons among different parallelism strategies with varying numbers of simultaneously trained LoRA adapters.”图】。该图通常会展示随着同时训练的 LoRA Adapter 数量增加，不同并行策略（如仅 BatchLoRA、仅 LoRAPP、mLoRA 等）的吞吐量（例如，每秒处理的样本数或 token 数）。通常，结合了 LoRAPP 和 BatchLoRA 的 mLoRA 策略，其吞吐量会随着 LoRA 任务数量的增加而显著提升，表明其能更高效地处理并行微调场景。","4-偏好优化-preference-optimization#4. 偏好优化 (Preference Optimization)":"","41-偏好优化的目的与数据特点#4.1 偏好优化的目的与数据特点":"目的： 偏好优化旨在让模型生成的文本更符合人类偏好和期望。这是在大语言模型部署过程中，继预训练和监督微调之后，进一步提升模型实用性和用户满意度的关键步骤。 数据特点： 与监督微调所使用的带有标准答案（标签）的平均数据集不同，偏好优化的训练数据一般没有标准答案。 它通常只包含相对的评分或排名，即表达了某个输出比另一个输出“更好”的偏好信息。 例如： 在代码数据集中，我们希望模型能够更多地学习优秀编程者编写的代码，而不仅仅是任何一段能够运行的代码。","42-偏好优化方法概述#4.2 偏好优化方法概述":"为实现模型生成行为与人类偏好的对齐，业界发展了多种偏好优化方法：\n基于人类反馈的强化学习 (RLHF, Reinforcement Learning from Human Feedback)： 这是当前最主流和成功的方法之一，通过人类对模型输出的偏好反馈来训练奖励模型，并进一步使用强化学习优化语言模型。 基于人类提供的规则列表的自我训练机制 (如 Constitutional AI)： 通过设定一系列原则或规则，引导模型进行自我评估和修正，使其输出符合预设的规范。 基于重新标注的有监督方法 (HIR)： 对现有数据进行重新标注，使其包含偏好信息，然后进行监督学习。 直接偏好优化 (DPO, Direct Preference Optimization)： 一种更直接的偏好学习方法，它通过一个单一的优化目标来直接学习偏好，而无需训练单独的奖励模型。 强化自训练 (ReST)： 模型通过自我生成数据和评估来提升性能，形成一个自给自足的训练循环。 基于人工智能反馈的强化学习 (RLAIF)： 使用另一个AI模型作为奖励函数来提供反馈，而非直接依赖人类反馈。","43-强化学习-reinforcement-learning-rl-基础#4.3 强化学习 (Reinforcement Learning, RL) 基础":"定义： 强化学习是一种机器学习范式，智能体（Agent）通过与环境（Environment）进行交互，并根据环境的奖励（Reward）反馈，不断调整自身行为（Actions），以期找到一种策略，从而获得最大化的累积奖励。 核心组成要素： 智能体 (Agent)： 学习者或决策者，在大语言模型场景中即为大语言模型本身。 环境 (Environment)： 智能体所处的外部世界，可以是一个模拟器、真实世界，或在偏好优化中指代人类反馈系统。 动作 (Actions)： 智能体在环境中可以执行的操作，对于大语言模型而言，就是生成文本。 环境状态 (Environment State)： 环境在某一时刻的状况。 奖励 (Reward)： 环境对智能体执行动作后给出的反馈信号，用于评估动作的好坏。正奖励鼓励智能体的行为，负奖励则抑制。 工作机制： 智能体观察环境状态，选择并执行一个动作。环境接收动作后，更新到新的状态，并给予智能体一个奖励。智能体根据这个奖励来调整其内部策略或模型参数，以期望在未来获得更高的累积奖励。这个过程是一个持续的试错与学习循环。 应用示例： 围棋游戏（AlphaGo）、机器臂控制、自动驾驶等。 图片内容描述： 原始文档中的“什么是强化学习 (Reinforcement Learning, RL) ？”示意图清晰地描绘了强化学习的循环过程： 智能体首先从环境中获取当前的环境状态。 根据当前状态，智能体决定并执行动作。 环境收到动作后，会产生一个环境奖励，并更新到新的环境状态。 智能体根据收到的奖励信号来更新模型（即调整其策略），以在未来的交互中获得更多奖励。 这个循环持续进行，智能体通过不断与环境互动和学习，最终掌握最优策略。 【若需查看原始图片详情，请参考原文中的“什么是强化学习 (Reinforcement Learning, RL) ？”示意图】","44-基于人类反馈的强化学习-rlhf#4.4 基于人类反馈的强化学习 (RLHF)":"RLHF 是偏好优化的核心方法，它通过引入人类的偏好反馈来指导大语言模型的学习，使其生成更符合人类期望的内容。","441-rlhf-的挑战与瓶颈#4.4.1 RLHF 的挑战与瓶颈":"瓶颈： 在传统的强化学习设置中，如果直接使用人类作为奖励的提供者，那么人类将成为整个微调训练的瓶颈。这是因为强化学习通常需要大量的环境交互和实时反馈，而人类提供反馈的速度和效率远低于模型训练所需。 解决方案思路： 为解决这一问题，核心思路是训练一个能够预测人类判断的“人类”模型，即奖励模型 (Reward Model)，来代替人类进行高效的打分。 历史成功案例： [Christiano 等人] (2017) 在 MuJoCo 和 Atari 游戏中成功训练了一个能够遵循人类偏好的模型，而所需的真实人类环境交互数据标注量不到 1%，这证明了奖励模型的可行性。","442-奖励模型-reward-model#4.4.2 奖励模型 (Reward Model)":"作用： 奖励模型 (Reward Model, RM) 是RLHF中的核心组件，它的目标是学习人类的偏好，并能够对语言模型的生成结果进行打分，以量化其符合人类偏好的程度。在强化学习阶段，它充当了奖励函数，为语言模型提供训练信号。","4421-奖励模型的训练数据人类偏好数据#4.4.2.1 奖励模型的训练数据：人类偏好数据":"数据来源： 奖励模型的训练依赖于人类偏好数据。 数据收集方式： 通常，人类被要求对语言模型生成的多个回答进行比较、排名或直接打分。这些评估会基于多种指标，包括但不限于： 有用性 (Helpfulness)：回答是否能有效解决问题或提供所需信息。 无害性 (Harmlessness)：回答是否避免了不当、歧视或有害内容。 真实性 (Truthfulness)：回答是否准确和可信。 连贯性 (Coherence)：回答的逻辑性和流畅性。 图片内容描述： 原始文档中的“奖励模型的训练数据：人类偏好数据”图示通常会展示一个流程：对于同一个“问题/指令”，语言模型会生成多个“LLM人类回答”候选。然后，人类评估员会对这些回答进行比较和排序，或者直接给出“反馈分数”，指出哪个回答更符合他们的偏好。这些带有偏好信息的数据集被用来训练奖励模型。 【若需查看原始图片详情，请参考原文中的“奖励模型的训练数据：人类偏好数据”示意图】 重要性： 预训练模型和监督微调后的模型，其输出往往难以在上述多维度上同时满足人类的高要求，因此需要奖励模型来引导其向符合人类偏好的方向优化。","4422-奖励模型的作用#4.4.2.2 奖励模型的作用":"替代人类反馈： 一旦奖励模型训练完成，它就能高效地为语言模型生成的所有输出提供奖励分数，从而实现强化学习的规模化训练，避免了对人类的实时依赖。 引导模型行为： 强化学习算法会利用这些奖励分数作为信号，更新语言模型的参数，使其倾向于生成高分（即更符合人类偏好）的文本。","443-rlhf-训练过程#4.4.3 RLHF 训练过程":"RLHF 的整个训练过程通常包含三个关键阶段：\n监督微调 (SFT, Supervised Fine-Tuning)：\n目的： 使用人工标注的高质量数据（例如：prompt → 理想输出）对预训练的大语言模型进行微调。 作用： 使模型能够更好地理解指令，并生成合理且符合语法规范的初始输出，将模型从“吐字”阶段调整到“能够完成任务”的合理初始状态，确保模型不会生成不着边际的内容。 训练奖励模型 (Reward Model, RM)：\n目的： 利用SFT阶段的模型生成的数据，结合人类偏好标注，训练一个独立的奖励模型。 过程： 人类对SFT模型生成的多个输出进行打分或排名，奖励模型学习预测**“人类更喜欢哪个输出”**，从而捕捉人类的偏好模式。 强化学习 (Reinforcement Learning)：\n目的： 使用训练好的奖励模型作为奖励函数，通过强化学习算法（如PPO, Proximal Policy Optimization）进一步微调语言模型。 过程： 语言模型在接收到奖励模型的反馈（分数）后，会调整自身参数，使其倾向于生成获得高分（即更符合人类偏好）的文本。这是一个循环迭代的过程，不断优化模型，使其输出越来越符合人类期望。 图片内容描述： 原始文档中的“RLHF训练过程”图示概括了这三个步骤的流程： SFT：一个预训练模型通过人工标注数据进行监督微调，得到一个基础模型。 训练奖励模型：SFT后的模型生成多个回答，人类对这些回答进行偏好排序，利用这些人类偏好数据训练一个独立的奖励模型。 强化学习：SFT后的模型作为智能体，与训练好的奖励模型（作为奖励函数）和PPO等强化学习算法结合，形成一个强化学习循环。奖励模型对语言模型的生成进行评分，强化学习算法根据这些评分优化语言模型。 【若需查看原始图片详情，请参考原文中的“RLHF训练过程”示意图】","444-rlhf-提升大模型实际功用#4.4.4 RLHF 提升大模型实际功用":"RLHF 在实践中显著提升了大语言模型在特定任务上的表现，使其更具实际应用价值：\n总结任务： [Stiennon et al., 2020] 的研究表明，RLHF 能够显著提升模型在文本总结任务上的表现。 【若需查看原始图片详情，请参考原文中的“Performance on summarization”图表，该图通常会对比基础模型、SFT模型和RLHF模型在总结性能上的提升】 代码补全/生成： [Bai et al., 2022] 的研究显示，在给定上下文的情况下，RLHF 能够提高模型填充 Python 函数体的能力。 【若需查看原始图片详情，请参考原文中的“Performance on filling python function body given the context”图表，该图通常会展示不同模型大小下，RLHF对代码生成性能的积极影响】","445-verl-rlhf-统一框架#4.4.5 VERL: RLHF 统一框架":"VERL 是一个为RLHF设计的全流程统一框架，它旨在将RLHF的各个核心阶段（SFT、奖励模型训练、强化学习训练）无缝集成。 关键特性： 高速策略推理与采样： 实现了10倍以上的加速，显著提升了RLHF训练的效率。 多种RL算法支持： 框架支持多种强化学习算法，包括PPO (Proximal Policy Optimization)、GRPO (Generalized Reinforcement Learning with Policy Optimization) 和 DPO (Direct Preference Optimization)，为研究和应用提供了灵活性。"},"title":"MLSYS微调优化"},"/notes/learn/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96/mlsys%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1/":{"data":{"":"","1-llm基础与生成机制#1. LLM基础与生成机制":"","11-语言模型-lm-定义#1.1 语言模型 (LM) 定义":"语言模型 (Language Model, LM) 的核心功能是对一系列词元 (token) 序列的概率分布进行建模。\n词汇表 (A\\mathcal{A}A)：这是一个包含所有可能词元的集合。 语言模型的概率赋值：对于词汇表 A\\mathcal{A}A 中的任意一个词元序列 A1,A2,…,AL∈AA_1, A_2, \\dots, A_L \\in \\mathcal{A}A1​,A2​,…,AL​∈A，语言模型会为其分配一个介于 0 和 1 之间的概率值 P(A1,A2,…,AL)∈[0,1]P(A_1, A_2, \\dots, A_L) \\in [0,1]P(A1​,A2​,…,AL​)∈[0,1]。 概率的直观含义：这个概率值直观地表示了一个词元序列的“合理性”或“流畅性”。概率越高，序列越符合语言习惯或训练数据中的模式。 示例： 假设词汇表为 A={the,man,walks,on,street}\\mathcal{A}=\\{\\text{the}, \\text{man}, \\text{walks}, \\text{on}, \\text{street}\\}A={the,man,walks,on,street}。 语言模型可能会分配以下概率：\nP(the,man,walks,on,street)=0.02P(\\text{the}, \\text{man}, \\text{walks}, \\text{on}, \\text{street}) = 0.02P(the,man,walks,on,street)=0.02 P(the,street,man,on,walks)=0.01P(\\text{the}, \\text{street}, \\text{man}, \\text{on}, \\text{walks}) = 0.01P(the,street,man,on,walks)=0.01 P(man,the,the,street,walks)=0.0001P(\\text{man}, \\text{the}, \\text{the}, \\text{street}, \\text{walks}) = 0.0001P(man,the,the,street,walks)=0.0001 从上述示例可以看出，第一个序列的概率最高，因为它在语义和语法上更合理。","12-llm的自回归特性#1.2 LLM的自回归特性":"目前主流的大型语言模型 (LLM) 主要采用自回归 (autoregressive) 架构。\n自回归生成过程：这意味着模型在生成序列中的下一个词元 x[i+1]x[i+1]x[i+1] 时，会依赖于它已经生成的所有前序词元 x[1:i]x[1:i]x[1:i]。 具体来说，给定已有的词元序列 x[1:i]x[1:i]x[1:i]，大模型会计算下一个词元 x[i+1]x[i+1]x[i+1] 的概率分布，并从中选择一个词元。 这个过程是递归进行的，每次生成一个新词元，直到生成终止符或达到最大长度。 推理与训练的区别： 训练阶段：通常可以进行批处理 (batch processing)，模型可以同时处理多个序列，并计算其损失。 推理阶段：由于自回归的特性，推理过程是序列化、多次运行模型前向传播 (FP) 的过程。这意味着，为了生成一个完整的回答，模型需要逐个词元地进行计算和输出。 概率输出机制：通常，在Transformer模型的最后一层、最后一个词元的输出特征上，通过 Softmax 函数计算出词汇表中每个词元的概率分布，从而进行下一个词元的预测。","13-token选择策略#1.3 Token选择策略":"在自回归生成过程中，模型输出的是下一个词元的概率分布。如何从这个分布中“选择”一个实际的词元，是生成效果的关键。","131-最大概率搜索#1.3.1 最大概率搜索":"这类方法的核心思想是倾向于选择概率最高的词元。","1311-greedy-search#1.3.1.1 Greedy Search":"原理：在每一步生成时，始终选择当前概率最高的词元作为下一个词元。 特点： 简单直接，计算开销小。 局部最优：但由于只考虑当前步的最优选择，可能会错过全局最优的序列。生成的文本可能听起来合理，但缺乏多样性和创造性。","1312-beam-search#1.3.1.2 Beam Search":"原理： Beam Search 维护一个固定大小的“束” (beam size, kkk)，同时跟踪 kkk 条当前最有可能的序列路径。 在每一步生成时，它会扩展这 kkk 条路径，并从所有可能的扩展中选择新的 kkk 条概率最高的序列，作为下一轮的候选。 最终，选择这 kkk 条路径中累计概率最高的作为输出序列。 特点： 比 Greedy Search 更能找到全局最优解，通常能生成更流畅、语法更正确的文本。 计算开销大于 Greedy Search。","1313-search类最大概率方法的优劣#1.3.1.3 Search类最大概率方法的优劣":"对话模型不喜欢 Beam Search 的核心原因：\n会放大高概率词元，导致输出死板：Beam Search倾向于选择最“安全”的路径，即那些在训练数据中出现频率高、概率大的词元组合。 表现为： 更容易出现重复：模型可能陷入重复的短语或模式中，难以跳出。 更倾向模板式说法：生成的内容缺乏多样性，听起来像固定的模板。 丢失创造性、想象力：对于需要开放式、创新性回答的对话任务，Beam Search 的输出会显得过于保守和缺乏新意。 长文本结构容易塌陷：在生成长文本时，模型可能会过早地收敛到常见的结束语或总结性短语（如“in conclusion …”），导致文本结构僵硬，缺乏自然的过渡。 适合使用 Beam Search 的场景： Beam Search 更适用于任务需要强确定性输出的场景，例如：\n机器翻译：目标是生成与原文意思一致且语法正确的译文。 代码自动补全：需要生成语法正确的代码片段。 工业写作模板：如客服回复、合同草拟等，需要标准化和高准确性的文本。 大规模离线批处理生成 (Large-scale batch offline generation)：在不需要实时交互、对生成质量有较高要求的场景。","132-概率抽样#1.3.2 概率抽样":"为了解决最大概率搜索方法（特别是 Beam Search）在对话场景中缺乏多样性的问题，引入了概率抽样方法。这些方法在生成过程中引入了一定的随机性。","1321-top-k-抽样#1.3.2.1 Top-k 抽样":"原理： 模型首先根据概率分布，找出概率最高的 kkk 个词元。 然后，从这 kkk 个词元中进行随机抽样，而不是简单地选择概率最大的那一个。 作用：在保留一定质量的同时，引入了多样性。 对话模型常用 kkk 值：通常选择 k∈[40,100]k \\in [40, 100]k∈[40,100]。","1322-top-p-抽样-nucleus-sampling#1.3.2.2 Top-p 抽样 (Nucleus Sampling)":"原理： 首先将词汇表中的词元按概率降序排列。 然后，从累积概率刚好超过预设阈值 ppp 的最小词元集合中进行随机抽样。 例如，如果 p=0.9p=0.9p=0.9，模型会选择累积概率达到或超过 0.9 的词元子集，然后从这个子集中进行抽样。 作用：动态地选择词元数量，避免了 Top-k 中固定 kkk 值可能带来的问题（当分布平坦时，Top-k 可能包含太多不相关的词元；当分布尖锐时，Top-k 又过于集中）。它能够更灵活地适应不同的概率分布形状。 对话模型常用 ppp 值：通常选择 p∈[0.8,0.95]p \\in [0.8, 0.95]p∈[0.8,0.95]。","2-transformer生成过程中的计算冗余与优化#2. Transformer生成过程中的计算冗余与优化":"","21-transformer生成过程分析#2.1 Transformer生成过程分析":"Transformer 模型在生成文本时，是自回归（autoregressive）的。这意味着模型是逐个 token 进行预测和生成的。\n生成过程迭代性： 为了生成下一个 token，模型需要考虑之前所有已生成的 token。在没有优化的情况下，每次生成新 token 时，整个序列（包括已生成的和新加入的 token）都需要重新进行前向传播 (Forward Pass) 计算，包括注意力机制和前馈网络。 计算冗余： 这种逐个 token 生成的方式导致了大量的重复冗余计算。具体来说，当生成第 i+1i+1i+1 个 token 时，模型需要重新计算从第 1 个 token 到第 iii 个 token 的所有中间激活值（包括 Key, Value, Query 等）。然而，这些激活值在生成第 iii 个 token 时就已经计算过了。 核心问题： 这意味着每次生成一个新的 token，新的计算其实只针对于刚加入的 token 的前向传播过程，而之前 token 的计算结果却被重复计算，造成了巨大的性能浪费。 （若需查看原始图片详情，请参考原文中的“Transformer生成过程:token 1”和“Transformer生成过程:token 2”示意图，以及“GPT结构图”，它们通常展示了模型逐层、逐token处理数据的过程，以及这种处理方式如何导致重复计算的。）","22-kv-cache-优化#2.2 KV Cache 优化":"针对上述计算冗余问题，KV Cache 成为了一种关键的优化技术。","221-kv-cache-原理#2.2.1 KV Cache 原理":"定义： Key-Value 缓存 (KV Cache) 是一种存储机制，用于缓存Transformer 模型中每个自注意力层在处理先前 tokens 时生成的 Key (K) 和 Value (V) 向量。 存储内容： 在 Transformer 的自注意力机制中，对于每个 token，都会计算出其对应的 Query (Q)、Key (K) 和 Value (V) 向量。KV Cache 就是用来存储 K 和 V 向量的。 目的： 其核心思想是在后续的推理过程中重用这些已计算的 K 和 V，避免重复计算。","222-增量推理#2.2.2 增量推理":"工作机制： 当模型接收到新 token 时，不再需要重新计算整个序列的 K 和 V 矩阵。 模型只计算新 token 自身的 Query (Q)。 然后，将这个新 token 的 Query 与缓存中所有先前 token 的 Key (K) 矩阵以及新 token 自己的 Key进行注意力计算。 同时，将这个新 token 的 Value (V) 向量也添加到 KV Cache 中，以备后续 token 的生成使用。 优势： 这种方法被称为增量推理 (Incremental Inference)。它大大减少了计算量，特别是对于长序列的生成，因为大部分 K 和 V 的计算都被缓存并重用了，从而显著提升了推理速度。","23-生成式推理-generative-inference#2.3 生成式推理 (Generative Inference)":"由于用户输入 (prompt) 和模型输出 (answer) 的处理方式存在差异，生成式推理通常分为两个阶段。\n输入与输出的差异： 人们输入的提示词 (prompt) 通常是一次性输入的，是一个完整的序列。 模型的回答 (answer) token 是序列输出的，即逐个 token 生成。 因此，处理这两种类型的任务通常采用不同的策略：","231-预填充阶段-prefill-phase#2.3.1 预填充阶段 (Prefill phase)":"目的： 处理用户输入的完整 prompt。 过程： 模型将整个提示（prompt）序列作为输入，进行一次完整的前向传播。在这个过程中，为每个 Transformer 层生成并填充键值缓存 (KV cache)。此时的计算模式与模型训练时的批处理（batch processing）相似。 输出： 得到 prompt 中所有 token 的 KV Cache，以及第一个要生成的回答 token 的 logits (未归一化概率)。","232-解码阶段-decode-phase#2.3.2 解码阶段 (Decode phase)":"目的： 逐个生成回答 token。 过程： 在预填充阶段完成后，模型进入解码阶段。在每一步解码过程中，模型利用增量推理（如 2.2 节所述），计算当前新生成的 token 的 Query，并结合更新后的 KV 缓存进行注意力计算，最终预测下一个 token。然后将新 token 的 Key 和 Value 加入 KV Cache，并重复此过程。 特点： 这个阶段是自回归的、序列化的。","24-性能分析#2.4 性能分析":"理解 Prefill 和 Decode 阶段的计算特性对于优化模型性能至关重要。","241-prefill与decode阶段的计算特点#2.4.1 Prefill与Decode阶段的计算特点":"预填充阶段 (Prefill phase)： 计算受限 (Computation bounded)： 此阶段需要处理整个 prompt 序列，涉及大量的矩阵乘法和复杂的注意力计算。这些操作通常受限于 GPU 的计算能力（flops），即每秒浮点运算次数。 原因： 需要处理较长的输入序列，并行计算量大。 解码阶段 (Decode phase)： I/O 或带宽受限 (IO/bandwidth bounded)： 在此阶段，每次生成一个新 token，计算量相对较小。主要的开销在于从内存中读取和写入 KV Cache，以及将模型参数加载到计算单元。这些操作受限于 GPU 的内存带宽，即每秒数据传输速率。 原因： 每次只处理一个新 token，但需要频繁访问和更新可能非常大的 KV Cache。","242-内存占用组成#2.4.2 内存占用组成":"生成式推理过程中，主要的内存占用包括：\n模型参数： 存储大型语言模型（LLM）的所有权重和偏置。这部分内存占用通常是固定的，且非常大。 KV 缓存： 存储每个 Transformer 层中所有已处理 token 的 Key 和 Value 向量。这部分内存会随上下文长度的增加而正比增长，是导致推理内存占用过高的一个重要因素。上下文越长，KV Cache 越大。","3-高级推理优化技术#3. 高级推理优化技术":"本章将深入探讨两项关键的高级推理优化技术：KV Cache内存管理（PagedAttention）和投机采样（Speculative Decoding），它们旨在解决LLM推理过程中遇到的计算和内存瓶颈。","31-kv-cache-内存管理-pagedattention-sosp23#3.1 KV Cache 内存管理 (PagedAttention, SOSP’23)":"KV Cache 是 Transformer 模型在自回归生成过程中存储历史 Key 和 Value 矩阵的机制。然而，随着序列长度的增加和多用户并发请求，KV Cache 会带来显著的内存管理挑战。","311-kv-cache-大小问题#3.1.1 KV Cache 大小问题":"存储需求大：KV Cache 需要存储每个 Transformer 层中每个 token 的历史中间结果（Key 和 Value 向量）。对于大型语言模型，这会占用大量显存。 训练与推理的差异：在训练阶段，模型通常通过批处理（batch training）和已知序列进行，不需要持久化KV Cache。但在推理阶段，尤其是自回归生成时，模型需要回顾之前的 token，因此 KV Cache 对于加速生成至关重要。","312-内存碎片问题#3.1.2 内存碎片问题":"由于LLM推理过程中请求的输入和输出长度具有高度不确定性，KV Cache的内存管理面临以下挑战：\n预留 (Reservation)：系统为了未来的使用需要提前保留资源，即使这些资源当前尚未被完全利用。这可能导致资源分配不灵活。 内部碎片 (Internal Fragmentation)：由于输出长度未知，系统为了避免频繁重新分配，可能会过度分配资源（例如，为某个序列分配一个超出实际所需大小的内存块）。这导致已分配空间的一部分未能被有效利用。 外部碎片 (External Fragmentation)：由于不同序列的长度不一致，在内存中释放和分配操作后，会出现大量不连续的小块空闲空间。尽管总的空闲内存可能足够大，但由于不连续性，无法满足大块内存分配的需求，这可能导致在明明还有显存的情况下出现**OOM（Out Of Memory）**错误，极大降低GPU利用率。 【若需查看原始图片详情，请参考原文中的“vLLM-pre.pdf”引用的统计图，其中展示了优化后真正用于保存KV Cache内容的部分从20%提升至96.3%】","313-pagedattention-原理#3.1.3 PagedAttention 原理":"PagedAttention 借鉴了操作系统中分页内存管理（Paging Memory Management）的思想来高效管理KV Cache。","3131-kv-block-概念#3.1.3.1 KV Block 概念":"定义：一个KV Block 是一段固定大小、地址连续的内存块，用于存放特定数量 token 的 Key 和 Value 状态。 类比：它在概念上类似于操作系统中的“内存页”（Memory Page）。通过将KV Cache划分为固定大小的块，可以更灵活、更细粒度地进行内存管理。","3132-逻辑物理block映射#3.1.3.2 逻辑/物理Block映射":"逻辑Block：每个序列的KV Cache在逻辑上是连续的，由一系列逻辑Block组成。 物理Block：这些逻辑Block被映射到物理内存中的非连续的物理Block上。 Block Table：系统维护一个Block Table（块表），记录了每个逻辑Block对应的物理Block地址，从而实现了逻辑地址到物理地址的映射查询。这种方式允许在物理内存中动态分配和重用KV Block，而无需保证物理连续性。","3133-多请求存储与内部碎片优化#3.1.3.3 多请求存储与内部碎片优化":"多请求同时存储：PagedAttention允许来自不同请求的KV Cache Block在物理内存中交错存储，极大地提高了显存的利用率。 内部碎片优化：通过使用固定大小的KV Block，每个序列浪费的 token 数被限制在一个Block的大小之内。例如，如果块大小是16或32个token，无论序列长度如何（0到1000个token），每个序列的最大浪费都远小于整个序列的长度，从而有效降低了内部碎片。","3134-copy-on-write-写时复制-机制#3.1.3.4 Copy-on-Write (写时复制) 机制":"应用场景：在Beam Search等场景下，模型会基于当前的KV Cache生成多条候选路径（形成树形结构的 token 展开）。传统的做法是为每条路径复制整个KV Cache，效率低下。 机制：Copy-on-Write 机制允许不同的Beam共享相同的KV Cache Block，直到某个Beam需要修改该Block的内容（例如，当其生成一个新的 token 导致KV状态改变时）。只有在发生修改时，系统才会为该修改创建 Block 的副本，否则保持共享。这极大地减少了内存复制和占用，提高了Beam Search的效率。","32-投机采样-speculative-decoding-icml23#3.2 投机采样 (Speculative Decoding, ICML’23)":"投机采样（Speculative Decoding）是一种旨在加速LLM解码阶段（序列生成）过程的技术，因为这一阶段的序列生成是影响生成回答的重要瓶颈。","321-原理与加速效果#3.2.1 原理与加速效果":"核心思路：通过结合一个“轻量级模型预测”和“重模型验证”的方式实现并行化，以提高生成速度。 轻量级模型预判：首先使用一个较小、速度更快的语言模型（通常称为“辅助模型”或“草稿模型”，Draft Model）快速生成多个候选输出 token 序列。 大型模型验证：接着，将这些由轻量级模型生成的候选序列一次性提供给更强大但较慢的大型模型（例如 GPT-3/4，称为“验证模型”，Verifier Model）进行并行验证。 加速效果： 如果轻量级模型预测正确，大模型直接接受这些 token，从而一次性“跳过”多个生成步骤。 如果预测不正确，大模型会从第一个错误点重新生成并修正。 通过这种方式，大模型不再需要从头逐个生成所有内容，而是大部分时间进行快速验证，显著减少了整体生成时间，降低了推理延迟。","322-投机采样算法流程#3.2.2 投机采样算法流程":"投机采样算法涉及两个模型：一个辅助小模型和一个大模型。\n小模型生成序列：辅助小模型（Draft Model）根据当前已生成的 token 序列，快速生成一个包含kkk个未来 token 的候选序列。 大模型并行验证：大模型（Verifier Model）在一个前向传播中并行检查小模型生成的这kkk个 token 是否正确。它计算出这些 token 的真实概率分布。 修正与迭代： 大模型从候选序列的最早一个被验证为不正确的 token 开始进行修正。 一旦修正完毕，辅助小模型会从大模型修正后的位置继续开始生成新的候选序列，重复上述过程。","323-概率分布一致性证明#3.2.3 概率分布一致性证明":"投机采样的重要特性在于，它能够在显著加速生成速度的同时，保持与大模型单独生成时相同的概率分布。这意味着投机采样生成的文本在质量和多样性上与大模型直接生成的文本是等效的。\n原论文证明了该方法生成的序列概率分布与大模型本身生成序列的概率相同。其证明核心基于接收-拒绝采样（Accept-Reject Sampling）机制：\n为了从目标概率分布 P(x)P(x)P(x) 中采样，我们不直接采样，而是从一个提议分布 Q(x)Q(x)Q(x) 中采样。 接受条件：如果从 Q(x)Q(x)Q(x) 采样的样本 xxx 满足 Q(x)≤P(x)Q(x) \\le P(x)Q(x)≤P(x)，则接受该样本。 拒绝条件与调整：如果 Q(x)\u003eP(x)Q(x) \u003e P(x)Q(x)\u003eP(x)，则以概率 1−P(x)Q(x)1 - \\frac{P(x)}{Q(x)}1−Q(x)P(x)​ 拒绝该样本。被拒绝的样本不会直接丢弃，而是从一个调整后的分布 P′(x)P'(x)P′(x) 中重新采样： P′(x)=norm(max⁡(0,P(x)−Q(x)))P'(x) = norm(\\max(0, P(x) - Q(x)))P′(x)=norm(max(0,P(x)−Q(x))) 其中 normnormnorm 表示归一化，确保调整后的概率总和为1。通过这种严谨的概率调整和重采样机制，投机采样保证了最终输出序列的概率分布与大模型本身的概率分布一致。 总结：投机采样通过“并行预测+串行验证”的策略，显著降低了LLM的推理延迟，同时确保了生成质量与大模型原生生成的一致性。","4-推理系统-serving-system-优化#4. 推理系统 (Serving System) 优化":"","41-推理系统概述#4.1 推理系统概述":"推理系统（Serving System）负责将经过训练的机器学习模型部署到生产环境中，并为终端用户提供模型推理服务。其主要功能和目标包括：","411-模型部署与推理api#4.1.1 模型部署与推理API":"模型部署：将训练好的机器学习模型打包，部署到服务器或云平台上。这包括模型的序列化、加载、环境配置等步骤，目标是确保模型能够在生产环境中稳定、高效地运行。 推理API：提供一个接口，接收用户或应用程序的输入数据（请求数据），调用部署好的模型进行推理计算，并返回推理结果。推理API需要确保服务具备低延迟（快速响应用户请求）、高吞吐（在单位时间内处理大量请求）和可扩展性（能够根据负载变化动态调整资源）。","412-分布式部署#4.1.2 分布式部署":"对于大规模模型（特别是大语言模型LLM），单台设备往往难以满足其计算或内存需求，或者难以应对高并发的推理请求。在这种情况下，通常采用分布式部署的方式：\n负载均衡：利用负载均衡技术将用户的推理请求分发到不同的模型服务实例上，避免单个实例过载。 提高整体性能：通过多个实例并行处理请求，提高整体的吞吐能力和可用性。","42-生成式推理中的并行策略#4.2 生成式推理中的并行策略":"在生成式推理中，由于模型通常较大且生成过程是自回归的，对并行策略的设计尤为重要。\nNaïve Generative Inference (朴素生成式推理)：\n通常是逐个token序列推理。这意味着每生成一个token，模型都需要运行一次前向传播，效率较低。 在之前的讨论中（如KV Cache），我们已经看到了这种逐个token生成带来的计算冗余。 重新思考训练阶段的并行方式：\n训练阶段常用的并行策略，如数据并行（DP）、模型并行（TP）和管道并行（PP），也可以应用于推理阶段，但需要根据推理的特点进行调整和优化。 数据并行 (Data Parallelism, DP)： 在推理中，DP主要用于增加运行实例，从而同时服务多个用户请求。每个实例加载完整的模型，处理一部分用户的请求。 张量并行 (Tensor Parallelism, TP)： TP将模型的单个层（或张量）拆分到多个设备上，用于加速单个推理请求的计算。特别适用于单个大模型无法完全载入单个GPU内存的情况，或需要降低单个token生成延迟的场景。 管道并行 (Pipeline Parallelism, PP)： PP将模型的不同层分配到不同的设备上，形成一个处理“管道”。一个请求的数据会依次流经这些设备。 潜在优势：尽管管道并行可能会增加单个请求的处理延迟（因为数据需要在设备间传输，产生通讯开销），但它能够很好地实现GPU复用。通过将模型的不同部分分摊到多个GPU上，可以提高整体设备的利用率，让所有设备尽可能同时工作。","43-alpaserve模型并行与统计复用-osdi23#4.3 AlpaServe：模型并行与统计复用 (OSDI’23)":"论文名称：Statistical Multiplexing with Model Parallelism for Deep Learning Serving. Zhuohan Li, et al. OSDI 2023. 核心观察： 在深度学习推理服务中，即使一个模型可以完全放入一个设备（GPU）中，如果能够将其拆分进行管道并行（PP），并结合统计复用（Statistical Multiplexing），也可能带来性能提升。 传统观念认为PP会增加延迟，但在多用户、动态负载的服务场景下，通过精巧的调度，PP可以显著提高整体资源的利用率。 设计原则： 最大化GPU复用：目标是让集群中的所有GPU尽可能同时工作。 统计复用：通过将多个并发请求的计算在不同管道阶段交错执行，来隐藏设备间的通信延迟和计算空闲时间。即使单个请求的延迟可能略有增加，系统的总吞吐量和资源利用率可以大幅提高。 目的：让所有设备同时工作，从而提升整个推理服务的吞吐量和效率。","44-orca连续批处理-continuous-batching-osdi22#4.4 Orca：连续批处理 (Continuous Batching) (OSDI’22)":"核心问题：为了充分利用计算资源，推理过程中通常会将多个用户请求组织成一个批次（batch）进行模型推理。然而，传统批处理方式存在以下问题：\n批次组织和完成：经典方法通常是等待请求队列中的多个请求积累到一定数量后，将它们组织成一个批次，并一起完成推理。 GPU利用率低：由于不同请求的回答长度往往不一致（例如，一个请求只需要生成几个token，另一个需要生成几十个token），在一个批次中，完成较早的请求会因为等待批次中其他请求完成而导致其所占用的GPU资源被空闲，从而造成GPU利用率低下。 Orca的解决方案：Continuous Batching (连续批处理)：\nBatch一直维护：Orca采用一种动态的批处理机制，批次不再是固定大小或固定生命周期的。只要批次中存在空闲位置，新的请求就可以即时加入。 Token-level batching (Token级批处理)：而非传统的请求级批处理。这意味着Orca不是等待整个请求（直到生成所有token）完成后才将其从批次中移除，而是在每个生成步（每次生成一个token）后，动态地管理批次中的token。当一个请求生成完它的当前token后，它可以继续留在批次中生成下一个token，或者如果它已经完成，则可以离开批次。这种细粒度的管理使得GPU可以更有效地被利用。 效果：通过连续批处理，Orca显著提高了GPU的利用率，减少了因请求长度不一导致的资源浪费。 实现挑战：\n“What behind the elegant idea may be … labor work” (一个优雅的想法背后可能是大量的工程工作)。 为了实现continuous batching，特别是在注意力（attention）机制的计算中，难以保持简单高效的批处理矩阵运算。传统的Attention计算通常假定批次中的所有序列长度一致，但在动态的Token级批处理中，序列长度是变化的，这需要复杂的内存管理和调度机制来高效地执行矩阵运算。","45-distserve解耦推理-disaggregated-inference-osdi24#4.5 DistServe：解耦推理 (Disaggregated Inference) (OSDI’24)":"核心观察：生成式大语言模型（LLM）的推理过程通常包含两个截然不同的阶段：Prefill（预填充）和Decoding（解码）。这两个阶段具有不同的计算特性和资源瓶颈。\n两个任务的特点不同：\nPrefill 阶段： 模型将提示（prompt）序列作为输入，并计算出所有prompt token的KV Cache。 这一阶段是计算能力限制（Computation bounded）。因为它涉及到对整个输入prompt序列的一次性处理，计算量大。 批处理带来的收益很小：由于prompt长度可能各异，且每个prompt需要完全计算一次，批处理带来的效率提升不如解码阶段显著。 Decoding 阶段： 模型在每一步解码过程中，基于前一个生成的token和已有的KV Cache生成下一个token。 这一阶段是内存带宽限制（Memory bandwidth bounded）。每次生成一个token时，需要频繁地从内存中读取和写入KV Cache，内存访问成为主要瓶颈。 批处理能显著提升吞吐量：在解码阶段，将多个请求（每个请求生成一个token）打包成一个批次，可以更高效地利用GPU的计算单元，并减少内存访问的开销，从而大幅提高吞吐量。 两个任务会相互影响：\n当一个新的请求的Prefill阶段（计算密集型）被插入到正在进行Decoding的批处理中时，可能会导致**“卡顿”现象**。例如，在使用流式推理API时，用户可能会感觉到某个输出token突然停顿，这是因为Prefill任务抢占了资源，影响了Decoding任务的流畅性。 DistServe的解决方案：将Prefill和Decoding任务分离：\n专用资源：DistServe建议在不同的GPU集群上分别处理Prefill和Decoding任务。 某些GPU专门用于Prefill计算。 其他一些GPU专门用于Decoding计算。 不同的并行配置：由于Prefill和Decoding阶段的特点不同，它们可以采用不同的并行配置。例如，Prefill集群可能更侧重于计算能力，而Decoding集群可能更侧重于高内存带宽和批处理效率。 动态资源比率：Prefill和Decoding服务器实例的集群资源比率可以进行动态配置，以适应不同的工作负载模式。 主要开销：这种分离式架构的主要开销在于KV Cache的通信。由于Prefill阶段生成的KV Cache需要传输到Decoding集群进行后续使用，这会引入额外的数据传输延迟。","46-lora推理优化#4.6 LoRA推理优化":"LoRA (Low-Rank Adaptation) 是一种高效的微调技术，它通过引入少量可训练参数来适应大型预训练模型，而无需修改原始模型的全部参数。LoRA在服务系统中变得极其重要，原因如下：\n大规模LoRA模型部署需求：例如，Hugging Face 提供了超过 9,000 个版本的微调 BERT 模型。这意味着在实际生产环境中，可能需要同时部署和服务成千上万个基于LoRA微调的同一个基础模型。","461-朴素lora推理服务的问题#4.6.1 朴素LoRA推理服务的问题":"若按照传统方式，将每个LoRA模型独立部署到GPU上，会面临显著的效率问题：\nGPU利用率低：如果一张或多张GPU仅仅服务一个LoRA模型，那么它们将未能充分利用基础LLM的共享权重。因为LoRA只添加了少量参数，大部分计算仍然在共享的基础模型上进行。 【若需查看原始图片详情，请参考原文中的“LoRA推理服务示意图”】，该图展示了每个GPU独立服务一个LoRA模型（LoRA 1, LoRA 2, LoRA 3分别对应GPU 0, GPU 1, GPU 2），导致资源利用不佳。 批处理潜力未充分利用：LLM具有很强的批处理效应，即同时处理多个请求可以显著提高吞吐量。 错误做法示例：如果仅仅把使用同一个LoRA的请求放入一个批次，会导致批次大小波动（例如：b=2, b=1, b=3）。当不同LoRA的请求混合到来时，如果严格按照LoRA模型来区分批次，将无法形成大的批次。 正确做法示例：理想情况是能够将所有请求（无论属于哪个LoRA）都放入一个大批次（例如：b=6），这样才能充分发挥LLM的批处理优势。","462-punica--s-lora批处理不同lora请求#4.6.2 Punica \u0026amp; S-LoRA：批处理不同LoRA请求":"核心思想：由于不同的LoRA推理都使用相同的基础模型部分（这部分通常占模型参数的99%以上），因此存在将不同LoRA的请求批处理的可能性。 朴素做法的局限：仅仅将属于同一LoRA模型的输入连续地归为一组进行批处理，无法充分利用LLM的批处理能力，因为它忽略了不同LoRA请求之间共享的基础模型计算。 Punica (Proceedings of Machine Learning and Systems, 2024) \u0026 S-LoRA (arXiv preprint, 2023)： 这些工作提出了创新的方法来批处理来自不同LoRA适配器的请求。 原理：LoRA的计算可以表示为 Y=XW+X(BTAT)=XW+X(ALBLT)Y = XW + X(B^T A^T) = XW + X(A_L B_L^T)Y=XW+X(BTAT)=XW+X(AL​BLT​)。其中 XWXWXW 是基础模型的计算，X(ALBLT)X(A_L B_L^T)X(AL​BLT​) 是LoRA适配器的增量计算。 这两个优化方案的核心思想是：对于基础模型计算 XWXWXW，所有不同LoRA的请求可以共享一个大的批次，因为它们都使用相同的权重 WWW。 对于LoRA的增量计算 X(ALBLT)X(A_L B_L^T)X(AL​BLT​)，这些计算是独立于各个LoRA的，但可以在批处理中高效地执行。 这意味着，可以通过精巧的调度和内存管理，将来自多个不同LoRA适配器的请求在同一个批次中一起处理，共享基础模型的前向传播计算，然后只在最后的LoRA层进行区分和合并，从而大幅提高GPU利用率和吞吐量。 【若需查看原始图片详情，请参考原文中的“Punica \u0026 S-LoRA示意图”和“LLM具有强大的批处理效应图示”】。","5-lora推理优化#5. LoRA推理优化":"","51-lora在服务系统中的重要性#5.1 LoRA在服务系统中的重要性":"LoRA（Low-Rank Adaptation）是一种高效的参数微调技术，它在**大型语言模型（LLM）**的服务系统中扮演着至关重要的角色。其重要性体现在：\n模型定制化需求激增：随着LLM的广泛应用，用户对模型特定任务或领域知识的定制化需求爆炸式增长。例如，Hugging Face平台就提供了超过9,000个不同版本的微调BERT模型。 高效微调：LoRA允许在不修改LLM大部分参数的情况下，通过引入少量可训练的低秩矩阵来适应新任务，这大大降低了微调成本和存储需求。 服务复杂性：尽管LoRA微调本身很高效，但在生产环境中同时服务成百上千个定制化的LoRA模型却带来了新的挑战，尤其是如何高效地利用计算资源。","52-朴素lora推理服务的问题#5.2 朴素LoRA推理服务的问题":"传统的或“朴素”的LoRA推理服务方法，通常将每个LoRA模型作为一个独立的实体进行部署和管理。这种做法存在显著的效率问题：\nGPU利用率低： 如果为每个LoRA适配器分配一张或多张GPU（如图所示：LoRA 1 在 GPU 0，LoRA 2 在 GPU 1，LoRA 3 在 GPU 2），会导致未能充分利用基座LLM的共享权重。 由于LoRA适配器只占模型总参数的一小部分（例如，LoRA参数可能只占整个模型参数的0.01%到1%），而基座模型参数是所有LoRA共用的，为每个LoRA实例单独分配GPU会使得GPU大部分计算能力闲置。这最终导致GPU利用率低，整体性能效率下降。 批处理潜力未充分利用： LLM推理具有显著的批处理效应（Batching Effect），即将多个请求打包成一个批次并行处理可以显著提高吞吐量。 然而，朴素做法仅仅是将使用同一个LoRA的请求放入一个批次。 例如，如果请求队列中有A、A、B、C、C、C这六个请求，朴素方法可能会分为三个批次：一个批次包含两个A，一个批次包含一个B，一个批次包含三个C。 这种做法不能充分利用批处理的潜力，因为它忽略了不同LoRA请求之间共享基座模型的计算。理想情况下，如果能够批处理所有请求，即使它们对应不同的LoRA，也可以形成一个更大的批次（如示例中的包含六个请求的批次），从而更好地发挥批处理的优势。","53-punica--s-lora批处理不同lora请求#5.3 Punica \u0026amp; S-LoRA：批处理不同LoRA请求":"针对朴素LoRA推理服务的问题，Punica和S-LoRA等系统提出了创新的解决方案，核心思想是批处理来自不同LoRA适配器的推理请求。\n核心思想与原理： 参数共享：不同LoRA的推理请求都要使用相同的基础模型部分。基座模型（如GPT-3、LLaMA等）的参数占据了模型总参数的绝大部分（通常高达99%）。 计算分解：一个经过LoRA微调的模型 W′W'W′ 的输出 YYY 可以表示为： Y=W′X=(W+ΔW)X=WX+ΔWXY = W'X = (W + \\Delta W)X = WX + \\Delta W XY=W′X=(W+ΔW)X=WX+ΔWX 其中，WWW 是基座模型的原始权重，ΔW\\Delta WΔW 是LoRA引入的低秩更新矩阵，XXX 是输入。 关键在于：WXWXWX 部分的计算对于所有基于同一基座模型的LoRA请求是通用且共享的。ΔWX\\Delta W XΔWX 部分是LoRA特有的，但其计算量相对较小。 批处理可能性：正因为 WXWXWX 部分的共享性，存在将不同LoRA的请求批处理的可能性。这意味着可以在一个大的批次中，首先计算所有请求共享的基座模型输出 WXWXWX，然后再为每个请求独立地计算并叠加其特定的LoRA更新 ΔWX\\Delta W XΔWX。 实现方式： Punica和S-LoRA通过巧妙的系统设计，实现了对不同LoRA请求的动态批处理（Multi-tenant LoRA Serving）。 它们不再将每个LoRA视为一个独立的模型实例，而是将基座模型权重和多个LoRA适配器权重在内存中高效管理，并允许在一个批次中同时处理来自不同LoRA的请求。 在推理过程中，模型可以执行一个大的批处理操作来处理所有请求的基座模型计算，然后根据每个请求所属的LoRA，在内存中快速切换并应用相应的低秩更新矩阵。这种方式极大地提高了GPU的利用率和推理吞吐量。","总结#总结":"PagedAttention 通过操作系统分页内存管理的概念，解决了KV Cache带来的内存碎片和高内存占用问题，提升了多用户并发下的GPU利用率。投机采样则通过轻量级模型预判和大模型验证相结合的方式，在不牺牲生成质量的前提下，显著加速了LLM的解码过程。这两种技术都是当前LLM推理服务中至关重要的优化手段。"},"title":"MLSYS推理服务"},"/notes/learn/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E8%BD%AF%E4%BB%B6%E4%BC%98%E5%8C%96/mlsys%E7%BC%96%E7%A8%8B%E6%A1%86%E6%9E%B6/":{"data":{"1-编程框架概述#1. 编程框架概述":"1. 编程框架概述","11-为什么需要编程框架#1.1 为什么需要编程框架？":"深度学习编程框架的出现是为了解决深度学习算法开发和应用中的一系列挑战，主要包括：\n算法广泛关注与应用需求： 深度学习算法获得了广泛关注，越来越多的公司和程序员需要使用这些算法。 算法理论复杂性与代码实现工作量大： 深度学习算法本身理论复杂，手动实现算法涉及大量的代码编写工作，效率低下。 为了提高深度学习算法的开发效率，有必要将算法中的常用操作封装成组件提供给程序员使用。 多层结构与共性运算： 深度学习算法通常具有多层结构，每层运算由一些基本操作构成。 这些基本操作中存在大量共性运算，例如：卷积 (Convolution)、池化 (Pooling)、激活函数 (Activation)、自注意力机制 (Self-attention) 等。 将这些共性运算操作封装起来，可以显著提高编程实现效率，避免重复造轮子。 自动微分 (Automatic Differentiation)： 深度学习模型的训练严重依赖于梯度计算来优化模型参数。手动计算复杂模型的梯度极其困难且易错。 编程框架能够对用户任意搭建的模型快速高效地自动计算其代价函数相对于所有模型参数的梯度。这极大地方便了用户进行模型训练和优化。 硬件优化利用： 面向这些封装好的操作，硬件程序员可以根据特定硬件（如GPU、NPU）的特征，进行有针对性的充分优化。 这种优化能够使深度学习模型在目标硬件上充分发挥计算效率，加速训练和推理过程。","12-机器学习框架包含内容#1.2 机器学习框架包含内容":"原始资料中，此部分仅为概念性示意，未提供具体内容细节，仅指出机器学习框架包含“全部”或“部分”能力。这暗示了不同框架可能在功能完整性或覆盖范围上有所差异。","13-深度学习编程框架定义#1.3 深度学习编程框架定义":"定义： 随着深度学习研究的深入，算法日益复杂，研究人员需要投入更多时间在算法实现上。深度学习编程框架应运而生，它将深度学习算法中的基本操作封装成一系列组件。这些组件的集合就构成了一套深度学习框架。 核心作用： 简化算法实现： 帮助算法开发人员更简单地实现已有的算法，或设计全新的算法，将精力集中在算法创新而非底层实现细节。 促进硬件优化： 有助于硬件程序员更有针对性地对关键操作进行优化，使其能充分发挥硬件的计算效率，例如针对GPU或专用AI芯片进行性能调优。","2-国内外主流编程框架#2. 国内外主流编程框架":"","21-主流框架列表#2.1 主流框架列表":"下表列举了当前国内外主流的深度学习编程框架及其发布者和首次发布时间：\n序号 框架名称 发布者 首次发布时间 1 PyTorch Facebook (Meta) 2017 2 TensorFlow Google 2015 3 Keras Google 2015 4 Caffe BVLC 2013 5 PaddlePaddle 百度 (Baidu) 2018 6 OneFlow 一流科技 (OneFlow Inc.) 2020 7 MindSpore 华为 (Huawei) 2019","22-pytorch概述#2.2 PyTorch概述":"","221-pytorch简介#2.2.1 PyTorch简介":"名称由来： PyTorch = Py (Python) + Torch (一个用于科学计算的开源机器学习库)。 发布者与时间： 2017年由 Facebook AI Research 开源。 核心功能： PyTorch是一个基于Torch的Python开源机器学习库，用于自然语言处理等多种应用程序。它最显著的特点是具有强大的GPU加速的张量计算能力，类似于NumPy库，但支持在GPU上进行高效运算。 产生背景： 高效编程库的出现： 编程语言领域出现了面向深度学习的高效编程库，如NumPy（用于数值计算）、Eigen（C++模板库，用于线性代数）、以及原生的Torch。 Python开源生态蓬勃发展： Python语言及其丰富的开源库生态为PyTorch的普及和发展提供了肥沃的土壤。其易用性和强大的社区支持是其成功的关键因素之一。 案例示例 (Driving example-VGG19)： 在原始资料的第9页，展示了一个关于VGG19神经网络的PyTorch实现及其在计算设备上运行的示例。 图片内容描述： 图片左侧是一个简化的神经网络模型，标示为VGG19。图片右侧展示了该模型如何在PyTorch中实现，并最终转换为底层硬件（如昇腾AI处理器）上的特定算子代码 (__dlp_entry__ void Proposal(...) { ... __nram__ half scores[...]; __nramset_half(scores, ...); ... __bang_maxpool(...); ... })。这表明编程框架在高级语言中定义算子，然后集成到框架中，最终能够在计算设备上高效执行。 图片作用： 此图旨在说明深度学习框架如何将高级的神经网络概念（如VGG19）通过编程语言实现（如PyTorch），最终编译成底层硬件可执行的优化代码，从而连接了算法层和硬件执行层。 【若需查看原始图片详情，请参考原文中的“Driving example-VGG19”】","222-设计原则#2.2.2 设计原则":"PyTorch在设计时秉持以下核心原则，使其成为研究人员和开发者首选的工具之一：\n基于Python： 充分利用Python语言的简洁性、易用性和丰富的生态系统，降低学习和开发门槛。 把研究人员放在首位： 优先考虑研究人员的需求，提供灵活、动态的计算图机制和方便的调试功能，以支持快速实验和原型开发。 易用性： 提供直观的API和文档，使得用户能够快速上手并高效构建模型。 高性能： 尽管强调易用性，PyTorch也通过GPU加速等技术确保其在计算效率上达到工业级标准。 内部实现简单，节省学习时间： 力求框架内部机制的清晰和简洁，减少用户的理解负担，从而节省学习和排查问题的时间。 在顶会中的高占比： PyTorch在包括EMNLP、ACL、ICLR等在内的顶级学术会议中，其使用率已超过80%，在其他会议中也保持在70%以上，这充分体现了其在学术界和研究领域的主导地位和影响力。","223-发展历程#2.2.3 发展历程":"PyTorch自2017年发布以来，持续迭代更新，不断增强功能和优化性能。其主要版本更新内容如下：\n2017.10.1： 发布了第一个版本，标志着PyTorch的正式问世。 2017.80.2： 增加了对高阶导数、分布式计算、张量广播等重要功能的支持，扩展了框架的能力。 2018.40.4： 增加了对Windows操作系统的支持，扩大了用户群体；将张量（Tensor）和变量（Variable）合并为张量，简化了API，统一了数据和计算图节点。 2018.111.0： 完善了对不同后端的分布式计算支持；加强了对C++前端的支持，使得生产部署更加灵活；发布了PyTorch Hub，为用户提供一系列预训练模型，方便模型复用。 2019.51.1： 增加了对TensorBoard可视化工具的支持，方便用户对张量、模型结构、训练过程进行可视化分析。 2019.101.3： 增加了对移动端处理的支持，拓展了模型的部署场景；增加了对模型量化功能的支持，有助于模型压缩和加速。 2022.111.13： 发布了BetterTransformer的稳定版，优化了Transformer模型的性能。 2023.32.0： 目前的最新版，增加了编译模式（如torch.compile()），旨在结合动态图的灵活性和静态图的优化潜力。","224-学习资料#2.2.4 学习资料":"以下是一些推荐的PyTorch学习资源：\n有趣的应用集锦： https://github.com/ritchieng/the-incredible-pytorch 斯坦福课程关于PyTorch的介绍： https://cs230.stanford.edu/blog/pytorch/ PyTorch官方GitHub仓库： https://github.com/pytorch","3-自动微分#3. 自动微分":"自动微分（Automatic Differentiation, AD）是现代深度学习框架中用于高效、精确计算模型参数梯度的核心技术。它结合了数值微分的精确性和符号微分的效率，是机器学习模型训练，特别是反向传播算法的基础。","31-微分方式概述#3.1 微分方式概述":"在介绍自动微分之前，我们需要了解几种不同的微分方式及其特点。","311-数值微分#3.1.1 数值微分":"定义： 数值微分通过对函数在某点附近进行微小扰动，利用函数值在两点之间的变化率来近似计算导数。最常见的方法是中心差分法，即 f′(x)≈f(x+ϵ)−f(x−ϵ)2ϵf'(x) \\approx \\frac{f(x + \\epsilon) - f(x - \\epsilon)}{2\\epsilon}f′(x)≈2ϵf(x+ϵ)−f(x−ϵ)​。这种方法在数值上更精确，尤其在泰勒展开的证明中可以体现。 特点： 优点： 定义直接，理解简单。常用于单元测试中验证自动微分算法实现的正确性。 缺点： 数值误差： 由于浮点数精度限制和 ϵ\\epsilonϵ 的选择问题，容易引入数值误差。 效率低下： 对于有 MMM 个输入变量的函数，需要对每个输入变量进行两次函数求值来近似其偏导数，因此计算复杂度较高。 不适用于复杂计算图： 在大型计算图或具有长链式计算的图中，计算复杂度会急剧增加。","312-符号微分#3.1.2 符号微分":"定义： 符号微分（Symbolic Differentiation）是指根据微积分的求导法则（如和、积、链式法则等）直接推导出函数的解析导数表达式。 特点： 优点： 能够得到完全精确的导数表达式，没有数值误差。 缺点： 计算复杂性： 导数表达式可能非常复杂，尤其是对于大型计算图，推导和简化过程可能导致表达式爆炸，增加计算量。 不利于优化： 衍生的导数表达式可能包含大量冗余计算，不易进行优化。","313-自动微分ad#3.1.3 自动微分（AD）":"定义： 自动微分（Automatic Differentiation, AD）是一种介于数值微分和符号微分之间的方法。它通过将复杂的数学运算分解为一系列基本操作（如加、减、乘、除、指数、对数等），然后对这些基本操作应用链式法则来计算导数。自动微分利用计算图在给定计算图上自动地计算任意偏导数。 核心原理： 计算图： 使用有向图来表示函数计算过程，每个节点代表一个基本操作或变量。 单位算子梯度： 预定义每个基本操作的导数。 链式法则： 沿着计算图应用链式法则，将基本操作的导数组合起来，得到最终的导数。 目的： 主要用于帮助机器学习模型的训练，高效计算损失函数相对于模型参数的梯度。","32-计算图#3.2 计算图":"计算图是自动微分和深度学习框架的基础，它以图形化方式表示数学表达式的计算过程。","321-节点和边#3.2.1 节点和边":"计算图构成： 编程框架中使用有向图来描述计算过程，包含一组节点和边。 节点（Nodes）： 表示对象： 节点一般用来表示各类操作（如数学运算、变量读写、数据填充等），也可以表示输入数据、模型参数或输出数据。 叶子节点（Leaf Nodes）： 通常指那些不是由其他操作结果生成的变量或参数，例如模型的输入数据和可训练参数。 中间节点（Intermediate Nodes）： 通常代表各类算子（操作）的输出结果。 示例： 在表达式 y = w * x 中，w 和 x 是叶子节点，*（乘法操作）是一个中间节点。 边（Edges）： 表示关系： 边表示“节点”之间的输入输出关系。 数据流边： 传递具体数据的边。这些数据通常以**张量（tensor）**的形式在图中流动。例如，x 的值通过边传递给乘法操作。 控制依赖边： 表示节点之间执行顺序的边。这类边不传递数据，只表示某个节点必须在前序节点计算完成后才能开始执行。 示例图（y = w * x）： 节点：w (变量), x (变量), matmul (操作), y (输出) 边：w -\u003e matmul, x -\u003e matmul, matmul -\u003e y 【若需查看原始图片详情，请参考原文中的“计算图示例：y=w*x”】 复杂示例（Forward evaluation trace）： 考虑函数 y=f(x1,x2)=ln⁡(x22+x2x1)−sin⁡(x1)y = f(x_1, x_2) = \\ln(x_2^2 + x_2 x_1) - \\sin(x_1)y=f(x1​,x2​)=ln(x22​+x2​x1​)−sin(x1​)。 这个表达式可以分解为一系列基本操作，并构成一个计算图，其中 x1,x2x_1, x_2x1​,x2​ 是输入，中间会生成 v3,v4,v5,v6,v7v_3, v_4, v_5, v_6, v_7v3​,v4​,v5​,v6​,v7​ 等中间变量，最终得到 yyy。 【若需查看原始图片详情，请参考原文中的“Forward evaluation trace”计算图】","322-静态图-vs-动态图#3.2.2 静态图 vs. 动态图":"计算图的构建和执行方式可以分为静态图和动态图两种模式，各有优缺点。\n静态图（Static Graph）：\n工作方式： 首先定义（构建）整个计算图的结构，然后编译并固化。在后续执行中，数据通过已定义的图流动，图结构本身不再改变。 优点： 全局优化： 由于图结构固定，可以在运行前对整个图进行全局优化，例如算子融合、内存预分配、跨设备调度等，从而获得更快的运算速度和更高的内存效率。 部署友好： 编译后的图可以脱离Python运行时环境独立部署，适用于生产环境。 缺点： 调试不便： 图一旦构建完成，其内部执行流程是“黑盒”，难以在运行时查看中间结果或修改图结构，调试相对困难。 灵活性差： 不适合处理动态的控制流（如条件判断、循环次数不确定的循环），这些会使图结构不固定。 典型代表： TensorFlow 1.x 早期版本。 动态图（Dynamic Graph）：\n工作方式： 逐行执行代码，每个操作都会立即执行并产生结果。计算图是在运行时动态构建的，可以根据程序的逻辑实时修改图结构。 优点： 代码编写灵活： 像编写普通的Python程序一样，可以立即获得每一步的执行结果，便于进行实验和快速迭代。 调试方便： 可以直接使用标准调试工具（如pdb）进行断点调试，观察变量的中间状态。 支持动态控制流： 能够轻松处理条件判断和循环，因为图结构是动态生成的。 缺点： 优化不便： 由于图结构是动态变化的，难以进行全局性的编译时优化，可能导致运行效率低于静态图。 部署挑战： 通常需要Python运行时环境，部署相对复杂。 典型代表： PyTorch。 代码示例对比（静态图 vs. 动态图）：\nTensorFlow 1.x (静态图): import tensorflow.compat.v1 as tf tf.disable_v2_behavior() # 禁用TF2.x行为以模拟TF1.x x = tf.placeholder(tf.float32, shape=(1, 2)) y = tf.placeholder(tf.float32) w = tf.Variable(tf.random_normal((2, 1))) y_pred = tf.matmul(x, w) loss = y_pred - y grad_w = tf.gradients(loss, w) update_w = w.assign(w - alpha * grad_w[0]) # grad_w是列表 with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for i in range(300): # 每一次iteration中重复执行同样的图 sess.run([loss, update_w], feed_dict={x: valuex, y: valuey}) PyTorch (动态图): import torch x = torch.randn(1, 2) y = torch.randn(1, 1) w = torch.randn(2, 1, requires_grad=True) # requires_grad=True 表示需要计算梯度 for i in range(300): # 每一次iteration中构建并执行新图 y_pred = x.mm(w) # 矩阵乘法 loss = y_pred - y loss.backward() # 反向传播，计算梯度 # loss.backward() # 再次执行将报错，因为梯度已计算并清空 with torch.no_grad(): # 在此块内不计算梯度，避免影响w的梯度 w -= 0.01 * w.grad # 手动更新权重 w.grad.zero_() # 清空梯度，为下一次迭代做准备 【若需查看原始图片详情，请参考原文中的“静态图 vs. 动态图”代码对比】","323-现有编程框架中的图模式#3.2.3 现有编程框架中的图模式":"最初，深度学习框架在静态图和动态图之间存在明确的选择。然而，现代框架正朝着融合两者优点的方向发展。\n传统模式： 静态图： TensorFlow 1.x, Caffe2。 动态图： PyTorch。 融合趋势： PyTorch 2.x： 引入 torch.compile()，能够将动态图模式的代码编译成高效的静态图，从而结合了动态图的灵活性和静态图的性能优势。 TensorFlow 2.x： 默认采用动态图模式（eager execution），但通过 @tf.function 装饰器，可以将Python函数转换为可优化的静态图。 JAX： 天然使用Python语义（类似动态图），但通过 jit（Just-In-Time编译）将函数编译成静态图，实现高性能。 PaddlePaddle 和 MindSpore： 提供了同时支持动态图和静态图的模式。","33-自动微分方法#3.3 自动微分方法":"自动微分主要分为正向模式（Forward Mode）和反向模式（Reverse Mode），它们在计算梯度时遍历计算图的方向不同，因此在不同场景下有不同的效率特点。","331-正向自动微分#3.3.1 正向自动微分":"原理： 正向自动微分（Forward Mode AD）按照计算图的正向拓扑顺序（从输入到输出）逐一计算每个中间变量的导数，最终得到输出相对于输入的导数。它基于链式法则，从输入变量开始，逐层计算中间变量对输入的偏导数。 过程： 为每个输入变量 xix_ixi​ 定义一个“种子”向量 xi˙\\dot{x_i}xi​˙​，通常只有一个元素为1，其余为0，表示只对该输入计算导数。 从输入节点开始，按照正向传播顺序，计算每个节点输出值的同时，也计算其导数值。 对于每个操作 z=f(x,y)z = f(x, y)z=f(x,y)，同时计算 zzz 和 z˙=∂f∂xx˙+∂f∂yy˙\\dot{z} = \\frac{\\partial f}{\\partial x}\\dot{x} + \\frac{\\partial f}{\\partial y}\\dot{y}z˙=∂x∂f​x˙+∂y∂f​y˙​。 缺陷： 对于一个函数 F:RM→RNF: \\mathbb{R}^M \\rightarrow \\mathbb{R}^NF:RM→RN，如果需要计算所有输出对所有输入的梯度矩阵（Jacobian矩阵），正向模式需要进行 MMM 次正向AD遍历，每次遍历计算一个输出对所有输入的导数。 效率问题： 当输出维度 N=1N=1N=1（例如，损失函数通常是一个标量），而输入维度 MMM 非常大时（例如，深度学习模型参数的数量），正向AD需要 MMM 次独立的遍历。每次遍历都是为了计算代价函数对某个特定参数的偏导数，这些计算之间几乎没有复用。因为它们导数链条的前缀（prefix）不一样，无法有效复用计算。 在深度学习中，我们通常关心单个代价函数（N=1N=1N=1）对大量模型参数（MMM 很大）的梯度。因此，正向自动微分在这种场景下效率低下。 【若需查看原始图片详情，请参考原文中的“正向自动微分方法”示意图】","332-反向自动微分#3.3.2 反向自动微分":"原理： 反向自动微分（Reverse Mode AD）按照计算图的反向拓扑顺序（从输出到输入）逐一计算最终输出相对于每一个计算图节点的梯度。它也被称为反向传播（Backpropagation），是深度学习训练的基础算法。\n过程：\n从最终输出开始，其梯度通常设置为1（∂L∂L=1\\frac{\\partial L}{\\partial L}=1∂L∂L​=1）。 逆向遍历计算图，对于每个操作，应用链式法则将“上游”梯度（∂L∂output\\frac{\\partial L}{\\partial \\text{output}}∂output∂L​）乘以“局部”梯度（∂output∂input\\frac{\\partial \\text{output}}{\\partial \\text{input}}∂input∂output​），从而得到“下游”梯度（∂L∂input\\frac{\\partial L}{\\partial \\text{input}}∂input∂L​）。 核心优势： 这种从输出端反向传播梯度的方式，能够高效地处理输出维度 N=1N=1N=1 但输入维度 MMM 很大的情况。因为所有变量的链式计算的后缀（suffix，即从当前节点到输出的路径）使用的梯度都是相同的，反向计算能有大量的计算复用。 示例：多路径微分计算\n当一个变量（如 v1v_1v1​）被多个后续操作（如 v2,v3v_2, v_3v2​,v3​）使用时，其最终梯度是所有路径上梯度贡献的总和。 在反向模式中，从输出开始计算梯度，当梯度传播到 v1v_1v1​ 时，来自 v2v_2v2​ 的梯度贡献和来自 v3v_3v3​ 的梯度贡献会被累加起来，从而一次性得到 v1v_1v1​ 的完整梯度。 【若需查看原始图片详情，请参考原文中的“微分的计算过程如果有多条路径如何？”示意图】 偏伴随（Partial Adjoint）：\n在反向自动微分中，为了更精确地描述多路径梯度累加的过程，引入了“偏伴随”的概念。 定义： 对于计算图中任意一对输入输出节点 iii 和 jjj，通过 i→ji \\rightarrow ji→j 的计算路径反向能够获得的关于 iii 的偏导数部分，即为“偏伴随”。 求和： 一个变量的完整偏导数是其所有通过不同路径传播回来的“偏伴随”的总和。 例如，在图 y=f(v2,v3)y = f(v_2, v_3)y=f(v2​,v3​) 中，计算 ∂y∂v1\\frac{\\partial y}{\\partial v_1}∂v1​∂y​ 需要将 ∂y∂v2∂v2∂v1\\frac{\\partial y}{\\partial v_2} \\frac{\\partial v_2}{\\partial v_1}∂v2​∂y​∂v1​∂v2​​ 和 ∂y∂v3∂v3∂v1\\frac{\\partial y}{\\partial v_3} \\frac{\\partial v_3}{\\partial v_1}∂v3​∂y​∂v1​∂v3​​ 相加。 【若需查看原始图片详情，请参考原文中的“微分的计算过程如果有多条路径如何？”和“Define partial adjoint”示意图】 完整的反向自动微分算法： 反向自动微分算法通常涉及以下步骤：\n正向计算并保存中间结果： 执行一次正向传播，计算所有中间节点的值，并将这些值以及用于计算局部梯度的信息（如操作的输入）存储起来。 初始化输出梯度： 将最终输出节点（损失函数）的梯度初始化为1。 反向遍历计算图： 从输出节点开始，按照反向拓扑顺序遍历计算图。 应用链式法则： 在每个节点处，利用当前节点的上游梯度和局部梯度，计算其输入节点的梯度。 梯度累加： 如果一个节点有多个下游分支，来自这些分支的梯度贡献会在该节点处累加。 通过这种方式，可以高效地计算所有叶子节点（模型参数）相对于最终输出的梯度。","34-自动微分的图计算#3.4 自动微分的图计算":"将梯度计算过程也纳入计算图中，带来了额外的优势。\n将反向梯度传播加入计算图的优势：\n递归计算高阶梯度： 将梯度计算本身也视为图中的一系列操作，使得计算高阶梯度（例如，Hessian矩阵或二阶导数）变得自然而然，无需手动编写复杂的求导规则，只需递归地应用自动微分。 性能优化： 在反向梯度传播过程中，需要使用正向传播产生的中间结果。如果将反向计算也融入到计算图中，框架可以利用计算图优化技术（如算子融合、内存管理）对梯度计算本身进行优化，提升性能。 统一表示： 前向和反向计算都通过统一的计算图表示，简化了框架的设计和实现。 现代深度学习框架实践： 在最新的深度学习框架中，通常都采取这种将反向梯度计算集成到计算图中的方案。 【若需查看原始图片详情，请参考原文中的“将反向梯度传播加入计算图中有何优势？”示意图，其右侧图示为将梯度计算也纳入计算图的方案】 进一步了解：\n如需深入了解自动微分的理论和实践，可以参考论文：Automatic differentiation in machine learning: a survey (https://arxiv.org/abs/1502.05767)。","35-梯度检查点gradient-checkpointing#3.5 梯度检查点（Gradient Checkpointing）":"梯度检查点（Gradient Checkpointing），也称为重计算（Recomputation），是一种优化技术，用于平衡深度学习模型训练过程中的内存使用和计算开销，尤其适用于训练大型模型。","351-内存与计算的权衡#3.5.1 内存与计算的权衡":"问题： 在反向传播过程中，为了计算梯度，通常需要保存正向传播时计算的所有中间激活值。对于非常深的神经网络，这些中间激活值会占用大量的内存。当模型过大导致内存不足时，就需要寻找解决方案。 极端方案： 全部保存： 保存所有正向传播（FP）的中间激活值，以便在反向传播（BP）时直接使用。这节省了计算，但消耗大量内存。 全部重新计算： 不保存任何中间激活值。在反向传播时，需要重新执行正向传播来计算所需的中间激活值。这节省了内存，但消耗大量计算。 梯度检查点目标： 在内存不足时，它提供了一种折衷方案，即用计算效率换取内存，以使得训练大型模型成为可能。","352-实现原理#3.5.2 实现原理":"核心思想： 不保存所有中间激活值，只保存计算图中的**少量关键“检查点”**处的激活值。 反向传播过程： 当反向传播到未保存激活值的层时，从最近的已保存检查点重新执行正向计算，生成所需的激活值。 这些重新计算的激活值只用于计算当前检查点和下一个检查点之间的梯度，一旦计算完成，便可以丢弃。 Checkpointing点选择： 通常将模型分成若干段（segment），只在每段的起始点保存激活值。 当计算某段的梯度时，从该段的起始检查点重新进行一次正向传播。 在一次反向传播过程中，每个检查点段只会重新计算一次，并在计算该段的所有梯度时复用结果。 优化策略： 对于一个有 NNN 层的网络，如果将 kkk 个检查点均匀分布，选择 k=Nk = \\sqrt{N}k=N​ 可以达到一个较好的内存与计算平衡。 这样，反向传播的总计算成本增加为正向传播成本的 ≈2N\\approx 2 \\sqrt{N}≈2N​ 倍，而内存使用减少到 ≈N\\approx \\sqrt{N}≈N​ 倍。 【若需查看原始图片详情，请参考原文中的“Optimization: Gradient checkpointing”示意图】","353-进一步考量#3.5.3 进一步考量":"选择性保存： 一种快速应用梯度检查点的方法是，有选择地丢弃计算开销较低操作的结果，只保留那些计算耗时或内存占用大的操作的结果。 例如，在卷积神经网络中，Conv-BatchNorm-Activation 流水线上： 可以始终保留 卷积（Conv） 操作的结果，因为卷积的计算成本较高。 可以丢弃 批归一化（BatchNorm）、激活函数（Activation） 和 池化（Pooling） 的结果，因为这些操作通常计算量较小，重新计算它们的代价相对较低。 参考文献： Tianqi Chen等人在2016年的论文 Training Deep Nets with Sublinear Memory Cost (https://arxiv.org/abs/1604.06174) 详细阐述了这种次线性内存成本的训练方法。","354-计算图中的梯度检查点#3.5.4 计算图中的梯度检查点":"效果： 通过在计算图中应用梯度检查点技术，可以实现在内存中拟合尺寸大10倍的神经网络模型。 代价： 这种内存节省通常伴随着大约 20% 的计算时间开销。 应用示例： 该技术已成功应用于TensorFlow官方的CIFAR10模型等，显著提升了模型训练的可扩展性。 【若需查看原始图片详情，请参考原文中的“Gradient checkpointing in a computation graph”示意图】","4-计算图执行#4. 计算图执行":"计算图（Computation Graph）是深度学习编程框架中描述模型计算逻辑的核心。在模型训练或推理时，这些计算图需要被实际执行。这一节将深入探讨计算图的执行过程、涉及的关键要素以及深度学习编译器在此过程中扮演的角色。","41-计算图执行要素#4.1 计算图执行要素":"计算图的执行是将抽象的计算逻辑映射到具体硬件设备上并实际运行的过程。其核心要素包括：\n将计算图中的张量和操作（算子）映射到给定设备上具体执行：这是指将定义好的数学运算和数据流，根据其依赖关系，调度到CPU、GPU或其他加速器上进行计算。 设备管理： 概念：深度学习框架需要有效管理异构计算资源（如CPU、多个GPU），包括设备的发现、初始化、内存分配和释放，以及任务在不同设备之间的调度。 重要性：合理的设备管理能最大限度地利用硬件资源，提高计算效率。 张量实现： 概念：张量是深度学习中的基本数据结构。框架需要提供高效的张量实现，包括内存布局（如行主序、列主序，或特定硬件友好的布局）、数据类型转换、以及在不同设备之间的数据传输机制。 重要性：张量操作是深度学习计算的核心，其实现效率直接影响整体性能。 算子执行： 概念：算子（Operator）是计算图中的节点，代表具体的数学运算（如卷积、矩阵乘法、激活函数等）。算子执行涉及根据算子类型和输入张量，调用对应的底层优化实现。 获取算子执行序列：框架需要根据计算图的拓扑结构，确定算子的执行顺序，以满足数据依赖性。 实现算子： 前端定义：算子在编程语言层面（如Python）的接口定义，供用户调用。 后端实现：算子在底层硬件（如CUDA for GPU, AVX for CPU）上的高效实现。这些实现通常经过高度优化，以充分利用硬件特性。 前后端绑定：将前端的算子调用映射到正确的后端实现。 查找并调用算子：在运行时，框架根据计算图中的节点信息，查找并调用预编译好的或动态生成的底层算子实现。","42-深度学习编译器#4.2 深度学习编译器":"随着深度学习模型复杂度的增加和硬件的多样化，深度学习编译器成为优化模型执行效率的关键技术。","421-定义与多层级优化#4.2.1 定义与多层级优化":"什么是深度学习编译器？ 定义：它是一个接收以计算图形式表示的深度学习任务（模型），并能在指定的硬件平台上生成高性能代码的软件系统。 核心目标：实现模型在不同硬件上的高性能执行，提高开发效率，并简化硬件后端适配。 多层级优化：深度学习编译器通常在多个抽象层级进行优化，以全面提升性能。 图层级优化： 关注点：主要关注计算图的结构和数据流，而不关心单个算子的具体实现细节。 优化类型：包括子图替换、常量折叠、公共子表达式删除、布局优化以及算子融合等。这些优化操作在计算图层面重构、简化或合并计算，减少不必要的开销。 对应章节：（在原始资料中提示为第四章内容，此处为本节后续部分） 算子层级优化： 关注点：基于目标计算硬件的特点，对单个算子（如矩阵乘法、卷积）的实现内部进行性能提升。 优化类型：每个算子可能有多种实现方式，例如不同的循环展开、tile 分块、内存布局、线程绑定方式等。算子层级优化旨在使算子在给定硬件上以最快速度运行（例如，在GPU上利用最大并行度）。 对应章节：原始资料中提示为第五章内容。 常见深度学习框架中所采用的编译技术和深度学习编译器： TVM：一个开源的深度学习编译器栈，支持多种硬件后端。 TC (Tensor Comprehensions)：一个用于生成高性能张量运算代码的编译器。 XLA (Accelerated Linear Algebra)：Google开发的线性代数编译器，TensorFlow 的后端之一。 MLIR (Multi-Level Intermediate Representation)：Google开发的通用编译器基础设施，旨在统一不同领域的编译器技术。","422-编译优化流程示例#4.2.2 编译优化流程示例":"[图内容的文字描述]：原始资料中展示了一个“原始计算图”到“硬件平台”的编译优化流程。 原始计算图包含多个独立的3x3和1x1卷积操作。 经过图层级编译优化，这些操作被组合或简化。例如，独立的卷积操作可能被融合。 接着，通过算子层级编译优化，将优化后的图结构进一步转换为针对特定硬件（如CPU、GPU、DLP等）的高性能底层代码。 例如，一个Python中简单的矩阵乘法循环 for i in range(len(A)): for j in range(len(B[0])): for k in range(len(B)): C[i][j] += A[i][k] * B[k][j]，在算子层级优化后，可能会被转换为包含SIMD指令（如_mm256_loadu_pd、_mm256_broadcast_sd等）的C/C++代码，以充分利用硬件的并行计算能力。\n这个示例形象地说明了编译器如何将高级抽象的计算图层层优化，最终生成高效的机器代码。 【若需查看原始图片详情，请参考原文中的“编译优化流程图”】","43-图层级编译优化#4.3 图层级编译优化":"图层级编译优化是在计算图层面进行的，它不关心特定算子的具体执行过程，而重点关注数据在图中的流动方式。","431-优化方法概述#4.3.1 优化方法概述":"下表列出了常见的图优化方法及其说明：\n优化方法 说明 子图替换 (Subgraph rewriting) 识别计算图中常见的算子组合（如 Conv + BN + ReLU），并将其替换为功能等价但经过高度优化的复合算子（或自定义融合算子）。这能减少开销，提高性能。 常量折叠 (Constant folding) 在编译期计算出常量表达式的结果。例如，add(x, 2+3) 可以被优化为 add(x, 5)，避免运行时重复计算常量。 公共子表达式删除 (CSE, Common Subexpression Elimination) 如果计算图中存在两个或多个节点计算了相同的表达式，并且其输入也相同，则只保留其中一个计算结果，其他地方复用该结果。这可以消除冗余计算。 布局优化 (Layout optimization) 调整张量在内存中的存储格式（例如，从 NCHW 转换为 NHWC，或反之），以适应不同后端硬件的内存访问模式和特性。合适的布局可以显著提升数据访问效率，特别是在使用 Tensor Core 等特殊硬件时。 算子融合 (Operator fusion) 将多个连续的、计算量较小的算子（或同级的、相互独立的算子）融合成一个大的算子。这能有效减少 kernel 启动次数、内存访存开销以及中间结果的存储，从而提升整体性能。","432-子图替换#4.3.2 子图替换":"原理：将原计算图中的节点或节点序列（计算操作）替换为功能等价但运算逻辑更优或已经高度优化的形式。 示例：在 TensorFlow 中，常常通过人为设定的替换规则，识别并替换某些特定的子图模式，例如将 Conv + BatchNorm + ReLU 序列替换为一个单一的、优化过的融合算子。 优势：通过替换为更高效的实现，可以减少计算开销，提高执行速度。","433-常量折叠与公共子表达式删除#4.3.3 常量折叠与公共子表达式删除":"常量折叠 (Constant folding)： 原理：在编译阶段预先计算出所有常量表达式的结果，并用计算出的常量值替换表达式。 示例：如果表达式中包含 16 * 16 * 224 这样的常量乘法，编译器会在编译时就计算出结果 57344，然后在运行时直接使用 57344，避免了不必要的乘法运算。 公共子表达式删除 (CSE, Common Subexpression Elimination)： 原理：当同一个表达式在计算图的不同位置被多次计算，且其输入张量不变时，CSE 会识别出这些冗余计算，只保留第一次的计算结果，并在后续引用时直接使用该结果。 示例： [图内容的文字描述]：原始资料中展示了 CSE 优化前后的计算图。 优化前：两个独立的 Matmul 操作都接收 Tensor 0 和 Tensor 1 作为输入。 优化后：只保留一个 Matmul 操作，其输出同时作为 Divide 和 Subtract 操作的输入，消除了冗余的 Matmul 计算。 【若需查看原始图片详情，请参考原文中的“公共子表达式删除示例图”】 优势：减少了重复计算，节省了计算资源和时间。","434-代数化简与布局优化#4.3.4 代数化简与布局优化":"代数化简： 原理：将计算代价高的运算替换为等价的、计算代价低的运算。这通常基于数学恒等式或特殊情况。 示例：如果表达式中出现乘以 0 的操作，编译器会直接将其结果判断为 0，而无需实际执行乘法运算，例如 A * 0 直接优化为 0。 布局优化： 原理：张量在内存中的存储布局会影响数据访问的效率，特别是对于并行计算硬件。布局优化旨在调整张量的存储格式以更好地适应硬件特性。 背景：常见的张量布局有 NCHW (Batch, Channels, Height, Width) 和 NHWC (Batch, Height, Width, Channels)。不同的硬件或库可能对某种布局有更好的优化。 示例：在使用 NVIDIA Tensor Core 进行计算时，采用 NHWC 格式的张量性能通常优于 NCHW 格式。编译器可以根据目标硬件自动转换张量布局以获得最佳性能。","435-算子融合纵向#4.3.5 算子融合（纵向）":"原理：将依赖关系链上的连续算子融合成一个更大的算子（也称为“Kernel”）。 动机： 函数调用开销：每次调用一个算子（特别是在GPU上启动一个 Kernel）都有一定的开销。融合可以减少 Kernel 启动次数。 内存访存开销：非融合操作可能需要将中间结果写回全局内存，然后再从全局内存读出供下一个算子使用。融合操作可以在片上缓存（如寄存器、共享内存）中直接传递中间结果，减少全局内存访问次数。 示例： [图内容的文字描述]：原始资料中展示了纵向算子融合的示例。 融合前：一个 Multiply 算子和一个 Add 算子串联，Tensor 经过 Multiply 后产生中间结果，然后该中间结果再输入 Add 算子。 融合后：Multiply 和 Add 被融合成一个 FMA (Fused Multiply-Add) 算子。 【若需查看原始图片详情，请参考原文中的“纵向算子融合示例图”】 优势：显著减少了 Kernel 启动次数和全局内存读写，从而提升性能。","436-算子融合横向#4.3.6 算子融合（横向）":"原理：将同级、相互独立的算子在同一个 Kernel 中融合计算。 动机：当多个独立的计算具有相似的输入或在计算图的同一层级时，可以将它们合并到一个 Kernel 中，以利用数据局部性和并行性。 示例： [图内容的文字描述]：原始资料中展示了横向算子融合的示例。 融合前：两个独立的 Matmul 算子，分别接收不同的输入 Tensor，但它们可能在计算图的同一层，并且没有直接的依赖关系。 融合后：这两个 Matmul 算子被融合成一个更大的“Fused Matmul”算子，在一个 Kernel 中并行或以更优的方式计算这两个矩阵乘法。 【若需查看原始图片详情，请参考原文中的“横向算子融合示例图”】 优势：提高硬件利用率，减少多次 Kernel 启动和数据传输的开销。","437-算子融合的典型实现流程#4.3.7 算子融合的典型实现流程":"算子融合的实现通常遵循以下步骤：\n图遍历 (Graph Traversal)： 编译器首先遍历计算图的所有节点，分析它们之间的依赖关系、输入输出以及操作类型。 判断哪些节点可以融合： 纵向 fusion：识别连续依赖的节点序列，这些序列符合预定义的融合模式（如 Conv+BN+ReLU）。 横向 fusion：识别在同一输入（或同一组输入）上操作的、在同一层级且相互独立的节点，它们可以被并行执行。 图变换 (Graph Transformation)： 替换节点：用一个新的融合算子或“fused kernel”来替换原来的一系列节点。这个新的算子包含了被融合的所有操作的逻辑。 修改连接：更新新融合算子的输入输出连接，确保计算图的正确性。 更新依赖：调整计算图的依赖关系，以反映融合后的结构。 生成最终中间表示和硬件可用的计算单元： 最终目标是生成一个优化的计算图，它可以进一步被编译成针对特定硬件的高性能机器代码。 核心目标：通过上述步骤，有效减少内存访问次数和Kernel Launch 次数，从而显著提升深度学习模型的执行性能。"},"title":"MLSYS编程框架"},"/notes/skill/bevy/bevy%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/":{"data":{"":"","bevy简介#Bevy简介":"Bevy是一个开源的游戏引擎，使用Rust语言编写。它采用了ECS（Entity-Component-System）架构，旨在提供高性能和易用性。Bevy支持2D和3D游戏开发，并且具有强大的渲染、音频、输入处理等功能。","参考资料#参考资料":"Introduction\nBevy Examples in WebGL2\nbevy - Rust\nBevy Assets\nIntroduction - Unofficial Bevy Cheat Book"},"title":"Bevy简介与快速入门"},"/wiki/":{"data":{"":"知识库与参考资料\n欢迎来到站点的知识库区域，这里包含：\nBevyBook 教程文档（type: docs） 项目维基与长期参考资料"},"title":"维基"},"/wiki/bevybook/":{"data":{"":"欢迎来到 Bevy 游戏引擎完整教程！本教程旨在帮助你从零开始掌握 Bevy 游戏开发。","2d-图形#2D 图形":"2D 基础 - 2D 渲染基础概念 2D 开发 - 精灵、相机、2D 物理 索引文件：2D_Graphics/README.md","3d-图形#3D 图形":"3D 开发 - 3D 模型、材质、光照、相机 索引文件：3D_Graphics/README.md","学习路径#学习路径":"Foundation（基础） ↓ ECS（实体组件系统） ↓ Assets（资源管理） ↓ Input（输入处理） ↓ Graphics（图形渲染） ├── 2D Graphics └── 3D Graphics ↓ UI \u0026 Audio（界面与音频） ↓ Architecture（架构设计） ↓ Advanced（高级主题）","快速开始#快速开始":"如果你是 Bevy 新手，建议按以下顺序学习：\nFoundation（基础） - 了解 Bevy 和 Rust 基础 ECS（实体组件系统） - 掌握 Bevy 的核心编程范式 Assets（资源管理） - 学习如何加载和管理资源 Input（输入处理） - 处理用户输入 Graphics（图形渲染） - 根据你的需求选择 2D 或 3D UI \u0026 Audio \u0026 Window（界面、音频与窗口） - 添加用户界面、音效和窗口管理 Architecture（架构设计） - 学习如何组织大型项目 Advanced（高级主题） - 深入高级功能","教程特点#教程特点":"渐进式学习：从简单到复杂，循序渐进 实用示例：每个概念都配有实际代码示例 中文友好：全中文教程，降低学习门槛 完整覆盖：涵盖 Bevy 的核心功能和高级特性 最佳实践：分享实际开发中的经验和技巧","教程结构#教程结构":"本教程采用渐进式学习路径，从基础概念到高级应用，帮助你系统地学习 Bevy。","目录#目录":"","相关资源#相关资源":"Bevy 官方文档 Bevy 官方示例 Bevy Cheatbook Bevy Discord","第一部分基础foundation#第一部分：基础（Foundation）":"快速入门 - 安装、配置、第一个程序 Bevy 与 Rust 框架 - Bevy 简介、Rust 基础 游戏引擎基础 - 游戏引擎核心概念 索引文件：Foundation/README.md","第七部分架构设计architecture#第七部分：架构设计（Architecture）":"代码组织 - 项目结构、模块化设计 逻辑-渲染分离 - MainWorld 与 RenderApp 插件系统 - 创建插件、插件组、插件管理 索引文件：Architecture/README.md","第三部分资源管理assets#第三部分：资源管理（Assets）":"资源管理 - 资源加载、生命周期、异步加载 索引文件：Assets/README.md","第九部分示例项目examples#第九部分：示例项目（Examples）":"示例项目索引 - 完整项目示例","第二部分ecs实体组件系统#第二部分：ECS（实体组件系统）":"ECS 是 Bevy 的核心编程范式，理解 ECS 是掌握 Bevy 的关键。\n核心编程框架（ECS） - ECS 概述 ECS 基础概述 - 组件、实体、系统基础 ECS 进阶 - 查询、资源、事件系统 索引文件：ECS/README.md","第五部分图形渲染graphics#第五部分：图形渲染（Graphics）":"","第八部分高级主题advanced#第八部分：高级主题（Advanced）":"性能优化 - 优化技巧、性能分析 自定义渲染 - 自定义着色器、渲染管线 网络编程 - 多人游戏、网络同步 拆解学习 - 深入理解 Bevy 内部机制 索引文件：Advanced/README.md","第六部分ui音频与窗口ui--audio--window#第六部分：UI、音频与窗口（UI \u0026amp; Audio \u0026amp; Window）":"窗口管理 - 窗口创建、配置、多窗口、透明窗口 用户界面（UI） - UI 组件、布局、样式、交互 音频系统 - 音频加载、播放控制、3D 音频 索引文件：UI_Audio_Window/README.md","第四部分输入处理input#第四部分：输入处理（Input）":"输入基础 - 输入系统概述 输入处理 - 键盘、鼠标、游戏手柄 索引文件：Input/README.md","许可证#许可证":"本教程遵循与 Bevy 相同的许可证。","贡献#贡献":"欢迎提交问题和改进建议！\n最后更新：2025-01-XX"},"title":"Bevy 完整教程"},"/wiki/bevybook/2d_graphics/":{"data":{"":"","1-2d-基础#1. 2D 基础":"","2-2d-开发#2. 2D 开发":"本部分介绍如何在 Bevy 中进行 2D 图形渲染和开发。\n内容列表 1. 2D 基础 2D 渲染概述 2D 坐标系 2D 相机系统 2D 渲染管线 精灵（Sprite） 纹理（Texture） 学习目标：理解 Bevy 2D 渲染的基本概念\n2. 2D 开发 精灵系统\n创建精灵 精灵动画 精灵图集（Sprite Sheet） 精灵批处理 2D 相机\n相机设置 相机移动 相机缩放 相机跟随 2D 物理\n刚体（Rigid Body） 碰撞检测 物理材质 物理约束 2D 特效\n粒子系统 后处理效果 光照（可选） 学习目标：能够开发完整的 2D 游戏","下一步#下一步":"完成本部分学习后，建议继续学习：\n3D Graphics（3D 图形） - 学习 3D 渲染 UI \u0026 Audio（界面与音频） - 添加 UI 和音效 Architecture（架构设计） - 组织大型 2D 项目 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"从简单开始：先学会显示一个精灵，再逐步增加复杂度 理解坐标系：理解 2D 坐标系和变换 性能优化：注意精灵批处理和性能优化 实践项目：通过实际项目加深理解","相关资源#相关资源":"Bevy 2D 官方文档 2D 渲染示例 2D 物理示例"},"title":"2D Graphics（2D 图形）"},"/wiki/bevybook/2d_graphics/2d%E5%9F%BA%E7%A1%80/":{"data":{"":"","2d-渲染的核心组件#2D 渲染的核心组件":"Bevy 2D 渲染系统包含以下核心组件：\nSprite：精灵，用于显示图像 Camera2d：2D 相机，用于控制视图 Transform：变换，用于控制位置、旋转、缩放 AssetServer：资源服务器，用于加载图像资源","什么是-2d-渲染#什么是 2D 渲染？":"2D 渲染是在二维平面上显示图像和图形。Bevy 提供了强大的 2D 渲染系统，支持精灵、纹理、动画等功能。\n为什么需要 2D 渲染？\n游戏开发：大多数 2D 游戏需要 2D 渲染 UI 开发：用户界面通常使用 2D 渲染 性能优化：2D 渲染比 3D 渲染更高效","在游戏开发中的应用场景#在游戏开发中的应用场景":"2D 渲染在游戏开发中有广泛的应用：\n角色显示：显示游戏角色和 NPC 背景渲染：显示游戏背景和场景 UI 元素：显示用户界面元素 特效显示：显示粒子效果和动画","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：精灵不显示怎么办？\n解决方案：\n确保创建了 Camera2d 检查图像资源路径是否正确 确认精灵的位置在相机视野内 问题 2：如何控制精灵的显示顺序？\n解决方案：\n使用 Transform 的 translation.z 控制深度 Z 值越大，显示越靠前 默认 Z 值为 0 问题 3：如何优化 2D 渲染性能？\n解决方案：\n使用精灵图集（Sprite Atlas）减少绘制调用 合理使用精灵批处理 避免过多的小精灵","性能考虑#性能考虑":"精灵批处理：将多个精灵合并为一次绘制调用 纹理优化：使用合适的纹理格式和大小 相机优化：只渲染相机视野内的精灵","显示单个精灵#显示单个精灵":"创建并显示一个精灵图像。\n源代码文件：bevy/examples/2d/sprite.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .run(); } fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(Camera2d); commands.spawn(Sprite::from_image( asset_server.load(\"branding/bevy_bird_dark.png\"), )); } 关键要点：\n使用 Camera2d 创建 2D 相机 使用 Sprite::from_image() 从图像创建精灵 使用 AssetServer 加载图像资源 精灵默认显示在屏幕中心 说明： 这是最简单的 2D 渲染示例。Camera2d 是 2D 相机，用于控制视图。Sprite::from_image() 从图像文件创建精灵。AssetServer 用于加载图像资源。精灵默认显示在屏幕中心（0, 0, 0）位置。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 2D 渲染的基本概念 掌握如何创建和显示精灵（Sprite） 学会使用 2D 相机（Camera2d） 理解精灵的变换（Transform）和动画 前置知识要求：\nBevy 快速入门 ECS 基础 资源管理基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/2d/sprite.rs - 精灵显示示例 bevy/examples/2d/sprite_flipping.rs - 精灵翻转示例 bevy/examples/2d/move_sprite.rs - 精灵移动示例 bevy/examples/2d/rotation.rs - 精灵旋转示例 官方文档链接：\nBevy 2D 官方文档 2D 渲染示例 精灵系统文档 进一步学习建议：\n学习 2D 开发，了解精灵动画、精灵图集等高级功能 学习 2D 物理，了解碰撞检测和物理模拟 学习 2D 相机控制，了解相机跟随、缩放等功能 索引：返回上级目录","精灵旋转#精灵旋转":"实现精灵的旋转动画。\n源代码文件：bevy/examples/2d/rotation.rs\n代码示例：\nfn sprite_rotation(mut sprite_query: Query\u003c\u0026mut Transform, With\u003cSprite\u003e\u003e, time: Res\u003cTime\u003e) { for mut transform in \u0026mut sprite_query { transform.rotate_z(time.delta_secs() * 1.0); } } 注意事项：\n旋转角度以弧度为单位 rotate_z() 绕 Z 轴旋转（2D 平面） 使用 time.delta_secs() 确保旋转速度与帧率无关 最佳实践：\n使用 time.delta_secs() 确保动画速度一致 合理设置旋转速度，避免过快或过慢 考虑性能影响，避免过多旋转的精灵","精灵移动#精灵移动":"实现精灵的移动动画。\n源代码文件：bevy/examples/2d/move_sprite.rs\n代码示例：\n#[derive(Component)] enum Direction { Left, Right, } fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(Camera2d); commands.spawn(( Sprite::from_image(asset_server.load(\"branding/icon.png\")), Transform::from_xyz(0., 0., 0.), Direction::Right, )); } fn sprite_movement(time: Res\u003cTime\u003e, mut sprite_position: Query\u003c(\u0026mut Direction, \u0026mut Transform)\u003e) { for (mut logo, mut transform) in \u0026mut sprite_position { match *logo { Direction::Right =\u003e transform.translation.x += 150. * time.delta_secs(), Direction::Left =\u003e transform.translation.x -= 150. * time.delta_secs(), } if transform.translation.x \u003e 200. { *logo = Direction::Left; } else if transform.translation.x \u003c -200. { *logo = Direction::Right; } } } 关键要点：\n使用 Transform 组件控制位置 使用 time.delta_secs() 确保帧率无关的移动 通过边界检测改变移动方向 使用组件存储移动方向 说明： 精灵移动是 2D 游戏开发中的基本功能。使用 Transform 组件控制精灵的位置。time.delta_secs() 确保移动速度与帧率无关，无论帧率如何，移动速度都保持一致。通过边界检测可以改变移动方向，实现来回移动的效果。","精灵缩放#精灵缩放":"控制精灵的大小。\n代码示例：\nfn sprite_scale(mut sprite_query: Query\u003c\u0026mut Transform, With\u003cSprite\u003e\u003e, time: Res\u003cTime\u003e) { for mut transform in \u0026mut sprite_query { let scale = (time.elapsed_secs() * 0.5).sin() * 0.5 + 1.0; transform.scale = Vec3::splat(scale); } } 注意事项：\n缩放值 1.0 表示原始大小 小于 1.0 表示缩小，大于 1.0 表示放大 可以使用 Vec3::splat() 统一设置三个轴的缩放 最佳实践：\n使用统一的缩放值保持精灵比例 避免过度缩放，影响性能 考虑缩放对碰撞检测的影响","精灵翻转#精灵翻转":"控制精灵的水平和垂直翻转。\n源代码文件：bevy/examples/2d/sprite_flipping.rs\n代码示例：\ncommands.spawn(Sprite { image: asset_server.load(\"branding/bevy_bird_dark.png\"), flip_x: true, // 水平翻转 flip_y: false, // 垂直翻转（默认） ..default() }); 关键要点：\nflip_x: true 水平翻转精灵 flip_y: true 垂直翻转精灵 翻转是相对于精灵原始方向的 可以同时进行水平和垂直翻转 说明： 精灵翻转用于改变精灵的显示方向。这在游戏开发中很有用，例如让角色面向不同方向。翻转是相对于精灵原始方向的，不会改变精灵的位置。","进阶用法#进阶用法":""},"title":"2D 基础"},"/wiki/bevybook/2d_graphics/2d%E5%BC%80%E5%8F%91/":{"data":{"":"","2d-开发的核心组件#2D 开发的核心组件":"Bevy 2D 开发系统包含以下核心组件：\nSprite：精灵，用于显示图像 TextureAtlas：纹理图集，用于管理多个精灵 Animation：动画，用于创建精灵动画 Text2d：2D 文本，用于显示文本 Camera2d：2D 相机，用于控制视图 Bloom：泛光效果，用于后处理","2d-文本渲染#2D 文本渲染":"在 2D 场景中渲染文本。\n源代码文件：bevy/examples/2d/text2d.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .add_systems(Update, (animate_translation, animate_rotation, animate_scale)) .run(); } fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { let font = asset_server.load(\"fonts/FiraSans-Bold.ttf\"); let text_font = TextFont { font: font.clone(), font_size: 50.0, ..default() }; commands.spawn(Camera2d); // 演示变换 commands.spawn(( Text2d::new(\" translation \"), text_font.clone(), TextLayout::new_with_justify(Justify::Center), TextBackgroundColor(Color::BLACK.with_alpha(0.5)), Text2dShadow::default(), Transform::from_xyz(0.0, 0.0, 0.0), )); // 演示文本换行 let box_size = Vec2::new(300.0, 200.0); commands.spawn(( Sprite::from_color(Color::srgb(0.25, 0.25, 0.55), box_size), Transform::from_translation(Vec3::new(0.0, -250.0, 0.0)), children![( Text2d::new(\"this text wraps in the box\\n(Unicode linebreaks)\"), TextFont { font, font_size: 35.0, ..default() }, TextLayout::new(Justify::Left, LineBreak::WordBoundary), // 在矩形中换行文本 TextBounds::from(box_size), // 确保文本绘制在框的上方 Transform::from_translation(Vec3::Z), Text2dShadow::default(), )], )); } 关键要点：\n使用 Text2d 在 2D 场景中渲染文本 使用 TextFont 设置字体和大小 使用 TextLayout 设置文本布局和对齐 使用 TextBounds 设置文本边界和换行 使用 Text2dShadow 添加文本阴影 说明： 2D 文本渲染允许在 2D 场景中显示文本。与 UI 文本不同，2D 文本是场景的一部分，可以应用变换、动画等效果。","2d-相机控制视口到世界坐标转换#2D 相机控制（视口到世界坐标转换）":"将视口坐标转换为世界坐标。\n源代码文件：bevy/examples/2d/2d_viewport_to_world.rs\n关键信息：\n使用 Camera 的 viewport_to_world() 方法 可以将屏幕坐标转换为世界坐标 适合处理鼠标点击、触摸输入等 需要考虑相机的变换和投影 说明： 视口到世界坐标转换允许将屏幕坐标转换为游戏世界坐标。这对于处理鼠标点击、触摸输入等交互非常有用。","什么是-2d-开发#什么是 2D 开发？":"2D 开发是在二维平面上创建游戏和应用。Bevy 提供了强大的 2D 渲染系统，支持精灵、动画、文本、后处理等功能。\n为什么需要 2D 开发？\n游戏开发：大多数 2D 游戏需要 2D 开发 UI 开发：用户界面通常使用 2D 渲染 性能优化：2D 渲染比 3D 渲染更高效 简单性：2D 开发通常比 3D 开发更简单","像素完美渲染#像素完美渲染":"实现像素完美渲染。\n源代码文件：bevy/examples/2d/pixel_grid_snap.rs\n关键信息：\n使用 ImagePlugin::default_nearest() 禁用纹理过滤 使用像素对齐确保精灵对齐到像素网格 适合像素艺术风格的游戏 可以避免模糊和抗锯齿 说明： 像素完美渲染确保精灵对齐到像素网格，避免模糊和抗锯齿。这对于像素艺术风格的游戏非常重要。","后处理效果泛光#后处理效果（泛光）":"使用泛光效果增强渲染效果。\n源代码文件：bevy/examples/2d/bloom_2d.rs\n代码示例：\nuse bevy::{ core_pipeline::tonemapping::{DebandDither, Tonemapping}, post_process::bloom::{Bloom, BloomCompositeMode}, prelude::*, }; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .add_systems(Update, update_bloom_settings) .run(); } fn setup( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cColorMaterial\u003e\u003e, asset_server: Res\u003cAssetServer\u003e, ) { commands.spawn(( Camera2d, Camera { clear_color: ClearColorConfig::Custom(Color::BLACK), ..default() }, Tonemapping::TonyMcMapface, // 使用色调映射器 Bloom::default(), // 启用泛光效果 DebandDither::Enabled, // 可选：泛光会导致渐变，导致条带 )); // 精灵 commands.spawn(Sprite { image: asset_server.load(\"branding/bevy_bird_dark.png\"), color: Color::srgb(5.0, 5.0, 5.0), // 在暗环境中放置明亮的东西以看到效果 custom_size: Some(Vec2::splat(160.0)), ..default() }); } 关键要点：\n使用 Bloom 组件添加泛光效果 使用 Tonemapping 进行色调映射 使用 DebandDither 减少条带 泛光效果在暗环境中更明显 说明： 泛光效果可以在明亮区域周围创建光晕效果。这对于创建发光效果、增强视觉冲击力非常有用。","在游戏开发中的应用场景#在游戏开发中的应用场景":"2D 开发在游戏开发中有广泛的应用：\n2D 游戏：创建 2D 平台游戏、RPG、策略游戏等 UI 开发：创建游戏 UI 和 HUD 粒子效果：创建粒子效果和特效 菜单系统：创建游戏菜单和界面","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何优化精灵动画性能？\n解决方案：使用精灵图集、批处理、剔除等技术来优化精灵动画性能。\n问题 2：如何处理透明对象？\n解决方案：透明对象需要正确的渲染顺序。Bevy 会自动处理透明对象的排序。\n问题 3：如何实现像素完美渲染？\n解决方案：使用 ImagePlugin::default_nearest() 禁用纹理过滤，并确保精灵对齐到像素网格。","性能优化#性能优化":"优化 2D 渲染性能。\n关键信息：\n使用精灵图集减少绘制调用 使用批处理优化渲染 使用剔除减少渲染对象 合理使用透明度 说明： 性能优化对于 2D 游戏非常重要。通过使用精灵图集、批处理、剔除等技术，可以显著提高渲染性能。","性能考虑#性能考虑":"精灵图集：使用精灵图集减少绘制调用 批处理：使用批处理优化渲染 剔除：使用剔除减少渲染对象 透明度：合理使用透明度以减少性能开销","核心概念#核心概念":"","概述#概述":"学习目标：\n掌握精灵图集的使用 学会创建精灵动画 了解 2D 文本渲染 掌握透明度的使用 了解后处理效果（泛光） 理解 2D 相机控制（视口到世界坐标转换） 掌握像素完美渲染 前置知识要求：\n2D 基础 ECS 基础 资源管理基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/2d/texture_atlas.rs - 精灵图集示例 bevy/examples/2d/sprite_animation.rs - 精灵动画示例 bevy/examples/2d/text2d.rs - 2D 文本渲染示例 bevy/examples/2d/transparency_2d.rs - 透明度示例 bevy/examples/2d/bloom_2d.rs - 泛光效果示例 bevy/examples/2d/2d_viewport_to_world.rs - 视口到世界坐标转换示例 bevy/examples/2d/pixel_grid_snap.rs - 像素完美渲染示例 官方文档链接：\nBevy 2D 渲染文档 2D 示例 进一步学习建议：\n学习动画系统，了解如何创建更复杂的动画 学习 UI 系统，了解如何创建用户界面 学习性能优化，了解如何优化 2D 渲染性能 索引：返回上级目录","精灵动画#精灵动画":"创建精灵动画。\n源代码文件：bevy/examples/2d/sprite_animation.rs\n代码示例：\nuse bevy::prelude::*; use std::time::Duration; fn main() { App::new() .add_plugins(DefaultPlugins.set(ImagePlugin::default_nearest())) .add_systems(Startup, setup) .add_systems(Update, execute_animations) .run(); } #[derive(Component)] struct AnimationConfig { first_sprite_index: usize, last_sprite_index: usize, fps: u8, frame_timer: Timer, } impl AnimationConfig { fn new(first: usize, last: usize, fps: u8) -\u003e Self { Self { first_sprite_index: first, last_sprite_index: last, fps, frame_timer: Timer::new(Duration::from_secs_f32(1.0 / (fps as f32)), TimerMode::Repeating), } } } // 这个系统循环遍历 `TextureAtlas` 中的所有精灵，从 `first_sprite_index` 到 `last_sprite_index` fn execute_animations(time: Res\u003cTime\u003e, mut query: Query\u003c(\u0026mut AnimationConfig, \u0026mut Sprite)\u003e) { for (mut config, mut sprite) in \u0026mut query { // 跟踪当前精灵已显示的时间 config.frame_timer.tick(time.delta()); // 如果已显示用户定义的时间（fps）... if config.frame_timer.just_finished() { if let Some(atlas) = \u0026mut sprite.texture_atlas { if atlas.index == config.last_sprite_index { // ...并且是最后一帧，则回到第一帧 atlas.index = config.first_sprite_index; } else { // ...并且不是最后一帧，则移动到下一帧 atlas.index += 1; } } } } } 关键要点：\n使用 AnimationConfig 配置动画 使用 Timer 控制动画帧率 通过更新 Sprite 的 texture_atlas.index 来切换帧 可以设置动画的起始帧和结束帧 说明： 精灵动画通过在不同帧之间切换来创建动画效果。通过控制帧切换的时间，可以创建流畅的动画。","精灵图集#精灵图集":"使用精灵图集管理多个精灵。\n源代码文件：bevy/examples/2d/texture_atlas.rs\n代码示例：\nuse bevy::{asset::LoadedFolder, image::ImageSampler, prelude::*}; fn main() { App::new() .add_plugins(DefaultPlugins.set(ImagePlugin::default_nearest())) .add_systems(Startup, setup) .run(); } fn setup( mut commands: Commands, asset_server: Res\u003cAssetServer\u003e, mut texture_atlases: ResMut\u003cAssets\u003cTextureAtlasLayout\u003e\u003e, mut textures: ResMut\u003cAssets\u003cImage\u003e\u003e, ) { // 从文件夹加载多个单独的精灵 let loaded_folder = asset_server.load_folder(\"textures/rpg\"); // 创建纹理图集 let (texture_atlas, sources, texture) = create_texture_atlas( loaded_folder, Some(UVec2::new(6, 6)), // 填充 Some(ImageSampler::nearest()), // 采样方式 \u0026mut textures, ); let atlas_handle = texture_atlases.add(texture_atlas); // 使用图集中的精灵 commands.spawn(( Sprite { texture_atlas: Some(atlas_handle), ..default() }, Transform::from_xyz(0.0, 0.0, 0.0), )); } 关键要点：\n使用 TextureAtlasLayout 创建纹理图集 可以从文件夹加载多个精灵 可以设置填充和采样方式 使用 Sprite 的 texture_atlas 属性使用图集 说明： 精灵图集允许将多个精灵打包到一个纹理中，减少绘制调用和提高性能。","进阶用法#进阶用法":"","透明度#透明度":"使用透明度创建半透明效果。\n源代码文件：bevy/examples/2d/transparency_2d.rs\n关键信息：\n使用 Color::srgba() 创建带透明度的颜色 使用 AlphaMode 控制透明度模式 AlphaMode::Blend 用于半透明对象 AlphaMode::Mask 用于带透明度的纹理 透明对象需要正确的渲染顺序 说明： 透明度是 2D 渲染中的重要特性。Bevy 支持多种透明度模式，可以创建玻璃、水、烟雾等效果。","高级动画#高级动画":"创建复杂的动画效果。\n关键信息：\n可以创建多个动画轨道 可以混合不同的动画 可以使用动画事件 可以控制动画的播放速度 说明： 高级动画允许创建复杂的动画效果。可以组合多个动画、控制播放速度、响应动画事件等。"},"title":"2D开发"},"/wiki/bevybook/3d_graphics/":{"data":{"":"","1-3d-开发#1. 3D 开发":"","2-相机系统camera#2. 相机系统（Camera）":"本部分介绍如何在 Bevy 中进行 3D 图形渲染和开发。\n内容列表 1. 3D 开发 3D 基础\n3D 坐标系 3D 变换（Transform） 3D 渲染管线 3D 模型\n加载 3D 模型 模型格式（GLTF、OBJ） 模型动画 模型优化 材质系统\n标准材质（Standard Material） PBR 材质（Physically Based Rendering） 自定义材质 材质属性 光照系统\n环境光（Ambient Light） 方向光（Directional Light） 点光源（Point Light） 聚光灯（Spot Light） 阴影（Shadows） 3D 相机\n透视相机（Perspective Camera） 正交相机（Orthographic Camera） 相机控制 相机跟随 3D 物理\n3D 刚体 3D 碰撞检测 物理材质 物理约束 学习目标：能够开发完整的 3D 游戏\n2. 相机系统（Camera） 相机系统概述 透视相机 正交相机 相机控制 相机跟随 多相机渲染 学习目标：能够控制 3D 视图和相机","下一步#下一步":"完成本部分学习后，建议继续学习：\nUI \u0026 Audio（界面与音频） - 添加 UI 和音效 Architecture（架构设计） - 组织大型 3D 项目 Advanced（高级主题） - 自定义渲染、性能优化 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"理解 3D 数学：理解向量、矩阵、四元数等 3D 数学基础 学习 PBR：理解基于物理的渲染原理 性能优化：注意 3D 渲染的性能优化 实践项目：通过实际项目加深理解","相关资源#相关资源":"Bevy 3D 官方文档 3D 渲染示例 GLTF 格式文档"},"title":"3D Graphics（3D 图形）"},"/wiki/bevybook/3d_graphics/%E7%9B%B8%E6%9C%BA%E7%B3%BB%E7%BB%9Fcamera/":{"data":{"":"","什么是相机系统#什么是相机系统？":"相机系统是 Bevy 中用于控制视角的功能。相机系统提供了多种相机类型和控制方式，包括轨道相机、第一人称相机、自定义投影等。\n为什么需要相机系统？\n视角控制：相机系统可以控制游戏的视角 相机移动：相机系统可以实现相机的移动和旋转 相机投影：相机系统可以自定义相机的投影方式 相机效果：相机系统可以实现相机特效（如屏幕抖动）","在游戏开发中的应用场景#在游戏开发中的应用场景":"相机系统在游戏开发中有广泛的应用：\n视角控制：控制游戏的视角 相机移动：实现相机的移动和旋转 相机投影：自定义相机的投影方式 相机效果：实现相机特效（如屏幕抖动） 相机切换：实现不同相机之间的切换","基础用法#基础用法":"","实际应用#实际应用":"","屏幕抖动#屏幕抖动":"使用屏幕抖动实现相机特效。\n源代码文件：bevy/examples/camera/2d_screen_shake.rs\n关键信息：\n使用 Transform 控制相机位置 使用随机数生成抖动效果 使用时间控制抖动持续时间 使用衰减函数平滑抖动 说明： 屏幕抖动是相机系统的重要功能。通过使用屏幕抖动，可以实现相机特效，增强游戏体验。","常见问题#常见问题":"问题 1：如何控制相机移动？\n解决方案：\n使用 CameraController 组件控制相机 使用键盘和鼠标控制相机移动和旋转 使用 Transform 控制相机位置和旋转 问题 2：如何实现相机轨道？\n解决方案：\n使用 AccumulatedMouseMotion 获取鼠标移动 使用 Transform 控制相机位置和旋转 使用 Quat::from_euler 创建旋转四元数 问题 3：如何自定义相机投影？\n解决方案：\n使用 CameraProjection trait 实现自定义投影 使用 Projection::custom() 设置自定义投影 使用 get_clip_from_view() 获取投影矩阵","性能考虑#性能考虑":"相机控制器：相机控制器更新是高效的，可以频繁使用 相机投影：自定义投影计算可能较慢，应谨慎使用 相机效果：相机效果应适度使用，避免影响性能","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 相机系统的基本概念 掌握相机控制器的使用 了解相机投影的使用 学会使用相机轨道和第一人称相机 前置知识要求：\nBevy 快速入门 ECS 基础 3D 开发基础 输入处理基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/helpers/camera_controller.rs - 相机控制器示例 bevy/examples/camera/camera_orbit.rs - 相机轨道示例 bevy/examples/camera/custom_projection.rs - 自定义投影示例 bevy/examples/camera/2d_screen_shake.rs - 屏幕抖动示例 bevy/examples/camera/first_person_view_model.rs - 第一人称相机示例 官方文档链接：\nBevy 相机系统 Bevy 相机示例 进一步学习建议：\n学习 3D 开发，了解 3D 渲染基础 学习输入处理，了解输入系统 索引：返回上级目录","相机控制器#相机控制器":"使用相机控制器实现自由相机。\n源代码文件：bevy/examples/helpers/camera_controller.rs\n代码示例：\nuse bevy::{ input::mouse::{AccumulatedMouseMotion, AccumulatedMouseScroll, MouseScrollUnit}, prelude::*, window::{CursorGrabMode, CursorOptions}, }; use std::{f32::consts::*, fmt}; /// 自由相机风格的相机控制器插件。 pub struct CameraControllerPlugin; impl Plugin for CameraControllerPlugin { fn build(\u0026self, app: \u0026mut App) { app.add_systems(Update, run_camera_controller); } } /// 相机控制器组件。 #[derive(Component)] pub struct CameraController { /// 当为 `true` 时启用此 [`CameraController`]。 pub enabled: bool, /// 指示此控制器是否已由 [`CameraControllerPlugin`] 初始化。 pub initialized: bool, /// 俯仰和偏航旋转速度的乘数。 pub sensitivity: f32, /// 向前平移的 [`KeyCode`]。 pub key_forward: KeyCode, /// 向后平移的 [`KeyCode`]。 pub key_back: KeyCode, /// 向左平移的 [`KeyCode`]。 pub key_left: KeyCode, /// 向右平移的 [`KeyCode`]。 pub key_right: KeyCode, /// 向上平移的 [`KeyCode`]。 pub key_up: KeyCode, /// 向下平移的 [`KeyCode`]。 pub key_down: KeyCode, /// 使用 [`run_speed`](CameraController::run_speed) 而不是 /// [`walk_speed`](CameraController::walk_speed) 进行平移的 [`KeyCode`]。 pub key_run: KeyCode, /// 用于抓取鼠标焦点的 [`MouseButton`]。 pub mouse_key_cursor_grab: MouseButton, /// 用于抓取键盘焦点的 [`KeyCode`]。 pub keyboard_key_toggle_cursor_grab: KeyCode, /// 未修改平移速度的乘数。 pub walk_speed: f32, /// 运行平移速度的乘数。 pub run_speed: f32, /// 鼠标滚轮修改 [`walk_speed`](CameraController::walk_speed) /// 和 [`run_speed`](CameraController::run_speed) 的乘数。 pub scroll_factor: f32, /// 用于随时间指数衰减 [`velocity`](CameraController::velocity) 的摩擦因子。 pub friction: f32, /// 此 [`CameraController`] 的俯仰旋转。 pub pitch: f32, /// 此 [`CameraController`] 的偏航旋转。 pub yaw: f32, /// 此 [`CameraController`] 的平移速度。 pub velocity: Vec3, } impl Default for CameraController { fn default() -\u003e Self { Self { enabled: true, initialized: false, sensitivity: 1.0, key_forward: KeyCode::KeyW, key_back: KeyCode::KeyS, key_left: KeyCode::KeyA, key_right: KeyCode::KeyD, key_up: KeyCode::KeyE, key_down: KeyCode::KeyQ, key_run: KeyCode::ShiftLeft, mouse_key_cursor_grab: MouseButton::Left, keyboard_key_toggle_cursor_grab: KeyCode::KeyM, walk_speed: 5.0, run_speed: 15.0, scroll_factor: 0.1, friction: 0.5, pitch: 0.0, yaw: 0.0, velocity: Vec3::ZERO, } } } 关键要点：\n使用 CameraController 组件控制相机 使用 CameraControllerPlugin 插件添加相机控制器系统 使用键盘和鼠标控制相机移动和旋转 使用 CursorGrabMode 控制鼠标抓取模式 说明： 相机控制器是相机系统的基础。通过使用相机控制器，可以实现自由相机，控制游戏的视角。","相机系统的核心组件#相机系统的核心组件":"Bevy 相机系统包含以下核心组件：\nCamera3d：3D 相机组件 Camera2d：2D 相机组件 Projection：投影组件 Transform：变换组件，用于控制相机位置和旋转","相机轨道#相机轨道":"使用相机轨道实现轨道相机。\n源代码文件：bevy/examples/camera/camera_orbit.rs\n代码示例：\nuse std::{f32::consts::FRAC_PI_2, ops::Range}; use bevy::{input::mouse::AccumulatedMouseMotion, prelude::*}; #[derive(Debug, Resource)] struct CameraSettings { pub orbit_distance: f32, pub pitch_speed: f32, // 将俯仰限制在此范围内 pub pitch_range: Range\u003cf32\u003e, pub roll_speed: f32, pub yaw_speed: f32, } impl Default for CameraSettings { fn default() -\u003e Self { // 限制俯仰可以防止超过 90° 向上或向下的意外旋转。 let pitch_limit = FRAC_PI_2 - 0.01; Self { // 这些值完全是任意的，选择它们是因为它们似乎为这个示例产生\"合理\"的结果。 // 根据需要调整。 orbit_distance: 20.0, pitch_speed: 0.003, pitch_range: -pitch_limit..pitch_limit, roll_speed: 1.0, yaw_speed: 0.004, } } } fn main() { App::new() .add_plugins(DefaultPlugins) .init_resource::\u003cCameraSettings\u003e() .add_systems(Startup, (setup, instructions)) .add_systems(Update, orbit) .run(); } fn orbit( mut camera: Single\u003c\u0026mut Transform, With\u003cCamera\u003e\u003e, settings: Res\u003cCameraSettings\u003e, mouse_motion: Res\u003cAccumulatedMouseMotion\u003e, mouse_buttons: Res\u003cButtonInput\u003cMouseButton\u003e\u003e, ) { // 根据鼠标移动更新俯仰和偏航 let mut pitch_delta = 0.0; let mut yaw_delta = 0.0; let mut roll_delta = 0.0; if mouse_motion.is_changed() { let delta = mouse_motion.delta(); pitch_delta -= delta.y * settings.pitch_speed; yaw_delta -= delta.x * settings.yaw_speed; } // 根据鼠标按钮更新滚动 if mouse_buttons.pressed(MouseButton::Left) { roll_delta += settings.roll_speed; } if mouse_buttons.pressed(MouseButton::Right) { roll_delta -= settings.roll_speed; } // 更新相机变换 let mut pitch = camera.rotation.to_euler(EulerRot::YXZ).1; let mut yaw = camera.rotation.to_euler(EulerRot::YXZ).0; let mut roll = camera.rotation.to_euler(EulerRot::YXZ).2; pitch += pitch_delta; pitch = pitch.clamp(settings.pitch_range.start, settings.pitch_range.end); yaw += yaw_delta; roll += roll_delta; // 计算相机位置 let rotation = Quat::from_euler(EulerRot::YXZ, yaw, pitch, roll); let position = rotation * Vec3::new(0.0, 0.0, settings.orbit_distance); camera.translation = position; camera.rotation = rotation; } 关键要点：\n使用 AccumulatedMouseMotion 获取鼠标移动 使用 ButtonInput 获取鼠标按钮状态 使用 Transform 控制相机位置和旋转 使用 Quat::from_euler 创建旋转四元数 说明： 相机轨道是相机系统的重要功能。通过使用相机轨道，可以实现轨道相机，围绕场景旋转相机。","第一人称相机#第一人称相机":"使用第一人称相机实现第一人称视角。\n源代码文件：bevy/examples/camera/first_person_view_model.rs\n关键信息：\n使用 CameraController 控制相机 使用鼠标控制视角 使用键盘控制移动 使用 CursorGrabMode 控制鼠标抓取 说明： 第一人称相机是相机系统的重要功能。通过使用第一人称相机，可以实现第一人称视角，增强游戏沉浸感。","自定义投影#自定义投影":"使用自定义投影实现特殊投影效果。\n源代码文件：bevy/examples/camera/custom_projection.rs\n代码示例：\nuse bevy::camera::CameraProjection; use bevy::prelude::*; /// 类似于透视投影，但消失点不居中。 #[derive(Debug, Clone)] struct ObliquePerspectiveProjection { horizontal_obliqueness: f32, vertical_obliqueness: f32, perspective: PerspectiveProjection, } /// 为我们的自定义投影实现 [`CameraProjection`] trait： impl CameraProjection for ObliquePerspectiveProjection { fn get_clip_from_view(\u0026self) -\u003e Mat4 { let mut mat = self.perspective.get_clip_from_view(); mat.col_mut(2)[0] = self.horizontal_obliqueness; mat.col_mut(2)[1] = self.vertical_obliqueness; mat } fn get_clip_from_view_for_sub(\u0026self, sub_view: \u0026bevy::camera::SubCameraView) -\u003e Mat4 { let mut mat = self.perspective.get_clip_from_view_for_sub(sub_view); mat.col_mut(2)[0] = self.horizontal_obliqueness; mat.col_mut(2)[1] = self.vertical_obliqueness; mat } fn update(\u0026mut self, width: f32, height: f32) { self.perspective.update(width, height); } fn far(\u0026self) -\u003e f32 { self.perspective.far } fn get_frustum_corners(\u0026self, z_near: f32, z_far: f32) -\u003e [Vec3A; 8] { self.perspective.get_frustum_corners(z_near, z_far) } } fn setup( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { commands.spawn(( Camera3d::default(), // 使用我们的自定义投影： Projection::custom(ObliquePerspectiveProjection { horizontal_obliqueness: 0.2, vertical_obliqueness: 0.6, perspective: PerspectiveProjection::default(), }), Transform::from_xyz(-2.5, 4.5, 9.0).looking_at(Vec3::ZERO, Vec3::Y), )); } 关键要点：\n使用 CameraProjection trait 实现自定义投影 使用 Projection::custom() 设置自定义投影 使用 get_clip_from_view() 获取投影矩阵 使用 update() 更新投影参数 说明： 自定义投影是相机系统的高级功能。通过使用自定义投影，可以实现特殊的投影效果，如斜投影。","进阶用法#进阶用法":""},"title":"相机系统（Camera）"},"/wiki/bevybook/3d_graphics/3d%E5%BC%80%E5%8F%91/":{"data":{"":"","3d-渲染的核心组件#3D 渲染的核心组件":"Bevy 3D 渲染系统包含以下核心组件：\nMesh3d：3D 网格，用于定义 3D 模型的形状 MeshMaterial3d：3D 材质，用于定义 3D 模型的外观 Camera3d：3D 相机，用于控制 3D 视图 Transform：变换，用于控制位置、旋转、缩放 Light：光照，用于照亮场景","pbr-材质#PBR 材质":"使用 PBR（Physically Based Rendering）材质创建真实的材质效果。\n源代码文件：bevy/examples/3d/pbr.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .run(); } fn setup( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { let sphere_mesh = meshes.add(Sphere::new(0.45)); // 创建网格的球体，每个球体有不同的 PBR 参数 for y in -2..=2 { for x in -5..=5 { let x01 = (x + 5) as f32 / 10.0; let y01 = (y + 2) as f32 / 4.0; // 球体 commands.spawn(( Mesh3d(sphere_mesh.clone()), MeshMaterial3d(materials.add(StandardMaterial { base_color: Srgba::hex(\"#ffd891\").unwrap().into(), // 在网格的球体上变化关键的 PBR 参数以显示效果 metallic: y01, perceptual_roughness: x01, ..default() })), Transform::from_xyz(x as f32, y as f32 + 0.5, 0.0), )); } } // 无光照球体 commands.spawn(( Mesh3d(sphere_mesh), MeshMaterial3d(materials.add(StandardMaterial { base_color: Srgba::hex(\"#ffd891\").unwrap().into(), unlit: true, ..default() })), Transform::from_xyz(-5.0, -2.5, 0.0), )); // 方向光 commands.spawn(( DirectionalLight { illuminance: 1_500., ..default() }, Transform::from_xyz(50.0, 50.0, 50.0).looking_at(Vec3::ZERO, Vec3::Y), )); } 关键要点：\n使用 StandardMaterial 创建 PBR 材质 metallic 控制金属度 perceptual_roughness 控制粗糙度 base_color 控制基础颜色 unlit 可以禁用光照 说明： PBR 材质使用物理属性来模拟真实材质的外观。通过调整金属度和粗糙度，可以创建各种材质效果。","什么是-3d-渲染#什么是 3D 渲染？":"3D 渲染是在三维空间中显示模型和场景。Bevy 提供了强大的 3D 渲染系统，支持 PBR 材质、多种光照类型、阴影、后处理等功能。\n为什么需要 3D 渲染？\n游戏开发：大多数 3D 游戏需要 3D 渲染 视觉效果：3D 渲染可以提供更真实的视觉效果 沉浸感：3D 渲染可以增强游戏的沉浸感 灵活性：3D 渲染提供了更多的创作空间","光照系统#光照系统":"使用不同类型的光照照亮场景。\n源代码文件：bevy/examples/3d/lighting.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .add_systems(Update, (update_exposure, toggle_ambient_light, movement, animate_light_direction)) .run(); } fn setup( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { // 地面平面 commands.spawn(( Mesh3d(meshes.add(Plane3d::default().mesh().size(10.0, 10.0))), MeshMaterial3d(materials.add(StandardMaterial { base_color: Color::WHITE, perceptual_roughness: 1.0, ..default() })), )); // 立方体 commands.spawn(( Mesh3d(meshes.add(Cuboid::new(1.0, 1.0, 1.0))), MeshMaterial3d(materials.add(StandardMaterial { base_color: Color::srgb_u8(124, 144, 255), ..default() })), Transform::from_xyz(0.0, 0.5, 0.0), )); // 环境光 commands.insert_resource(AmbientLight { color: Color::WHITE, brightness: 150.0, }); // 方向光 commands.spawn(( DirectionalLight { illuminance: 1_500., shadows_enabled: true, ..default() }, Transform::from_xyz(4.0, 8.0, 4.0).looking_at(Vec3::ZERO, Vec3::Y), )); // 点光源 commands.spawn(( PointLight { intensity: 1_500_000.0, shadows_enabled: true, ..default() }, Transform::from_xyz(4.0, 8.0, 4.0), )); // 聚光灯 commands.spawn(( SpotLight { intensity: 1_500_000.0, shadows_enabled: true, ..default() }, Transform::from_xyz(4.0, 8.0, 4.0).looking_at(Vec3::ZERO, Vec3::Y), )); // 相机 commands.spawn(( Camera3d::default(), Transform::from_xyz(-2.5, 4.5, 9.0).looking_at(Vec3::ZERO, Vec3::Y), )); } 关键要点：\nAmbientLight 提供环境光 DirectionalLight 提供方向光（如太阳光） PointLight 提供点光源（如灯泡） SpotLight 提供聚光灯 可以启用阴影来增强真实感 说明： 光照系统是 3D 渲染的重要组成部分。不同类型的光照可以创建不同的视觉效果。Bevy 支持环境光、方向光、点光源和聚光灯。","创建简单的-3d-场景#创建简单的 3D 场景":"创建并显示一个简单的 3D 场景。\n源代码文件：bevy/examples/3d/3d_scene.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .run(); } /// 设置简单的 3D 场景 fn setup( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { // 圆形底座 commands.spawn(( Mesh3d(meshes.add(Circle::new(4.0))), MeshMaterial3d(materials.add(Color::WHITE)), Transform::from_rotation(Quat::from_rotation_x(-std::f32::consts::FRAC_PI_2)), )); // 立方体 commands.spawn(( Mesh3d(meshes.add(Cuboid::new(1.0, 1.0, 1.0))), MeshMaterial3d(materials.add(Color::srgb_u8(124, 144, 255))), Transform::from_xyz(0.0, 0.5, 0.0), )); // 光照 commands.spawn(( PointLight { shadows_enabled: true, ..default() }, Transform::from_xyz(4.0, 8.0, 4.0), )); // 相机 commands.spawn(( Camera3d::default(), Transform::from_xyz(-2.5, 4.5, 9.0).looking_at(Vec3::ZERO, Vec3::Y), )); } 关键要点：\n使用 Mesh3d 创建 3D 网格 使用 MeshMaterial3d 应用材质 使用 Transform 控制位置、旋转、缩放 使用 PointLight 添加点光源 使用 Camera3d 创建 3D 相机 说明： 这是最简单的 3D 场景示例。它展示了如何创建基本的 3D 对象、添加光照和相机。","加载-gltf-模型#加载 GLTF 模型":"加载和使用 GLTF 模型。\n源代码文件：bevy/examples/3d/load_gltf.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .insert_resource(DirectionalLightShadowMap { size: 4096 }) .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .add_systems(Update, animate_light_direction) .run(); } fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { // 相机 commands.spawn(( Camera3d::default(), Transform::from_xyz(0.7, 0.7, 1.0).looking_at(Vec3::new(0.0, 0.3, 0.0), Vec3::Y), EnvironmentMapLight { diffuse_map: asset_server.load(\"environment_maps/pisa_diffuse_rgb9e5_zstd.ktx2\"), specular_map: asset_server.load(\"environment_maps/pisa_specular_rgb9e5_zstd.ktx2\"), intensity: 250.0, ..default() }, )); // 方向光 commands.spawn(( DirectionalLight { shadows_enabled: true, ..default() }, CascadeShadowConfigBuilder { num_cascades: 1, maximum_distance: 1.6, ..default() } .build(), )); // 加载 GLTF 场景 commands.spawn(SceneRoot(asset_server.load( GltfAssetLabel::Scene(0).from_asset(\"models/FlightHelmet/FlightHelmet.gltf\"), ))); } 关键要点：\n使用 SceneRoot 加载 GLTF 场景 使用 GltfAssetLabel::Scene(0) 指定场景索引 GLTF 文件可以包含多个场景、网格、材质等 可以使用环境贴图增强渲染效果 说明： GLTF 是一种标准的 3D 模型格式。Bevy 支持加载 GLTF 文件，包括场景、网格、材质、动画等。","后处理效果#后处理效果":"使用后处理效果增强渲染效果。\n源代码文件：bevy/examples/3d/post_processing.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .add_systems(Update, handle_keyboard_input) .run(); } fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { // 相机，包含色差效果 commands.spawn(( Camera3d::default(), Hdr, Transform::from_xyz(0.7, 0.7, 1.0).looking_at(Vec3::new(0.0, 0.3, 0.0), Vec3::Y), DistanceFog { color: Color::srgb_u8(43, 44, 47), falloff: FogFalloff::Linear { start: 1.0, end: 8.0, }, ..default() }, EnvironmentMapLight { diffuse_map: asset_server.load(\"environment_maps/pisa_diffuse_rgb9e5_zstd.ktx2\"), specular_map: asset_server.load(\"environment_maps/pisa_specular_rgb9e5_zstd.ktx2\"), intensity: 2000.0, ..default() }, // 包含色差效果组件 ChromaticAberration::default(), )); } 关键要点：\n使用 ChromaticAberration 添加色差效果 使用 Hdr 启用 HDR 渲染 使用 DistanceFog 添加距离雾效果 后处理效果可以组合使用 说明： 后处理效果可以在渲染完成后对图像进行处理。Bevy 支持多种后处理效果，如色差、色调映射、泛光等。","在游戏开发中的应用场景#在游戏开发中的应用场景":"3D 渲染在游戏开发中有广泛的应用：\n3D 游戏：创建 3D 游戏场景和角色 可视化：创建数据可视化应用 模拟：创建物理模拟和训练应用 艺术创作：创建 3D 艺术作品和动画","基础用法#基础用法":"","多相机渲染#多相机渲染":"使用多个相机渲染不同的视图。\n源代码文件：bevy/examples/3d/multiple_windows.rs\n关键信息：\n可以创建多个相机 每个相机可以渲染到不同的窗口 可以使用 RenderTarget 指定渲染目标 适合创建分屏或多显示器应用 说明： 多相机渲染允许同时显示多个视图。这对于创建分屏游戏、多显示器应用或调试视图非常有用。","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何优化 3D 渲染性能？\n解决方案：可以使用 LOD（细节层次）、遮挡剔除、视锥剔除等技术来优化 3D 渲染性能。\n问题 2：如何处理透明对象？\n解决方案：透明对象需要正确的渲染顺序。Bevy 会自动处理透明对象的排序。\n问题 3：如何创建自定义材质？\n解决方案：可以实现 Material trait 来创建自定义材质。可以参考 StandardMaterial 的实现。","性能考虑#性能考虑":"网格优化：使用优化的网格减少顶点数量 材质优化：使用简单的材质减少渲染开销 光照优化：合理使用光照类型和阴影 剔除优化：使用视锥剔除和遮挡剔除减少渲染对象","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 3D 渲染的基本概念 掌握如何创建简单的 3D 场景 学会使用 PBR 材质和光照系统 了解如何加载 GLTF 模型 掌握后处理效果的使用 理解透明度和多相机渲染 前置知识要求：\nBevy 快速入门 ECS 基础 资源管理基础 2D 基础（可选）","相关资源#相关资源":"相关源代码文件：\nbevy/examples/3d/3d_scene.rs - 简单 3D 场景示例 bevy/examples/3d/pbr.rs - PBR 材质示例 bevy/examples/3d/lighting.rs - 光照系统示例 bevy/examples/3d/load_gltf.rs - GLTF 加载示例 bevy/examples/3d/post_processing.rs - 后处理效果示例 bevy/examples/3d/transparency_3d.rs - 透明度示例 bevy/examples/3d/multiple_windows.rs - 多相机渲染示例 官方文档链接：\nBevy 3D 渲染文档 3D 示例 进一步学习建议：\n学习相机系统，了解如何控制 3D 视图 学习动画系统，了解如何为 3D 模型添加动画 学习自定义渲染，了解如何创建自定义渲染效果 索引：返回上级目录","进阶用法#进阶用法":"","透明度#透明度":"处理透明对象。\n源代码文件：bevy/examples/3d/transparency_3d.rs\n关键信息：\n使用 AlphaMode 控制透明度模式 AlphaMode::Blend 用于半透明对象 AlphaMode::Mask 用于带透明度的纹理 透明对象需要正确的渲染顺序 说明： 透明度是 3D 渲染中的重要特性。Bevy 支持多种透明度模式，可以创建玻璃、水、烟雾等效果。"},"title":"3D开发"},"/wiki/bevybook/advanced/":{"data":{"":"","1-性能优化#1. 性能优化":"","2-自定义渲染#2. 自定义渲染":"","3-网络编程#3. 网络编程":"","4-拆解学习#4. 拆解学习":"本部分介绍 Bevy 的高级功能和优化技巧。\n内容列表 1. 性能优化 性能分析\n性能分析工具 性能瓶颈识别 性能指标 优化技巧\nECS 查询优化 系统调度优化 资源管理优化 渲染优化 内存优化 最佳实践\n避免常见性能问题 性能测试 性能监控 学习目标：能够优化 Bevy 应用的性能\n2. 自定义渲染 渲染管线\n渲染管线概述 自定义渲染管线 渲染阶段（Render Stages） 着色器\n着色器语言（WGSL） 顶点着色器 片段着色器 计算着色器 自定义材质\n材质系统 自定义材质 材质属性 后处理效果\n后处理管线 自定义后处理 常见效果实现 学习目标：能够实现自定义渲染效果\n3. 网络编程 网络基础\n网络架构 客户端-服务器模型 同步机制 实现方法\n网络库选择 消息协议 状态同步 预测与插值 多人游戏\n房间系统 玩家管理 游戏状态同步 学习目标：能够开发多人网络游戏\n4. 拆解学习 深入理解 Bevy\nBevy 内部机制 源码阅读 架构分析 扩展 Bevy\n自定义系统 自定义组件 自定义资源 学习目标：深入理解 Bevy 的内部机制","下一步#下一步":"完成本部分学习后，你已经掌握了 Bevy 的核心功能。建议：\n开始实际项目开发 参与 Bevy 社区 贡献代码和文档 分享你的经验 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"循序渐进：先掌握基础，再学习高级主题 实践为主：通过实际项目应用高级功能 阅读源码：阅读 Bevy 源码加深理解 社区参与：参与 Bevy 社区讨论 注意：插件开发内容已移至 Architecture（架构设计） 部分。","相关资源#相关资源":"Bevy 官方文档 Bevy 源码 Bevy Discord Bevy 插件仓库"},"title":"Advanced（高级主题）"},"/wiki/bevybook/advanced/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/":{"data":{"":"","ecs-查询优化#ECS 查询优化":"优化 ECS 查询以提高性能。\n源代码文件：bevy/examples/stress_tests/many_cubes.rs\n关键信息：\n使用精确的查询过滤器减少查询范围 避免不必要的组件访问 使用并行查询提高性能 合理使用 Changed 过滤器 说明： ECS 查询是性能的关键。通过优化查询，可以减少不必要的组件访问，提高系统执行效率。","什么是性能优化#什么是性能优化？":"性能优化是提高应用运行效率的过程。在 Bevy 中，性能优化涉及多个方面，包括 ECS 查询优化、系统调度优化、渲染优化、内存优化等。\n为什么需要性能优化？\n提高帧率：优化可以提高游戏的帧率，提供更流畅的体验 减少延迟：优化可以减少输入延迟，提高响应性 降低资源消耗：优化可以降低 CPU 和内存使用 支持更大规模：优化可以支持更多实体和更复杂的场景","内存优化#内存优化":"优化内存使用以提高性能。\n关键信息：\n合理使用资源生命周期 及时清理不再使用的资源 使用对象池减少分配 避免不必要的克隆 说明： 内存优化可以减少内存分配和垃圾回收，提高性能。通过合理管理资源生命周期，可以避免内存泄漏。","在游戏开发中的应用场景#在游戏开发中的应用场景":"性能优化在游戏开发中有广泛的应用：\n大规模场景：优化大规模场景的渲染性能 复杂系统：优化复杂系统的执行效率 移动平台：优化移动平台的性能 实时应用：优化实时应用的响应性","基础用法#基础用法":"","大规模实体处理#大规模实体处理":"处理大规模实体以提高性能。\n源代码文件：bevy/examples/stress_tests/bevymark.rs\n代码示例：\nuse bevy::prelude::*; const BIRDS_PER_SECOND: u32 = 10000; fn spawn_birds( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, time: Res\u003cTime\u003e, ) { let bird_count = (BIRDS_PER_SECOND as f32 * time.delta_secs()) as u32; for _ in 0..bird_count { commands.spawn(( Mesh3d(meshes.add(Cuboid::new(0.1, 0.1, 0.1))), MeshMaterial3d(materials.add(Color::srgb(0.5, 0.5, 1.0))), Transform::from_xyz( rand::random::\u003cf32\u003e() * 100.0 - 50.0, rand::random::\u003cf32\u003e() * 100.0 - 50.0, rand::random::\u003cf32\u003e() * 100.0 - 50.0, ), Bird { velocity: Vec3::new( rand::random::\u003cf32\u003e() * 2.0 - 1.0, rand::random::\u003cf32\u003e() * 2.0 - 1.0, rand::random::\u003cf32\u003e() * 2.0 - 1.0, ), }, )); } } 关键要点：\n使用批处理减少绘制调用 使用实例化渲染提高性能 合理使用剔除减少渲染对象 优化实体创建和销毁 说明： 大规模实体处理是性能优化的挑战。通过使用批处理、实例化、剔除等技术，可以支持更多实体。","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何识别性能瓶颈？\n解决方案：使用性能分析工具，如 FrameTimeDiagnosticsPlugin、LogDiagnosticsPlugin，或者使用外部性能分析器。\n问题 2：如何优化 ECS 查询？\n解决方案：使用精确的查询过滤器，避免不必要的组件访问，使用并行查询，合理使用 Changed 过滤器。\n问题 3：如何优化渲染性能？\n解决方案：使用视锥剔除、遮挡剔除、批处理、实例化渲染等技术。","性能优化的核心原则#性能优化的核心原则":"测量优先：在优化之前先测量性能 识别瓶颈：找到真正的性能瓶颈 针对性优化：针对瓶颈进行优化 验证效果：优化后验证效果","性能分析工具#性能分析工具":"使用 Bevy 的诊断插件进行性能分析。\n源代码文件：bevy/examples/stress_tests/bevymark.rs\n代码示例：\nuse bevy::{ diagnostic::{DiagnosticsStore, FrameTimeDiagnosticsPlugin, LogDiagnosticsPlugin}, prelude::*, }; fn main() { App::new() .add_plugins(DefaultPlugins) .add_plugins(FrameTimeDiagnosticsPlugin) .add_plugins(LogDiagnosticsPlugin::default()) .add_systems(Update, print_diagnostics) .run(); } fn print_diagnostics(diagnostics: Res\u003cDiagnosticsStore\u003e) { if let Some(fps) = diagnostics.get(\u0026FrameTimeDiagnosticsPlugin::FPS) { if let Some(value) = fps.smoothed() { println!(\"FPS: {:.2}\", value); } } } 关键要点：\n使用 FrameTimeDiagnosticsPlugin 监控帧率 使用 LogDiagnosticsPlugin 记录诊断信息 使用 DiagnosticsStore 访问诊断数据 可以监控 FPS、帧时间等指标 说明： 性能分析是优化的第一步。通过诊断插件，可以监控应用的性能指标，识别性能瓶颈。","性能考虑#性能考虑":"测量优先：在优化之前先测量性能 识别瓶颈：找到真正的性能瓶颈 针对性优化：针对瓶颈进行优化 验证效果：优化后验证效果","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 性能优化的基本概念 掌握性能分析工具的使用 学会优化 ECS 查询和系统调度 了解渲染优化技巧 掌握内存优化方法 理解大规模实体处理 前置知识要求：\nECS 基础 系统调度基础 渲染基础 资源管理基础","渲染优化#渲染优化":"优化渲染以提高性能。\n源代码文件：bevy/examples/stress_tests/many_cubes.rs\n代码示例：\nuse bevy::{ camera::visibility::{NoCpuCulling, NoFrustumCulling}, render::{ batching::NoAutomaticBatching, view::NoIndirectDrawing, }, prelude::*, }; // 禁用视锥剔除（用于压力测试） commands.spawn(( Camera3d::default(), NoFrustumCulling, NoCpuCulling, )); // 禁用自动批处理（用于压力测试） commands.spawn(( Mesh3d(mesh_handle), MeshMaterial3d(material_handle), NoAutomaticBatching, NoIndirectDrawing, )); 关键要点：\n使用视锥剔除（Frustum Culling）减少渲染对象 使用遮挡剔除（Occlusion Culling）进一步优化 使用批处理（Batching）减少绘制调用 使用实例化渲染（Instancing）提高性能 说明： 渲染优化是性能优化的重要部分。通过使用剔除、批处理、实例化等技术，可以显著提高渲染性能。","相关资源#相关资源":"相关源代码文件：\nbevy/examples/stress_tests/bevymark.rs - 2D 性能测试示例 bevy/examples/stress_tests/many_cubes.rs - 3D 性能测试示例 bevy/examples/stress_tests/many_sprites.rs - 精灵性能测试示例 bevy/examples/stress_tests/README.md - 性能测试说明 官方文档链接：\nBevy 性能优化文档 性能测试示例 进一步学习建议：\n学习自定义渲染，了解如何优化渲染管线 学习大规模实体开发，了解如何处理大规模场景 学习性能分析工具，了解如何识别性能瓶颈 索引：返回上级目录","系统调度优化#系统调度优化":"优化系统调度以提高性能。\n关键信息：\n合理组织系统集（SystemSet） 使用运行条件（Run Conditions）避免不必要的执行 利用并行执行提高性能 避免系统间的数据竞争 说明： 系统调度优化可以提高系统的执行效率。通过合理组织系统，可以充分利用并行执行，提高性能。","自定义批处理#自定义批处理":"实现自定义批处理策略。\n关键信息：\n理解批处理原理 实现自定义批处理逻辑 优化批处理性能 处理批处理边界情况 说明： 自定义批处理可以根据具体需求优化批处理策略，提高性能。","进阶用法#进阶用法":"","高级性能分析#高级性能分析":"使用更高级的性能分析工具。\n关键信息：\n使用性能分析器（如 tracy、puffin） 分析系统执行时间 识别热点函数 优化关键路径 说明： 高级性能分析可以提供更详细的性能信息，帮助识别性能瓶颈。"},"title":"性能优化"},"/wiki/bevybook/advanced/%E6%8B%86%E8%A7%A3%E5%AD%A6%E4%B9%A0/":{"data":{"":"","什么是拆解学习#什么是拆解学习？":"拆解学习是通过阅读和分析 Bevy 源代码，深入理解 Bevy 的内部机制和设计原理。这包括理解架构设计、实现细节、性能优化等。\n为什么需要拆解学习？\n深入理解：深入理解 Bevy 的工作原理 扩展功能：基于 Bevy 扩展自己的功能 性能优化：理解性能优化原理 问题解决：更好地解决遇到的问题","功能扩展#功能扩展":"基于 Bevy 扩展功能。\n关键信息：\n创建自定义插件 实现自定义系统 创建自定义组件和资源 扩展渲染功能 说明： 功能扩展是拆解学习的应用。通过扩展功能，可以深入理解 Bevy 的扩展机制。","在游戏开发中的应用场景#在游戏开发中的应用场景":"拆解学习在游戏开发中有广泛的应用：\n问题调试：通过理解源代码更好地调试问题 功能扩展：基于 Bevy 扩展自己的功能 性能优化：理解性能优化原理，优化自己的应用 学习提升：通过学习 Bevy 的设计提升自己的编程能力","基础用法#基础用法":"","学习建议#学习建议":"循序渐进：从简单到复杂，逐步深入 实践为主：通过实践加深理解 参考文档：参考官方文档和示例 社区参与：参与 Bevy 社区讨论","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何开始阅读 Bevy 源代码？\n解决方案：从 bevy/src/lib.rs 开始，了解整体结构，然后阅读感兴趣的模块。\n问题 2：如何理解 Bevy 的架构设计？\n解决方案：阅读架构文档，分析源代码结构，理解设计思想。\n问题 3：如何基于 Bevy 扩展功能？\n解决方案：创建自定义插件，实现自定义系统，参考 Bevy 的扩展机制。","性能分析#性能分析":"分析性能优化原理。\n关键信息：\n理解 ECS 的性能优化原理 理解渲染性能优化原理 理解内存管理优化原理 理解系统调度优化原理 说明： 性能分析帮助理解 Bevy 的性能优化原理。通过分析性能优化，可以学习如何优化自己的应用。","拆解学习的核心方法#拆解学习的核心方法":"源代码阅读：阅读 Bevy 源代码 架构分析：分析 Bevy 的架构设计 功能扩展：基于 Bevy 扩展功能 性能分析：分析性能优化原理","架构分析#架构分析":"分析 Bevy 的架构设计。\n关键信息：\n理解 ECS 架构的设计和实现 理解渲染管线的设计和实现 理解插件系统的设计和实现 理解资源管理系统的设计和实现 说明： 架构分析帮助理解 Bevy 的整体设计。通过分析架构，可以理解 Bevy 的设计思想和实现原理。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解如何深入理解 Bevy 的内部机制 掌握源代码阅读方法 学会架构分析方法 了解如何扩展 Bevy 功能 理解性能优化原理 前置知识要求：\nBevy 基础 Rust 高级特性 系统编程基础 游戏引擎原理","深入理解-ecs#深入理解 ECS":"深入理解 Bevy ECS 的实现。\n关键信息：\n理解组件存储机制 理解系统调度机制 理解查询优化原理 理解变更检测机制 说明： ECS 是 Bevy 的核心。通过深入理解 ECS 的实现，可以更好地使用和扩展 Bevy。","深入理解插件系统#深入理解插件系统":"深入理解 Bevy 插件系统的实现。\n关键信息：\n理解插件注册机制 理解插件依赖管理 理解插件生命周期 理解插件配置机制 说明： 插件系统是 Bevy 的扩展机制。通过深入理解插件系统的实现，可以更好地创建和使用插件。","深入理解渲染系统#深入理解渲染系统":"深入理解 Bevy 渲染系统的实现。\n关键信息：\n理解渲染管线设计 理解材质系统实现 理解着色器编译流程 理解批处理机制 说明： 渲染系统是 Bevy 的重要组成部分。通过深入理解渲染系统的实现，可以更好地优化渲染性能。","源代码阅读#源代码阅读":"阅读 Bevy 源代码的方法。\n关键信息：\n从 bevy/src/lib.rs 开始，了解 Bevy 的整体结构 阅读各个模块的源代码，理解实现细节 参考示例代码，理解使用方法 阅读文档注释，理解设计思想 说明： 源代码阅读是拆解学习的基础。通过阅读源代码，可以理解 Bevy 的实现细节和设计思想。","相关资源#相关资源":"相关源代码文件：\nbevy/src/lib.rs - Bevy 主库文件 bevy/crates/bevy_ecs/ - ECS 实现 bevy/crates/bevy_render/ - 渲染系统实现 bevy/crates/bevy_app/ - 应用系统实现 官方文档链接：\nBevy 源代码 Bevy 架构文档 Bevy 社区 进一步学习建议：\n阅读 Bevy 源代码，深入理解实现细节 参与 Bevy 社区，学习最佳实践 贡献代码，提升编程能力 学习游戏引擎原理，理解设计思想 索引：返回上级目录","进阶用法#进阶用法":""},"title":"拆解学习"},"/wiki/bevybook/advanced/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/":{"data":{"":"","什么是网络编程#什么是网络编程？":"网络编程是在 Bevy 应用中实现网络通信的功能。Bevy 提供了 RemotePlugin 和 RemoteHttpPlugin，允许通过网络连接远程访问和控制 Bevy 应用。\n为什么需要网络编程？\n远程调试：通过网络远程调试 Bevy 应用 远程控制：通过网络远程控制 Bevy 应用 多人游戏：实现多人游戏功能 工具集成：与外部工具集成","在游戏开发中的应用场景#在游戏开发中的应用场景":"网络编程在游戏开发中有广泛的应用：\n远程调试：通过网络远程调试游戏 远程控制：通过网络远程控制游戏 多人游戏：实现多人游戏功能 工具集成：与外部工具集成","基础用法#基础用法":"","实际应用#实际应用":"","客户端开发#客户端开发":"创建客户端应用。\n源代码文件：bevy/examples/remote/client.rs\n代码示例：\nuse bevy::{ prelude::*, remote::{ builtin_methods::{ BrpQuery, BrpQueryFilter, BrpQueryParams, ComponentSelector, BRP_QUERY_METHOD, }, http::{DEFAULT_ADDR, DEFAULT_PORT}, BrpRequest, }, transform::components::Transform, }; fn main() -\u003e Result\u003c(), anyhow::Error\u003e { let host_part = format!(\"{DEFAULT_ADDR}:{DEFAULT_PORT}\"); let url = format!(\"http://{host_part}/\"); // 查询所有 Transform 组件 run_transform_only_query(\u0026url)?; // 查询根实体 run_query_root_entities(\u0026url)?; // 查询所有组件和实体 run_query_all_components_and_entities(\u0026url)?; Ok(()) } fn run_transform_only_query(url: \u0026str) -\u003e Result\u003c(), anyhow::Error\u003e { let request = BrpRequest { jsonrpc: String::from(\"2.0\"), method: String::from(BRP_QUERY_METHOD), id: Some(serde_json::to_value(1)?), params: Some( serde_json::to_value(BrpQueryParams { data: BrpQuery { components: vec![std::any::type_name::\u003cTransform\u003e().to_string()], ..Default::default() }, strict: false, filter: BrpQueryFilter::default(), })?, ), }; let response = ureq::post(url) .send_json(request)? .body_mut() .read_json::\u003cserde_json::Value\u003e()?; println!(\"Transform query response: {response:#}\"); Ok(()) } 关键要点：\n使用 BrpRequest 创建 JSON-RPC 请求 使用 BrpQuery 查询实体和组件 使用 ComponentSelector 选择组件 通过 HTTP POST 发送请求 说明： 客户端应用通过网络访问服务器端应用。通过 JSON-RPC 协议，可以查询实体、组件、资源等，并可以修改它们。","常见问题#常见问题":"问题 1：如何启用远程功能？\n解决方案：添加 RemotePlugin 和 RemoteHttpPlugin 到应用中，使用 #[derive(Reflect)] 标记可远程访问的类型。\n问题 2：如何查询远程实体？\n解决方案：使用 BrpQuery 创建查询请求，通过 JSON-RPC 协议发送请求。\n问题 3：如何修改远程资源？\n解决方案：使用 BrpRequest 创建修改请求，通过 JSON-RPC 协议发送请求。","性能考虑#性能考虑":"请求频率：减少网络请求频率 批量操作：使用批量查询和操作 缓存：合理使用缓存减少网络请求 序列化：优化序列化性能","服务器端开发#服务器端开发":"创建服务器端应用。\n源代码文件：bevy/examples/remote/server.rs\n代码示例：\nuse bevy::{ prelude::*, remote::{http::RemoteHttpPlugin, RemotePlugin}, }; fn main() { App::new() .add_plugins(DefaultPlugins) .add_plugins(RemotePlugin::default()) .add_plugins(RemoteHttpPlugin::default()) .add_systems(Startup, setup) .add_systems(Update, move_cube) .run(); } fn setup( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { // 创建场景 commands.spawn(( Mesh3d(meshes.add(Cuboid::new(1.0, 1.0, 1.0))), MeshMaterial3d(materials.add(Color::srgb_u8(124, 144, 255))), Transform::from_xyz(0.0, 0.5, 0.0), Cube(1.0), )); // 创建资源（可以被远程访问和修改） commands.insert_resource(TestResource { foo: Vec2::new(1.0, -1.0), bar: false, }); // 创建光照和相机 commands.spawn(( PointLight { shadows_enabled: true, ..default() }, Transform::from_xyz(4.0, 8.0, 4.0), )); commands.spawn(( Camera3d::default(), Transform::from_xyz(-2.5, 4.5, 9.0).looking_at(Vec3::ZERO, Vec3::Y), )); } #[derive(Resource, Reflect, Serialize, Deserialize)] #[reflect(Resource, Serialize, Deserialize)] pub struct TestResource { pub foo: Vec2, pub bar: bool, } #[derive(Component, Reflect, Serialize, Deserialize)] #[reflect(Component, Serialize, Deserialize)] struct Cube(f32); fn move_cube(mut query: Query\u003c\u0026mut Transform, With\u003cCube\u003e\u003e, time: Res\u003cTime\u003e) { for mut transform in \u0026mut query { transform.translation.y = -time.elapsed_secs().cos() + 1.5; } } 关键要点：\n使用 RemotePlugin 启用远程功能 使用 RemoteHttpPlugin 启用 HTTP 接口 使用 #[derive(Reflect, Serialize, Deserialize)] 使资源可远程访问 使用 #[reflect(Resource)] 或 #[reflect(Component)] 标记可远程访问的类型 说明： 服务器端应用提供远程访问接口。通过 RemotePlugin 和 RemoteHttpPlugin，可以启用 HTTP 接口，允许客户端通过网络访问和控制应用。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 网络编程的基本概念 了解 RemotePlugin 的使用 掌握服务器端开发 掌握客户端开发 理解网络同步机制 前置知识要求：\nECS 基础 系统调度基础 HTTP 基础 JSON-RPC 基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/remote/server.rs - 服务器端示例 bevy/examples/remote/client.rs - 客户端示例 官方文档链接：\nBevy Remote 文档 JSON-RPC 规范 远程示例 进一步学习建议：\n学习 JSON-RPC 协议，了解通信机制 学习 Reflect 系统，了解序列化机制 学习网络编程，了解如何实现多人游戏 索引：返回上级目录","网络优化#网络优化":"优化网络性能。\n关键信息：\n减少网络请求频率 使用批量查询减少请求数量 合理使用缓存 优化序列化性能 说明： 网络优化可以提高网络通信的性能。通过减少请求频率、使用批量查询、合理使用缓存等技术，可以显著提高性能。","网络同步机制#网络同步机制":"理解网络同步机制。\n关键信息：\n使用 Reflect trait 使类型可序列化 使用 Serialize 和 Deserialize 进行序列化 通过 JSON-RPC 协议进行通信 支持查询、修改、调用方法等操作 说明： 网络同步机制允许客户端和服务器端同步数据。通过 Reflect、Serialize 和 Deserialize，可以将 Bevy 的类型序列化并通过网络传输。","网络编程的核心组件#网络编程的核心组件":"Bevy 网络编程系统包含以下核心组件：\nRemotePlugin：远程插件，提供基本的远程功能 RemoteHttpPlugin：HTTP 远程插件，提供 HTTP 接口 BRP：Bevy Remote Protocol，Bevy 远程协议 JSON-RPC：JSON-RPC 协议，用于通信","自定义远程方法#自定义远程方法":"实现自定义远程方法。\n关键信息：\n可以定义自定义的远程方法 可以在服务器端实现自定义逻辑 客户端可以调用这些方法 说明： 自定义远程方法允许你实现自己的远程功能。这对于实现特定的网络功能非常有用。","进阶用法#进阶用法":""},"title":"网络编程"},"/wiki/bevybook/advanced/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B8%B2%E6%9F%93/":{"data":{"":"","什么是自定义渲染#什么是自定义渲染？":"自定义渲染是在 Bevy 默认渲染系统基础上，创建自定义的渲染效果。这包括自定义材质、自定义着色器、自定义后处理效果等。\n为什么需要自定义渲染？\n特殊效果：实现默认渲染系统不支持的特殊效果 性能优化：针对特定场景优化渲染性能 艺术风格：实现特定的艺术风格和视觉效果 扩展功能：扩展 Bevy 的渲染功能","在游戏开发中的应用场景#在游戏开发中的应用场景":"自定义渲染在游戏开发中有广泛的应用：\n特殊效果：实现水、火、烟雾等特殊效果 艺术风格：实现卡通、像素等艺术风格 后处理：实现泛光、色差、色调映射等后处理效果 性能优化：针对特定场景优化渲染性能","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何创建自定义材质？\n解决方案：实现 Material trait，使用 ExtractComponent 和 UniformComponentPlugin 将数据传递到 GPU。\n问题 2：如何编写自定义着色器？\n解决方案：使用 WGSL 编写着色器，通过 uniform buffer 访问材质数据，使用 textureSample 采样纹理。\n问题 3：如何实现自定义后处理效果？\n解决方案：使用 ViewNode trait 创建自定义渲染节点，通过 RenderGraph 组织渲染管线。","性能考虑#性能考虑":"着色器优化：优化着色器代码，减少计算量 批处理：使用批处理和实例化减少绘制调用 纹理优化：合理使用纹理格式和大小 渲染目标：减少渲染目标切换","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 渲染系统的基本概念 掌握自定义材质的创建 学会编写自定义着色器（WGSL） 了解自定义后处理效果的实现 理解自定义渲染阶段和实例化 前置知识要求：\n3D 渲染基础 着色器基础 WGSL 语言基础 渲染管线基础","渲染管线优化#渲染管线优化":"优化自定义渲染管线。\n关键信息：\n减少渲染目标切换 优化着色器性能 使用批处理和实例化 合理使用渲染阶段 说明： 渲染管线优化可以提高自定义渲染的性能。通过减少状态切换、优化着色器、使用批处理等技术，可以显著提高性能。","相关资源#相关资源":"相关源代码文件：\nbevy/examples/shader_advanced/custom_post_processing.rs - 自定义后处理示例 bevy/examples/shader_advanced/custom_vertex_attribute.rs - 自定义顶点属性示例 bevy/examples/shader_advanced/custom_shader_instancing.rs - 自定义实例化示例 bevy/examples/shader_advanced/custom_render_phase.rs - 自定义渲染阶段示例 bevy/examples/shader_advanced/specialized_mesh_pipeline.rs - 专用网格管线示例 官方文档链接：\nBevy 渲染系统文档 WGSL 规范 着色器示例 进一步学习建议：\n学习 WGSL 语言，了解着色器编程 学习渲染管线，了解渲染流程 学习性能优化，了解如何优化自定义渲染 索引：返回上级目录","自定义后处理效果#自定义后处理效果":"创建自定义后处理效果。\n源代码文件：bevy/examples/shader_advanced/custom_post_processing.rs\n代码示例：\nuse bevy::{ core_pipeline::core_3d::graph::{Core3d, Node3d}, prelude::*, render::{ render_graph::{RenderGraphContext, RenderLabel, ViewNode, ViewNodeRunner}, render_resource::*, RenderApp, RenderStartup, }, }; #[derive(RenderLabel)] struct PostProcessLabel; struct PostProcessNode; impl ViewNode for PostProcessNode { type ViewQuery = ( \u0026'static ViewTarget, \u0026'static PostProcessSettings, ); fn run( \u0026self, _graph: \u0026mut RenderGraphContext, render_context: \u0026mut RenderContext, (view_target, settings): QueryItem\u003cSelf::ViewQuery\u003e, world: \u0026World, ) -\u003e Result\u003c(), NodeRunError\u003e { // 实现后处理逻辑 Ok(()) } } fn init_post_process_pipeline(mut render_app: ResMut\u003cRenderApp\u003e) { render_app .add_render_graph_node::\u003cViewNodeRunner\u003cPostProcessNode\u003e\u003e( Core3d, PostProcessLabel, ) .add_render_graph_edges( Core3d, ( Node3d::Tonemapping, PostProcessLabel, Node3d::EndMainPassPostProcessing, ), ); } 关键要点：\n使用 ViewNode trait 创建自定义渲染节点 使用 RenderGraph 组织渲染管线 通过 ViewTarget 访问渲染目标 可以读取和写入渲染纹理 说明： 自定义后处理效果允许你在渲染完成后对图像进行处理。通过 ViewNode 和 RenderGraph，可以创建自己的后处理管线。","自定义实例化#自定义实例化":"实现自定义实例化渲染。\n源代码文件：bevy/examples/shader_advanced/custom_shader_instancing.rs\n关键信息：\n使用实例化渲染批量绘制相同对象 通过实例数据传递每个实例的属性 可以显著提高渲染性能 说明： 自定义实例化允许你批量渲染相同对象，每个实例可以有不同的属性。这对于渲染大量相似对象非常有用。","自定义材质#自定义材质":"创建自定义材质。\n源代码文件：bevy/examples/shader_advanced/custom_post_processing.rs\n代码示例：\nuse bevy::{ prelude::*, render::{ extract_component::{ ExtractComponent, ExtractComponentPlugin, UniformComponentPlugin, }, render_resource::*, }, }; #[derive(Component, Clone, Copy)] struct PostProcessSettings { intensity: f32, } impl ExtractComponent for PostProcessSettings { type Query = \u0026'static Self; type Filter = (); type Out = Self; fn extract_component(item: QueryItem\u003cSelf::Query\u003e) -\u003e Option\u003cSelf::Out\u003e { Some(*item) } } fn main() { App::new() .add_plugins(DefaultPlugins) .add_plugins(ExtractComponentPlugin::\u003cPostProcessSettings\u003e::default()) .add_plugins(UniformComponentPlugin::\u003cPostProcessSettings\u003e::default()) .run(); } 关键要点：\n使用 ExtractComponent trait 提取组件到渲染世界 使用 UniformComponentPlugin 将组件数据传递到 GPU 材质数据通过 uniform buffer 传递到着色器 可以在主世界控制材质属性 说明： 自定义材质允许你创建自己的材质类型。通过 ExtractComponent 和 UniformComponentPlugin，可以将主世界的组件数据传递到渲染世界，并在着色器中使用。","自定义渲染的核心组件#自定义渲染的核心组件":"Bevy 自定义渲染系统包含以下核心组件：\nMaterial：材质系统，用于定义材质属性 Shader：着色器，用于定义渲染逻辑 RenderGraph：渲染图，用于组织渲染管线 RenderPhase：渲染阶段，用于组织渲染对象 Instancing：实例化，用于批量渲染","自定义渲染阶段#自定义渲染阶段":"创建自定义渲染阶段。\n源代码文件：bevy/examples/shader_advanced/custom_render_phase.rs\n关键信息：\n使用 RenderPhase 组织渲染对象 可以创建自己的渲染阶段 可以控制渲染顺序和方式 说明： 自定义渲染阶段允许你组织渲染对象，控制渲染顺序和方式。这对于实现复杂的渲染效果非常有用。","自定义着色器wgsl#自定义着色器（WGSL）":"编写自定义着色器。\n源代码文件：bevy/examples/shader_advanced/custom_post_processing.rs\n着色器示例：\n#import bevy_core_pipeline::tonemapping::tone_mapping @group(0) @binding(0) var\u003cuniform\u003e settings: PostProcessSettings; @group(0) @binding(1) var main_texture: texture_2d\u003cf32\u003e; @group(0) @binding(2) var main_texture_sampler: sampler; @fragment fn fragment(in: FragmentInput) -\u003e @location(0) vec4\u003cf32\u003e { let color = textureSample(main_texture, main_texture_sampler, in.uv); let tone_mapped = tone_mapping(color); return vec4\u003cf32\u003e(tone_mapped * settings.intensity, 1.0); } 关键要点：\n使用 WGSL 编写着色器 通过 uniform buffer 访问材质数据 使用 textureSample 采样纹理 可以应用后处理效果 说明： 自定义着色器允许你实现自己的渲染逻辑。Bevy 使用 WGSL 作为着色器语言，支持现代图形 API。","自定义顶点属性#自定义顶点属性":"创建自定义顶点属性。\n源代码文件：bevy/examples/shader_advanced/custom_vertex_attribute.rs\n关键信息：\n使用 MeshVertexAttribute 定义自定义顶点属性 在着色器中访问自定义顶点属性 可以传递额外的顶点数据到着色器 说明： 自定义顶点属性允许你传递额外的顶点数据到着色器。这对于实现特殊效果非常有用。","进阶用法#进阶用法":"","高级着色器技术#高级着色器技术":"使用高级着色器技术。\n关键信息：\n使用计算着色器进行 GPU 计算 使用纹理数组和采样器数组 实现复杂的渲染效果 说明： 高级着色器技术可以让你实现更复杂的渲染效果。通过计算着色器和高级纹理技术，可以实现各种视觉效果。"},"title":"自定义渲染"},"/wiki/bevybook/animation/":{"data":{"":"","1-动画基础#1. 动画基础":"","2-动画进阶#2. 动画进阶":"","3-ui-动画#3. UI 动画":"","4-变形目标#4. 变形目标":"本部分介绍 Bevy 的动画系统，包括动画网格、动画变换、动画图、动画事件等。\n内容列表 1. 动画基础 动画网格（Animated Mesh） 动画变换（Animated Transform） 动画播放器（Animation Player） 动画图（Animation Graph） 学习目标：理解 Bevy 动画系统的基本概念，掌握动画的创建和播放\n2. 动画进阶 动画图（Animation Graph） 动画事件（Animation Events） 动画遮罩（Animation Masks） 缓动函数（Easing Functions） 学习目标：掌握动画的高级功能，包括动画混合、事件处理和遮罩\n3. UI 动画 UI 动画基础 动画 UI 属性 UI 动画示例 学习目标：掌握 UI 动画的创建和使用\n4. 变形目标 变形目标基础 变形目标动画 变形目标示例 学习目标：掌握变形目标动画的创建和使用","下一步#下一步":"完成本部分学习后，建议继续学习：\n3D Graphics（3D 图形） - 深入学习 3D 渲染 Advanced（高级主题） - 深入高级功能 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"循序渐进：从动画基础开始，逐步学习高级功能 实践为主：通过实际项目应用动画功能 理解概念：深入理解动画图、动画事件等核心概念 参考示例：参考 Bevy 官方示例加深理解","相关资源#相关资源":"Bevy 动画系统文档 Bevy 动画示例 Bevy 官方文档"},"title":"Animation（动画系统）"},"/wiki/bevybook/animation/%E5%8A%A8%E7%94%BB%E5%9F%BA%E7%A1%80/":{"data":{"":"","什么是动画系统#什么是动画系统？":"动画系统是 Bevy 中用于创建和播放动画的功能。Bevy 的动画系统支持网格动画、变换动画、UI 动画等多种类型的动画。\n为什么需要动画系统？\n视觉效果：动画可以增强游戏的视觉效果 用户体验：动画可以改善用户体验 游戏性：动画是游戏性的重要组成部分 艺术表现：动画可以增强艺术表现力","动画变换#动画变换":"创建和播放动画变换。\n源代码文件：bevy/examples/animation/animated_transform.rs\n代码示例：\nuse bevy::{ animation::{animated_field, AnimationTarget, AnimationTargetId}, prelude::*, }; fn main() { App::new() .add_plugins(DefaultPlugins) .insert_resource(AmbientLight { color: Color::WHITE, brightness: 150.0, ..default() }) .add_systems(Startup, setup) .run(); } fn setup( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, mut animations: ResMut\u003cAssets\u003cAnimationClip\u003e\u003e, mut graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, ) { // 相机 commands.spawn(( Camera3d::default(), Transform::from_xyz(-2.0, 2.5, 5.0).looking_at(Vec3::ZERO, Vec3::Y), )); // 光源 commands.spawn(( PointLight { intensity: 500_000.0, ..default() }, Transform::from_xyz(0.0, 2.5, 0.0), )); // 让我们使用 `Name` 组件来定位实体。我们可以使用任何我们喜欢的东西， // 但名称很方便。 let planet = Name::new(\"planet\"); let orbit_controller = Name::new(\"orbit_controller\"); let satellite = Name::new(\"satellite\"); // 创建动画 let mut animation = AnimationClip::default(); // 曲线可以修改变换的单个部分：这里，平移。 let planet_animation_target_id = AnimationTargetId::from_name(\u0026planet); animation.add_curve_to_target( planet_animation_target_id, AnimatableCurve::new( animated_field!(Transform::translation), UnevenSampleAutoCurve::new([0.0, 1.0, 2.0, 3.0, 4.0].into_iter().zip([ Vec3::new(1.0, 0.0, 1.0), Vec3::new(-1.0, 0.0, 1.0), Vec3::new(-1.0, 0.0, -1.0), Vec3::new(1.0, 0.0, -1.0), // 如果需要无缝循环，最后一帧应该与第一帧相同 Vec3::new(1.0, 0.0, 1.0), ])) .expect(\"应该能够构建平移曲线，因为我们传入有效的样本\"), ), ); // 或者它可以修改变换的旋转。 // 为了找到要修改的实体，将遍历层次结构，在每个级别查找具有正确名称的实体。 let orbit_controller_animation_target_id = AnimationTargetId::from_names([planet.clone(), orbit_controller.clone()].iter()); animation.add_curve_to_target( orbit_controller_animation_target_id, AnimatableCurve::new( animated_field!(Transform::rotation), UnevenSampleAutoCurve::new([0.0, 1.0, 2.0, 3.0, 4.0].into_iter().zip([ Quat::IDENTITY, Quat::from_axis_angle(Vec3::Y, PI / 2.), Quat::from_axis_angle(Vec3::Y, PI / 2. * 2.), Quat::from_axis_angle(Vec3::Y, PI / 2. * 3.), Quat::IDENTITY, ])) .expect(\"无法构建旋转曲线\"), ), ); // 创建动画图 let (graph, animation_index) = AnimationGraph::from_clip(animations.add(animation)); // 创建动画播放器，并设置为重复播放 let mut player = AnimationPlayer::default(); player.play(animation_index).repeat(); // 创建将被动画化的场景 // 第一个实体是行星 let planet_entity = commands .spawn(( Mesh3d(meshes.add(Sphere::default())), MeshMaterial3d(materials.add(Color::srgb(0.8, 0.7, 0.6))), // 添加动画图和播放器 planet, AnimationGraphHandle(graphs.add(graph)), player, )) .id(); commands.entity(planet_entity).insert(( AnimationTarget { id: planet_animation_target_id, player: planet_entity, }, children![( Transform::default(), Visibility::default(), orbit_controller, AnimationTarget { id: orbit_controller_animation_target_id, player: planet_entity, }, children![( Mesh3d(meshes.add(Cuboid::new(0.5, 0.5, 0.5))), MeshMaterial3d(materials.add(Color::srgb(0.3, 0.9, 0.3))), Transform::from_xyz(1.5, 0.0, 0.0), AnimationTarget { id: satellite_animation_target_id, player: planet_entity, }, satellite, )], )], )); } 关键要点：\n使用 AnimationClip 创建动画片段 使用 AnimatableCurve 创建动画曲线 使用 animated_field! 宏指定动画字段 使用 AnimationTarget 指定动画目标 说明： 动画变换是动画系统的重要功能。通过创建动画曲线，可以动画化实体的变换属性。","动画播放器#动画播放器":"使用动画播放器控制动画播放。\n关键信息：\n使用 AnimationPlayer::play() 播放动画 使用 .repeat() 重复播放动画 使用 .once() 播放一次动画 使用 .pause() 暂停动画 使用 .resume() 恢复动画 说明： 动画播放器是动画系统的核心组件。通过使用动画播放器，可以控制动画的播放状态。","动画系统的核心组件#动画系统的核心组件":"Bevy 动画系统包含以下核心组件：\nAnimationClip：动画片段，包含动画数据 AnimationGraph：动画图，用于组织和管理动画 AnimationPlayer：动画播放器，用于播放动画 AnimationTarget：动画目标，用于指定动画作用的对象","动画网格#动画网格":"创建和播放动画网格。\n源代码文件：bevy/examples/animation/animated_mesh.rs\n代码示例：\nuse bevy::{light::CascadeShadowConfigBuilder, prelude::*, scene::SceneInstanceReady}; // 包含网格和动画的示例资源 const GLTF_PATH: \u0026str = \"models/animated/Fox.glb\"; fn main() { App::new() .insert_resource(AmbientLight { color: Color::WHITE, brightness: 2000., ..default() }) .add_plugins(DefaultPlugins) .add_systems(Startup, setup_mesh_and_animation) .add_systems(Startup, setup_camera_and_environment) .run(); } // 一个存储我们要播放的动画引用的组件。这在我们开始加载网格时创建 // （参见 `setup_mesh_and_animation`），并在网格生成时读取（参见 `play_animation_when_ready`）。 #[derive(Component)] struct AnimationToPlay { graph_handle: Handle\u003cAnimationGraph\u003e, index: AnimationNodeIndex, } fn setup_mesh_and_animation( mut commands: Commands, asset_server: Res\u003cAssetServer\u003e, mut graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, ) { // 创建一个包含单个动画的动画图。我们想要示例资源中的\"run\"动画，其索引为二。 let (graph, index) = AnimationGraph::from_clip( asset_server.load(GltfAssetLabel::Animation(2).from_asset(GLTF_PATH)), ); // 将动画图存储为资源。 let graph_handle = graphs.add(graph); // 创建一个存储我们动画引用的组件。 let animation_to_play = AnimationToPlay { graph_handle, index, }; // 开始将资源作为场景加载，并将其引用存储在 SceneRoot 组件中。 // 此组件将在资源加载后自动生成包含我们网格的场景。 let mesh_scene = SceneRoot(asset_server.load(GltfAssetLabel::Scene(0).from_asset(GLTF_PATH))); // 生成一个包含我们组件的实体，并将其连接到一个观察者， // 该观察者将在场景加载并生成时触发。 commands .spawn((animation_to_play, mesh_scene)) .observe(play_animation_when_ready); } fn play_animation_when_ready( scene_ready: On\u003cSceneInstanceReady\u003e, mut commands: Commands, children: Query\u003c\u0026Children\u003e, animations_to_play: Query\u003c\u0026AnimationToPlay\u003e, mut players: Query\u003c\u0026mut AnimationPlayer\u003e, ) { // 我们在 `setup_mesh_and_animation` 中生成的实体是触发器的目标。 // 首先找到我们添加到该实体的 AnimationToPlay 组件。 if let Ok(animation_to_play) = animations_to_play.get(scene_ready.entity) { // SceneRoot 组件将场景生成为我们实体的子实体的层次结构。 // 由于资源包含蒙皮网格和动画，它还会生成一个动画播放器组件。 // 搜索我们实体的后代以找到动画播放器。 for child in children.iter_descendants(scene_ready.entity) { if let Ok(mut player) = players.get_mut(child) { // 告诉动画播放器开始动画并保持重复播放。 // // 如果你想尝试停止和切换动画，请参阅 `animated_mesh_control.rs` 示例。 player.play(animation_to_play.index).repeat(); // 添加动画图。这只需要执行一次即可将动画播放器连接到网格。 commands .entity(child) .insert(AnimationGraphHandle(animation_to_play.graph_handle.clone())); } } } } 关键要点：\n使用 AnimationGraph::from_clip 从动画片段创建动画图 使用 AnimationPlayer 播放动画 使用 AnimationGraphHandle 将动画图连接到实体 使用 SceneInstanceReady 事件在场景加载后播放动画 说明： 动画网格是动画系统的基础。通过加载包含动画的 glTF 文件，可以创建和播放动画网格。","在游戏开发中的应用场景#在游戏开发中的应用场景":"动画系统在游戏开发中有广泛的应用：\n角色动画：创建角色行走、跑步、跳跃等动画 物体动画：创建物体移动、旋转、缩放等动画 UI 动画：创建 UI 元素的动画效果 特效动画：创建特效的动画效果","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何加载动画网格？\n解决方案：\n使用 AssetServer 加载 glTF 文件 使用 GltfAssetLabel::Animation 加载动画 使用 GltfAssetLabel::Scene 加载场景 使用 SceneInstanceReady 事件在场景加载后播放动画 问题 2：如何创建动画变换？\n解决方案：\n使用 AnimationClip 创建动画片段 使用 AnimatableCurve 创建动画曲线 使用 animated_field! 宏指定动画字段 使用 AnimationTarget 指定动画目标 问题 3：如何控制动画播放？\n解决方案：\n使用 AnimationPlayer::play() 播放动画 使用 .repeat() 重复播放动画 使用 .pause() 暂停动画 使用 .resume() 恢复动画","性能考虑#性能考虑":"动画图：使用动画图组织和管理动画 动画目标：使用动画目标指定动画作用的对象 动画播放器：合理使用动画播放器控制动画播放","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 动画系统的基本概念 掌握动画网格的创建和播放 了解动画变换的使用 学会使用动画播放器和动画图 前置知识要求：\nBevy 快速入门 ECS 基础 3D 开发基础 资源管理基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/animation/animated_mesh.rs - 动画网格示例 bevy/examples/animation/animated_transform.rs - 动画变换示例 官方文档链接：\nBevy 动画系统 Bevy 动画示例 进一步学习建议：\n学习动画进阶，了解动画图、动画事件等高级功能 学习 UI 动画，了解 UI 动画的创建和使用 索引：返回上级目录","进阶用法#进阶用法":""},"title":"动画基础"},"/wiki/bevybook/animation/%E5%8A%A8%E7%94%BB%E8%BF%9B%E9%98%B6/":{"data":{"":"","动态调整动画权重#动态调整动画权重":"在运行时动态调整动画混合权重。\n源代码文件：bevy/examples/animation/animation_graph.rs\n关键信息：\n可以在运行时动态调整混合权重 权重调整会平滑过渡 可以基于游戏状态调整权重 权重总和应该为 1.0 说明： 动态调整动画权重是创建响应式动画的关键。通过根据游戏状态调整权重，可以创建更加动态和交互的动画效果。","动画事件#动画事件":"在动画播放时触发自定义事件。\n源代码文件：bevy/examples/animation/animation_events.rs\n代码示例：\nuse bevy::prelude::*; #[derive(AnimationEvent, Clone)] struct SetMessage { value: String, color: Color, } fn setup( mut commands: Commands, mut animations: ResMut\u003cAssets\u003cAnimationClip\u003e\u003e, mut graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, ) { // 创建动画片段 let mut animation = AnimationClip::default(); animation.set_duration(2.0); // 添加事件 animation.add_event( 0.0, SetMessage { value: \"HELLO\".into(), color: Color::srgb(0.0, 0.5, 1.0), }, ); animation.add_event( 1.0, SetMessage { value: \"BYE\".into(), color: Color::srgb(1.0, 0.0, 0.0), }, ); // 创建动画图 let (graph, animation_index) = AnimationGraph::from_clip(animations.add(animation)); let mut player = AnimationPlayer::default(); player.play(animation_index).repeat(); commands.spawn(( AnimationGraphHandle(graphs.add(graph)), player, )); } // 监听动画事件 fn on_set_message( set_message: On\u003cSetMessage\u003e, text: Single\u003c(\u0026mut Text2d, \u0026mut TextColor), With\u003cMessageText\u003e\u003e, ) { let (mut text, mut color) = text.into_inner(); text.0 = set_message.value.clone(); color.0 = set_message.color; } 关键要点：\n动画事件可以在动画播放的特定时间点触发 需要实现 AnimationEvent trait 可以使用 On 观察者来监听动画事件 事件可以携带自定义数据 说明： 动画事件是同步动画和其他系统的重要机制。通过动画事件，可以在动画播放时触发自定义逻辑，使动画更加交互和动态。","动画事件animation-events#动画事件（Animation Events）":"动画事件允许你在动画播放的特定时间点触发自定义事件。\n为什么需要动画事件？\n同步：可以在动画播放时同步其他系统 交互：可以在动画播放时触发交互 反馈：可以在动画播放时提供反馈 控制：可以更好地控制动画播放流程","动画图#动画图":"创建和使用动画图。\n源代码文件：bevy/examples/animation/animation_graph.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .run(); } fn setup( mut commands: Commands, asset_server: Res\u003cAssetServer\u003e, mut graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, ) { // 加载动画片段 let clip_handle = asset_server.load(\"animations/fox_idle.gltf#Animation0\"); // 从动画片段创建动画图 let (graph, node_index) = AnimationGraph::from_clip(clip_handle); let graph_handle = graphs.add(graph); // 创建动画播放器 let mut player = AnimationPlayer::default(); player.play(node_index).repeat(); // 创建实体并添加动画组件 commands.spawn(( AnimationGraphHandle(graph_handle), player, // ... 其他组件 )); } 关键要点：\n动画图用于组织和管理动画 可以从动画片段创建动画图 动画播放器用于播放动画图中的节点 可以设置动画的重复模式 说明： 动画图是 Bevy 动画系统的核心。它允许你创建复杂的动画混合和过渡，使动画更加灵活和强大。","动画图animation-graph#动画图（Animation Graph）":"动画图是 Bevy 中用于组织和管理动画的图形结构。它允许你创建复杂的动画混合和过渡。\n为什么需要动画图？\n动画混合：可以在多个动画之间进行平滑过渡 动画组织：可以更好地组织和管理复杂的动画 性能优化：可以优化动画播放的性能 灵活性：可以动态调整动画权重","动画图序列化#动画图序列化":"将动画图序列化为文件。\n源代码文件：bevy/examples/animation/animation_graph.rs\n关键信息：\n动画图可以序列化为 RON 格式 可以从文件加载动画图 序列化可以保存复杂的动画配置 可以编辑序列化的动画图 说明： 动画图序列化是保存和加载动画配置的重要功能。通过序列化，可以保存复杂的动画配置，并在需要时加载它们。","动画混合#动画混合":"在多个动画之间进行混合。\n源代码文件：bevy/examples/animation/animation_graph.rs\n代码示例：\nuse bevy::prelude::*; fn setup_animation_graph( mut graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, mut clips: ResMut\u003cAssets\u003cAnimationClip\u003e\u003e, asset_server: Res\u003cAssetServer\u003e, ) { // 加载多个动画片段 let idle_clip = asset_server.load(\"animations/fox_idle.gltf#Animation0\"); let walk_clip = asset_server.load(\"animations/fox_walk.gltf#Animation0\"); let run_clip = asset_server.load(\"animations/fox_run.gltf#Animation0\"); // 创建动画图 let mut graph = AnimationGraph::default(); // 添加动画节点 let idle_node = graph.add_clip(idle_clip); let walk_node = graph.add_clip(walk_clip); let run_node = graph.add_clip(run_clip); // 创建混合节点 let blend_node = graph.add_blend(\"Root\"); // 连接节点 graph.connect(idle_node, blend_node); graph.connect(walk_node, blend_node); graph.connect(run_node, blend_node); // 设置混合权重 graph.set_blend_weight(blend_node, idle_node, 0.5); graph.set_blend_weight(blend_node, walk_node, 0.3); graph.set_blend_weight(blend_node, run_node, 0.2); let graph_handle = graphs.add(graph); // 使用动画图 // ... } 关键要点：\n可以在多个动画之间进行混合 可以设置混合权重来控制混合比例 混合节点用于组合多个动画 可以动态调整混合权重 说明： 动画混合是创建平滑动画过渡的关键。通过混合多个动画，可以创建更加自然和流畅的动画效果。","动画遮罩#动画遮罩":"限制动画的作用范围。\n源代码文件：bevy/examples/animation/animation_masks.rs\n代码示例：\nuse bevy::prelude::*; use std::collections::HashSet; // 定义遮罩组 const MASK_GROUP_HEAD: u32 = 0; const MASK_GROUP_LEFT_ARM: u32 = 1; const MASK_GROUP_RIGHT_ARM: u32 = 2; fn setup_animation_with_mask( mut commands: Commands, mut graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, asset_server: Res\u003cAssetServer\u003e, ) { // 加载动画 let clip_handle = asset_server.load(\"animations/character_walk.gltf#Animation0\"); // 创建动画图 let (graph, node_index) = AnimationGraph::from_clip(clip_handle); // 创建遮罩组 let mut mask_group = HashSet::new(); mask_group.insert(AnimationTargetId::from_name(\u0026Name::new(\"Head\"))); mask_group.insert(AnimationTargetId::from_name(\u0026Name::new(\"Neck\"))); // 应用遮罩 graph.set_mask(node_index, MASK_GROUP_HEAD, mask_group); let graph_handle = graphs.add(graph); let mut player = AnimationPlayer::default(); player.play(node_index).repeat(); commands.spawn(( AnimationGraphHandle(graph_handle), player, )); } 关键要点：\n动画遮罩可以限制动画的作用范围 可以创建多个遮罩组 遮罩组由动画目标 ID 集合定义 可以动态启用或禁用遮罩组 说明： 动画遮罩是创建局部动画的重要工具。通过遮罩，可以对特定部位应用动画，而不会影响其他部位，使动画更加灵活和精细。","动画遮罩animation-masks#动画遮罩（Animation Masks）":"动画遮罩允许你限制动画的作用范围，只对特定的骨骼或目标应用动画。\n为什么需要动画遮罩？\n局部动画：可以对特定部位应用动画 动画组合：可以组合多个局部动画 性能优化：可以减少不必要的动画计算 灵活性：可以更灵活地控制动画","在游戏开发中的应用场景#在游戏开发中的应用场景":"动画进阶功能在游戏开发中有广泛的应用：\n角色动画：使用动画混合创建平滑的角色动画过渡 交互反馈：使用动画事件触发交互反馈 局部动画：使用动画遮罩创建局部动画效果 UI 动画：使用缓动函数创建自然的 UI 动画","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何创建平滑的动画过渡？\n解决方案：使用动画混合和缓动函数。通过混合多个动画并应用缓动函数，可以创建平滑的动画过渡。\n问题 2：如何在动画播放时触发其他系统？\n解决方案：使用动画事件。通过定义自定义动画事件并在动画播放时触发它们，可以同步动画和其他系统。\n问题 3：如何只对特定部位应用动画？\n解决方案：使用动画遮罩。通过创建遮罩组并应用它们，可以限制动画的作用范围。","性能考虑#性能考虑":"动画图优化：尽量减少动画图中的节点数量 遮罩优化：只对需要的部位应用遮罩 事件优化：避免在动画事件中执行耗时操作 缓动函数优化：选择简单的缓动函数以提高性能","核心概念#核心概念":"","概述#概述":"学习目标：\n掌握动画图的创建和使用 理解动画混合的工作原理 学会使用动画事件 了解动画遮罩的使用 掌握缓动函数的使用 前置知识要求：\n动画基础 ECS 基础 3D 开发基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/animation/animation_graph.rs - 动画图示例 bevy/examples/animation/animation_events.rs - 动画事件示例 bevy/examples/animation/animation_masks.rs - 动画遮罩示例 bevy/examples/animation/easing_functions.rs - 缓动函数示例 官方文档链接：\nBevy Animation 官方文档 动画示例 进一步学习建议：\n学习 UI 动画，了解如何对 UI 元素应用动画 学习变形目标，了解如何使用变形目标动画 学习 3D 图形，了解如何将动画应用于 3D 模型 索引：返回上级目录","缓动函数#缓动函数":"使用缓动函数控制动画曲线。\n源代码文件：bevy/examples/animation/easing_functions.rs\n代码示例：\nuse bevy::prelude::*; fn setup_animation_with_easing( mut commands: Commands, mut animations: ResMut\u003cAssets\u003cAnimationClip\u003e\u003e, mut graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, ) { // 创建动画片段 let mut animation = AnimationClip::default(); // 创建缓动曲线 let ease_function = EaseFunction::CubicInOut; // 添加动画曲线（使用缓动函数） animation.add_curve_to_target( target_id, AnimatableCurve::new( animated_field!(Transform::translation), AnimatableKeyframeCurve::new( [0.0, 1.0, 2.0].into_iter().zip([ Vec3::ZERO, Vec3::new(5.0, 0.0, 0.0), Vec3::ZERO, ]), ) .with_easing(ease_function) .expect(\"valid curve\"), ), ); let (graph, node_index) = AnimationGraph::from_clip(animations.add(animation)); let mut player = AnimationPlayer::default(); player.play(node_index).repeat(); commands.spawn(( AnimationGraphHandle(graphs.add(graph)), player, )); } 关键要点：\n缓动函数控制动画的加速和减速曲线 Bevy 提供了多种内置缓动函数 可以在动画曲线上应用缓动函数 缓动函数使动画更加自然 说明： 缓动函数是创建自然动画的关键。通过使用不同的缓动函数，可以创建各种动画效果，从线性到弹性，从平滑到弹跳。","缓动函数easing-functions#缓动函数（Easing Functions）":"缓动函数控制动画的加速和减速曲线，使动画更加自然。\n为什么需要缓动函数？\n自然感：可以使动画更加自然 视觉效果：可以增强视觉效果 用户体验：可以改善用户体验 艺术表现：可以增强艺术表现力","进阶用法#进阶用法":""},"title":"动画进阶"},"/wiki/bevybook/animation/%E5%8F%98%E5%BD%A2%E7%9B%AE%E6%A0%87/":{"data":{"":"","什么是变形目标#什么是变形目标？":"变形目标是 3D 模型中用于创建形状变化的顶点位置集合。通过混合多个变形目标，可以创建各种形状变化效果，如面部表情、肌肉变形等。\n为什么需要变形目标？\n面部表情：可以创建各种面部表情 形状变化：可以创建各种形状变化效果 细节动画：可以创建细节动画效果 性能优化：可以优化动画性能","变形目标与骨骼动画结合#变形目标与骨骼动画结合":"可以将变形目标动画与骨骼动画结合使用。\n源代码文件：bevy/examples/animation/morph_targets.rs\n关键信息：\n变形目标动画可以与骨骼动画同时使用 变形目标通常用于细节动画，而骨骼动画用于主要动画 可以创建复杂的动画组合 性能考虑：变形目标会增加计算开销 说明： 将变形目标动画与骨骼动画结合是创建复杂动画效果的关键。通过结合使用，可以创建更加丰富和详细的动画效果。","变形目标动画#变形目标动画":"创建和播放变形目标动画。\n源代码文件：bevy/examples/animation/morph_targets.rs\n代码示例：\nuse bevy::prelude::*; fn setup( mut commands: Commands, asset_server: Res\u003cAssetServer\u003e, mut graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, ) { // 加载包含变形目标的 GLTF 模型 let gltf_path = \"models/animated/MorphStressTest.gltf\"; // 加载动画片段（包含变形目标动画） let animation_clip = asset_server.load( GltfAssetLabel::Animation(2).from_asset(gltf_path) ); // 创建动画图 let (graph, index) = AnimationGraph::from_clip(animation_clip); let graph_handle = graphs.add(graph); // 创建场景根节点 commands.spawn(( SceneRoot( asset_server.load(GltfAssetLabel::Scene(0).from_asset(gltf_path)) ), AnimationGraphHandle(graph_handle), AnimationPlayer::default().play(index).repeat(), )); } 关键要点：\n变形目标通常存储在 GLTF 模型中 可以从 GLTF 文件加载变形目标动画 变形目标动画使用标准的动画系统 可以设置动画的重复模式 说明： 变形目标动画是创建细节动画的重要工具。通过使用变形目标，可以创建各种形状变化效果，如面部表情、肌肉变形等，而不需要额外的骨骼动画。","变形目标权重#变形目标权重":"控制变形目标的混合权重。\n源代码文件：bevy/examples/animation/morph_targets.rs\n代码示例：\nuse bevy::prelude::*; fn control_morph_weights( mut morph_weights: Query\u003c\u0026mut MorphWeights\u003e, input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, ) { for mut weights in \u0026mut morph_weights { // 设置特定变形目标的权重 if input.just_pressed(KeyCode::Key1) { weights.set_weight(0, 1.0); // 设置第一个变形目标的权重为 1.0 } if input.just_pressed(KeyCode::Key2) { weights.set_weight(1, 1.0); // 设置第二个变形目标的权重为 1.0 } // 重置所有权重 if input.just_pressed(KeyCode::Key0) { weights.clear(); } } } 关键要点：\n可以使用 MorphWeights 组件来控制变形目标权重 权重值通常在 0.0 到 1.0 之间 可以同时设置多个变形目标的权重 权重控制变形目标的混合比例 说明： 控制变形目标权重是创建变形效果的关键。通过调整权重，可以控制不同变形目标的混合比例，创建各种形状变化效果。","变形目标的核心组件#变形目标的核心组件":"Bevy 变形目标动画包含以下核心组件：\nMorphTargets：变形目标集合，包含多个变形目标 MorphWeights：变形权重，控制变形目标的混合比例 AnimationClip：动画片段，包含变形目标动画数据 AnimationGraph：动画图，用于组织和管理变形目标动画","在游戏开发中的应用场景#在游戏开发中的应用场景":"变形目标在游戏开发中有广泛的应用：\n面部表情：创建角色的各种面部表情 肌肉变形：创建肌肉的变形效果 细节动画：创建细节动画效果，如布料变形 形状变化：创建各种形状变化效果","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何创建变形目标？\n解决方案：变形目标通常在 3D 建模软件中创建，然后导出为 GLTF 格式。Bevy 支持从 GLTF 文件加载变形目标。\n问题 2：如何控制变形目标的混合？\n解决方案：使用 MorphWeights 组件来控制变形目标权重。可以通过动画系统或直接设置权重来控制混合。\n问题 3：变形目标会影响性能吗？\n解决方案：变形目标会增加计算开销，特别是当有多个变形目标时。应该合理使用变形目标，避免过度使用。","性能考虑#性能考虑":"变形目标数量：尽量减少变形目标的数量 权重计算：优化权重计算以提高性能 动画优化：使用动画图来组织和管理变形目标动画 LOD 系统：在远距离时可以减少变形目标的使用","核心概念#核心概念":"","概述#概述":"学习目标：\n理解变形目标的基本概念 掌握变形目标动画的创建和使用 学会读取变形目标名称 了解变形目标的应用场景 前置知识要求：\n动画基础 3D 开发基础 资源管理基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/animation/morph_targets.rs - 变形目标示例 官方文档链接：\nBevy Animation 官方文档 变形目标示例 进一步学习建议：\n学习动画基础，了解动画系统的基本使用 学习 3D 开发，了解如何加载和使用 3D 模型 学习动画进阶，了解动画图和动画混合 索引：返回上级目录","程序化创建变形目标动画#程序化创建变形目标动画":"可以程序化创建变形目标动画。\n源代码文件：bevy/examples/animation/morph_targets.rs\n关键信息：\n可以程序化创建变形目标动画曲线 可以使用 AnimatableCurve 来定义变形目标权重随时间的变化 可以组合多个变形目标动画 可以使用动画图来组织复杂的变形目标动画 说明： 程序化创建变形目标动画是创建动态变形效果的关键。通过程序化创建动画，可以根据游戏状态动态调整变形目标，创建更加动态和交互的变形效果。","读取变形目标名称#读取变形目标名称":"读取网格的变形目标名称。\n源代码文件：bevy/examples/animation/morph_targets.rs\n代码示例：\nuse bevy::prelude::*; fn name_morphs( asset_server: Res\u003cAssetServer\u003e, mut events: MessageReader\u003cAssetEvent\u003cMesh\u003e\u003e, meshes: Res\u003cAssets\u003cMesh\u003e\u003e, ) { for event in events.read() { if let AssetEvent::\u003cMesh\u003e::Added { id } = event \u0026\u0026 let Some(path) = asset_server.get_path(*id) \u0026\u0026 let Some(mesh) = meshes.get(*id) \u0026\u0026 let Some(names) = mesh.morph_target_names() { info!(\"Morph target names for {path:?}:\"); for name in names { info!(\" {name}\"); } } } } 关键要点：\n可以使用 mesh.morph_target_names() 来获取变形目标名称 变形目标名称通常在 GLTF 文件中定义 可以通过名称来识别和操作特定的变形目标 变形目标名称对于调试和开发很有用 说明： 读取变形目标名称是了解和使用变形目标的重要步骤。通过读取名称，可以识别模型中的变形目标，并在代码中引用它们。","进阶用法#进阶用法":""},"title":"变形目标（Morph Targets）"},"/wiki/bevybook/animation/ui%E5%8A%A8%E7%94%BB/":{"data":{"":"","ui-动画的核心组件#UI 动画的核心组件":"Bevy UI 动画包含以下核心组件：\nAnimationClip：动画片段，包含 UI 属性动画数据 AnimationGraph：动画图，用于组织和管理 UI 动画 AnimationPlayer：动画播放器，用于播放 UI 动画 AnimationTarget：动画目标，用于指定动画作用的 UI 元素","ui-属性动画#UI 属性动画":"对 UI 属性（如字体大小）进行动画处理。\n源代码文件：bevy/examples/animation/animated_ui.rs\n代码示例：\nuse bevy::prelude::*; fn setup( mut commands: Commands, mut animation_graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, mut animation_clips: ResMut\u003cAssets\u003cAnimationClip\u003e\u003e, ) { // 创建动画目标 ID let animation_target_name = Name::new(\"Text\"); let animation_target_id = AnimationTargetId::from_name(\u0026animation_target_name); // 创建动画片段 let mut animation_clip = AnimationClip::default(); // 创建字体大小动画曲线 animation_clip.add_curve_to_target( animation_target_id, AnimatableCurve::new( animated_field!(TextFont::font_size), AnimatableKeyframeCurve::new( [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0] .into_iter() .zip([24.0, 80.0, 24.0, 80.0, 24.0, 80.0, 24.0]), ) .expect(\"valid curve\"), ), ); // 保存动画片段 let animation_clip_handle = animation_clips.add(animation_clip); // 创建动画图 let (animation_graph, animation_node_index) = AnimationGraph::from_clip(animation_clip_handle); let animation_graph_handle = animation_graphs.add(animation_graph); // 创建文本实体 commands.spawn(( Text::default(), TextFont { font_size: 24.0, ..default() }, animation_target_name, AnimationGraphHandle(animation_graph_handle), AnimationPlayer::default().play(animation_node_index).repeat(), )); } 关键要点：\n可以使用 animated_field! 宏来指定要动画的属性 需要为 UI 元素设置名称以作为动画目标 动画曲线定义属性值随时间的变化 可以设置动画的重复模式 说明： UI 属性动画是创建动态用户界面的重要工具。通过对 UI 属性进行动画处理，可以创建各种视觉效果，如字体大小的变化、颜色的渐变等。","什么是-ui-动画#什么是 UI 动画？":"UI 动画是对用户界面元素进行动画处理的功能。Bevy 支持对 UI 属性（如字体大小、颜色等）进行动画处理。\n为什么需要 UI 动画？\n用户体验：动画可以改善用户体验 视觉反馈：动画可以提供视觉反馈 交互性：动画可以增强交互性 艺术表现：动画可以增强艺术表现力","响应式-ui-动画#响应式 UI 动画":"可以根据用户交互触发 UI 动画。\n源代码文件：bevy/examples/animation/animated_ui.rs\n关键信息：\n可以在用户交互时触发动画 可以使用动画事件来同步动画和交互 可以根据游戏状态调整动画 可以动态创建和销毁动画 说明： 响应式 UI 动画是创建交互式用户界面的关键。通过根据用户交互触发动画，可以创建更加动态和交互的用户界面。","在游戏开发中的应用场景#在游戏开发中的应用场景":"UI 动画在游戏开发中有广泛的应用：\n按钮动画：对按钮进行悬停、点击等动画处理 文本动画：对文本进行闪烁、渐变等动画处理 菜单动画：对菜单进行展开、收起等动画处理 提示动画：对提示信息进行出现、消失等动画处理","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何创建平滑的 UI 动画？\n解决方案：使用缓动函数。通过应用缓动函数，可以创建平滑的 UI 动画过渡。\n问题 2：如何同时动画多个 UI 属性？\n解决方案：在同一个动画片段中添加多个属性动画曲线。所有曲线应该有相同的时间范围。\n问题 3：如何根据用户交互触发动画？\n解决方案：在交互系统中触发动画播放。可以使用 AnimationPlayer 的 play() 方法来播放动画。","性能考虑#性能考虑":"动画数量：尽量减少同时播放的动画数量 属性选择：只对需要的属性进行动画处理 缓动函数：选择简单的缓动函数以提高性能 动画图优化：使用动画图来组织和管理动画","文本动画#文本动画":"对文本进行动画处理。\n源代码文件：bevy/examples/animation/animated_ui.rs\n代码示例：\nuse bevy::prelude::*; fn setup_text_animation( mut commands: Commands, mut animation_graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, mut animation_clips: ResMut\u003cAssets\u003cAnimationClip\u003e\u003e, ) { let animation_target_name = Name::new(\"Text\"); let animation_target_id = AnimationTargetId::from_name(\u0026animation_target_name); let mut animation_clip = AnimationClip::default(); // 创建字体大小动画 animation_clip.add_curve_to_target( animation_target_id, AnimatableCurve::new( animated_field!(TextFont::font_size), AnimatableKeyframeCurve::new( [0.0, 1.0, 2.0].into_iter().zip([24.0, 48.0, 24.0]), ) .expect(\"valid curve\"), ), ); // 创建文本颜色动画 animation_clip.add_curve_to_target( animation_target_id, AnimatableCurve::new( TextColorProperty, AnimatableKeyframeCurve::new( [0.0, 1.0, 2.0].into_iter().zip([ Srgba::RED, Srgba::GREEN, Srgba::BLUE, ]), ) .expect(\"valid curve\"), ), ); let animation_clip_handle = animation_clips.add(animation_clip); let (animation_graph, animation_node_index) = AnimationGraph::from_clip(animation_clip_handle); let animation_graph_handle = animation_graphs.add(animation_graph); commands.spawn(( Text::default(), TextFont { font_size: 24.0, ..default() }, TextColor(Srgba::RED), animation_target_name, AnimationGraphHandle(animation_graph_handle), AnimationPlayer::default().play(animation_node_index).repeat(), )); } 关键要点：\n可以对文本的多个属性进行动画处理 可以使用 TextColorProperty 来动画文本颜色 所有动画曲线应该有相同的时间范围 可以组合多个属性动画 说明： 文本动画是创建动态文本效果的重要工具。通过对文本的字体大小、颜色等属性进行动画处理，可以创建各种视觉效果，如闪烁、渐变、缩放等。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 UI 动画的基本概念 掌握 UI 属性动画的创建和使用 学会对文本进行动画处理 了解颜色动画的使用 前置知识要求：\n动画基础 UI 基础 ECS 基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/animation/animated_ui.rs - UI 动画示例 官方文档链接：\nBevy Animation 官方文档 UI 动画示例 进一步学习建议：\n学习动画进阶，了解动画图和动画混合 学习 UI 基础，了解 UI 系统的使用 学习动画事件，了解如何在动画中触发事件 索引：返回上级目录","组合多个-ui-动画#组合多个 UI 动画":"可以组合多个 UI 属性动画来创建复杂的动画效果。\n源代码文件：bevy/examples/animation/animated_ui.rs\n关键信息：\n可以在同一个动画片段中添加多个属性动画 所有动画曲线应该有相同的时间范围 可以同时动画多个 UI 元素 可以使用动画图来组织复杂的动画 说明： 组合多个 UI 动画是创建复杂动画效果的关键。通过组合多个属性动画，可以创建各种视觉效果，如同时改变字体大小和颜色、同时动画多个 UI 元素等。","进阶用法#进阶用法":"","颜色动画#颜色动画":"对 UI 元素的颜色进行动画处理。\n源代码文件：bevy/examples/animation/animated_ui.rs\n代码示例：\nuse bevy::prelude::*; fn setup_color_animation( mut commands: Commands, mut animation_graphs: ResMut\u003cAssets\u003cAnimationGraph\u003e\u003e, mut animation_clips: ResMut\u003cAssets\u003cAnimationClip\u003e\u003e, ) { let animation_target_name = Name::new(\"Button\"); let animation_target_id = AnimationTargetId::from_name(\u0026animation_target_name); let mut animation_clip = AnimationClip::default(); // 创建背景颜色动画 animation_clip.add_curve_to_target( animation_target_id, AnimatableCurve::new( BackgroundColorProperty, AnimatableKeyframeCurve::new( [0.0, 1.0, 2.0].into_iter().zip([ Srgba::RED, Srgba::GREEN, Srgba::BLUE, ]), ) .expect(\"valid curve\"), ), ); let animation_clip_handle = animation_clips.add(animation_clip); let (animation_graph, animation_node_index) = AnimationGraph::from_clip(animation_clip_handle); let animation_graph_handle = animation_graphs.add(animation_graph); commands.spawn(( Node::default(), BackgroundColor(Srgba::RED), animation_target_name, AnimationGraphHandle(animation_graph_handle), AnimationPlayer::default().play(animation_node_index).repeat(), )); } 关键要点：\n可以对 UI 元素的背景颜色进行动画处理 可以使用 BackgroundColorProperty 来动画背景颜色 颜色值使用 Srgba 类型 可以创建平滑的颜色过渡 说明： 颜色动画是创建动态 UI 效果的重要工具。通过对 UI 元素的颜色进行动画处理，可以创建各种视觉效果，如颜色渐变、闪烁、脉冲等。"},"title":"UI 动画"},"/wiki/bevybook/architecture/":{"data":{"":"","1-代码组织#1. 代码组织":"","2-逻辑-渲染分离#2. 逻辑-渲染分离":"","3-插件系统#3. 插件系统":"本部分介绍如何组织和架构大型 Bevy 项目。\n内容列表 1. 代码组织 项目结构\n模块化设计 文件组织 命名规范 代码分层 插件系统\n创建插件 插件组织 插件依赖 插件配置 状态管理\nAppState 模式 状态转换 状态清理 状态持久化 学习目标：能够组织大型项目的代码结构\n2. 逻辑-渲染分离 架构概述\nMainWorld 与 RenderApp ExtractSchedule 数据流向 Headless 模式 无渲染模式 实现方法\n逻辑组件设计 渲染组件设计 数据提取 同步机制 最佳实践\n性能优化 代码组织 常见问题 学习目标：理解并实现逻辑-渲染分离架构\n3. 插件系统 插件基础\n创建插件 插件注册 插件配置 插件组\n创建插件组 插件组织 插件依赖 高级功能\n插件依赖管理 条件插件 插件生命周期 学习目标：能够创建和管理 Bevy 插件","下一步#下一步":"完成本部分学习后，建议继续学习：\nAdvanced（高级主题） - 深入高级功能和优化 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"模块化思维：将项目拆分为独立的模块 可维护性：编写易于维护和扩展的代码 性能考虑：在架构设计时考虑性能影响 团队协作：考虑多人协作的代码组织","相关资源#相关资源":"Bevy 插件系统 Bevy 状态管理 架构示例"},"title":"Architecture（架构设计）"},"/wiki/bevybook/architecture/%E4%BB%A3%E7%A0%81%E7%BB%84%E7%BB%87/":{"data":{"1-功能模块模式#1. 功能模块模式":"// 每个功能一个模块 mod player { pub struct PlayerPlugin; impl Plugin for PlayerPlugin { /* ... */ } } mod enemy { pub struct EnemyPlugin; impl Plugin for EnemyPlugin { /* ... */ } } // 主插件组合所有功能 pub struct GamePlugin; impl Plugin for GamePlugin { fn build(\u0026self, app: \u0026mut App) { app.add_plugins(( player::PlayerPlugin, enemy::EnemyPlugin, )); } }","1-模块组织#1. 模块组织":"按功能划分模块，而不是按类型 使用清晰的模块层次结构 在模块根文件中重新导出常用类型 避免过深的模块嵌套","2-分层架构模式#2. 分层架构模式":"// 数据层 mod data { mod components; mod resources; } // 逻辑层 mod logic { mod systems; mod events; } // 表现层 mod presentation { mod ui; mod rendering; }","2-插件设计#2. 插件设计":"每个主要功能创建一个插件 使用配置结构体自定义插件行为 实现插件依赖管理 使用条件编译控制插件功能","3-bundle设计#3. Bundle设计":"将经常一起使用的组件组合成Bundle 提供便捷的构造方法 支持参数化配置 使用组合模式构建复杂Bundle","3-特性模块模式#3. 特性模块模式":"// 核心功能 mod core { pub struct CorePlugin; } // 可选功能 #[cfg(feature = \"debug\")] mod debug { pub struct DebugPlugin; } #[cfg(feature = \"networking\")] mod networking { pub struct NetworkingPlugin; } 通过合理的代码组织，您可以构建出可维护、可扩展、高性能的Bevy游戏项目。记住，好的代码组织不仅能提高开发效率，还能让团队协作更加顺畅。","4-系统集管理#4. 系统集管理":"使用系统集组织相关系统 明确定义系统执行顺序 使用条件系统集控制执行 避免系统集之间的循环依赖","5-代码组织原则#5. 代码组织原则":"单一职责: 每个模块、插件、系统只负责一个功能 开闭原则: 对扩展开放，对修改封闭 依赖倒置: 依赖抽象而不是具体实现 接口隔离: 提供小而专注的接口","6-性能考虑#6. 性能考虑":"合理使用系统集避免不必要的系统执行 使用Bundle减少实体创建开销 避免在插件初始化时进行复杂计算 使用条件系统减少运行时开销","bevy-代码组织指南#Bevy 代码组织指南":"Bevy 代码组织指南本指南介绍Bevy引擎中推荐的代码组织方式，帮助您构建可维护、可扩展的游戏项目。","bundle-组件集合#Bundle 组件集合":"","bundle基础#Bundle基础":"Bundle是组件的集合，用于一次性添加多个相关组件：\n#[derive(Bundle)] struct PlayerBundle { player: Player, health: Health, transform: Transform, sprite: Sprite, collider: Collider, } impl Default for PlayerBundle { fn default() -\u003e Self { Self { player: Player, health: Health::new(100.0), transform: Transform::from_xyz(0.0, 0.0, 0.0), sprite: Sprite::new(Vec2::new(32.0, 32.0)), collider: Collider::circle(16.0), } } }","rust模块基础#Rust模块基础":"Rust的模块系统是代码组织的基础，在Bevy项目中尤为重要：\n// lib.rs 或 main.rs mod player; mod enemy; mod ui; mod systems; mod resources; // 重新导出常用类型 pub use player::PlayerPlugin; pub use enemy::EnemyPlugin; pub use ui::UiPlugin;","主入口文件#主入口文件":"// main.rs use bevy::prelude::*; use game::GamePlugin; fn main() { App::new() .add_plugins(DefaultPlugins) .add_plugins(GamePlugin) .run(); }","动态bundle#动态Bundle":"fn spawn_player( mut commands: Commands, asset_server: Res\u003cAssetServer\u003e, mut materials: ResMut\u003cAssets\u003cColorMaterial\u003e\u003e, ) { let mut bundle = PlayerBundle::default(); // 根据配置动态修改 if let Some(texture) = asset_server.get_handle(\"player.png\") { bundle.sprite = Sprite::new(Vec2::new(64.0, 64.0)); bundle.material = materials.add(ColorMaterial::from(texture)); } commands.spawn(bundle); }","动态系统集#动态系统集":"#[derive(SystemSet, Debug, Hash, PartialEq, Eq, Clone)] enum GameState { Menu, Playing, Paused, GameOver, } fn main() { App::new() .add_plugins(DefaultPlugins) .add_state::\u003cGameState\u003e() .add_systems(Update, ( menu_system.run_if(in_state(GameState::Menu)), game_system.run_if(in_state(GameState::Playing)), pause_system.run_if(in_state(GameState::Paused)), game_over_system.run_if(in_state(GameState::GameOver)), )) .run(); }","参数化bundle#参数化Bundle":"#[derive(Bundle)] struct PlayerBundle { player: Player, health: Health, transform: Transform, sprite: Sprite, collider: Collider, } impl PlayerBundle { pub fn new(position: Vec3, health: f32) -\u003e Self { Self { player: Player, health: Health::new(health), transform: Transform::from_translation(position), sprite: Sprite::new(Vec2::new(32.0, 32.0)), collider: Collider::circle(16.0), } } pub fn with_sprite(mut self, size: Vec2) -\u003e Self { self.sprite = Sprite::new(size); self } pub fn with_collider(mut self, radius: f32) -\u003e Self { self.collider = Collider::circle(radius); self } }","完整的项目结构示例#完整的项目结构示例":"","常见模式#常见模式":"","按功能组织模块#按功能组织模块":"// player/mod.rs mod components; mod systems; mod resources; pub use components::*; pub use systems::*; pub use resources::*; pub struct PlayerPlugin; impl Plugin for PlayerPlugin { fn build(\u0026self, app: \u0026mut App) { app.add_systems(Startup, systems::spawn_player) .add_systems(Update, systems::player_movement); } }","按层级组织模块#按层级组织模块":"// 游戏逻辑层 mod game { mod player; mod enemy; mod combat; } // 系统层 mod systems { mod movement; mod collision; mod rendering; } // 资源层 mod resources { mod assets; mod config; mod state; }","插件-plugin-系统#插件 (Plugin) 系统":"","插件依赖管理#插件依赖管理":"pub struct CombatPlugin; impl Plugin for CombatPlugin { fn build(\u0026self, app: \u0026mut App) { // 确保依赖的插件已经添加 if !app.is_plugin_added::\u003cPlayerPlugin\u003e() { app.add_plugins(PlayerPlugin); } app.add_systems(Update, combat_system); } }","插件基础#插件基础":"插件是Bevy中最重要的代码组织方式，将相关功能打包成可重用的单元：\nuse bevy::prelude::*; pub struct GamePlugin; impl Plugin for GamePlugin { fn build(\u0026self, app: \u0026mut App) { app // 添加子插件 .add_plugins(( PlayerPlugin, EnemyPlugin, UiPlugin, )) // 添加资源 .init_resource::\u003cGameState\u003e() .insert_resource(GameConfig::default()) // 添加事件 .add_event::\u003cPlayerDied\u003e() .add_event::\u003cEnemySpawned\u003e() // 添加系统 .add_systems(Startup, setup_game) .add_systems(Update, game_loop); } }","插件配置#插件配置":"通过配置结构体自定义插件行为：\n#[derive(Resource)] pub struct PlayerConfig { pub speed: f32, pub health: f32, pub spawn_position: Vec3, } impl Default for PlayerConfig { fn default() -\u003e Self { Self { speed: 5.0, health: 100.0, spawn_position: Vec3::ZERO, } } } pub struct PlayerPlugin { config: PlayerConfig, } impl PlayerPlugin { pub fn new(config: PlayerConfig) -\u003e Self { Self { config } } pub fn with_speed(mut self, speed: f32) -\u003e Self { self.config.speed = speed; self } } impl Plugin for PlayerPlugin { fn build(\u0026self, app: \u0026mut App) { app.insert_resource(self.config.clone()) .add_systems(Startup, spawn_player) .add_systems(Update, player_movement); } } // 使用 fn main() { App::new() .add_plugins(DefaultPlugins) .add_plugins(PlayerPlugin::new(PlayerConfig { speed: 10.0, health: 150.0, spawn_position: Vec3::new(0.0, 0.0, 0.0), })) .run(); }","最佳实践#最佳实践":"","条件插件#条件插件":"根据配置或环境决定是否启用插件：\npub struct DebugPlugin; impl Plugin for DebugPlugin { fn build(\u0026self, app: \u0026mut App) { #[cfg(debug_assertions)] { app.add_systems(Update, debug_system); } } } // 或者使用特性标志 #[cfg(feature = \"debug\")] pub struct DebugPlugin; impl Plugin for DebugPlugin { fn build(\u0026self, app: \u0026mut App) { app.add_systems(Update, debug_system); } }","条件系统集#条件系统集":"#[derive(SystemSet, Debug, Hash, PartialEq, Eq, Clone)] enum GameSet { Input, Movement, Combat, Rendering, } #[derive(SystemSet, Debug, Hash, PartialEq, Eq, Clone)] enum PauseSet { Paused, Unpaused, } fn main() { App::new() .add_plugins(DefaultPlugins) .configure_sets(Update, ( GameSet::Input, GameSet::Movement, GameSet::Combat, GameSet::Rendering, ).chain()) .configure_sets(Update, ( PauseSet::Paused, PauseSet::Unpaused, ).chain()) .add_systems(Update, ( handle_input.in_set(GameSet::Input), player_movement.in_set((GameSet::Movement, PauseSet::Unpaused)), pause_menu.in_set((GameSet::Input, PauseSet::Paused)), )) .run(); }","模块-module-组织#模块 (Module) 组织":"","游戏模块#游戏模块":"// game/mod.rs mod player; mod enemy; mod combat; pub use player::PlayerPlugin; pub use enemy::EnemyPlugin; pub use combat::CombatPlugin; pub struct GamePlugin; impl Plugin for GamePlugin { fn build(\u0026self, app: \u0026mut App) { app.add_plugins(( PlayerPlugin, EnemyPlugin, CombatPlugin, )) .add_systems(Startup, setup_game) .add_systems(Update, game_loop); } } fn setup_game(mut commands: Commands) { // 游戏初始化逻辑 } fn game_loop() { // 游戏主循环逻辑 }","玩家模块#玩家模块":"// game/player/mod.rs mod components; mod systems; mod resources; pub use components::*; pub use systems::*; pub use resources::*; pub struct PlayerPlugin; impl Plugin for PlayerPlugin { fn build(\u0026self, app: \u0026mut App) { app.init_resource::\u003cPlayerConfig\u003e() .add_systems(Startup, spawn_player) .add_systems(Update, ( player_movement, player_animation, player_health, )); } } // game/player/components.rs use bevy::prelude::*; #[derive(Component)] pub struct Player; #[derive(Component)] pub struct PlayerHealth { pub current: f32, pub maximum: f32, } #[derive(Bundle)] pub struct PlayerBundle { pub player: Player, pub health: PlayerHealth, pub transform: Transform, pub sprite: Sprite, } // game/player/systems.rs use bevy::prelude::*; use super::components::*; pub fn spawn_player(mut commands: Commands) { commands.spawn(PlayerBundle { player: Player, health: PlayerHealth { current: 100.0, maximum: 100.0, }, transform: Transform::from_xyz(0.0, 0.0, 0.0), sprite: Sprite::new(Vec2::new(32.0, 32.0)), }); } pub fn player_movement( keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, mut query: Query\u003c\u0026mut Transform, With\u003cPlayer\u003e\u003e, ) { for mut transform in \u0026mut query { if keyboard_input.pressed(KeyCode::KeyW) { transform.translation.y += 1.0; } if keyboard_input.pressed(KeyCode::KeyS) { transform.translation.y -= 1.0; } if keyboard_input.pressed(KeyCode::KeyA) { transform.translation.x -= 1.0; } if keyboard_input.pressed(KeyCode::KeyD) { transform.translation.x += 1.0; } } }","目录结构#目录结构":"src/ ├── main.rs ├── lib.rs ├── game/ │ ├── mod.rs │ ├── player/ │ │ ├── mod.rs │ │ ├── components.rs │ │ ├── systems.rs │ │ ├── resources.rs │ │ └── plugin.rs │ ├── enemy/ │ │ ├── mod.rs │ │ ├── components.rs │ │ ├── systems.rs │ │ └── plugin.rs │ └── combat/ │ ├── mod.rs │ ├── components.rs │ ├── systems.rs │ └── plugin.rs ├── systems/ │ ├── mod.rs │ ├── movement.rs │ ├── collision.rs │ └── rendering.rs ├── resources/ │ ├── mod.rs │ ├── assets.rs │ ├── config.rs │ └── state.rs └── ui/ ├── mod.rs ├── components.rs ├── systems.rs └── plugin.rs","系统集-systemset#系统集 (SystemSet)":"","系统集基础#系统集基础":"系统集用于组织和排序相关的系统：\n#[derive(SystemSet, Debug, Hash, PartialEq, Eq, Clone)] enum GameSet { Input, Movement, Combat, Rendering, } fn main() { App::new() .add_plugins(DefaultPlugins) .configure_sets(Update, ( GameSet::Input, GameSet::Movement, GameSet::Combat, GameSet::Rendering, ).chain()) .add_systems(Update, ( handle_input.in_set(GameSet::Input), player_movement.in_set(GameSet::Movement), enemy_movement.in_set(GameSet::Movement), combat_system.in_set(GameSet::Combat), render_system.in_set(GameSet::Rendering), )) .run(); }","组合bundle#组合Bundle":"#[derive(Bundle)] struct PhysicsBundle { transform: Transform, velocity: Velocity, collider: Collider, } #[derive(Bundle)] struct RenderBundle { sprite: Sprite, material: Handle\u003cColorMaterial\u003e, } #[derive(Bundle)] struct PlayerBundle { #[bundle] physics: PhysicsBundle, #[bundle] render: RenderBundle, player: Player, health: Health, } // 使用 commands.spawn(PlayerBundle { physics: PhysicsBundle { transform: Transform::from_xyz(0.0, 0.0, 0.0), velocity: Velocity::default(), collider: Collider::circle(16.0), }, render: RenderBundle { sprite: Sprite::new(Vec2::new(32.0, 32.0)), material: materials.add(Color::RED), }, player: Player, health: Health::new(100.0), });"},"title":"代码组织"},"/wiki/bevybook/architecture/%E9%80%BB%E8%BE%91-%E6%B8%B2%E6%9F%93%E5%88%86%E7%A6%BB/":{"data":{"":"","extractschedule#ExtractSchedule":"使用 ExtractSchedule 同步数据。\n关键信息：\nExtractSchedule 在每帧开始时运行 从 MainWorld 提取数据到 RenderApp 可以提取组件、资源等数据 数据同步是单向的（MainWorld → RenderApp） 说明： ExtractSchedule 是逻辑-渲染分离的关键。通过 ExtractSchedule，可以将游戏逻辑数据同步到渲染世界，供渲染使用。","headless-模式#Headless 模式":"使用 Headless 模式运行无窗口应用。\n源代码文件：bevy/examples/app/headless.rs\n代码示例：\nuse bevy::{app::ScheduleRunnerPlugin, log::LogPlugin, prelude::*}; use core::time::Duration; fn main() { // 禁用默认特性，只启用需要的功能 // Cargo.toml: // [dependencies] // bevy = { version = \"*\", default-features = false, features = [\"bevy_log\"] } // 运行一次的应用 App::new() .add_plugins(DefaultPlugins.set(ScheduleRunnerPlugin::run_once())) .add_systems(Update, hello_world_system) .run(); // 以 60 FPS 循环运行的应用 App::new() .add_plugins( DefaultPlugins .set(ScheduleRunnerPlugin::run_loop(Duration::from_secs_f64(1.0 / 60.0))) .disable::\u003cLogPlugin\u003e(), ) .add_systems(Update, counter) .run(); } fn hello_world_system() { println!(\"hello world\"); } fn counter(mut state: Local\u003cCounterState\u003e) { if state.count.is_multiple_of(60) { println!(\"{}\", state.count); } state.count += 1; } #[derive(Default)] struct CounterState { count: u32, } 关键要点：\nHeadless 模式不需要窗口 可以用于服务器端应用 可以用于纯逻辑处理 需要禁用默认特性并只启用需要的功能 说明： Headless 模式适合服务器端应用、纯逻辑处理等场景。通过禁用窗口和渲染功能，可以减少资源消耗。","headless-渲染器#Headless 渲染器":"创建 Headless 渲染器。\n源代码文件：bevy/examples/app/headless_renderer.rs\n关键信息：\n可以创建无窗口的渲染器 可以渲染到图像 可以保存渲染结果 适合批量渲染、CI 等场景 说明： Headless 渲染器允许在没有窗口的情况下进行渲染。这对于批量渲染、CI 等场景非常有用。","mainworld-和-renderapp#MainWorld 和 RenderApp":"理解 MainWorld 和 RenderApp 的关系。\n架构：\n主线程（MainWorld） 渲染线程（RenderApp） ├─ 游戏逻辑更新 ├─ Extract（提取数据） ├─ 物理模拟 ├─ Prepare（准备渲染） ├─ AI 计算 ├─ Queue（队列渲染） └─ 输入处理 └─ Render（实际渲染） 关键要点：\nMainWorld 运行游戏逻辑 RenderApp 运行渲染逻辑 两者通过 ExtractSchedule 同步数据 渲染逻辑在独立线程中运行 说明： MainWorld 和 RenderApp 的分离是 Bevy 性能优化的关键。通过将逻辑和渲染分离，可以实现并行执行，提高性能。","什么是逻辑-渲染分离#什么是逻辑-渲染分离？":"逻辑-渲染分离是 Bevy 的重要架构模式。它将游戏逻辑和渲染逻辑分离到不同的线程中，实现并行执行。\n为什么需要逻辑-渲染分离？\n性能优化：逻辑和渲染可以并行执行，提高性能 架构清晰：逻辑和渲染分离，使架构更加清晰 灵活性：可以独立优化逻辑和渲染 可测试性：可以独立测试逻辑和渲染","在游戏开发中的应用场景#在游戏开发中的应用场景":"逻辑-渲染分离在游戏开发中有广泛的应用：\n性能优化：通过并行执行逻辑和渲染提高性能 服务器端应用：使用 Headless 模式创建服务器 集成测试：使用无渲染模式进行集成测试 批量渲染：使用 Headless 渲染器进行批量渲染","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何确保数据同步正确？\n解决方案：使用 Extract 系统正确提取数据，并使用 SyncToRenderWorld 同步组件。\n问题 2：如何在 Headless 模式下运行应用？\n解决方案：禁用默认特性，只启用需要的功能，并使用 ScheduleRunnerPlugin 控制运行方式。\n问题 3：如何从 MainWorld 访问 RenderApp？\n解决方案：使用 App::sub_app_mut() 访问 RenderApp，但需要注意线程安全。","性能考虑#性能考虑":"数据同步开销：尽量减少需要同步的数据量 线程安全：注意 MainWorld 和 RenderApp 之间的线程安全 内存使用：注意 MainWorld 和 RenderApp 之间的内存使用 同步频率：合理控制数据同步频率","数据同步#数据同步":"在 MainWorld 和 RenderApp 之间同步数据。\n关键信息：\n使用 Extract 系统提取数据 使用 SyncToRenderWorld 同步组件 数据同步是单向的 可以同步组件、资源等数据 说明： 数据同步是逻辑-渲染分离的关键。通过正确同步数据，可以确保渲染世界有正确的数据。","无渲染模式#无渲染模式":"使用无渲染模式运行有窗口但无渲染的应用。\n源代码文件：bevy/examples/app/no_renderer.rs\n代码示例：\nuse bevy::{ prelude::*, render::{settings::WgpuSettings, RenderPlugin}, }; fn main() { App::new() .add_plugins( DefaultPlugins.set(RenderPlugin { render_creation: WgpuSettings { backends: None, ..default() } .into(), ..default() }), ) .run(); } 关键要点：\n无渲染模式显示窗口但不渲染 可以用于集成测试或 CI 可以用于调试逻辑 需要禁用渲染后端 说明： 无渲染模式适合集成测试、CI 等场景。通过禁用渲染后端，可以运行应用但不进行实际渲染。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解逻辑-渲染分离的基本概念 掌握 MainWorld 和 RenderApp 的使用 了解 ExtractSchedule 的作用 学会使用 Headless 模式和无渲染模式 前置知识要求：\nBevy 快速入门 ECS 基础 代码组织基础","渲染世界访问#渲染世界访问":"从 MainWorld 访问渲染世界。\n关键信息：\n可以使用 RenderApp 访问渲染世界 可以添加渲染系统 可以配置渲染管线 需要注意线程安全 说明： 渲染世界访问允许从主世界配置渲染。这对于创建自定义渲染效果非常有用。","相关资源#相关资源":"相关源代码文件：\nbevy/examples/app/headless.rs - Headless 模式示例 bevy/examples/app/no_renderer.rs - 无渲染模式示例 bevy/examples/app/headless_renderer.rs - Headless 渲染器示例 官方文档链接：\nBevy App 官方文档 渲染系统文档 进一步学习建议：\n学习代码组织，了解如何组织逻辑-渲染分离的代码 学习性能优化，了解如何优化逻辑-渲染分离的性能 学习自定义渲染，了解如何在渲染世界中创建自定义效果 索引：返回上级目录","进阶用法#进阶用法":"","逻辑-渲染分离的核心组件#逻辑-渲染分离的核心组件":"Bevy 逻辑-渲染分离包含以下核心组件：\nMainWorld：主世界，运行游戏逻辑 RenderApp：渲染应用，运行渲染逻辑 ExtractSchedule：提取调度，用于从 MainWorld 同步数据到 RenderApp SyncToRenderWorld：同步到渲染世界，用于同步组件数据"},"title":"逻辑-渲染分离"},"/wiki/bevybook/architecture/plugin%E7%B3%BB%E7%BB%9F/":{"data":{"":"","什么是插件系统#什么是插件系统？":"插件系统是 Bevy 中用于组织和模块化功能的方式。插件是封装相关功能的模块，可以独立开发、测试和复用。\n为什么需要插件系统？\n模块化：插件系统使代码更加模块化 可复用性：插件可以在不同项目中复用 可测试性：插件可以独立测试 可维护性：插件使代码更容易维护","创建插件#创建插件":"创建自定义插件。\n源代码文件：bevy/examples/app/plugin.rs\n代码示例：\nuse bevy::prelude::*; use core::time::Duration; fn main() { App::new() .add_plugins(( DefaultPlugins, PrintMessagePlugin { wait_duration: Duration::from_secs(1), message: \"这是一个示例插件\".to_string(), }, )) .run(); } // 打印消息插件 struct PrintMessagePlugin { wait_duration: Duration, message: String, } impl Plugin for PrintMessagePlugin { fn build(\u0026self, app: \u0026mut App) { let state = PrintMessageState { message: self.message.clone(), timer: Timer::new(self.wait_duration, TimerMode::Repeating), }; app.insert_resource(state) .add_systems(Update, print_message_system); } } #[derive(Resource)] struct PrintMessageState { message: String, timer: Timer, } fn print_message_system(mut state: ResMut\u003cPrintMessageState\u003e, time: Res\u003cTime\u003e) { if state.timer.tick(time.delta()).is_finished() { info!(\"{}\", state.message); } } 关键要点：\n实现 Plugin trait 来创建插件 在 build() 方法中配置插件 可以添加系统、资源、事件等 可以接受配置参数 说明： 创建插件是组织代码的重要方式。通过将相关功能封装到插件中，可以使代码更加模块化和可维护。","在游戏开发中的应用场景#在游戏开发中的应用场景":"插件系统在游戏开发中有广泛的应用：\n功能模块：将游戏功能组织成插件 第三方库：将第三方库封装成插件 游戏系统：将游戏系统（如物理、渲染）封装成插件 可配置性：通过插件系统创建可配置的应用程序","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何创建可配置的插件？\n解决方案：在插件结构体中添加配置字段，并在 build() 方法中使用这些配置。\n问题 2：如何处理插件依赖？\n解决方案：使用 PluginGroupBuilder 管理插件顺序，确保依赖插件先于被依赖插件初始化。\n问题 3：如何条件性地启用插件？\n解决方案：使用条件编译（#[cfg]）或运行时条件来启用或禁用插件。","性能考虑#性能考虑":"插件数量：尽量减少插件数量以提高启动速度 插件初始化：优化插件初始化逻辑以减少启动时间 插件依赖：合理组织插件依赖以减少初始化开销 条件插件：只在需要时启用插件以减少运行时开销","插件依赖#插件依赖":"管理插件之间的依赖关系。\n关键信息：\n插件可以依赖其他插件 可以使用 PluginGroupBuilder 管理依赖顺序 可以检查插件是否已注册 可以处理插件依赖冲突 说明： 插件依赖管理是创建复杂应用程序的关键。通过正确管理依赖关系，可以确保插件按正确顺序初始化。","插件生命周期#插件生命周期":"理解插件的生命周期。\n关键信息：\n插件在 App::build() 时初始化 插件可以添加启动系统、更新系统等 插件可以注册清理逻辑 插件可以监听应用事件 说明： 理解插件生命周期对于正确使用插件非常重要。通过了解插件的生命周期，可以确保插件在正确的时机执行。","插件系统的核心组件#插件系统的核心组件":"Bevy 插件系统包含以下核心组件：\nPlugin：插件 trait，用于定义插件 PluginGroup：插件组 trait，用于组织多个插件 App：应用程序，用于注册和管理插件 DefaultPlugins：默认插件组，包含基本功能","插件组#插件组":"创建和管理插件组。\n源代码文件：bevy/examples/app/plugin_group.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(( DefaultPlugins, HelloWorldPlugins, )) .run(); } // 插件组 pub struct HelloWorldPlugins; impl PluginGroup for HelloWorldPlugins { fn build(self) -\u003e PluginGroupBuilder { PluginGroupBuilder::start::\u003cSelf\u003e() .add(PrintHelloPlugin) .add(PrintWorldPlugin) } } struct PrintHelloPlugin; impl Plugin for PrintHelloPlugin { fn build(\u0026self, app: \u0026mut App) { app.add_systems(Update, print_hello_system); } } fn print_hello_system() { info!(\"hello\"); } struct PrintWorldPlugin; impl Plugin for PrintWorldPlugin { fn build(\u0026self, app: \u0026mut App) { app.add_systems(Update, print_world_system); } } fn print_world_system() { info!(\"world\"); } 关键要点：\n实现 PluginGroup trait 来创建插件组 使用 PluginGroupBuilder 来构建插件组 可以组织多个相关插件 可以统一配置和管理插件 说明： 插件组允许将多个相关插件组织在一起。这对于创建功能模块、管理插件依赖等非常有用。","插件配置#插件配置":"配置插件行为。\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins( HelloWorldPlugins .build() .disable::\u003cPrintWorldPlugin\u003e() .add_before::\u003cPrintHelloPlugin\u003e( LogDiagnosticsPlugin::default(), ), ) .run(); } 关键要点：\n可以使用 disable() 禁用插件 可以使用 add_before() 和 add_after() 控制插件顺序 可以动态配置插件行为 可以条件性地启用插件 说明： 插件配置允许灵活控制插件行为。这对于创建可配置的应用程序、支持不同平台等非常有用。","条件插件#条件插件":"根据条件启用或禁用插件。\n代码示例：\nuse bevy::prelude::*; fn main() { let mut app = App::new(); // 根据条件添加插件 #[cfg(feature = \"debug\")] { app.add_plugins(LogDiagnosticsPlugin::default()); } app.add_plugins(DefaultPlugins) .run(); } 关键要点：\n可以使用条件编译来启用或禁用插件 可以根据平台、特性等条件添加插件 可以创建可配置的插件系统 可以支持不同的构建配置 说明： 条件插件允许根据不同的条件启用或禁用功能。这对于创建可配置的应用程序、支持不同平台等非常有用。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解插件系统的基本概念 掌握插件的创建和注册 了解插件组的使用 学会配置和管理插件依赖 前置知识要求：\nBevy 快速入门 ECS 基础 代码组织基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/app/plugin.rs - 插件示例 bevy/examples/app/plugin_group.rs - 插件组示例 官方文档链接：\nBevy Plugin 官方文档 插件示例 进一步学习建议：\n学习代码组织，了解如何组织插件代码 学习 ECS 系统，了解如何在插件中使用 ECS 学习资源管理，了解如何在插件中管理资源 索引：返回上级目录","进阶用法#进阶用法":""},"title":"插件系统"},"/wiki/bevybook/assets/":{"data":{"":"","1-资源管理#1. 资源管理":"","2-场景系统scene#2. 场景系统（Scene）":"本部分介绍如何在 Bevy 中加载、管理和使用各种资源（Assets）。\n内容列表 1. 资源管理 资源系统概述\n什么是 Assets Assets 的生命周期 资源加载流程 资源类型\n图像资源（Image） 网格资源（Mesh） 材质资源（Material） 音频资源（Audio） 字体资源（Font） 自定义资源 资源加载\n同步加载 异步加载 资源预加载 资源热重载 资源管理\n资源句柄（Handle） 资源生命周期 资源清理 资源缓存 学习目标：能够加载和管理各种类型的资源\n2. 场景系统（Scene） 场景保存 场景加载 动态场景 场景序列化 学习目标：能够保存和加载游戏场景","下一步#下一步":"完成本部分学习后，建议继续学习：\nInput（输入处理） - 处理用户输入 Graphics（图形渲染） - 使用资源进行渲染 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"理解生命周期：理解资源的加载、使用和卸载流程 实践加载：尝试加载不同类型的资源 性能考虑：注意资源加载对性能的影响 错误处理：学会处理资源加载失败的情况","相关资源#相关资源":"Bevy Assets 官方文档 资源加载示例"},"title":"Assets（资源管理）"},"/wiki/bevybook/assets/%E5%9C%BA%E6%99%AF%E7%B3%BB%E7%BB%9Fscene/":{"data":{"":"","什么是场景系统#什么是场景系统？":"场景系统是 Bevy 中用于保存和加载场景数据的功能。场景系统允许您将实体、组件和资源序列化到文件中，并在需要时加载它们。\n为什么需要场景系统？\n场景保存：场景系统可以保存游戏场景到文件 场景加载：场景系统可以从文件加载游戏场景 数据持久化：场景系统可以实现数据持久化 场景编辑：场景系统可以用于场景编辑工具","动态场景#动态场景":"使用动态场景在运行时创建场景。\n关键信息：\n使用 DynamicScene::from_world() 从世界创建动态场景 使用 DynamicSceneBuilder 构建动态场景 使用 DynamicScene::write_to_world() 将场景写入世界 说明： 动态场景是场景系统的高级功能。通过使用动态场景，可以在运行时创建场景，实现更灵活的场景管理。","在游戏开发中的应用场景#在游戏开发中的应用场景":"场景系统在游戏开发中有广泛的应用：\n场景保存：保存游戏场景到文件 场景加载：从文件加载游戏场景 数据持久化：实现游戏数据的持久化 场景编辑：用于场景编辑工具","场景保存#场景保存":"保存场景到文件。\n源代码文件：bevy/examples/scene/scene.rs\n代码示例：\nuse bevy::{asset::LoadState, prelude::*, tasks::IoTaskPool}; use core::time::Duration; use std::{fs::File, io::Write}; /// 入口点 /// /// 设置默认插件，注册所有必要的组件/资源类型 /// 以进行序列化/反射，并在正确的调度中运行各种系统。 fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems( Startup, (save_scene_system, load_scene_system, infotext_system), ) .add_systems(Update, (log_system, panic_on_fail)) .run(); } /// 演示如何从头开始创建新场景，填充数据， /// 然后将其序列化到文件。新文件写入 `NEW_SCENE_FILE_PATH`。 /// /// 此系统创建一个新世界，复制类型注册表以便我们的 /// 自定义组件类型被识别，生成一些示例实体和资源， /// 然后序列化生成的动态场景。 fn save_scene_system(world: \u0026mut World) { // 场景可以从任何 ECS World 创建。 // 您可以创建一个新场景或使用当前 World。 // 为了演示目的，我们将创建一个新的。 let mut scene_world = World::new(); // `TypeRegistry` 资源包含有关所有已注册类型（包括组件）的信息。 // 这用于构建场景，因此我们希望确保之前的类型注册 // 也存在于这个新场景世界中。 // 为此，我们可以简单地克隆 `AppTypeRegistry` 资源。 let type_registry = world.resource::\u003cAppTypeRegistry\u003e().clone(); scene_world.insert_resource(type_registry); let mut component_b = ComponentB::from_world(world); component_b.value = \"hello\".to_string(); scene_world.spawn(( component_b, ComponentA { x: 1.0, y: 2.0 }, Transform::IDENTITY, Name::new(\"joe\"), )); scene_world.spawn(ComponentA { x: 3.0, y: 4.0 }); scene_world.insert_resource(ResourceA { score: 1 }); // 准备好我们的示例世界后，我们现在可以使用 DynamicScene 或 DynamicSceneBuilder 创建场景。 // 为了简单起见，我们将使用 DynamicScene 创建场景： let scene = DynamicScene::from_world(\u0026scene_world); // 场景可以像这样序列化： let type_registry = world.resource::\u003cAppTypeRegistry\u003e(); let type_registry = type_registry.read(); let serialized_scene = scene.serialize(\u0026type_registry).unwrap(); // 在控制台中显示场景 info!(\"{}\", serialized_scene); // 将场景写入新文件。使用任务避免在系统中调用文件系统 API， // 因为它们是阻塞的。 // // 这在 Wasm 中无法工作，因为没有文件系统访问。 #[cfg(not(target_arch = \"wasm32\"))] IoTaskPool::get() .spawn(async move { // 写入场景文件 File::create(\"scenes/load_scene_example-new.scn.ron\") .and_then(|mut file| file.write_all(serialized_scene.as_bytes())) .expect(\"Error while writing scene to file\"); }) .detach(); } /// 从资源文件加载场景并将其动态应用到 Bevy World 中的实体。 /// /// 生成 `DynamicSceneRoot` 会创建一个新的父实体，然后生成场景的 /// 新实例作为其子实体。如果您修改 `SCENE_FILE_PATH` 场景文件， /// 或者如果您启用文件监视，您可以看到更改立即反映。 fn load_scene_system(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(DynamicSceneRoot(asset_server.load(\"scenes/load_scene_example.scn.ron\"))); } /// 记录对 `ComponentA` 实体所做的更改，并检查 `ResourceA` 是否最近被添加。 /// /// 每当修改 `ComponentA` 时，该更改将出现在这里。此系统 /// 演示了如何在运行时检测和处理场景更新。 fn log_system( query: Query\u003c(Entity, \u0026ComponentA), Changed\u003cComponentA\u003e\u003e, res: Option\u003cRes\u003cResourceA\u003e\u003e, ) { for (entity, component_a) in \u0026query { info!(\" Entity({})\", entity.index()); info!( \" ComponentA: {{ x: {} y: {} }}\\n\", component_a.x, component_a.y ); } if let Some(res) = res \u0026\u0026 res.is_added() { info!(\" New ResourceA: {{ score: {} }}\\n\", res.score); } } /// 一个示例组件，完全可序列化。 /// /// 此组件具有将包含在场景文件中的公共 `x` 和 `y` 字段。 /// 注意它如何派生 `Default`、`Reflect`，并使用 `#[reflect(Component)]` 声明自己为反射组件。 #[derive(Component, Reflect, Default)] #[reflect(Component)] // 这告诉反射派生也反射组件行为 struct ComponentA { /// 示例 `f32` 字段 pub x: f32, /// 另一个示例 `f32` 字段 pub y: f32, } /// 一个示例组件，包括可序列化和不可序列化字段。 /// /// 这对于跳过运行时数据的序列化或您不想要写入场景文件的字段很有用。 #[derive(Component, Reflect)] #[reflect(Component)] struct ComponentB { /// 将被序列化的字符串字段。 pub value: String, /// 一个 `Duration` 字段，永远不应该序列化到场景文件，所以我们跳过它。 #[reflect(skip_serializing)] pub _time_since_startup: Duration, } /// 这为 `ComponentB` 实现了 `FromWorld`，让我们通过访问当前 ECS 资源来初始化运行时字段。 /// 在这种情况下，我们获取 `Time` 资源并存储当前经过的时间。 impl FromWorld for ComponentB { fn from_world(world: \u0026mut World) -\u003e Self { let time = world.resource::\u003cTime\u003e(); ComponentB { _time_since_startup: time.elapsed(), value: \"Default Value\".to_string(), } } } /// 一个简单的资源，也派生 `Reflect`，允许它存储在场景中。 /// /// 就像组件一样，如果需要，您可以跳过序列化字段或实现 `FromWorld`。 #[derive(Resource, Reflect, Default)] #[reflect(Resource)] struct ResourceA { /// 此资源跟踪 `score` 值。 pub score: u32, } 关键要点：\n使用 DynamicScene::from_world() 从世界创建场景 使用 scene.serialize() 序列化场景 使用 DynamicSceneRoot 加载场景 使用 #[reflect(Component)] 和 #[reflect(Resource)] 使类型可序列化 使用 #[reflect(skip_serializing)] 跳过序列化字段 说明： 场景保存是场景系统的基础。通过使用场景保存，可以将游戏场景保存到文件，实现数据持久化。","场景加载#场景加载":"从文件加载场景。\n关键信息：\n使用 AssetServer::load() 加载场景文件 使用 DynamicSceneRoot 生成场景根实体 场景会自动生成为场景根的子实体 使用文件监视可以实时更新场景 说明： 场景加载是场景系统的基础。通过使用场景加载，可以从文件加载游戏场景，实现场景的复用。","场景序列化#场景序列化":"使用反射系统序列化和反序列化场景。\n关键信息：\n使用 #[derive(Reflect)] 使类型可反射 使用 #[reflect(Component)] 使组件可序列化 使用 #[reflect(Resource)] 使资源可序列化 使用 #[reflect(skip_serializing)] 跳过序列化字段 说明： 场景序列化是场景系统的重要功能。通过使用反射系统，可以序列化和反序列化场景，实现场景的保存和加载。","场景系统的核心组件#场景系统的核心组件":"Bevy 场景系统包含以下核心组件：\nScene：场景，包含序列化的实体和组件 DynamicScene：动态场景，用于运行时创建场景 DynamicSceneRoot：动态场景根，用于加载场景 SceneSpawner：场景生成器，用于生成场景实体","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何使类型可序列化？\n解决方案：\n使用 #[derive(Reflect)] 使类型可反射 使用 #[reflect(Component)] 使组件可序列化 使用 #[reflect(Resource)] 使资源可序列化 使用 AppTypeRegistry 注册类型 问题 2：如何跳过序列化字段？\n解决方案：\n使用 #[reflect(skip_serializing)] 跳过序列化字段 使用 FromWorld 实现初始化运行时字段 问题 3：如何加载场景？\n解决方案：\n使用 AssetServer::load() 加载场景文件 使用 DynamicSceneRoot 生成场景根实体 场景会自动生成为场景根的子实体","性能考虑#性能考虑":"场景序列化：场景序列化是阻塞操作，应使用异步任务 场景加载：场景加载是异步操作，应使用 AssetServer 类型注册：类型注册应在应用启动时完成","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 场景系统的基本概念 掌握场景的保存和加载 了解动态场景的使用 学会使用场景序列化和反序列化 前置知识要求：\nBevy 快速入门 ECS 基础 资源管理基础 反射系统基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/scene/scene.rs - 场景系统示例 官方文档链接：\nBevy 场景系统 Bevy 反射系统 进一步学习建议：\n学习资源管理，了解资源加载和管理 学习反射系统，了解类型反射和序列化 索引：返回上级目录\n```markdown ## 内容列表 ### 1. [资源管理](/wiki/BevyBook/Assets/资源管理) - 资源系统概述 - 资源类型 - 资源加载 - 资源管理 **学习目标**：能够加载和管理资源 ### 2. [场景系统（Scene）](/wiki/BevyBook/Assets/场景系统（Scene）) - 场景保存 - 场景加载 - 动态场景 - 场景序列化 **学习目标**：能够保存和加载场景","进阶用法#进阶用法":""},"title":"场景系统（Scene）"},"/wiki/bevybook/assets/%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/":{"data":{"":"","什么是资源管理#什么是资源管理？":"资源管理是 Bevy 中用于加载和管理游戏资源的功能。Bevy 的资源管理系统支持多种资源类型，包括模型、纹理、音频、字体等。\n为什么需要资源管理？\n资源加载：游戏需要加载各种资源，如模型、纹理、音频等 异步加载：资源加载是异步的，不会阻塞游戏运行 资源缓存：资源管理系统会自动缓存已加载的资源 热重载：支持热重载，可以在运行时重新加载资源","在游戏开发中的应用场景#在游戏开发中的应用场景":"资源管理在游戏开发中有广泛的应用：\n模型加载：加载 3D 模型和场景 纹理加载：加载纹理和材质 音频加载：加载音频文件 字体加载：加载字体文件 配置文件：加载游戏配置数据","基础用法#基础用法":"","实际应用#实际应用":"","嵌入资源#嵌入资源":"将资源嵌入到可执行文件中。\n源代码文件：bevy/examples/asset/embedded_asset.rs\n关键信息：\n可以使用 embedded_asset! 宏嵌入资源 嵌入的资源包含在可执行文件中 适合小型资源或需要快速加载的资源 可以与其他资源加载方式结合使用 说明： 嵌入资源允许将资源直接包含在可执行文件中。这对于小型资源或需要快速加载的资源非常有用。","常见问题#常见问题":"问题 1：如何等待资源加载完成？\n解决方案：可以监听 AssetEvent::LoadedWithDependencies 事件，或者使用 Assets 的 get() 方法检查资源是否已加载。\n问题 2：如何管理资源的生命周期？\n解决方案：资源的生命周期由句柄管理。只要还有句柄引用资源，资源就会保持在内存中。确保在不再需要资源时丢弃句柄。\n问题 3：如何优化资源加载性能？\n解决方案：可以使用资源预加载、资源缓存、资源压缩等技术来优化资源加载性能。","性能考虑#性能考虑":"资源预加载：在需要之前预加载资源 资源缓存：合理使用资源缓存以减少重复加载 资源压缩：使用压缩格式减少资源大小 异步加载：利用异步加载避免阻塞游戏运行","核心概念#核心概念":"","概述#概述":"学习目标：\n理解资源管理系统的基本概念 掌握资源类型的定义和使用 学会加载资源（同步、异步、预加载、热重载） 了解资源管理（句柄、生命周期、清理、缓存） 前置知识要求：\nBevy 快速入门 ECS 基础 资源（Resources）基础","热重载#热重载":"在运行时重新加载资源。\n源代码文件：bevy/examples/asset/hot_asset_reloading.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .run(); } fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { // 加载我们的网格 let scene_handle = asset_server.load(GltfAssetLabel::Scene(0).from_asset(\"models/torus/torus.gltf\")); // 对网格的任何更改都会自动重新加载！尝试修改 torus.gltf // 你应该会立即看到更改出现在应用中 commands.spawn(SceneRoot(scene_handle)); } 关键要点：\n热重载允许在运行时修改资源文件 修改后的资源会自动重新加载 需要启用 file_watcher cargo feature 适合开发时快速迭代 说明： 热重载功能允许在开发时快速迭代。修改资源文件后，资源会自动重新加载，无需重启游戏。","相关资源#相关资源":"相关源代码文件：\nbevy/examples/asset/asset_loading.rs - 资源加载示例 bevy/examples/asset/custom_asset.rs - 自定义资源类型示例 bevy/examples/asset/hot_asset_reloading.rs - 热重载示例 bevy/examples/asset/embedded_asset.rs - 嵌入资源示例 bevy/examples/asset/extra_source.rs - 额外资源源示例 官方文档链接：\nBevy Asset 官方文档 资源示例 进一步学习建议：\n学习场景系统，了解如何加载和管理场景 学习资源管理，了解如何优化资源加载性能 学习自定义资源类型，了解如何创建自己的资源格式 索引：返回上级目录","自定义资源类型#自定义资源类型":"创建自定义资源类型。\n源代码文件：bevy/examples/asset/custom_asset.rs\n代码示例：\nuse bevy::{ asset::{io::Reader, AssetLoader, LoadContext}, prelude::*, reflect::TypePath, }; use serde::Deserialize; #[derive(Asset, TypePath, Debug, Deserialize)] struct CustomAsset { value: i32, } #[derive(Default)] struct CustomAssetLoader; impl AssetLoader for CustomAssetLoader { type Asset = CustomAsset; type Settings = (); type Error = CustomAssetLoaderError; async fn load( \u0026self, reader: \u0026mut dyn Reader, _settings: \u0026(), _load_context: \u0026mut LoadContext\u003c'_\u003e, ) -\u003e Result\u003cSelf::Asset, Self::Error\u003e { let mut bytes = Vec::new(); reader.read_to_end(\u0026mut bytes).await?; let custom_asset = ron::de::from_bytes::\u003cCustomAsset\u003e(\u0026bytes)?; Ok(custom_asset) } fn extensions(\u0026self) -\u003e \u0026[\u0026str] { \u0026[\"custom\"] } } fn main() { App::new() .add_plugins(DefaultPlugins) .init_asset::\u003cCustomAsset\u003e() .init_asset_loader::\u003cCustomAssetLoader\u003e() .run(); } 关键要点：\n使用 #[derive(Asset, TypePath)] 定义资源类型 实现 AssetLoader trait 来创建资源加载器 在应用中初始化资源类型和加载器 可以支持自定义文件格式 说明： 自定义资源类型允许你创建自己的资源格式。这对于游戏特定的数据格式非常有用。","资源加载#资源加载":"加载资源的基本方法。\n源代码文件：bevy/examples/asset/asset_loading.rs\n代码示例：\nuse bevy::{asset::LoadedFolder, prelude::*}; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .run(); } fn setup( mut commands: Commands, asset_server: Res\u003cAssetServer\u003e, meshes: Res\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { // 默认情况下，AssetServer 将从 \"assets\" 文件夹内加载资源 // 例如，下一行将加载 \"ROOT/assets/models/cube/cube.gltf\" // 其中 \"ROOT\" 是应用程序的目录 // // 这可以通过设置 [`AssetPlugin.file_path`] 来覆盖 let cube_handle = asset_server.load( GltfAssetLabel::Primitive { mesh: 0, primitive: 0, } .from_asset(\"models/cube/cube.gltf\"), ); let sphere_handle = asset_server.load( GltfAssetLabel::Primitive { mesh: 0, primitive: 0, } .from_asset(\"models/sphere/sphere.gltf\"), ); // 所有资源在加载完成后都会进入它们的 Assets 集合 if let Some(sphere) = meshes.get(\u0026sphere_handle) { // 你可能会注意到这不会运行！这是因为资源在并行加载时不会阻塞 // 当资源加载完成时，它将出现在相关的 Assets 集合中 info!(\"{:?}\", sphere.primitive_topology()); } else { info!(\"sphere 尚未加载\"); } // 你可以像这样加载文件夹中的所有资源。它们将在不阻塞的情况下并行加载 // LoadedFolder 资源保存文件夹中每个资源的句柄 // 这些都是 LoadedFolder 资源的依赖项，这意味着如果你想要等待文件夹中的所有资源加载 // 可以等待 LoadedFolder 资源触发 AssetEvent::LoadedWithDependencies // 如果你想保持文件夹中的资源存活，请确保存储返回的句柄 let _loaded_folder: Handle\u003cLoadedFolder\u003e = asset_server.load_folder(\"models/torus\"); // 如果你想要文件夹中特定资源的句柄，最简单的方法是调用 load // 它不会再次加载 // LoadedFolder 资源最终也会保存资源的句柄，但等待它加载并找到正确的句柄需要更多工作 let torus_handle = asset_server.load( GltfAssetLabel::Primitive { mesh: 0, primitive: 0, } .from_asset(\"models/torus/torus.gltf\"), ); // 你也可以直接将资源添加到它们的 Assets 存储中 let material_handle = materials.add(StandardMaterial { base_color: Color::srgb(0.8, 0.7, 0.6), ..default() }); // 使用加载的资源创建实体 commands.spawn(( Mesh3d(torus_handle), MeshMaterial3d(material_handle.clone()), Transform::from_xyz(-3.0, 0.0, 0.0), )); } 关键要点：\n使用 AssetServer 加载资源 资源加载是异步的，不会阻塞游戏运行 使用 Assets 集合访问已加载的资源 可以使用 load_folder() 加载整个文件夹的资源 可以使用 add() 方法直接添加资源到集合中 说明： 资源加载是资源管理系统的基础。通过 AssetServer 加载资源，资源会在后台异步加载，不会阻塞游戏运行。加载完成后，资源会出现在相应的 Assets 集合中。","资源句柄#资源句柄":"使用资源句柄引用资源。\n关键信息：\nHandle 是资源的引用 句柄可以在资源加载完成之前使用 句柄可以克隆，多个句柄可以引用同一个资源 资源只有在所有句柄都被丢弃后才会被卸载 说明： 资源句柄是资源管理系统的核心。它允许在资源加载完成之前就使用资源，并且可以安全地共享资源引用。","资源生命周期#资源生命周期":"理解资源的生命周期。\n关键信息：\n资源在加载时创建 资源在最后一个句柄被丢弃时卸载 资源可以被缓存以提高性能 资源可以被热重载 说明： 资源的生命周期由句柄管理。只要还有句柄引用资源，资源就会保持在内存中。当所有句柄都被丢弃时，资源会被卸载。","资源管理的核心组件#资源管理的核心组件":"Bevy 资源管理系统包含以下核心组件：\nAssetServer：资源服务器，用于加载资源 Assets：资源集合，存储已加载的资源 Handle：资源句柄，用于引用资源 AssetLoader：资源加载器，用于加载特定类型的资源","进阶用法#进阶用法":"","额外资源源#额外资源源":"从多个源加载资源。\n源代码文件：bevy/examples/asset/extra_source.rs\n关键信息：\n可以配置多个资源源 可以从不同的目录或服务器加载资源 可以设置资源源的优先级 适合模块化资源管理 说明： 额外资源源允许从多个位置加载资源。这对于模块化资源管理或从服务器加载资源非常有用。"},"title":"资源管理"},"/wiki/bevybook/changelog/":{"data":{"":"本文档记录教程的更新历史。","待完成#待完成":"完善各部分的详细内容 添加更多示例代码 添加更多实际项目示例 索引：返回主目录","改进#改进":"优化目录结构 统一文档格式 改进导航系统","新增#新增":"创建完整的教程架构 添加主索引文件（README.md） 为每个部分创建索引文件 添加学习路径指南（LEARNING_PATH.md） 添加贡献指南（CONTRIBUTING.md）","未发布#[未发布]":""},"title":"更新日志"},"/wiki/bevybook/contributing/":{"data":{"":"感谢你对 Bevy 教程的贡献！本指南帮助你了解如何贡献内容。","-内容规范#📋 内容规范":"","-教程结构#📚 教程结构":"","-联系方式#📧 联系方式":"如有问题，可以通过以下方式联系：\n创建 Issue 发送 Pull Request 参与讨论 感谢你的贡献！ 🙏\n索引：返回主目录","1-内容贡献#1. 内容贡献":"新教程：添加新的教程章节 内容改进：改进现有教程内容 示例代码：添加或改进代码示例 翻译：翻译教程内容","1-选择贡献内容#1. 选择贡献内容":"查看 Issues 了解需要的内容 或提出新的贡献想法","2-结构改进#2. 结构改进":"目录结构：优化教程结构 导航改进：改进教程导航 格式统一：统一文档格式","2-编写内容#2. 编写内容":"遵循现有的文档格式 使用中文编写 包含代码示例 添加必要的说明","3-提交贡献#3. 提交贡献":"Fork 仓库 创建新分支 提交更改 创建 Pull Request","3-错误修复#3. 错误修复":"拼写错误：修复拼写和语法错误 代码错误：修复代码示例错误 链接错误：修复失效链接","代码块格式#代码块格式":"// 使用 rust 代码块 fn example() { println!(\"Hello, Bevy!\"); }","代码示例#代码示例":"代码应该可以运行 添加必要的注释 使用有意义的变量名 遵循 Rust 代码规范","协作#协作":"尊重其他贡献者 提供建设性反馈 保持友好的讨论氛围 遵循代码审查流程","基本结构#基本结构":"每个教程文档应该包含：\n标题：清晰的标题 概述：简要介绍内容 目录：文档目录（如果内容较长） 正文：主要内容 示例：代码示例 总结：要点总结 相关链接：相关资源链接","引用代码#引用代码":"使用代码引用格式：\nfn example() { println!(\"Hello, Bevy!\"); }","文档格式#文档格式":"使用 Markdown 格式 遵循现有的文档结构 使用清晰的标题层级 添加代码示例","检查清单#检查清单":"提交前请检查：\n内容准确无误 代码示例可以运行 格式符合规范 没有拼写错误 链接有效 添加了必要的索引链接","语言风格#语言风格":"使用简体中文 语言清晰易懂 避免过于复杂的句子 使用专业术语时提供解释","贡献流程#贡献流程":"","贡献类型#贡献类型":""},"title":"贡献指南"},"/wiki/bevybook/ecs/":{"data":{"":"","1-核心编程框架ecs#1. 核心编程框架（ECS）":"","2-组件components#2. 组件（Components）":"","3-实体entities#3. 实体（Entities）":"","4-命令commands#4. 命令（Commands）":"","5-系统systems#5. 系统（Systems）":"","6-查询queries#6. 查询（Queries）":"","7-资源resources#7. 资源（Resources）":"","8-系统调度schedule--app#8. 系统调度（Schedule \u0026amp; App）":"","9-ecs-进阶#9. ECS 进阶":"ECS 是 Bevy 的核心编程范式。理解 ECS 是掌握 Bevy 的关键。\n内容列表 1. 核心编程框架（ECS） ECS 概述 为什么使用 ECS ECS 的核心概念 Bevy ECS 的特点 学习目标：理解 ECS 的基本概念和优势\n2. 组件（Components） 定义组件 组件类型 组件生命周期 组件存储 不可变组件 学习目标：能够定义和使用组件\n3. 实体（Entities） 创建实体 实体 ID 实体操作 实体禁用 实体层次结构 学习目标：能够创建和操作实体\n4. 命令（Commands） Commands 概念 创建实体 操作实体 管理资源 注册和运行系统 触发事件 发送消息 实体层次结构 学习目标：能够使用 Commands 安全地修改世界\n5. 系统（Systems） 定义系统 系统参数 系统闭包 泛型系统 一次性系统 系统管道 独占系统 可失败系统参数 系统错误处理 学习目标：能够定义和使用系统\n6. 查询（Queries） 基本查询 查询过滤器 自定义查询参数 查询组合 并行查询 学习目标：能够使用查询访问组件\n7. 资源（Resources） 定义资源 访问资源 资源初始化 资源生命周期 资源变更检测 学习目标：能够定义和使用资源\n8. 系统调度（Schedule \u0026 App） Schedule 概念 系统执行顺序 系统集（SystemSet） 自定义 Schedule 固定时间步 运行条件 系统步进 非确定性系统顺序 学习目标：能够控制系统执行顺序和应用生命周期\n9. ECS 进阶 变更检测（Change Detection）\n检测组件变化 检测资源变化 变更检测方法 组件生命周期钩子（Component Hooks）\n定义钩子 钩子类型 钩子应用场景 关系系统（Relationships）\n定义自定义关系 使用关系 关系遍历 并行查询（Parallel Queries）\n并行迭代器 批处理策略 性能优化 查询组合（Query Combinations）\n实体间交互 组合查询方法 观察者模式（Observers）\n响应组件生命周期事件 响应自定义事件 消息系统（Messages）\n定义消息 发送和接收消息 错误处理（Error Handling）\n系统错误处理 错误处理器 动态 ECS（Dynamic ECS）\n动态创建组件 动态创建实体 学习目标：掌握 ECS 的高级功能和最佳实践","下一步#下一步":"完成本部分学习后，建议继续学习：\nAssets（资源管理） - 学习如何加载和管理资源 Input（输入处理） - 处理用户输入 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"理解概念：ECS 是一种新的编程范式，需要时间适应 多写代码：通过实践加深理解 阅读示例：查看 Bevy 官方示例中的 ECS 用法 思考设计：思考如何用 ECS 思维设计游戏逻辑","学习路径#学习路径":"建议按照以下顺序学习：\n核心编程框架（ECS）：理解 ECS 的基本概念和优势 组件（Components）：学习如何定义和使用组件 实体（Entities）：学习如何创建和操作实体 命令（Commands）：学习如何使用 Commands 安全地修改世界 系统（Systems）：学习如何定义和使用系统 查询（Queries）：学习如何使用查询访问组件 资源（Resources）：学习如何定义和使用资源 系统调度（Schedule \u0026 App）：学习如何控制系统执行顺序和应用生命周期 ECS 进阶：掌握高级功能和最佳实践 每个章节都基于 Bevy 官方示例编写，确保内容的准确性和实用性。","相关资源#相关资源":"Bevy ECS 官方文档 ECS 设计模式 Bevy ECS 示例"},"title":"ECS（实体组件系统）"},"/wiki/bevybook/ecs/%E5%91%BD%E4%BB%A4commands/":{"data":{"":"","commands-的设计思想#Commands 的设计思想":"Commands 采用命令模式，将修改操作封装为命令，在系统执行完成后统一应用。这种设计使得：\n系统可以并行执行，同时安全地修改世界 修改操作可以延迟执行，提高性能 修改操作可以批量处理，减少开销","什么是-commands#什么是 Commands？":"Commands 是一种安全的方式来修改世界（World）。由于系统可以并行执行，直接访问世界是不安全的。Commands 将修改操作排队，在系统执行完成后统一应用。\n为什么使用 Commands？\n线程安全：Commands 允许系统安全地修改世界，即使系统并行执行 延迟执行：Commands 将修改操作排队，在系统执行完成后统一应用 命令缓冲：Commands 提供命令缓冲，允许批量操作","创建实体#创建实体":"使用 spawn() 和 spawn_batch() 创建实体。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\nfn startup_system(mut commands: Commands, mut game_state: ResMut\u003cGameState\u003e) { // 创建游戏规则资源 commands.insert_resource(GameRules { max_rounds: 10, winning_score: 4, max_players: 4, }); // 向我们的世界添加一些玩家。玩家从分数 0 开始 commands.spawn_batch(vec![ ( Player { name: \"Alice\".to_string(), }, Score { value: 0 }, PlayerStreak::None, ), ( Player { name: \"Bob\".to_string(), }, Score { value: 0 }, PlayerStreak::None, ), ]); // 设置总玩家数为 2 game_state.total_players = 2; } // 这个系统使用命令缓冲区（可能）在每次迭代时向我们的游戏添加一个新玩家 // 普通系统不能安全地直接访问 World 实例，因为它们并行运行 // 我们的 World 包含所有组件，所以并行修改其任意部分不是线程安全的 // 命令缓冲区使我们能够在不直接访问的情况下排队对 World 的更改 fn new_player_system( mut commands: Commands, game_rules: Res\u003cGameRules\u003e, mut game_state: ResMut\u003cGameState\u003e, ) { // 随机添加一个新玩家 let add_new_player = random::\u003cbool\u003e(); if add_new_player \u0026\u0026 game_state.total_players \u003c game_rules.max_players { game_state.total_players += 1; commands.spawn(( Player { name: format!(\"Player {}\", game_state.total_players), }, Score { value: 0 }, PlayerStreak::None, )); println!(\"Player {} joined the game!\", game_state.total_players); } } 关键要点：\n使用 spawn() 创建单个实体 使用 spawn_batch() 批量创建实体 可以在创建实体时同时添加多个组件 Commands 将修改操作排队，在系统执行完成后统一应用 说明： Commands 提供了一种安全的方式来修改世界。由于系统可以并行执行，直接访问世界是不安全的。Commands 将修改操作排队，在系统执行完成后统一应用。","发送消息#发送消息":"使用 write_message() 方法发送消息。\n源代码文件：bevy/examples/ecs/message.rs\n代码示例：\n/// 这是一个 [`Message`]，任何观察它的观察者都会在它被激活时运行 #[derive(Message)] struct MyMessage; fn send_message(mut commands: Commands) { // 发送消息 commands.write_message(MyMessage); } fn receive_message(_message: On\u003cMyMessage\u003e) { info!(\"Message received!\"); } 关键要点：\n使用 write_message() 方法发送消息 消息需要实现 Message trait 观察者会响应发送的消息 消息可以用于系统间通信 注意事项：\n消息需要实现 Message trait 观察者会响应发送的消息 消息可以用于系统间通信 最佳实践：\n对于系统间通信，使用消息 对于事件驱动逻辑，使用消息 注意消息的性能影响","在游戏开发中的应用场景#在游戏开发中的应用场景":"Commands 在游戏开发中有广泛的应用：\n实体创建：创建玩家、敌人、道具等游戏对象 组件管理：添加、移除、修改组件 资源管理：插入和初始化资源 事件驱动：触发事件和发送消息 系统管理：注册和运行一次性系统","基础用法#基础用法":"","实体层次结构#实体层次结构":"使用 with_children() 和 add_child() 管理实体层次结构。\n源代码文件：bevy/examples/ecs/hierarchy.rs\n代码示例：\nfn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(Camera2d); let texture = asset_server.load(\"branding/icon.png\"); // 生成一个没有父实体的根实体 let parent = commands .spawn(( Sprite::from_image(texture.clone()), Transform::from_scale(Vec3::splat(0.75)), )) // 以该实体作为父实体，运行一个 lambda 来生成其子实体 .with_children(|parent| { // parent 是一个 ChildSpawnerCommands，具有与 Commands 类似的 API parent.spawn(( Transform::from_xyz(250.0, 0.0, 0.0).with_scale(Vec3::splat(0.75)), Sprite { image: texture.clone(), color: BLUE.into(), ..default() }, )); }) .id(); // 另一种方法是使用 add_child 函数在父实体已经生成后添加子实体 let child = commands .spawn(( Sprite { image: texture, color: LIME.into(), ..default() }, Transform::from_xyz(0.0, 250.0, 0.0).with_scale(Vec3::splat(0.75)), )) .id(); // 将子实体添加到父实体 commands.entity(parent).add_child(child); } 关键要点：\n使用 with_children() 方法在创建实体时添加子实体 使用 add_child() 方法在实体创建后添加子实体 使用 remove_child() 方法移除子实体 销毁父实体会自动销毁所有子实体 注意事项：\n层次结构通过 ChildOf 和 Children 组件实现 销毁父实体会自动销毁所有子实体 可以通过移除 ChildOf 组件来断开父子关系 最佳实践：\n使用层次结构组织相关的实体 注意层次结构对变换和可见性传播的影响 合理使用层次结构，避免过深的嵌套","实际应用#实际应用":"","常见问题#常见问题":"问题 1：Commands 何时执行？\n解决方案：Commands 在系统执行完成后统一应用。这意味着在系统执行期间，Commands 的修改不会立即生效。\n问题 2：如何获取刚创建的实体 ID？\n解决方案：使用 .id() 方法在创建实体后立即获取实体 ID。即使实体本身尚未在世界中实例化，也可以获取 ID。\n问题 3：Commands 和直接访问 World 有什么区别？\n解决方案：\nCommands 是线程安全的，可以在并行系统中使用 直接访问 World 需要独占系统，会阻止并行执行 Commands 将修改操作排队，在系统执行完成后统一应用","性能考虑#性能考虑":"命令缓冲：Commands 将修改操作排队，批量处理，减少开销 延迟执行：Commands 的修改在系统执行完成后统一应用，提高性能 批量操作：使用 spawn_batch() 批量创建实体，比逐个创建更高效","操作实体#操作实体":"使用 entity() 方法获取实体命令，然后可以插入、移除组件或销毁实体。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 调用 `.id()` 在生成实体后将返回生成实体的 `Entity` 标识符 // 即使实体本身尚未在世界中实例化 // 这有效是因为 Commands 会在实际生成实体之前通过原子计数器保留实体 ID let alice = commands.spawn(Name::new(\"Alice\")).id(); let bob = commands.spawn((Name::new(\"Bob\"), Targeting(alice))).id(); // 使用 entity() 方法获取实体命令 commands.entity(alice).insert(Targeting(bob)); 源代码文件：bevy/examples/ecs/entity_disabling.rs\n代码示例：\nfn disable_entities_on_click( click: On\u003cPointer\u003cClick\u003e\u003e, valid_query: Query\u003c\u0026DisableOnClick\u003e, mut commands: Commands, ) { if valid_query.contains(click.entity) { // 只需将 `Disabled` 组件添加到实体即可禁用它 commands.entity(click.entity).insert(Disabled); } } fn reenable_entities_on_space( mut commands: Commands, disabled_entities: Query\u003cEntity, With\u003cDisabled\u003e\u003e, input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, ) { if input.just_pressed(KeyCode::Space) { for entity in disabled_entities.iter() { // 要重新启用实体，只需移除 `Disabled` 组件 commands.entity(entity).remove::\u003cDisabled\u003e(); } } } 源代码文件：bevy/examples/ecs/fallible_params.rs\n代码示例：\nfn user_input( mut commands: Commands, enemies: Query\u003cEntity, With\u003cEnemy\u003e\u003e, keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, asset_server: Res\u003cAssetServer\u003e, ) { if keyboard_input.just_pressed(KeyCode::KeyR) \u0026\u0026 let Some(entity) = enemies.iter().next() { // 使用 despawn() 销毁实体 commands.entity(entity).despawn(); } } 关键要点：\n使用 entity() 方法获取实体命令 使用 insert() 方法插入组件 使用 remove() 方法移除组件 使用 despawn() 方法销毁实体 可以链式调用多个操作 说明： entity() 方法返回一个 EntityCommands，可以用于操作实体。可以链式调用多个操作，如 commands.entity(entity).insert(component).remove::()。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Commands 的概念和作用 掌握如何使用 Commands 修改世界 了解 Commands 的各种操作方法 理解 Commands 的执行时机 前置知识要求：\n核心编程框架（ECS） 组件（Components） 实体（Entities） 系统（Systems） Rust 基础语法","注册和运行系统#注册和运行系统":"使用 register_system() 和 run_system() 注册和运行一次性系统。\n源代码文件：bevy/examples/ecs/one_shot_systems.rs\n代码示例：\nuse bevy::{ ecs::system::{RunSystemOnce, SystemId}, prelude::*, }; #[derive(Component)] struct Callback(SystemId); fn setup_with_commands(mut commands: Commands) { // 注册系统并获取系统 ID let system_id = commands.register_system(system_a); commands.spawn((Callback(system_id), A)); } /// 如果实体也有 `Triggered` 组件，则运行与每个 `Callback` 组件关联的系统 fn evaluate_callbacks(query: Query\u003c(Entity, \u0026Callback), With\u003cTriggered\u003e\u003e, mut commands: Commands) { for (entity, callback) in query.iter() { // 运行一次性系统 commands.run_system(callback.0); commands.entity(entity).remove::\u003cTriggered\u003e(); } } 关键要点：\n使用 register_system() 注册系统并获取系统 ID 使用 run_system() 运行一次性系统 一次性系统在触发时运行一次，而不是每次更新都运行 一次性系统可以用于推送式逻辑 注意事项：\n一次性系统在触发时运行一次 一次性系统可以减少很少运行的系统开销 一次性系统可以提高调度灵活性 最佳实践：\n对于很少运行的系统，使用一次性系统 对于事件驱动的逻辑，使用一次性系统 注意一次性系统的生命周期管理","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ecs/ecs_guide.rs - ECS 完整指南示例（Commands 使用） bevy/examples/ecs/one_shot_systems.rs - 一次性系统示例（注册和运行系统） bevy/examples/ecs/observers.rs - 观察者模式示例（触发事件） bevy/examples/ecs/hierarchy.rs - 实体层次结构示例（管理层次结构） bevy/examples/ecs/entity_disabling.rs - 实体禁用示例（操作实体） 官方文档链接：\nBevy Commands 官方文档 EntityCommands 文档 进一步学习建议：\n学习实体（Entities），了解如何创建和操作实体 学习系统（Systems），了解如何在系统中使用 Commands 学习 ECS 进阶，了解 Commands 的高级功能 索引：返回上级目录","管理资源#管理资源":"使用 insert_resource() 和 init_resource() 管理资源。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\nfn startup_system(mut commands: Commands, mut game_state: ResMut\u003cGameState\u003e) { // 创建游戏规则资源 commands.insert_resource(GameRules { max_rounds: 10, winning_score: 4, max_players: 4, }); } 关键要点：\n使用 insert_resource() 插入资源 使用 init_resource() 初始化资源（需要实现 Default 或 FromWorld trait） 资源可以在系统运行时插入或初始化 说明： Commands 可以用于管理资源。使用 insert_resource() 可以插入资源，使用 init_resource() 可以初始化资源。","触发事件#触发事件":"使用 trigger() 方法触发事件。\n源代码文件：bevy/examples/ecs/observers.rs\n代码示例：\n/// [`EntityEvent`] 是一种专门的 [`Event`] 类型，可以针对特定实体 /// 除了在触发时运行正常的\"顶级\"观察者（针对任何爆炸的实体）外 /// 它还会运行针对该事件的特定实体的任何观察者 #[derive(EntityEvent)] struct Explode { entity: Entity, } fn main() { App::new() .add_plugins(DefaultPlugins) .add_observer( |explode_mines: On\u003cExplodeMines\u003e, mines: Query\u003c\u0026Mine\u003e, index: Res\u003cSpatialIndex\u003e, mut commands: Commands| { for entity in index.get_nearby(explode_mines.pos) { let mine = mines.get(entity).unwrap(); if mine.pos.distance(explode_mines.pos) \u003c mine.size + explode_mines.radius { // 触发事件 commands.trigger(Explode { entity }); } } }, ) .run(); } 关键要点：\n使用 trigger() 方法触发事件 事件可以是普通事件或实体事件 实体事件可以针对特定实体 观察者会响应触发的事件 注意事项：\n事件可以是普通事件或实体事件 实体事件可以针对特定实体 观察者会响应触发的事件 最佳实践：\n对于事件驱动的逻辑，使用事件 对于需要针对特定实体的逻辑，使用实体事件 注意事件的性能影响","进阶用法#进阶用法":""},"title":"命令（Commands）"},"/wiki/bevybook/ecs/%E5%AE%9E%E4%BD%93entities/":{"data":{"":"","什么是实体#什么是实体？":"实体是具有唯一 ID 的组件集合。实体本身不包含任何数据，它只是一个标识符，用于将组件组合在一起。\n为什么使用实体？\n灵活组合：实体可以灵活组合不同的组件 唯一标识：每个实体都有唯一的 ID 高效查询：通过实体 ID 可以快速访问组件","创建实体#创建实体":"使用 Commands 创建实体并添加组件。关于 Commands 的详细使用方法，请参考命令（Commands）章节。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 这是一个\"启动\"系统，在应用启动时恰好运行一次 // 启动系统通常用于创建游戏的初始\"状态\" fn startup_system(mut commands: Commands, mut game_state: ResMut\u003cGameState\u003e) { // 向我们的世界添加一些玩家。玩家从分数 0 开始 commands.spawn_batch(vec![ ( Player { name: \"Alice\".to_string(), }, Score { value: 0 }, PlayerStreak::None, ), ( Player { name: \"Bob\".to_string(), }, Score { value: 0 }, PlayerStreak::None, ), ]); // 设置总玩家数为 2 game_state.total_players = 2; } 关键要点：\n使用 Commands 创建实体 使用 spawn() 创建单个实体 使用 spawn_batch() 批量创建实体 可以在创建实体时同时添加多个组件 说明： 实体通过 Commands 创建。Commands 提供了一种安全的方式来修改世界，允许系统并行执行。关于 Commands 的详细使用方法，请参考命令（Commands）章节。","在游戏开发中的应用场景#在游戏开发中的应用场景":"实体在游戏开发中有广泛的应用：\n游戏对象：玩家、敌人、道具等游戏对象都是实体 层次结构：场景图、UI 层次结构等 实体管理：实体池、实体禁用等","基础用法#基础用法":"","实体-id#实体 ID":"每个实体都有唯一的 ID，可以通过 .id() 方法获取。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 调用 `.id()` 在生成实体后将返回生成实体的 `Entity` 标识符 // 即使实体本身尚未在世界中实例化 // 这有效是因为 Commands 会在实际生成实体之前通过原子计数器保留实体 ID let alice = commands.spawn(Name::new(\"Alice\")).id(); let bob = commands.spawn((Name::new(\"Bob\"), Targeting(alice))).id(); 关键要点：\n使用 .id() 方法获取实体 ID 实体 ID 在实体创建之前就可以获取 实体 ID 是唯一的，可以用于引用实体 实体 ID 可以存储在组件中，用于建立实体间的关系 说明： 实体 ID 是实体的唯一标识符。即使在实体创建之前，也可以通过 Commands 获取实体 ID。这使得可以在创建实体时建立实体间的关系。","实体层次结构#实体层次结构":"实体可以形成层次结构，通过 ChildOf 和 Children 组件实现父子关系。\n源代码文件：bevy/examples/ecs/hierarchy.rs\n代码示例：\nfn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(Camera2d); let texture = asset_server.load(\"branding/icon.png\"); // 生成一个没有父实体的根实体 let parent = commands .spawn(( Sprite::from_image(texture.clone()), Transform::from_scale(Vec3::splat(0.75)), )) // 以该实体作为父实体，运行一个 lambda 来生成其子实体 .with_children(|parent| { // parent 是一个 ChildSpawnerCommands，具有与 Commands 类似的 API parent.spawn(( Transform::from_xyz(250.0, 0.0, 0.0).with_scale(Vec3::splat(0.75)), Sprite { image: texture.clone(), color: BLUE.into(), ..default() }, )); }) .id(); // 另一种方法是使用 add_child 函数在父实体已经生成后添加子实体 let child = commands .spawn(( Sprite { image: texture, color: LIME.into(), ..default() }, Transform::from_xyz(0.0, 250.0, 0.0).with_scale(Vec3::splat(0.75)), )) .id(); // 将子实体添加到父实体 commands.entity(parent).add_child(child); } // 一个简单的系统来旋转根实体，并分别旋转其所有子实体 fn rotate( mut commands: Commands, time: Res\u003cTime\u003e, mut parents_query: Query\u003c(Entity, \u0026Children), With\u003cSprite\u003e\u003e, mut transform_query: Query\u003c\u0026mut Transform, With\u003cSprite\u003e\u003e, ) { for (parent, children) in \u0026mut parents_query { if let Ok(mut transform) = transform_query.get_mut(parent) { transform.rotate_z(-PI / 2. * time.delta_secs()); } // 要遍历实体的子实体，只需将 Children 组件视为 Vec // 或者，你可以查询具有 ChildOf 组件的实体 for child in children { if let Ok(mut transform) = transform_query.get_mut(*child) { transform.rotate_z(PI * time.delta_secs()); } } } } 关键要点：\n使用 with_children() 方法在创建实体时添加子实体 使用 add_child() 方法在实体创建后添加子实体 使用 Children 组件访问子实体列表 使用 ChildOf 组件访问父实体 当添加 DefaultPlugins 时，系统会自动传播 Transform 和 Visibility 从父实体到子实体 注意事项：\n层次结构通过 ChildOf 和 Children 组件实现 销毁父实体会自动销毁所有子实体 可以通过移除 ChildOf 组件来断开父子关系 最佳实践：\n使用层次结构组织相关的实体 注意层次结构对变换和可见性传播的影响 合理使用层次结构，避免过深的嵌套","实体的设计思想#实体的设计思想":"实体采用数据导向的设计思想，将数据（组件）和标识符（实体）分离。这种设计使得：\n实体可以灵活组合不同的组件 系统可以高效查询具有特定组件的实体 实体可以动态添加和移除组件","实体禁用#实体禁用":"实体禁用允许你隐藏实体而不删除它们。这对于实现\"休眠\"对象或管理网络实体很有用。\n源代码文件：bevy/examples/ecs/entity_disabling.rs\n代码示例：\nuse bevy::ecs::entity_disabling::Disabled; use bevy::prelude::*; fn disable_entities_on_click( click: On\u003cPointer\u003cClick\u003e\u003e, valid_query: Query\u003c\u0026DisableOnClick\u003e, mut commands: Commands, ) { if valid_query.contains(click.entity) { // 只需将 `Disabled` 组件添加到实体即可禁用它 // 注意 `Disabled` 组件只添加到实体本身，其子实体不受影响 commands.entity(click.entity).insert(Disabled); } } // 这里的查询不会找到具有 `Disabled` 组件的实体 // 因为它没有明确包含它 fn list_all_named_entities( query: Query\u003c\u0026Name\u003e, mut name_text_query: Query\u003c\u0026mut Text, With\u003cEntityNameText\u003e\u003e, mut commands: Commands, ) { // 查询会自动跳过被禁用的实体 for name in query.iter().sort::\u003c\u0026Name\u003e() { // ... } } fn reenable_entities_on_space( mut commands: Commands, // 这个查询可以找到被禁用的实体 // 因为它明确包含了 `Disabled` 组件 disabled_entities: Query\u003cEntity, With\u003cDisabled\u003e\u003e, input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, ) { if input.just_pressed(KeyCode::Space) { for entity in disabled_entities.iter() { // 要重新启用实体，只需移除 `Disabled` 组件 commands.entity(entity).remove::\u003cDisabled\u003e(); } } } 关键要点：\n使用 Disabled 组件禁用实体 被禁用的实体会被默认查询过滤器跳过 可以通过明确包含 Disabled 组件来查询被禁用的实体 禁用实体不会影响其子实体 注意事项：\n禁用实体会使它们对 ECS 不可见，但这不是其主要目的 Visibility 应该用于隐藏实体 被禁用的实体会被完全跳过，这可能导致微妙的错误 最佳实践：\n使用 Visibility 隐藏实体 使用 Disabled 禁用不需要处理的实体 注意禁用实体对查询的影响","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何获取实体的 ID？\n解决方案：使用 .id() 方法在创建实体时获取 ID，或使用查询获取实体的 ID。\n问题 2：如何禁用实体而不删除它们？\n解决方案：使用 Disabled 组件禁用实体。被禁用的实体会被默认查询过滤器跳过。\n问题 3：如何建立实体间的层次结构？\n解决方案：使用 with_children() 或 add_child() 方法建立父子关系。Bevy 会自动管理 ChildOf 和 Children 组件。","性能考虑#性能考虑":"实体创建：批量创建实体比逐个创建更高效 实体查询：使用查询过滤器减少查询的实体数量 实体禁用：禁用不需要处理的实体可以提高性能","核心概念#核心概念":"","概述#概述":"学习目标：\n理解实体的概念和作用 掌握如何创建和操作实体 了解实体 ID 的使用方法 理解实体禁用和层次结构 前置知识要求：\n核心编程框架（ECS） 组件（Components） Rust 基础语法","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ecs/ecs_guide.rs - ECS 完整指南示例（实体创建） bevy/examples/ecs/entity_disabling.rs - 实体禁用示例 bevy/examples/ecs/hierarchy.rs - 实体层次结构示例 官方文档链接：\nBevy Entity 官方文档 Entity 禁用文档 Hierarchy 文档 进一步学习建议：\n学习系统（Systems），了解如何处理实体 学习查询（Queries），了解如何查询实体 学习关系系统（Relationships），了解如何建立实体间的关系 索引：返回上级目录","进阶用法#进阶用法":""},"title":"实体（Entities）"},"/wiki/bevybook/ecs/%E6%97%B6%E9%97%B4%E7%B3%BB%E7%BB%9Ftime/":{"data":{"":"","什么是时间系统#什么是时间系统？":"时间系统是 Bevy 中用于管理游戏时间的功能。时间系统提供了多种时间类型，包括真实时间、虚拟时间和固定时间步。\n为什么需要时间系统？\n游戏逻辑：时间系统可以控制游戏逻辑的执行速度 动画：时间系统可以控制动画的播放速度 物理模拟：时间系统可以控制物理模拟的时间步 游戏暂停：时间系统可以实现游戏暂停功能","在游戏开发中的应用场景#在游戏开发中的应用场景":"时间系统在游戏开发中有广泛的应用：\n游戏逻辑：控制游戏逻辑的执行速度 动画：控制动画的播放速度 物理模拟：控制物理模拟的时间步 游戏暂停：实现游戏暂停功能 定时任务：实现延迟和周期性任务","基础用法#基础用法":"","定时器#定时器":"使用定时器实现延迟和周期性任务。\n源代码文件：bevy/examples/time/timers.rs\n代码示例：\nuse bevy::{log::info, prelude::*}; fn main() { App::new() .add_plugins(DefaultPlugins) .init_resource::\u003cCountdown\u003e() .add_systems(Startup, setup) .add_systems(Update, (countdown, print_when_completed)) .run(); } #[derive(Component, Deref, DerefMut)] struct PrintOnCompletionTimer(Timer); #[derive(Resource)] struct Countdown { percent_trigger: Timer, main_timer: Timer, } impl Countdown { pub fn new() -\u003e Self { Self { percent_trigger: Timer::from_seconds(4.0, TimerMode::Repeating), main_timer: Timer::from_seconds(20.0, TimerMode::Once), } } } impl Default for Countdown { fn default() -\u003e Self::new() } } fn setup(mut commands: Commands) { // 向世界添加一个带有定时器的实体 commands.spawn(PrintOnCompletionTimer(Timer::from_seconds( 5.0, TimerMode::Once, ))); } /// 此系统使用 bevy 的 `Time` 资源来获取每次更新之间的增量， /// 对具有 `PrintOnCompletionTimer` 组件的实体上的 `Timer` 进行计时。 fn print_when_completed(time: Res\u003cTime\u003e, mut query: Query\u003c\u0026mut PrintOnCompletionTimer\u003e) { for mut timer in \u0026mut query { if timer.tick(time.delta()).just_finished() { info!(\"Entity timer just finished\"); } } } /// 此系统控制倒计时资源内的定时器计时并处理其状态。 fn countdown(time: Res\u003cTime\u003e, mut countdown: ResMut\u003cCountdown\u003e) { countdown.main_timer.tick(time.delta()); // API 鼓励这种定时器状态检查（如果您只检查一个值） // 此外，由于定时器是重复的，`is_finished()` 会完成与 `just_finished` 相同的事情， // 但这在视觉上更有意义。 if countdown.percent_trigger.tick(time.delta()).just_finished() { if !countdown.main_timer.is_finished() { // 打印主定时器完成的百分比。 info!( \"Timer is {:0.0}% complete!\", countdown.main_timer.fraction() * 100.0 ); } else { // 定时器已完成，因此我们暂停百分比输出定时器 countdown.percent_trigger.pause(); info!(\"Paused percent trigger timer\"); } } } 关键要点：\n使用 Timer::from_seconds() 创建定时器 使用 TimerMode::Once 创建单次定时器 使用 TimerMode::Repeating 创建重复定时器 使用 timer.tick() 更新定时器 使用 timer.just_finished() 检查定时器是否刚完成 使用 timer.is_finished() 检查定时器是否完成 使用 timer.fraction() 获取定时器完成的百分比 说明： 定时器是时间系统的重要功能。通过使用定时器，可以实现延迟和周期性任务。","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何获取时间增量？\n解决方案：\n使用 Time::delta() 获取时间增量 使用 Time::delta_secs() 获取时间增量（秒） 使用 Time::delta_secs_f64() 获取时间增量（秒，f64） 问题 2：如何创建定时器？\n解决方案：\n使用 Timer::from_seconds() 创建定时器 使用 TimerMode::Once 创建单次定时器 使用 TimerMode::Repeating 创建重复定时器 问题 3：如何控制游戏速度？\n解决方案：\n使用 Time::set_relative_speed() 设置相对速度 使用 Time::pause() 暂停时间 使用 Time::unpause() 恢复时间","性能考虑#性能考虑":"时间资源：时间资源是轻量级的，可以频繁访问 定时器：定时器更新是高效的，可以大量使用 虚拟时间：虚拟时间计算是高效的，可以用于控制游戏速度","时间系统的核心组件#时间系统的核心组件":"Bevy 时间系统包含以下核心组件：\nTime：真实时间，不受游戏速度影响 Time：虚拟时间，受游戏速度影响 Time：固定时间步，用于物理模拟 Timer：定时器，用于延迟和周期性任务","时间资源#时间资源":"使用时间资源获取时间信息。\n源代码文件：bevy/examples/time/time.rs\n代码示例：\nuse bevy::{app::AppExit, prelude::*}; use std::{ io::{self, BufRead}, time::Duration, }; fn main() { App::new() .add_plugins(MinimalPlugins) .insert_resource(Time::\u003cVirtual\u003e::from_max_delta(Duration::from_secs(5))) .insert_resource(Time::\u003cFixed\u003e::from_duration(Duration::from_secs(1))) .add_systems(PreUpdate, print_real_time) .add_systems(FixedUpdate, print_fixed_time) .add_systems(Update, print_time) .set_runner(runner) .run(); } fn print_real_time(time: Res\u003cTime\u003cReal\u003e\u003e) { println!( \"PreUpdate: this is real time clock, delta is {:?} and elapsed is {:?}\", time.delta(), time.elapsed() ); } fn print_fixed_time(time: Res\u003cTime\u003e) { println!( \"FixedUpdate: this is generic time clock inside fixed, delta is {:?} and elapsed is {:?}\", time.delta(), time.elapsed() ); } fn print_time(time: Res\u003cTime\u003e) { println!( \"Update: this is generic time clock, delta is {:?} and elapsed is {:?}\", time.delta(), time.elapsed() ); } 关键要点：\n使用 Time 获取真实时间 使用 Time 获取虚拟时间 使用 Time 获取固定时间步 使用 time.delta() 获取时间增量 使用 time.elapsed() 获取经过的时间 说明： 时间资源是时间系统的基础。通过使用时间资源，可以获取时间信息，控制游戏逻辑的执行速度。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 时间系统的基本概念 掌握时间资源的使用 了解定时器的使用 学会使用虚拟时间 前置知识要求：\nBevy 快速入门 ECS 基础 资源（Resources）基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/time/time.rs - 时间系统基础示例 bevy/examples/time/timers.rs - 定时器示例 bevy/examples/time/virtual_time.rs - 虚拟时间示例 官方文档链接：\nBevy 时间系统 Bevy 时间示例 进一步学习建议：\n学习系统调度，了解固定时间步的使用 学习资源管理，了解资源的生命周期 索引：返回上级目录","虚拟时间#虚拟时间":"使用虚拟时间控制游戏速度。\n源代码文件：bevy/examples/time/virtual_time.rs\n代码示例：\nuse std::time::Duration; use bevy::{ color::palettes::css::*, input::common_conditions::input_just_pressed, prelude::*, time::common_conditions::on_real_timer, }; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .add_systems( Update, ( move_virtual_time_sprites, move_real_time_sprites, toggle_pause.run_if(input_just_pressed(KeyCode::Space)), change_time_speed::\u003c1\u003e.run_if(input_just_pressed(KeyCode::ArrowUp)), change_time_speed::\u003c-1\u003e.run_if(input_just_pressed(KeyCode::ArrowDown)), (update_virtual_time_info_text, update_real_time_info_text) // 在定时器上更新文本以使其更易读 // `on_timer` 运行条件使用 `Virtual` 时间，这意味着它是缩放的 // 并且会根据 `Time::relative_speed` 和 `Time::is_paused()` 以不同的间隔更新 UI .run_if(on_real_timer(Duration::from_millis(250))), ), ) .run(); } /// `Real` 时间相关标记 #[derive(Component)] struct RealTime; /// `Virtual` 时间相关标记 #[derive(Component)] struct VirtualTime; /// 设置示例 fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e, mut time: ResMut\u003cTime\u003cVirtual\u003e\u003e) { // 从双倍 `Virtual` 时间开始，导致一个精灵以另一个精灵的两倍速度移动， // 另一个精灵基于 `Real`（未缩放）时间移动 time.set_relative_speed(2.); commands.spawn(Camera2d); // ... 创建精灵和 UI ... } /// 使用 `Virtual`（缩放）时间移动精灵 fn move_virtual_time_sprites( mut sprite_query: Query\u003c\u0026mut Transform, (With\u003cSprite\u003e, With\u003cVirtualTime\u003e)\u003e, // 默认 `Time` 在常规系统中是 `Time`， // 或在固定时间步系统中是 `Time`，因此 `Time::delta()`、 // `Time::elapsed()` 将返回适当的值 time: Res\u003cTime\u003e, ) { for mut transform in sprite_query.iter_mut() { // 在 `Virtual` 秒内移动大约屏幕的一半 // 当使用 `Time::set_relative_speed` 缩放时间时， // 它会以不同的速度移动，当时间暂停时精灵会保持静止 transform.translation.x = get_sprite_translation_x(time.elapsed_secs()); } } /// 更新 `Time` 的速度，增量为 `DELTA` fn change_time_speed\u003cconst DELTA: i8\u003e(mut time: ResMut\u003cTime\u003cVirtual\u003e\u003e) { let time_speed = (time.relative_speed() + DELTA as f32) .round() .clamp(0.25, 5.); // 设置虚拟时间的速度以加快或减慢速度 time.set_relative_speed(time_speed); } /// 暂停或恢复 `Relative` 时间 fn toggle_pause(mut time: ResMut\u003cTime\u003cVirtual\u003e\u003e) { if time.is_paused() { time.unpause(); } else { time.pause(); } } 关键要点：\n使用 Time 获取虚拟时间 使用 time.set_relative_speed() 设置相对速度 使用 time.pause() 暂停时间 使用 time.unpause() 恢复时间 使用 time.is_paused() 检查时间是否暂停 说明： 虚拟时间是时间系统的高级功能。通过使用虚拟时间，可以控制游戏速度，实现游戏暂停和加速功能。","进阶用法#进阶用法":""},"title":"时间系统（Time）"},"/wiki/bevybook/ecs/%E6%9F%A5%E8%AF%A2queries/":{"data":{"":"","什么是查询#什么是查询？":"查询用于访问具有特定组件的实体。查询会自动过滤出具有指定组件的实体，并允许系统对这些实体进行操作。\n为什么使用查询？\n自动过滤：查询自动过滤出具有指定组件的实体 高效访问：查询提供高效的组件访问方式 并行执行：查询可以并行执行，提高性能","在游戏开发中的应用场景#在游戏开发中的应用场景":"查询在游戏开发中有广泛的应用：\n游戏对象访问：访问玩家、敌人、道具等游戏对象 碰撞检测：使用查询组合检测实体间的碰撞 性能优化：使用并行查询提高系统执行效率","基本查询#基本查询":"使用 Query 查询具有特定组件的实体。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 这个系统更新所有具有 `Player`、`Score` 和 `PlayerStreak` 组件的实体的分数 fn score_system(mut query: Query\u003c(\u0026Player, \u0026mut Score, \u0026mut PlayerStreak)\u003e) { for (player, mut score, mut streak) in \u0026mut query { let scored_a_point = random::\u003cbool\u003e(); if scored_a_point { // 不可变访问组件通过常规引用完成 - `player` 的类型是 `\u0026Player` // 可变访问组件通过 `Mut` 类型完成 - `score` 的类型是 `Mut` // `Mut` 实现了 `Deref`，所以可以使用标准字段更新语法 score.value += 1; // 匹配枚举需要解引用 *streak = match *streak { PlayerStreak::Hot(n) =\u003e PlayerStreak::Hot(n + 1), PlayerStreak::Cold(_) | PlayerStreak::None =\u003e PlayerStreak::Hot(1), }; println!( \"{} scored a point! Their score is: {} ({})\", player.name, score.value, *streak ); } } } // 这个系统在所有具有 `Player` 和 `Score` 组件的实体上运行 // 它还访问 `GameRules` 资源来确定玩家是否获胜 fn score_check_system( game_rules: Res\u003cGameRules\u003e, mut game_state: ResMut\u003cGameState\u003e, query: Query\u003c(\u0026Player, \u0026Score)\u003e, ) { for (player, score) in \u0026query { if score.value == game_rules.winning_score { game_state.winning_player = Some(player.name.clone()); } } } 关键要点：\n使用 Query 查询具有特定组件的实体 \u0026T 表示不可变访问组件 \u0026mut T 表示可变访问组件 查询可以同时访问多个组件 使用 Mut 类型进行可变访问 说明： 查询是访问组件的主要方式。查询会自动过滤出具有指定组件的实体，并允许系统对这些实体进行操作。查询可以并行执行，提高性能。","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何查询具有多个组件的实体？\n解决方案：使用元组查询多个组件，如 Query\u003c(\u0026ComponentA, \u0026ComponentB)\u003e。\n问题 2：如何查询不具有特定组件的实体？\n解决方案：使用 Without 过滤器，如 Query\u003c\u0026ComponentA, Without\u003e。\n问题 3：如何优化查询性能？\n解决方案：\n只查询需要的组件 使用查询过滤器减少查询的实体数量 对于计算密集型操作，使用并行查询","并行查询#并行查询":"并行查询使用并行迭代器提高系统执行效率。\n源代码文件：bevy/examples/ecs/parallel_query.rs\n代码示例：\nuse bevy::{ecs::batching::BatchingStrategy, prelude::*}; #[derive(Component, Deref)] struct Velocity(Vec2); // 根据速度移动精灵 fn move_system(mut sprites: Query\u003c(\u0026mut Transform, \u0026Velocity)\u003e) { // 在 ComputeTaskPool 上并行计算每个精灵的新位置 // // 此示例仅用于演示目的。对于像加法这样便宜的操作，在只有 128 个元素时 // 使用 ParallelIterator 通常不会比使用普通 Iterator 更快 // 有关何时使用或不使用 ParallelIterator 的更多信息，请参阅 ParallelIterator 文档 sprites .par_iter_mut() .for_each(|(mut transform, velocity)| { transform.translation += velocity.extend(0.0); }); } // 在窗口外反弹精灵 fn bounce_system(window: Query\u003c\u0026Window\u003e, mut sprites: Query\u003c(\u0026Transform, \u0026mut Velocity)\u003e) { let Ok(window) = window.single() else { return; }; let width = window.width(); let height = window.height(); let left = width / -2.0; let right = width / 2.0; let bottom = height / -2.0; let top = height / 2.0; // 也可以覆盖默认批次大小 // 在这种情况下，选择批次大小为 32 以限制 ParallelIterator 的开销 // 因为取反向量非常便宜 sprites .par_iter_mut() .batching_strategy(BatchingStrategy::fixed(32)) .for_each(|(transform, mut v)| { if !(left \u003c transform.translation.x \u0026\u0026 transform.translation.x \u003c right \u0026\u0026 bottom \u003c transform.translation.y \u0026\u0026 transform.translation.y \u003c top) { // 为简单起见，只反转速度；不使用真实的反弹 v.0 = -v.0; } }); } 关键要点：\n使用 par_iter_mut() 获取并行迭代器 使用 batching_strategy() 自定义批处理策略 并行查询适用于计算密集型操作 对于简单操作，并行查询可能不会更快 注意事项：\n并行查询适用于计算密集型操作 对于简单操作，并行查询可能不会更快 可以使用 batching_strategy() 自定义批处理策略 最佳实践：\n只在计算密集型操作时使用并行查询 对于简单操作，使用普通查询 根据操作复杂度调整批处理策略","性能考虑#性能考虑":"查询优化：只查询需要的组件，减少查询开销 并行执行：查询可以并行执行，但可变访问会阻止并行 查询组合：注意性能影响，考虑使用空间分区","查询的设计思想#查询的设计思想":"查询采用数据导向的设计思想，将数据（组件）和逻辑（系统）分离。这种设计使得：\n系统可以高效访问组件 查询可以并行执行，提高性能 查询可以灵活组合，实现复杂的查询需求","查询组合#查询组合":"查询组合用于处理实体间的交互，如碰撞检测。\n源代码文件：bevy/examples/ecs/iter_combinations.rs\n代码示例：\nuse bevy::prelude::*; const GRAVITY_CONSTANT: f32 = 0.001; #[derive(Component, Default)] struct Mass(f32); #[derive(Component, Default)] struct Acceleration(Vec3); fn interact_bodies(mut query: Query\u003c(\u0026Mass, \u0026GlobalTransform, \u0026mut Acceleration)\u003e) { let mut iter = query.iter_combinations_mut(); while let Some([(Mass(m1), transform1, mut acc1), (Mass(m2), transform2, mut acc2)]) = iter.fetch_next() { let delta = transform2.translation() - transform1.translation(); let distance_sq: f32 = delta.length_squared(); let f = GRAVITY_CONSTANT / distance_sq; let force_unit_mass = delta * f; acc1.0 += force_unit_mass * *m2; acc2.0 -= force_unit_mass * *m1; } } 关键要点：\n使用 iter_combinations_mut() 获取可变组合迭代器 使用 fetch_next() 获取下一对实体 查询组合会跳过重复的组合（如 (A, B) 和 (B, A)） 查询组合用于处理实体间的成对交互 注意事项：\n查询组合用于处理实体间的成对交互 查询组合会跳过重复的组合 查询组合对于大量实体可能较慢 最佳实践：\n使用查询组合处理碰撞检测、物理交互等场景 注意性能影响，对于大量实体考虑使用空间分区 考虑使用并行查询组合提高性能","查询过滤器#查询过滤器":"使用查询过滤器进一步过滤查询结果。\n源代码文件：bevy/examples/ecs/change_detection.rs\n代码示例：\n/// 查询过滤器如 [`Changed`] 和 [`Added`] 确保只有匹配这些过滤器的实体 /// 才会被查询返回 /// /// 使用 [`Ref`] 系统参数允许你访问变更检测信息，但不会过滤查询 fn change_detection( changed_components: Query\u003cRef\u003cMyComponent\u003e, Changed\u003cMyComponent\u003e\u003e, my_resource: Res\u003cMyResource\u003e, ) { for component in \u0026changed_components { // 默认情况下，你只能知道组件被改变了 // 但如果有多个系统修改同一个组件，如何知道是哪个系统导致的改变？ warn!( \"Change detected!\\n\\t-\u003e value: {:?}\\n\\t-\u003e added: {}\\n\\t-\u003e changed: {}\\n\\t-\u003e changed by: {}\", component, component.is_added(), component.is_changed(), // 如果启用 `track_location` 特性，可以解锁 `changed_by()` 方法 // 它返回组件或资源被改变的文件和行号 // 不建议在发布的游戏中使用，但对调试很有用！ component.changed_by() ); } } 关键要点：\n使用 Changed 过滤器查询已变更的组件 使用 Added 过滤器查询新添加的组件 使用 With 过滤器查询具有特定组件的实体 使用 Without 过滤器查询不具有特定组件的实体 使用 Ref 访问变更检测信息，但不过滤查询 说明： 查询过滤器用于进一步过滤查询结果。使用 Changed 过滤器可以只查询已变更的组件，这对于性能优化很重要。使用 Added 过滤器可以只查询新添加的组件。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解查询的概念和作用 掌握如何定义和使用查询 了解查询过滤器的使用方法 理解自定义查询参数和查询组合 前置知识要求：\n核心编程框架（ECS） 组件（Components） 实体（Entities） 系统（Systems） Rust 基础语法","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ecs/ecs_guide.rs - ECS 完整指南示例（查询使用） bevy/examples/ecs/change_detection.rs - 变更检测示例（查询过滤器） bevy/examples/ecs/custom_query_param.rs - 自定义查询参数示例 bevy/examples/ecs/iter_combinations.rs - 查询组合示例 bevy/examples/ecs/parallel_query.rs - 并行查询示例 官方文档链接：\nBevy Query 官方文档 QueryData 文档 QueryFilter 文档 进一步学习建议：\n学习系统（Systems），了解如何在系统中使用查询 学习组件（Components），了解如何定义组件 学习 ECS 进阶，了解查询的高级功能 索引：返回上级目录","自定义查询参数#自定义查询参数":"使用 QueryData 派生宏定义自定义查询类型，避免使用元组。\n源代码文件：bevy/examples/ecs/custom_query_param.rs\n代码示例：\nuse bevy::{ ecs::query::{QueryData, QueryFilter}, prelude::*, }; #[derive(Component, Debug)] struct ComponentA; #[derive(Component, Debug)] struct ComponentB; #[derive(Component, Debug)] struct ComponentC; #[derive(Component, Debug)] struct ComponentD; /// 虽然常规元组查询在大多数简单场景中工作得很好 /// 但使用声明为命名结构体的自定义查询可以带来以下优势： /// - 它们有助于避免解构或使用 `q.0, q.1, ...` 访问模式 /// - 使用结构体添加、移除组件或更改项目顺序大大减少了维护负担 /// - 命名结构体支持组合模式，使查询类型更容易重用 /// - 你可以绕过查询元组存在的 15 个组件的限制 #[derive(QueryData)] #[query_data(derive(Debug))] struct ReadOnlyCustomQuery\u003cT: Component + Debug, P: Component + Debug\u003e { entity: Entity, a: \u0026'static ComponentA, b: Option\u003c\u0026'static ComponentB\u003e, nested: NestedQuery, optional_nested: Option\u003cNestedQuery\u003e, optional_tuple: Option\u003c(\u0026'static ComponentB, \u0026'static ComponentZ)\u003e, generic: GenericQuery\u003cT, P\u003e, empty: EmptyQuery, } #[derive(QueryData)] #[query_data(derive(Debug))] struct NestedQuery { c: \u0026'static ComponentC, d: Option\u003c\u0026'static ComponentD\u003e, } #[derive(QueryData)] #[query_data(derive(Debug))] struct GenericQuery\u003cT: Component, P: Component\u003e { generic: (\u0026'static T, \u0026'static P), } #[derive(QueryFilter)] struct CustomQueryFilter\u003cT: Component, P: Component\u003e { _c: With\u003cComponentC\u003e, _d: With\u003cComponentD\u003e, _or: Or\u003c(Added\u003cComponentC\u003e, Changed\u003cComponentD\u003e, Without\u003cComponentZ\u003e)\u003e, _generic_tuple: (With\u003cT\u003e, With\u003cP\u003e), } fn print_components_read_only( query: Query\u003c ReadOnlyCustomQuery\u003cComponentC, ComponentD\u003e, CustomQueryFilter\u003cComponentC, ComponentD\u003e, \u003e, ) { println!(\"Print components (read_only):\"); for e in \u0026query { println!(\"Entity: {}\", e.entity); println!(\"A: {:?}\", e.a); println!(\"B: {:?}\", e.b); println!(\"Nested: {:?}\", e.nested); println!(\"Optional nested: {:?}\", e.optional_nested); println!(\"Optional tuple: {:?}\", e.optional_tuple); println!(\"Generic: {:?}\", e.generic); } println!(); } 关键要点：\n使用 QueryData 派生宏定义自定义查询类型 自定义查询类型可以避免使用元组 自定义查询类型可以支持组合模式 自定义查询类型可以绕过 15 个组件的限制 使用 QueryFilter 派生宏定义自定义过滤器类型 注意事项：\n自定义查询类型需要实现 QueryData trait 自定义过滤器类型需要实现 QueryFilter trait 使用 #[query_data(mutable)] 属性定义可变查询 最佳实践：\n对于复杂的查询，使用自定义查询类型 对于需要重用的查询，使用自定义查询类型 对于超过 15 个组件的查询，使用自定义查询类型","进阶用法#进阶用法":""},"title":"查询（Queries）"},"/wiki/bevybook/ecs/%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B%E6%A1%86%E6%9E%B6ecs/":{"data":{"":"","ecs-定义#ECS 定义":"源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n//! This is a guided introduction to Bevy's \"Entity Component System\" (ECS) //! All Bevy app logic is built using the ECS pattern, so definitely pay attention! //! //! Why ECS? //! * Data oriented: Functionality is driven by data //! * Clean Architecture: Loose coupling of functionality / prevents deeply nested inheritance //! * High Performance: Massively parallel and cache friendly //! //! ECS Definitions: //! //! Component: just a normal Rust data type. generally scoped to a single piece of functionality //! Examples: position, velocity, health, color, name //! //! Entity: a collection of components with a unique id //! Examples: Entity1 { Name(\"Alice\"), Position(0, 0) }, //! Entity2 { Name(\"Bill\"), Position(10, 5) } //! //! Resource: a shared global piece of data //! Examples: asset storage, messages, system state //! //! System: runs logic on entities, components, and resources //! Examples: move system, damage system 关键要点：\nComponent（组件）：普通 Rust 数据类型，通常专注于单一功能 示例：位置、速度、生命值、颜色、名称 Entity（实体）：具有唯一 ID 的组件集合 示例：Entity1 { Name(“Alice”), Position(0, 0) } Resource（资源）：共享的全局数据 示例：资源存储、消息、系统状态 System（系统）：在实体、组件和资源上运行逻辑的函数 示例：移动系统、伤害系统 说明： ECS 是 Bevy 的核心编程范式。所有 Bevy 应用逻辑都基于 ECS 模式构建。理解 ECS 是掌握 Bevy 的关键。","ecs-的优势#ECS 的优势":"ECS 模式相比传统面向对象编程有以下优势：\n性能优化：\n系统可以并行执行 数据布局优化，提高缓存命中率 减少内存分配 代码组织：\n系统可以独立开发和测试 组件可以灵活组合 避免深层继承 可扩展性：\n易于添加新功能 易于修改现有功能 易于重构","ecs-的适用场景#ECS 的适用场景":"ECS 模式特别适用于：\n游戏开发：游戏对象管理、系统组织、性能优化 模拟系统：物理模拟、AI 系统、渲染系统 数据密集型应用：需要高性能和并行处理的应用","ecs-设计思想#ECS 设计思想":"ECS 采用数据导向的设计思想，将数据（组件）和逻辑（系统）分离。这种设计使得：\n系统可以独立开发和测试 组件可以灵活组合 系统可以并行执行，提高性能","为什么使用-ecs#为什么使用 ECS？":"源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n//! Why ECS? //! * Data oriented: Functionality is driven by data //! * Clean Architecture: Loose coupling of functionality / prevents deeply nested inheritance //! * High Performance: Massively parallel and cache friendly 关键要点：\n数据导向：功能由数据驱动，而非继承层次 清晰架构：松耦合的功能，避免深层继承 高性能：大规模并行执行，缓存友好 说明： ECS 模式提供了数据导向的设计，功能由数据驱动，而非继承层次。这种设计使得系统可以独立开发和测试，组件可以灵活组合，系统可以并行执行，提高性能。","什么是-ecs#什么是 ECS？":"ECS（Entity Component System）是 Bevy 的核心编程范式。所有 Bevy 应用逻辑都基于 ECS 模式构建。\n为什么使用 ECS？\n数据导向：功能由数据驱动，而非继承层次 清晰架构：松耦合的功能，避免深层继承 高性能：大规模并行执行，缓存友好 ECS 的核心组成部分：\nComponent（组件）：普通 Rust 数据类型，通常专注于单一功能 Entity（实体）：具有唯一 ID 的组件集合 Resource（资源）：共享的全局数据 System（系统）：在实体、组件和资源上运行逻辑的函数","在游戏开发中的应用场景#在游戏开发中的应用场景":"ECS 模式在游戏开发中有广泛的应用：\n游戏对象管理：每个游戏对象（如玩家、敌人、道具）都是一个实体，具有不同的组件组合 系统组织：游戏逻辑按系统组织（如移动系统、渲染系统、物理系统） 性能优化：系统可以并行执行，提高游戏性能","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：ECS 与面向对象编程有什么区别？\n解决方案：\nECS 是数据导向的，面向对象是行为导向的 ECS 将数据（组件）和逻辑（系统）分离，面向对象将数据和行为封装在一起 ECS 更适合并行执行，面向对象更适合顺序执行 问题 2：何时使用组件，何时使用资源？\n解决方案：\n组件用于实体特有的数据（如位置、速度） 资源用于全局共享的数据（如游戏设置、资源存储） 如果数据是实体特有的，使用组件；如果是全局共享的，使用资源 问题 3：如何设计 ECS 系统？\n解决方案：\n将功能拆分为独立的系统 每个系统只访问需要的数据 保持系统和组件的粒度细 避免在单个系统中放置太多功能","性能考虑#性能考虑":"系统并行性：保持系统粒度细，只访问需要的数据 数据布局：相关组件应该放在一起，提高缓存命中率 查询优化：只查询需要的组件，减少查询开销","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 ECS（Entity Component System）的核心概念 理解为什么 Bevy 使用 ECS 模式 掌握 ECS 的基本组成部分 理解 ECS 的设计优势 前置知识要求：\nBevy 快速入门 Rust 基础语法 理解基本的编程概念","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ecs/ecs_guide.rs - ECS 完整指南示例 官方文档链接：\nBevy ECS 官方文档 ECS 设计模式 Bevy ECS 示例 进一步学习建议：\n学习 ECS 基础，了解如何定义组件、实体和系统 学习 ECS 进阶，了解高级功能和最佳实践 阅读 Bevy ECS 源码，深入理解实现原理 索引：返回上级目录","进阶用法#进阶用法":""},"title":"核心编程框架（ECS）"},"/wiki/bevybook/ecs/%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86state/":{"data":{"":"","什么是状态管理#什么是状态管理？":"状态管理是 Bevy 中用于控制应用流程的功能。状态管理允许您定义应用的不同状态（如菜单、游戏中、暂停等），并根据状态控制系统的执行。\n为什么需要状态管理？\n应用控制流：状态管理可以控制应用的不同阶段 系统组织：状态管理可以组织和管理系统 资源管理：状态管理可以管理不同状态的资源 代码清晰：状态管理可以使代码更清晰、更易维护","在游戏开发中的应用场景#在游戏开发中的应用场景":"状态管理在游戏开发中有广泛的应用：\n游戏流程：控制游戏的不同阶段（菜单、游戏中、暂停等） 系统组织：根据状态组织和管理系统 资源管理：管理不同状态的资源 代码清晰：使代码更清晰、更易维护","基本状态#基本状态":"创建和使用基本状态。\n源代码文件：bevy/examples/state/states.rs\n代码示例：\nuse bevy::{dev_tools::states::*, prelude::*}; fn main() { App::new() .add_plugins(DefaultPlugins) .init_state::\u003cAppState\u003e() // 或者我们可以使用 .insert_state(AppState::Menu) .add_systems(Startup, setup) // 此系统在我们进入 `AppState::Menu` 时运行，在 `StateTransition` 调度期间。 // 首先运行我们离开的状态的退出调度中的所有系统， // 然后运行我们进入的状态的进入调度中的所有系统。 .add_systems(OnEnter(AppState::Menu), setup_menu) // 相比之下，更新系统存储在 `Update` 调度中。它们只是 // 检查 `State` 资源的值，以查看是否应该在每帧运行。 .add_systems(Update, menu.run_if(in_state(AppState::Menu))) .add_systems(OnExit(AppState::Menu), cleanup_menu) .add_systems(OnEnter(AppState::InGame), setup_game) .add_systems( Update, (movement, change_color).run_if(in_state(AppState::InGame)), ) .add_systems(Update, log_transitions::\u003cAppState\u003e) .run(); } #[derive(Debug, Clone, Copy, Default, Eq, PartialEq, Hash, States)] enum AppState { #[default] Menu, InGame, } #[derive(Resource)] struct MenuData { button_entity: Entity, } fn setup(mut commands: Commands) { commands.spawn(Camera2d); } fn setup_menu(mut commands: Commands) { let button_entity = commands .spawn(( Node { // 居中按钮 width: percent(100), height: percent(100), justify_content: JustifyContent::Center, align_items: AlignItems::Center, ..default() }, children![( Button, Node { width: px(150), height: px(65), // 水平居中子文本 justify_content: JustifyContent::Center, // 垂直居中子文本 align_items: AlignItems::Center, ..default() }, BackgroundColor(NORMAL_BUTTON), children![( Text::new(\"Play\"), TextFont { font_size: 33.0, ..default() }, TextColor(Color::srgb(0.9, 0.9, 0.9)), )], )], )) .id(); commands.insert_resource(MenuData { button_entity }); } fn menu( mut next_state: ResMut\u003cNextState\u003cAppState\u003e\u003e, mut interaction_query: Query\u003c (\u0026Interaction, \u0026mut BackgroundColor), (Changed\u003cInteraction\u003e, With\u003cButton\u003e), \u003e, ) { for (interaction, mut color) in \u0026mut interaction_query { match *interaction { Interaction::Pressed =\u003e { *color = PRESSED_BUTTON.into(); next_state.set(AppState::InGame); } Interaction::Hovered =\u003e { *color = HOVERED_BUTTON.into(); } Interaction::None =\u003e { *color = NORMAL_BUTTON.into(); } } } } fn cleanup_menu(mut commands: Commands, menu_data: Res\u003cMenuData\u003e) { commands.entity(menu_data.button_entity).despawn(); } fn setup_game(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(Sprite::from_image(asset_server.load(\"branding/icon.png\"))); } 关键要点：\n使用 #[derive(States)] 创建状态类型 使用 init_state::() 初始化状态 使用 OnEnter 在进入状态时运行系统 使用 OnExit 在退出状态时运行系统 使用 in_state(T) 条件运行系统 使用 NextState 设置下一状态 说明： 基本状态是状态管理的基础。通过使用基本状态，可以控制应用的不同阶段，并根据状态控制系统的执行。","基础用法#基础用法":"","子状态substates#子状态（SubStates）":"使用子状态创建更复杂的状态模式。\n源代码文件：bevy/examples/state/sub_states.rs\n代码示例：\nuse bevy::{dev_tools::states::*, prelude::*}; #[derive(Debug, Clone, Copy, Default, Eq, PartialEq, Hash, States)] enum AppState { #[default] Menu, InGame, } // 在这种情况下，我们不是派生 `States`，而是派生 `SubStates` #[derive(Debug, Clone, Copy, Default, Eq, PartialEq, Hash, SubStates)] // 我们需要添加一个属性来告诉我们源状态是什么 // 以及它需要什么值。这将确保除非我们 // 在 [`AppState::InGame`] 中，否则 [`IsPaused`] 状态资源 // 将不存在。 #[source(AppState = AppState::InGame)] #[states(scoped_entities)] enum IsPaused { #[default] Running, Paused, } fn main() { App::new() .add_plugins(DefaultPlugins) .init_state::\u003cAppState\u003e() .add_sub_state::\u003cIsPaused\u003e() // 我们在这里设置子状态 .add_systems(Startup, setup) .add_systems(OnEnter(AppState::Menu), setup_menu) .add_systems(Update, menu.run_if(in_state(AppState::Menu))) .add_systems(OnExit(AppState::Menu), cleanup_menu) .add_systems(OnEnter(AppState::InGame), setup_game) .add_systems(OnEnter(IsPaused::Paused), setup_paused_screen) .add_systems( Update, ( // 这里我们不是依赖 [`AppState::InGame`]，而是依赖 // [`IsPaused::Running`]，因为我们不希望在暂停时移动或改变颜色 (movement, change_color).run_if(in_state(IsPaused::Running)), // 另一方面，暂停切换需要无论是否暂停都能工作， // 所以它使用 [`AppState::InGame`] 而不是。 toggle_pause.run_if(in_state(AppState::InGame)), ), ) .add_systems(Update, log_transitions::\u003cAppState\u003e) .run(); } 关键要点：\n使用 #[derive(SubStates)] 创建子状态 使用 #[source(AppState = AppState::InGame)] 指定源状态 使用 add_sub_state::() 添加子状态 子状态只在源状态存在时存在 说明： 子状态是状态管理的高级功能。通过使用子状态，可以创建更复杂的状态模式，同时依赖简单的枚举。","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何创建状态？\n解决方案：\n使用 #[derive(States)] 创建状态类型 使用 init_state::() 初始化状态 使用 insert_state(T) 插入初始状态 问题 2：如何切换状态？\n解决方案：\n使用 NextState::set() 设置下一状态 使用 NextState::set_if_neq() 仅在状态不同时设置 状态转换在 StateTransition 调度中处理 问题 3：如何根据状态运行系统？\n解决方案：\n使用 in_state(T) 条件运行系统 使用 OnEnter 在进入状态时运行系统 使用 OnExit 在退出状态时运行系统","性能考虑#性能考虑":"状态转换：状态转换在 StateTransition 调度中处理 系统条件：使用 in_state 条件可以减少不必要的系统执行 子状态：子状态只在源状态存在时存在，可以减少资源使用","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 状态管理的基本概念 掌握基本状态的使用 了解子状态和计算状态 学会使用自定义状态转换 前置知识要求：\nBevy 快速入门 ECS 基础 系统（Systems） 系统调度（Schedule \u0026 App）","状态管理的核心组件#状态管理的核心组件":"Bevy 状态管理包含以下核心组件：\nStates：状态 trait，用于定义状态类型 State：状态资源，用于读取当前状态 NextState：下一状态资源，用于设置下一状态 OnEnter：进入状态时的调度 OnExit：退出状态时的调度","相关资源#相关资源":"相关源代码文件：\nbevy/examples/state/states.rs - 基本状态示例 bevy/examples/state/sub_states.rs - 子状态示例 bevy/examples/state/computed_states.rs - 计算状态示例 bevy/examples/state/custom_transitions.rs - 自定义状态转换示例 官方文档链接：\nBevy 状态管理 Bevy 状态示例 进一步学习建议：\n学习系统调度，了解系统执行顺序 学习 ECS 进阶，了解高级功能 索引：返回上级目录","自定义状态转换#自定义状态转换":"创建自定义状态转换行为。\n源代码文件：bevy/examples/state/custom_transitions.rs\n关键信息：\n使用 StateTransition 调度处理状态转换 使用 StateTransitionEvent 监听状态转换事件 使用 OnReenter 和 OnReexit 创建自定义转换 使用 IdentityTransitionsPlugin 注册自定义转换 说明： 自定义状态转换是状态管理的高级功能。通过使用自定义状态转换，可以实现更复杂的状态转换行为。","计算状态computedstates#计算状态（ComputedStates）":"使用计算状态创建更复杂的状态模式。\n源代码文件：bevy/examples/state/computed_states.rs\n关键信息：\n使用 ComputedStates trait 创建计算状态 使用 SourceStates 指定源状态 使用 compute 函数计算状态值 计算状态可以从多个源状态计算 说明： 计算状态是状态管理的高级功能。通过使用计算状态，可以创建从其他状态计算得出的状态，实现更灵活的状态管理。","进阶用法#进阶用法":""},"title":"状态管理（State）"},"/wiki/bevybook/ecs/%E7%B3%BB%E7%BB%9F%E8%B0%83%E5%BA%A6schedule%E4%B8%8Eapp/":{"data":{"":"","schedule-的设计思想#Schedule 的设计思想":"Schedule 采用数据导向的设计思想，将系统执行顺序和逻辑分离。这种设计使得：\n系统可以灵活组织 系统执行顺序可以明确控制 系统可以并行执行，提高性能","什么是-schedule#什么是 Schedule？":"Schedule 控制系统执行策略和每个 tick 内系统的广泛顺序。每个系统都属于一个 Schedule，Schedule 控制系统的执行顺序。\n为什么使用 Schedule？\n执行顺序：Schedule 控制系统的执行顺序 执行策略：Schedule 控制系统的执行策略（并行或顺序） 生命周期：Schedule 控制系统的生命周期（启动、更新、结束等）","固定时间步fixed-timestep#固定时间步（Fixed Timestep）":"固定时间步允许系统以固定时间间隔运行，而不是每帧运行。\n源代码文件：bevy/examples/ecs/fixed_timestep.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) // 这个系统将每次更新运行一次（它应该匹配你的屏幕刷新率） .add_systems(Update, frame_update) // 将我们的系统添加到固定时间步 Schedule .add_systems(FixedUpdate, fixed_update) // 配置我们的固定时间步 Schedule 每秒运行两次 .insert_resource(Time::\u003cFixed\u003e::from_seconds(0.5)) .run(); } fn frame_update(mut last_time: Local\u003cf32\u003e, time: Res\u003cTime\u003e) { // 默认 `Time` 这里是 `Time` info!( \"time since last frame_update: {}\", time.elapsed_secs() - *last_time ); *last_time = time.elapsed_secs(); } fn fixed_update(mut last_time: Local\u003cf32\u003e, time: Res\u003cTime\u003e, fixed_time: Res\u003cTime\u003cFixed\u003e\u003e) { // 默认 `Time` 这里是 `Time` info!( \"time since last fixed_update: {}\\n\", time.elapsed_secs() - *last_time ); info!(\"fixed timestep: {}\\n\", time.delta_secs()); // 如果我们想看到超步，我们需要专门访问 `Time` info!( \"time accrued toward next fixed_update: {}\\n\", fixed_time.overstep().as_secs_f32() ); *last_time = time.elapsed_secs(); } 关键要点：\n使用 FixedUpdate Schedule 运行固定时间步系统 使用 Time::::from_seconds() 配置固定时间步 固定时间步系统以固定时间间隔运行 固定时间步适合物理模拟等需要稳定时间步的场景 注意事项：\n固定时间步系统以固定时间间隔运行 固定时间步适合物理模拟等需要稳定时间步的场景 注意固定时间步与帧率的区别 最佳实践：\n对于物理模拟等需要稳定时间步的系统，使用固定时间步 对于与帧率相关的系统，使用 Update Schedule 注意固定时间步与帧率的区别","在游戏开发中的应用场景#在游戏开发中的应用场景":"系统调度在游戏开发中有广泛的应用：\n游戏逻辑：使用 Update Schedule 运行游戏逻辑 物理模拟：使用 FixedUpdate Schedule 运行物理模拟 初始化：使用 Startup Schedule 运行初始化代码 清理：使用 Last Schedule 运行清理代码","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何控制系统执行顺序？\n解决方案：\n使用 .before() 和 .after() 方法控制顺序 使用系统集组织系统 使用 .chain() 方法链式系统 问题 2：如何创建自定义 Schedule？\n解决方案：\n使用 Schedule::new() 创建自定义 Schedule 使用 ScheduleLabel 派生宏定义 Schedule 标签 使用 MainScheduleOrder 配置 Schedule 顺序 问题 3：如何控制系统是否运行？\n解决方案：\n使用 .run_if() 方法添加运行条件 使用 .and() 和 .or() 组合运行条件 使用 not() 反转运行条件","性能考虑#性能考虑":"并行执行：系统可以并行执行，但可变访问会阻止并行 系统顺序：明确指定系统顺序可以提高性能 运行条件：注意运行条件的性能影响","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Schedule 的概念和作用 掌握如何控制系统执行顺序 了解自定义 Schedule 的创建方法 理解 App 的生命周期和运行条件 前置知识要求：\n核心编程框架（ECS） 系统（Systems） 资源（Resources） Rust 基础语法","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ecs/ecs_guide.rs - ECS 完整指南示例（系统调度） bevy/examples/ecs/custom_schedule.rs - 自定义 Schedule 示例 bevy/examples/ecs/fixed_timestep.rs - 固定时间步示例 bevy/examples/ecs/run_conditions.rs - 运行条件示例 bevy/examples/ecs/system_stepping.rs - 系统步进示例 bevy/examples/ecs/nondeterministic_system_order.rs - 非确定性系统顺序示例 官方文档链接：\nBevy Schedule 官方文档 App 官方文档 SystemSet 文档 进一步学习建议：\n学习系统（Systems），了解如何定义系统 学习资源（Resources），了解如何访问资源 学习 ECS 进阶，了解系统调度的高级功能 索引：返回上级目录","系统执行顺序#系统执行顺序":"可以通过 .before() 和 .after() 方法控制系统的执行顺序。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 系统执行顺序 // // 每个系统属于一个 `Schedule`，它控制执行策略和每个 tick 内系统的广泛顺序 // `Startup` schedule 保存启动系统，它们在 `Update` 运行之前运行一次 // `Update` 每次应用更新运行一次，通常是一\"帧\"或一\"tick\" // // 默认情况下，`Schedule` 中的所有系统并行运行，除非它们需要对数据的可变访问 // 这是高效的，但有时顺序很重要 // 例如，我们希望我们的\"游戏结束\"系统在所有其他系统之后执行 // 以确保我们不会意外地多运行一轮游戏 // // 你可以使用 `.before` 或 `.after` 方法强制系统之间的显式顺序 // 系统不会调度，直到它们具有\"顺序依赖\"的所有系统都已完成 // 还有其他 Schedule，如 `Last`，它在每次运行的末尾运行 .add_systems(Last, print_at_end_round) 关键要点：\n默认情况下，系统并行运行 使用 .before() 和 .after() 方法控制顺序 系统不会调度，直到依赖的系统完成 可变访问会阻止并行执行 说明： 默认情况下，系统并行运行，除非它们需要对数据的可变访问。使用 .before() 和 .after() 方法可以明确控制系统的执行顺序。系统不会调度，直到它们依赖的所有系统都已完成。","系统步进system-stepping#系统步进（System Stepping）":"系统步进允许逐步执行系统，用于调试。\n源代码文件：bevy/examples/ecs/system_stepping.rs\n代码示例：\nuse bevy::{ecs::schedule::Stepping, log::LogPlugin, prelude::*}; fn main() { let mut app = App::new(); app.add_plugins(LogPlugin::default()) .add_systems( Update, ( update_system_one, // 在这里建立依赖关系以简化下面的描述 update_system_two.after(update_system_one), update_system_three.after(update_system_two), update_system_four, ), ) .add_systems(PreUpdate, pre_update_system); // 添加 Stepping 资源 app.insert_resource(Stepping::new()); // 将 Update Schedule 添加到 Stepping // 启用 Stepping let mut stepping = app.world_mut().resource_mut::\u003cStepping\u003e(); stepping.add_schedule(Update).enable(); // 步进一帧 stepping.step_frame(); app.update(); // 继续执行剩余系统 stepping.continue_frame(); app.update(); } 关键要点：\n使用 Stepping 资源控制系统步进 使用 step_frame() 步进一帧 使用 continue_frame() 继续执行剩余系统 使用 always_run() 和 never_run() 控制特定系统的执行 注意事项：\n系统步进需要启用 bevy_debug_stepping 特性 系统步进主要用于调试 注意系统步进对性能的影响 最佳实践：\n对于调试，使用系统步进 对于生产环境，禁用系统步进 注意系统步进对性能的影响","系统集systemset#系统集（SystemSet）":"系统集用于组织相关系统，并控制它们的执行顺序。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n/// 一组相关的系统集，用于控制系统顺序 /// 系统可以添加到任意数量的集合中 #[derive(SystemSet, Debug, Hash, PartialEq, Eq, Clone)] enum MySystems { BeforeRound, Round, AfterRound, } fn main() { App::new() // 我们也可以创建新的系统集，并相对于其他系统集对它们进行排序 // 这是我们游戏的执行顺序： // \"before_round\": new_player_system, new_round_system // \"round\": print_message_system, score_system // \"after_round\": score_check_system, game_over_system .configure_sets( Update, // chain() 将确保集合按列出的顺序运行 ( MySystems::BeforeRound, MySystems::Round, MySystems::AfterRound, ) .chain(), ) // add_systems 函数很强大。你可以轻松定义复杂的系统配置！ .add_systems( Update, ( // 这些 `BeforeRound` 系统将在 `Round` 系统之前运行，这要归功于链式集合配置 ( // 你也可以链式系统！new_round_system 将首先运行，然后是 new_player_system (new_round_system, new_player_system).chain(), exclusive_player_system, ) // 上面元组中的所有系统都将添加到这个集合中 .in_set(MySystems::BeforeRound), // 这个 `Round` 系统将在 `BeforeRound` 系统之后运行，这要归功于链式集合配置 score_system.in_set(MySystems::Round), // 这些 `AfterRound` 系统将在 `Round` 系统之后运行，这要归功于链式集合配置 ( score_check_system, // 除了 chain()，你还可以使用 `before(system)` 和 `after(system)` // 这也适用于集合！ game_over_system.after(score_check_system), ) .in_set(MySystems::AfterRound), ), ) .run(); } 关键要点：\n使用 SystemSet 组织相关系统 使用 configure_sets() 配置系统集的顺序 使用 .chain() 方法链式系统集 使用 .in_set() 方法将系统添加到系统集 说明： 系统集用于组织相关系统，并控制它们的执行顺序。使用 configure_sets() 可以配置系统集的顺序，使用 .chain() 方法可以链式系统集。","自定义-schedule#自定义 Schedule":"可以创建自定义 Schedule，用于特定的执行策略。\n源代码文件：bevy/examples/ecs/custom_schedule.rs\n代码示例：\nuse bevy::{ app::MainScheduleOrder, ecs::schedule::{ExecutorKind, ScheduleLabel}, prelude::*, }; #[derive(ScheduleLabel, Debug, Hash, PartialEq, Eq, Clone)] struct SingleThreadedUpdate; #[derive(ScheduleLabel, Debug, Hash, PartialEq, Eq, Clone)] struct CustomStartup; fn main() { let mut app = App::new(); // 创建一个新的 [`Schedule`] // 为了演示目的，我们将其配置为使用单线程执行器 // 这样此 Schedule 中的系统永远不会并行运行 // 但是，这不是自定义 Schedule 的一般要求 let mut custom_update_schedule = Schedule::new(SingleThreadedUpdate); custom_update_schedule.set_executor_kind(ExecutorKind::SingleThreaded); // 将 Schedule 添加到应用不会自动运行它 // 这只是注册 Schedule，以便系统可以使用 `Schedules` 资源查找它 app.add_schedule(custom_update_schedule); // Bevy `App` 有一个 `main_schedule_label` 字段，它配置应用运行器运行哪个 Schedule // 默认情况下，这是 `Main` // `Main` Schedule 负责运行 Bevy 的主要 Schedule，如 `Update`、`Startup` 或 `Last` // // 我们可以通过修改 `MainScheduleOrder` 资源来配置 `Main` Schedule 运行我们的自定义更新 Schedule // 相对于现有的 Schedule // // 注意，我们在 `main` 中直接修改 `MainScheduleOrder`，而不是在启动系统中 // 原因是 `MainScheduleOrder` 不能从作为 `Main` Schedule 一部分运行的系统修改 let mut main_schedule_order = app.world_mut().resource_mut::\u003cMainScheduleOrder\u003e(); main_schedule_order.insert_after(Update, SingleThreadedUpdate); // 添加自定义启动 Schedule 的工作方式类似，但需要使用 `insert_startup_after` // 而不是 `insert_after` app.add_schedule(Schedule::new(CustomStartup)); let mut main_schedule_order = app.world_mut().resource_mut::\u003cMainScheduleOrder\u003e(); main_schedule_order.insert_startup_after(PreStartup, CustomStartup); app.add_systems(SingleThreadedUpdate, single_threaded_update_system) .add_systems(CustomStartup, custom_startup_system) .add_systems(PreStartup, pre_startup_system) .add_systems(Startup, startup_system) .add_systems(First, first_system) .add_systems(Update, update_system) .add_systems(Last, last_system) .run(); } 关键要点：\n使用 Schedule::new() 创建自定义 Schedule 使用 ScheduleLabel 派生宏定义 Schedule 标签 使用 set_executor_kind() 设置执行器类型 使用 MainScheduleOrder 配置 Schedule 顺序 注意事项：\n自定义 Schedule 需要添加到应用 需要配置 MainScheduleOrder 来运行自定义 Schedule 可以使用 ExecutorKind::SingleThreaded 创建单线程 Schedule 最佳实践：\n对于需要特定执行策略的系统，使用自定义 Schedule 对于需要单线程执行的系统，使用单线程 Schedule 注意自定义 Schedule 的执行顺序","运行条件run-conditions#运行条件（Run Conditions）":"运行条件允许控制系统是否应该运行。\n源代码文件：bevy/examples/ecs/run_conditions.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .init_resource::\u003cInputCounter\u003e() .add_systems( Update, ( increment_input_counter // common_conditions 模块有一些有用的运行条件 // 用于检查资源和状态 // 这些包含在 prelude 中 .run_if(resource_exists::\u003cInputCounter\u003e) // `.or()` 是一个运行条件组合器，只有在第一个条件返回 `false` 时才评估第二个条件 // 这种行为称为\"短路\"，是 Rust 中 `||` 运算符的工作方式（以及大多数 C 系列语言） // 在这种情况下，`has_user_input` 运行条件将被评估，因为 `Unused` 资源尚未初始化 .run_if(resource_exists::\u003cUnused\u003e.or( // 这是一个自定义运行条件，使用返回 `bool` 的系统定义 // 并且具有只读 `SystemParam` // 只有一个运行条件必须返回 `true`，系统才会运行 has_user_input, )), print_input_counter // `.and()` 是一个运行条件组合器，只有在第一个条件返回 `true` 时才评估第二个条件 // 类似于 `\u0026\u0026` 运算符 // 在这种情况下，短路行为防止第二个运行条件在 `InputCounter` 资源未初始化时 panic .run_if(resource_exists::\u003cInputCounter\u003e.and( // 这是一个闭包形式的自定义运行条件 // 这对于不需要重用的小型、简单的运行条件很有用 // 所有正常规则仍然适用：所有参数必须是只读的，除了本地参数 |counter: Res\u003cInputCounter\u003e| counter.is_changed() \u0026\u0026 !counter.is_added(), )), print_time_message // 这个函数返回一个自定义运行条件，很像 common_conditions 模块 // 它只会在 2 秒过去后返回 true .run_if(time_passed(2.0)) // 你可以使用 common_conditions 模块中的 `not` 条件 // 来反转运行条件 // 在这种情况下，如果自应用启动以来经过的时间少于 2.5 秒，它将返回 true .run_if(not(time_passed(2.5))), ), ) .run(); } /// 如果任何定义的输入刚刚被按下，则返回 true /// /// 这是一个自定义运行条件，它可以接受任何正常的系统参数 /// 只要它们是只读的（除了本地参数可以是可变的） /// 它返回一个 bool，决定系统是否应该运行 fn has_user_input( keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, mouse_button_input: Res\u003cButtonInput\u003cMouseButton\u003e\u003e, touch_input: Res\u003cTouches\u003e, ) -\u003e bool { keyboard_input.just_pressed(KeyCode::Space) || keyboard_input.just_pressed(KeyCode::Enter) || mouse_button_input.just_pressed(MouseButton::Left) || mouse_button_input.just_pressed(MouseButton::Right) || touch_input.any_just_pressed() } /// 这是一个返回闭包的函数，可以用作运行条件 /// /// 这很有用，因为你可以重用相同的运行条件，但使用不同的变量 /// 这就是 common_conditions 模块的工作方式 fn time_passed(t: f32) -\u003e impl FnMut(Local\u003cf32\u003e, Res\u003cTime\u003e) -\u003e bool { move |mut timer: Local\u003cf32\u003e, time: Res\u003cTime\u003e| { // 计时器计时 *timer += time.delta_secs(); // 如果计时器已经超过时间，返回 true *timer \u003e= t } } 关键要点：\n使用 .run_if() 方法添加运行条件 使用 .and() 和 .or() 组合运行条件 使用 not() 反转运行条件 运行条件可以是函数或闭包 注意事项：\n运行条件必须返回 bool 运行条件参数必须是只读的（除了本地参数） 只有所有运行条件都返回 true 时，系统才会运行 最佳实践：\n对于条件系统执行，使用运行条件 使用 .and() 和 .or() 组合运行条件 注意运行条件的性能影响","进阶用法#进阶用法":"","非确定性系统顺序#非确定性系统顺序":"默认情况下，Bevy 系统并行运行，除非明确指定顺序，否则它们的相对顺序是非确定性的。\n源代码文件：bevy/examples/ecs/nondeterministic_system_order.rs\n代码示例：\nuse bevy::{ ecs::schedule::{LogLevel, ScheduleBuildSettings}, prelude::*, }; fn main() { App::new() // 我们可以按每个 Schedule 修改系统执行顺序歧义的报告策略 // 你必须为每个要检查的 Schedule 执行此操作 // 在已检查的 Schedule 内执行的子 Schedule 不会继承此修改 .edit_schedule(Update, |schedule| { schedule.set_build_settings(ScheduleBuildSettings { ambiguity_detection: LogLevel::Warn, ..default() }); }) .init_resource::\u003cA\u003e() .init_resource::\u003cB\u003e() .add_systems( Update, ( // 这对系统有歧义顺序 // 因为它们的数据访问冲突，并且它们之间没有顺序 reads_a, writes_a, // 这对系统有冲突的数据访问 // 但通过显式顺序解决： // 这里的 .after 关系意味着我们总是在添加之后加倍 adds_one_to_b, doubles_b.after(adds_one_to_b), // 这个系统与 adds_one_to_b 没有歧义 // 由于我们的约束创建的传递顺序： // 如果 A 在 B 之前，B 在 C 之前，那么 A 必须在 C 之前 reads_b.after(doubles_b), // 这个系统将与我们的所有写入系统冲突 // 但我们已经用 adds_one_to_b 静默了它的歧义 // 这应该只在明显的假阳性情况下完成： // 在你的代码中留下注释证明这个决定！ reads_a_and_b.ambiguous_with(adds_one_to_b), ), ) .add_plugins(DefaultPlugins) .run(); } 关键要点：\n默认情况下，系统并行运行，顺序是非确定性的 使用 .after() 和 .before() 明确指定顺序 使用 .ambiguous_with() 静默歧义 使用 ScheduleBuildSettings 配置歧义检测 注意事项：\n非确定性顺序可能导致微妙的错误 使用 .after() 和 .before() 明确指定顺序 注意歧义检测的性能影响 最佳实践：\n对于有数据访问冲突的系统，明确指定顺序 使用 .ambiguous_with() 静默明显的假阳性 注意歧义检测的性能影响","默认-schedule#默认 Schedule":"Bevy 提供了多个默认 Schedule，如 Startup、Update、Last 等。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\nfn main() { App::new() // `Startup` 系统在应用启动时恰好运行一次 // 这些通常用于应用初始化代码（例如：添加实体和资源） .add_systems(Startup, startup_system) // `Update` 系统每次更新运行一次 // 这些通常用于\"实时应用逻辑\" .add_systems(Update, print_message_system) // 还有其他 Schedule，如 `Last`，它在每次运行的末尾运行 .add_systems(Last, print_at_end_round) .run(); } 关键要点：\nStartup：启动系统，在应用启动时运行一次 Update：更新系统，每次更新运行一次 Last：最后系统，在每次运行的末尾运行 系统按 Schedule 顺序执行 说明： Bevy 提供了多个默认 Schedule，用于控制系统的执行顺序。Startup 系统在应用启动时运行一次，用于初始化。Update 系统每次更新运行一次，用于游戏逻辑。Last 系统在每次运行的末尾运行，用于清理。"},"title":"系统调度（Schedule \u0026 App）"},"/wiki/bevybook/ecs/%E7%B3%BB%E7%BB%9Fsystems/":{"data":{"":"","一次性系统#一次性系统":"一次性系统在触发时运行一次，而不是每次更新都运行。\n源代码文件：bevy/examples/ecs/one_shot_systems.rs\n代码示例：\nuse bevy::{ ecs::system::{RunSystemOnce, SystemId}, prelude::*, }; #[derive(Component)] struct Callback(SystemId); #[derive(Component)] struct Triggered; fn setup_with_commands(mut commands: Commands) { let system_id = commands.register_system(system_a); commands.spawn((Callback(system_id), A)); } fn setup_with_world(world: \u0026mut World) { // 我们可以手动运行一次 world.run_system_once(system_b).unwrap(); // 或使用 Callback let system_id = world.register_system(system_b); world.spawn((Callback(system_id), B)); } /// 用 `Triggered` 组件标记具有我们想要运行的回调的实体 fn trigger_system( mut commands: Commands, query_a: Single\u003cEntity, With\u003cA\u003e\u003e, query_b: Single\u003cEntity, With\u003cB\u003e\u003e, input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, ) { if input.just_pressed(KeyCode::KeyA) { let entity = *query_a; commands.entity(entity).insert(Triggered); } if input.just_pressed(KeyCode::KeyB) { let entity = *query_b; commands.entity(entity).insert(Triggered); } } /// 如果实体也有 `Triggered` 组件，则运行与每个 `Callback` 组件关联的系统 /// /// 这可以在独占系统中完成，而不是使用 `Commands`（如果首选） fn evaluate_callbacks(query: Query\u003c(Entity, \u0026Callback), With\u003cTriggered\u003e\u003e, mut commands: Commands) { for (entity, callback) in query.iter() { commands.run_system(callback.0); commands.entity(entity).remove::\u003cTriggered\u003e(); } } fn system_a(entity_a: Single\u003cEntity, With\u003cText\u003e\u003e, mut writer: TextUiWriter) { *writer.text(*entity_a, 3) = String::from(\"A\"); info!(\"A: One shot system registered with Commands was triggered\"); } fn system_b(entity_b: Single\u003cEntity, With\u003cText\u003e\u003e, mut writer: TextUiWriter) { *writer.text(*entity_b, 3) = String::from(\"B\"); info!(\"B: One shot system registered with World was triggered\"); } 关键要点：\n一次性系统在触发时运行一次 使用 register_system() 注册系统 使用 run_system() 或 run_system_once() 运行系统 一次性系统可以用于推送式逻辑 注意事项：\n一次性系统可以减少很少运行的系统开销 一次性系统可以提高调度灵活性 一次性系统可以用于事件驱动的逻辑 最佳实践：\n对于很少运行的系统，使用一次性系统 对于事件驱动的逻辑，使用一次性系统 注意一次性系统的生命周期管理","什么是系统#什么是系统？":"系统是在实体、组件和资源上运行逻辑的函数。系统是 ECS 中的逻辑单元，用于处理游戏逻辑。\n为什么使用系统？\n逻辑分离：将游戏逻辑分离为独立的系统 并行执行：系统可以并行执行，提高性能 易于测试：系统可以独立测试","可失败系统参数#可失败系统参数":"可失败系统参数在无法获取时会跳过系统，而不是导致错误。\n源代码文件：bevy/examples/ecs/fallible_params.rs\n代码示例：\n// 这个系统只在恰好有一个匹配实体时运行 fn track_targets( // `Single` 确保系统只在恰好有一个匹配实体时运行 mut player: Single\u003c(\u0026mut Transform, \u0026Player)\u003e, // `Option` 永远不会阻止系统运行，但如果没有恰好一个匹配实体，它将是 `None` enemy: Option\u003cSingle\u003c\u0026Transform, (With\u003cEnemy\u003e, Without\u003cPlayer\u003e)\u003e\u003e, time: Res\u003cTime\u003e, ) { let (player_transform, player) = \u0026mut *player; if let Some(enemy_transform) = enemy { // 找到敌人，旋转并朝它移动 // ... } else { // 找到 0 个或多个敌人，继续搜索 // ... } } // 这个系统只在至少有一个匹配实体时运行 fn move_targets(mut enemies: Populated\u003c(\u0026mut Transform, \u0026mut Enemy)\u003e, time: Res\u003cTime\u003e) { for (mut transform, mut target) in \u0026mut *enemies { // ... } } 关键要点：\nSingle：必须有恰好一个匹配实体，否则系统会被静默跳过 Option","在游戏开发中的应用场景#在游戏开发中的应用场景":"系统在游戏开发中有广泛的应用：\n游戏逻辑：移动系统、伤害系统、AI 系统等 渲染系统：渲染系统、UI 系统等 物理系统：物理模拟、碰撞检测等","基础用法#基础用法":"","定义系统#定义系统":"系统是普通 Rust 函数，用于处理实体、组件和资源。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 这是最简单的系统类型。它只是每次运行时打印 \"This game is fun!\" fn print_message_system() { println!(\"This game is fun!\"); } // 系统也可以读取和修改资源。这个系统在每次更新时开始一个新的\"轮次\" // 注意：\"mut\" 表示资源是\"可变的\" // Res 是只读的。ResMut 可以修改资源 fn new_round_system(game_rules: Res\u003cGameRules\u003e, mut game_state: ResMut\u003cGameState\u003e) { game_state.current_round += 1; println!( \"Begin round {} of {}\", game_state.current_round, game_rules.max_rounds ); } // 这个系统更新所有具有 `Player`、`Score` 和 `PlayerStreak` 组件的实体的分数 fn score_system(mut query: Query\u003c(\u0026Player, \u0026mut Score, \u0026mut PlayerStreak)\u003e) { for (player, mut score, mut streak) in \u0026mut query { let scored_a_point = random::\u003cbool\u003e(); if scored_a_point { // 不可变访问组件通过常规引用完成 - `player` 的类型是 `\u0026Player` // 可变访问组件通过 `Mut` 类型完成 - `score` 的类型是 `Mut` // `Mut` 实现了 `Deref`，所以可以使用标准字段更新语法 score.value += 1; // 匹配枚举需要解引用 *streak = match *streak { PlayerStreak::Hot(n) =\u003e PlayerStreak::Hot(n + 1), PlayerStreak::Cold(_) | PlayerStreak::None =\u003e PlayerStreak::Hot(1), }; println!( \"{} scored a point! Their score is: {} ({})\", player.name, score.value, *streak ); } } } 关键要点：\n系统是普通 Rust 函数 系统可以访问资源（Res、ResMut） 系统可以查询组件（Query） 系统可以创建和修改实体（Commands） 系统在每次应用更新时运行 说明： 系统是 ECS 中的逻辑单元。系统通过查询访问组件，通过 Res 或 ResMut 访问资源。系统可以并行执行，提高性能。","实际应用#实际应用":"","常见问题#常见问题":"问题 1：何时使用普通系统，何时使用独占系统？\n解决方案：\n大多数情况下使用普通系统 只在需要完全访问 World 时使用独占系统 考虑使用 Commands 代替独占系统 问题 2：如何控制系统的执行顺序？\n解决方案：\n使用 .before() 和 .after() 方法控制顺序 使用系统集（SystemSet）组织系统 使用系统管道连接系统 问题 3：如何处理系统错误？\n解决方案：\n使用可失败系统返回 Result 设置适当的错误处理器 使用系统管道处理错误","性能考虑#性能考虑":"系统粒度：保持系统粒度细，只访问需要的数据 并行执行：系统可以并行执行，但可变访问会阻止并行 系统数量：避免过多的小系统，考虑合并相关系统","核心概念#核心概念":"","概述#概述":"学习目标：\n理解系统的概念和作用 掌握如何定义和使用系统 了解系统参数类型 理解系统闭包、泛型系统、一次性系统等高级功能 前置知识要求：\n核心编程框架（ECS） 组件（Components） 实体（Entities） Rust 基础语法","泛型系统#泛型系统":"泛型系统允许在不同类型上重用逻辑。\n源代码文件：bevy/examples/ecs/generic_system.rs\n代码示例：\n// 类型参数在函数名之后，但在普通参数之前 // 这里，`Component` trait 是 T 的 trait 约束，我们的泛型类型 fn cleanup_system\u003cT: Component\u003e(mut commands: Commands, query: Query\u003cEntity, With\u003cT\u003e\u003e) { for e in \u0026query { commands.entity(e).despawn(); } } fn main() { App::new() .add_plugins(DefaultPlugins) .init_state::\u003cAppState\u003e() .add_systems(Startup, setup_system) .add_systems( Update, ( print_text_system, transition_to_in_game_system.run_if(in_state(AppState::MainMenu)), ), ) // 清理系统 // 使用 :: (turbofish) 语法传递系统应该操作的类型 .add_systems(OnExit(AppState::MainMenu), cleanup_system::\u003cMenuClose\u003e) .add_systems(OnExit(AppState::InGame), cleanup_system::\u003cLevelUnload\u003e) .run(); } 关键要点：\n泛型系统允许在不同类型上重用逻辑 使用 :: (turbofish) 语法指定类型 泛型类型必须满足 trait 约束 泛型系统可以用于处理相关组件或资源 注意事项：\n泛型系统需要为每个类型创建专门的副本 确保为每个类型都注册了系统 泛型系统可以结合用户定义的 trait 使用 最佳实践：\n对于处理相关组件或资源的系统，使用泛型系统 结合用户定义的 trait 使用泛型系统 确保为每个类型都注册了系统","独占系统#独占系统":"独占系统提供对 ECS World 的完全直接访问。它们不能与其他系统并行运行，因为它们可以访问任何东西并做任何事情。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 如果你真的需要完整、立即的读写访问世界或资源，你可以使用\"独占系统\" // 警告：这些会阻止所有其他系统的并行执行，直到它们完成 // 所以如果你想要最大化并行性，通常应该避免它们 fn exclusive_player_system(world: \u0026mut World) { // 这与 \"new_player_system\" 做同样的事情 let total_players = world.resource_mut::\u003cGameState\u003e().total_players; let should_add_player = { let game_rules = world.resource::\u003cGameRules\u003e(); let add_new_player = random::\u003cbool\u003e(); add_new_player \u0026\u0026 total_players \u003c game_rules.max_players }; // 随机添加一个新玩家 if should_add_player { println!(\"Player {} has joined the game!\", total_players + 1); world.spawn(( Player { name: format!(\"Player {}\", total_players + 1), }, Score { value: 0 }, PlayerStreak::None, )); let mut game_state = world.resource_mut::\u003cGameState\u003e(); game_state.total_players += 1; } } 关键要点：\n独占系统提供对 World 的完全访问 独占系统不能与其他系统并行运行 独占系统应该尽量避免，以最大化并行性 独占系统可以用于需要完全访问的场景 注意事项：\n独占系统会阻止所有其他系统的并行执行 独占系统应该尽量避免 独占系统可以用于需要完全访问的场景 最佳实践：\n尽量避免使用独占系统 只在必要时使用独占系统 考虑使用 Commands 代替独占系统","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ecs/ecs_guide.rs - ECS 完整指南示例（系统定义） bevy/examples/ecs/system_closure.rs - 系统闭包示例 bevy/examples/ecs/generic_system.rs - 泛型系统示例 bevy/examples/ecs/one_shot_systems.rs - 一次性系统示例 bevy/examples/ecs/system_piping.rs - 系统管道示例 bevy/examples/ecs/system_param.rs - 自定义系统参数示例 bevy/examples/ecs/error_handling.rs - 系统错误处理示例 bevy/examples/ecs/fallible_params.rs - 可失败系统参数示例 官方文档链接：\nBevy System 官方文档 SystemParam 文档 进一步学习建议：\n学习查询（Queries），了解如何访问组件 学习资源（Resources），了解如何访问资源 学习系统调度（Schedule \u0026 App），了解如何控制系统执行 索引：返回上级目录","系统参数类型#系统参数类型":"系统可以使用多种参数类型来访问不同的数据。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 这个系统在所有具有 `Player` 和 `Score` 组件的实体上运行 // 它还访问 `GameRules` 资源来确定玩家是否获胜 fn score_check_system( game_rules: Res\u003cGameRules\u003e, mut game_state: ResMut\u003cGameState\u003e, query: Query\u003c(\u0026Player, \u0026Score)\u003e, ) { for (player, score) in \u0026query { if score.value == game_rules.winning_score { game_state.winning_player = Some(player.name.clone()); } } } 关键要点：\nRes：只读访问资源 ResMut：可变访问资源 Query：查询组件 Commands：创建和修改实体 系统可以同时使用多种参数类型 说明： 系统参数必须实现 SystemParam trait。Bevy 提供了多种系统参数类型，如 Res、ResMut、Query、Commands 等。","系统的设计思想#系统的设计思想":"系统采用数据导向的设计思想，将数据（组件）和逻辑（系统）分离。这种设计使得：\n系统可以独立开发和测试 系统可以并行执行，提高性能 系统可以灵活组合，实现复杂的游戏逻辑","系统管道#系统管道":"系统管道允许将多个系统连接在一起，将第一个系统的输出传递给下一个系统。\n源代码文件：bevy/examples/ecs/system_piping.rs\n代码示例：\n// 这个系统通过尝试解析 Message 资源产生 Result 输出 fn parse_message_system(message: Res\u003cMessage\u003e) -\u003e Result\u003cusize, ParseIntError\u003e { message.parse::\u003cusize\u003e() } // 这个系统接受 Result 输入，并打印解析的值或错误消息 // 尝试将 Message 资源更改为不是整数的内容。你应该看到错误消息被打印 fn handler_system(In(result): In\u003cResult\u003cusize, ParseIntError\u003e\u003e) { match result { Ok(value) =\u003e println!(\"parsed message: {value}\"), Err(err) =\u003e println!(\"encountered an error: {err:?}\"), } } fn main() { App::new() .insert_resource(Message(\"42\".to_string())) .add_systems( Update, ( parse_message_system.pipe(handler_system), data_pipe_system.map(|out| info!(\"{out}\")), parse_message_system.map(|out| debug!(\"{out:?}\")), ), ) .run(); } 关键要点：\n使用 .pipe() 方法将系统连接在一起 使用 .map() 方法转换系统输出 系统管道允许将多个系统连接在一起 系统管道可以用于错误处理和数据转换 注意事项：\n系统管道要求系统输出类型匹配下一个系统的输入类型 系统管道可以用于错误处理 系统管道可以用于数据转换 最佳实践：\n对于需要错误处理的系统，使用系统管道 对于需要数据转换的系统，使用系统管道 注意系统管道的类型匹配","系统错误处理#系统错误处理":"系统可以返回 Result 来处理错误。\n源代码文件：bevy/examples/ecs/error_handling.rs\n代码示例：\nuse bevy::ecs::error::warn; fn main() { let mut app = App::new(); // 默认情况下，返回错误的可失败系统会 panic // // 我们可以通过设置自定义错误处理器来改变这一点，它适用于整个应用 // （你也可以为特定的 `World` 设置它） // 这里我们使用内置错误处理器之一 // Bevy 为 `panic`、`error`、`warn`、`info`、`debug`、`trace` 和 `ignore` 提供内置处理器 app.set_error_handler(warn); app.add_plugins(DefaultPlugins); app.add_systems(Startup, setup); app.add_systems(Startup, failing_commands); // 单个系统也可以通过管道输出结果来处理： app.add_systems( PostStartup, failing_system.pipe(|result: In\u003cResult\u003e| { let _ = result.0.inspect_err(|err| info!(\"captured error: {err}\")); }), ); // 可失败观察者也被支持 app.add_observer(fallible_observer); app.run(); } /// 一个调用多个可失败函数并使用问号运算符的系统的示例 fn setup( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) -\u003e Result { // ... Ok(()) } /// 这个系统总是失败验证，因为我们从未创建同时具有 `Player` 和 `Enemy` 组件的实体 fn failing_system(world: \u0026mut World) -\u003e Result { world // `get_resource` 返回 `Option`，所以我们使用 `ok_or` 将其转换为 `Result` // 然后我们可以调用 `?` 来传播错误 .get_resource::\u003cUninitializedResource\u003e() // 我们可以在这里提供 `str`，因为 `BevyError` 实现了 `From\u003c\u0026str\u003e` .ok_or(\"Resource not initialized\")?; Ok(()) } 关键要点：\n系统可以返回 Result\u003c(), BevyError\u003e 来处理错误 使用 set_error_handler() 设置错误处理器 使用 .pipe() 方法处理系统错误 可失败系统可以用于错误处理 注意事项：\n默认情况下，返回错误的系统会 panic 可以设置自定义错误处理器 系统错误可以通过管道处理 最佳实践：\n对于可能失败的操作，使用可失败系统 设置适当的错误处理器 使用系统管道处理错误","系统闭包#系统闭包":"系统可以是闭包，允许捕获外部变量。\n源代码文件：bevy/examples/ecs/system_closure.rs\n代码示例：\nfn main() { // 创建一个简单的闭包 let simple_closure = || { // 这是一个什么都不做的闭包 info!(\"Hello from a simple closure!\"); }; // 创建一个带有'input'值的闭包 let complex_closure = |mut value: String| { move || { info!(\"Hello from a complex closure! {}\", value); // 我们可以在闭包内修改值。这将在调用之间保存 value = format!(\"{value} - updated\"); } }; let outside_variable = \"bar\".to_string(); App::new() .add_plugins(LogPlugin::default()) // 我们可以使用闭包作为系统 .add_systems(Update, simple_closure) // 或者我们可以使用更复杂的闭包，并传递参数来初始化 Local 变量 .add_systems(Update, complex_closure(\"foo\".into())) // 我们也可以内联闭包 .add_systems(Update, || { info!(\"Hello from an inlined closure!\"); }) // 或使用闭包外部的变量 .add_systems(Update, move || { info!( \"Hello from an inlined closure that captured the 'outside_variable'! {}\", outside_variable ); // 你可以使用 outside_variable 或此闭包内的任何其他变量 // 它们的状态将被保存 }) .run(); } 关键要点：\n系统可以是闭包 闭包可以捕获外部变量 使用 move 关键字移动变量到闭包中 闭包可以用于简单的系统逻辑 注意事项：\n闭包捕获的变量会在系统调用之间保持状态 使用 move 关键字会移动变量到闭包中 注意闭包的生命周期和所有权 最佳实践：\n对于简单的系统逻辑，使用闭包 对于复杂的系统逻辑，使用普通函数 注意闭包捕获的变量的生命周期","进阶用法#进阶用法":""},"title":"系统（Systems）"},"/wiki/bevybook/ecs/%E7%BB%84%E4%BB%B6components/":{"data":{"":"","不可变组件#不可变组件":"不可变组件一旦插入到 ECS 中，就只能查看或移除，不能修改。替换是允许的，因为这等同于移除和插入。\n源代码文件：bevy/examples/ecs/immutable_components.rs\n代码示例：\n/// 这是可变组件，默认情况 /// 这通过组件实现 [`Component`] 来表示，其中 [`Component::Mutability`] 是 [`Mutable`] #[derive(Component)] pub struct MyMutableComponent(bool); /// 这是不可变组件。一旦插入到 ECS 中，它只能被查看或移除 /// 替换也是允许的，因为这等同于移除和插入 /// /// 添加 `#[component(immutable)]` 属性可以防止在派生宏中实现 [`Component","什么是组件#什么是组件？":"组件是普通 Rust 数据类型，通过 #[derive(Component)] 标记。组件是 ECS 中最基本的数据单元，每个组件代表实体的一个属性或特征。\n为什么使用组件？\n数据导向：功能由数据驱动，而非继承层次 灵活组合：组件可以灵活组合，创建不同的实体 性能优化：组件存储优化，提高缓存命中率","在游戏开发中的应用场景#在游戏开发中的应用场景":"组件在游戏开发中有广泛的应用：\n游戏对象属性：位置、速度、生命值、颜色等 游戏状态：玩家状态、敌人状态、道具状态等 标识符：名称、ID、标签等","基础用法#基础用法":"","定义组件#定义组件":"组件是普通 Rust 数据类型，通过 #[derive(Component)] 标记。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 我们的游戏将有一些\"玩家\"。每个玩家都有一个名称来标识他们 #[derive(Component)] struct Player { name: String, } // 每个玩家也有一个分数。这个组件保存分数 #[derive(Component)] struct Score { value: usize, } // 枚举也可以用作组件 // 这个组件跟踪玩家连续得分或未得分的轮数 #[derive(Component)] enum PlayerStreak { Hot(usize), None, Cold(usize), } 关键要点：\n组件是普通 Rust 结构体或枚举 使用 #[derive(Component)] 标记组件 组件通常专注于单一功能（如位置、分数、名称） 枚举也可以用作组件 说明： 组件是 ECS 中最基本的数据单元。每个组件代表实体的一个属性或特征。例如，Player 组件表示实体是一个玩家，Score 组件表示实体的分数。","实际应用#实际应用":"","常见问题#常见问题":"问题 1：何时使用结构体组件，何时使用枚举组件？\n解决方案：\n结构体组件用于存储多个相关数据（如位置、速度） 枚举组件用于表示状态或选项（如玩家状态、游戏状态） 问题 2：何时使用不可变组件？\n解决方案：\n对于不应该改变的数据（如名称、ID），使用不可变组件 对于需要频繁修改的数据，使用可变组件 使用不可变组件配合组件钩子来维护索引 问题 3：如何选择组件存储类型？\n解决方案：\n大多数组件使用默认的 Table 存储 不经常使用的组件可以考虑使用 SparseSet 存储 根据实际性能需求选择存储类型","性能考虑#性能考虑":"组件布局：相关组件应该放在一起，提高缓存命中率 组件大小：保持组件大小合理，避免过大的组件 组件数量：避免在单个实体上添加过多组件","核心概念#核心概念":"","概述#概述":"学习目标：\n理解组件的概念和作用 掌握如何定义和使用组件 了解组件类型和存储方式 理解不可变组件的使用场景 前置知识要求：\n核心编程框架（ECS） Rust 基础语法 理解基本的 Rust 类型系统","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ecs/ecs_guide.rs - ECS 完整指南示例（组件定义） bevy/examples/ecs/immutable_components.rs - 不可变组件示例 官方文档链接：\nBevy Component 官方文档 Component 存储文档 进一步学习建议：\n学习实体（Entities），了解如何将组件附加到实体 学习查询（Queries），了解如何访问组件 学习 ECS 进阶，了解组件生命周期钩子等高级功能 索引：返回上级目录","组件存储#组件存储":"组件可以存储在不同的存储类型中，影响性能和内存使用。\n关键要点：\nTable 存储：默认存储类型，适合大多数组件 SparseSet 存储：适合不经常使用的组件 存储类型影响查询性能和内存使用 说明： Bevy 使用两种主要的组件存储类型：Table 和 SparseSet。Table 存储适合大多数组件，提供良好的缓存局部性。SparseSet 存储适合不经常使用的组件，提供更灵活的内存布局。","组件的设计思想#组件的设计思想":"组件采用数据导向的设计思想，将数据（组件）和逻辑（系统）分离。这种设计使得：\n系统可以独立开发和测试 组件可以灵活组合 系统可以并行执行，提高性能","组件类型#组件类型":"组件可以是结构体或枚举，可以是任何实现了 Component trait 的类型。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 结构体组件 #[derive(Component)] struct Player { name: String, } // 枚举组件 #[derive(Component)] enum PlayerStreak { Hot(usize), None, Cold(usize), } // 元组结构体组件 #[derive(Component)] struct Position(f32, f32); // 单元结构体组件 #[derive(Component)] struct Marker; 关键要点：\n组件可以是结构体、枚举、元组结构体或单元结构体 组件必须实现 Component trait 使用 #[derive(Component)] 自动实现 Component trait 说明： 组件可以是任何 Rust 数据类型，只要实现了 Component trait。使用 #[derive(Component)] 可以自动实现 Component trait。","进阶用法#进阶用法":""},"title":"组件（Components）"},"/wiki/bevybook/ecs/%E8%B5%84%E6%BA%90resources/":{"data":{"":"","什么是资源#什么是资源？":"资源是共享的全局数据，可以在任何系统中访问。资源是全局唯一的，不需要附加到实体上。\n为什么使用资源？\n全局状态：资源用于存储全局状态，如游戏设置、配置信息等 共享数据：资源可以在任何系统中访问，便于共享数据 性能优化：资源访问比查询更高效","在游戏开发中的应用场景#在游戏开发中的应用场景":"资源在游戏开发中有广泛的应用：\n游戏设置：游戏配置、难度设置等 全局状态：游戏状态、分数、时间等 资源管理：资源服务器、资源缓存等","基础用法#基础用法":"","定义资源#定义资源":"资源是普通 Rust 数据类型，通过 #[derive(Resource)] 标记。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 这个资源保存游戏信息 #[derive(Resource, Default)] struct GameState { current_round: usize, total_players: usize, winning_player: Option\u003cString\u003e, } // 这个资源提供游戏的规则 #[derive(Resource)] struct GameRules { winning_score: usize, max_rounds: usize, max_players: usize, } 关键要点：\n资源是普通 Rust 结构体或枚举 使用 #[derive(Resource)] 标记资源 使用 Default trait 可以自动初始化资源 资源用于存储全局状态 说明： 资源用于存储全局状态，如游戏设置、配置信息等。与组件不同，资源是全局唯一的，不需要附加到实体上。","实际应用#实际应用":"","常见问题#常见问题":"问题 1：何时使用资源，何时使用组件？\n解决方案：\n资源用于全局共享的数据（如游戏设置、资源服务器） 组件用于实体特有的数据（如位置、速度） 如果数据是全局唯一的，使用资源；如果是实体特有的，使用组件 问题 2：如何初始化资源？\n解决方案：\n对于有默认值的资源，使用 init_resource() 对于需要自定义初始化的资源，使用 insert_resource() 在启动系统中初始化资源 问题 3：如何检测资源变化？\n解决方案：\n使用 is_changed() 检查资源是否已变更 使用 is_added() 检查资源是否新添加 使用 set_if_neq() 避免不必要的变更检测","性能考虑#性能考虑":"资源访问：资源访问比查询更高效 变更检测：注意变更检测的性能影响 资源数量：避免过多的资源，考虑合并相关资源","核心概念#核心概念":"","概述#概述":"学习目标：\n理解资源的概念和作用 掌握如何定义和使用资源 了解资源的初始化方法 理解资源的生命周期管理 前置知识要求：\n核心编程框架（ECS） 组件（Components） 系统（Systems） Rust 基础语法","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ecs/ecs_guide.rs - ECS 完整指南示例（资源定义和使用） bevy/examples/ecs/change_detection.rs - 变更检测示例（资源变更检测） 官方文档链接：\nBevy Resource 官方文档 Resource 初始化文档 进一步学习建议：\n学习系统（Systems），了解如何在系统中访问资源 学习系统调度（Schedule \u0026 App），了解资源的生命周期 学习 ECS 进阶，了解资源的高级功能 索引：返回上级目录","访问资源#访问资源":"使用 Res 和 ResMut 访问资源。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\n// 系统也可以读取和修改资源。这个系统在每次更新时开始一个新的\"轮次\" // 注意：\"mut\" 表示资源是\"可变的\" // Res 是只读的。ResMut 可以修改资源 fn new_round_system(game_rules: Res\u003cGameRules\u003e, mut game_state: ResMut\u003cGameState\u003e) { game_state.current_round += 1; println!( \"Begin round {} of {}\", game_state.current_round, game_rules.max_rounds ); } // 这个系统在所有具有 `Player` 和 `Score` 组件的实体上运行 // 它还访问 `GameRules` 资源来确定玩家是否获胜 fn score_check_system( game_rules: Res\u003cGameRules\u003e, mut game_state: ResMut\u003cGameState\u003e, query: Query\u003c(\u0026Player, \u0026Score)\u003e, ) { for (player, score) in \u0026query { if score.value == game_rules.winning_score { game_state.winning_player = Some(player.name.clone()); } } } 关键要点：\n使用 Res 只读访问资源 使用 ResMut 可变访问资源 资源可以在任何系统中访问 可变访问会阻止并行执行 说明： 资源访问与组件访问类似。使用 Res 可以只读访问资源，使用 ResMut 可以可变访问资源。资源可以在任何系统中访问，便于共享数据。","资源初始化#资源初始化":"资源可以通过多种方式初始化。\n源代码文件：bevy/examples/ecs/ecs_guide.rs\n代码示例：\nfn main() { App::new() // 实现 Default 或 FromWorld trait 的资源可以这样添加： .init_resource::\u003cGameState\u003e() // 或者使用 insert_resource 插入资源 .insert_resource(GameRules { max_rounds: 10, winning_score: 4, max_players: 4, }) .add_systems(Startup, startup_system) .add_systems(Update, new_round_system) .run(); } fn startup_system(mut commands: Commands, mut game_state: ResMut\u003cGameState\u003e) { // 创建游戏规则资源 commands.insert_resource(GameRules { max_rounds: 10, winning_score: 4, max_players: 4, }); // 设置总玩家数为 2 game_state.total_players = 2; } 关键要点：\n使用 init_resource::() 初始化实现 Default 或 FromWorld trait 的资源 使用 insert_resource() 插入资源 使用 Commands::insert_resource() 在系统中插入资源 资源可以在应用构建时或系统运行时初始化 注意事项：\ninit_resource() 要求资源实现 Default 或 FromWorld trait insert_resource() 可以插入任何资源 资源可以在应用构建时或系统运行时初始化 最佳实践：\n对于有默认值的资源，使用 init_resource() 对于需要自定义初始化的资源，使用 insert_resource() 在启动系统中初始化资源","资源变更检测#资源变更检测":"资源支持变更检测，可以检测资源的变化。\n源代码文件：bevy/examples/ecs/change_detection.rs\n代码示例：\n/// 资源的变更检测概念与组件类似 fn change_resource(time: Res\u003cTime\u003e, mut my_resource: ResMut\u003cMyResource\u003e) { if rand::rng().random_bool(0.1) { let new_resource = MyResource(time.elapsed_secs().round()); info!(\"New value: {new_resource:?}\"); // 为了避免在值未实际改变时触发变更检测，可以使用 `set_if_neq` 方法 // 该方法要求资源实现 PartialEq my_resource.set_if_neq(new_resource); } } fn change_detection( changed_components: Query\u003cRef\u003cMyComponent\u003e, Changed\u003cMyComponent\u003e\u003e, my_resource: Res\u003cMyResource\u003e, ) { // ... if my_resource.is_changed() { warn!( \"Change detected!\\n\\t-\u003e value: {:?}\\n\\t-\u003e added: {}\\n\\t-\u003e changed: {}\\n\\t-\u003e changed by: {}\", my_resource, my_resource.is_added(), my_resource.is_changed(), my_resource.changed_by() // 与组件一样，需要 `track_location` 特性 ); } } 关键要点：\n使用 is_changed() 检查资源是否已变更 使用 is_added() 检查资源是否新添加 使用 set_if_neq() 避免不必要的变更检测 使用 changed_by() 获取变更位置（需要 track_location 特性） 注意事项：\n资源的变更检测与组件类似 使用 set_if_neq() 避免不必要的变更检测 changed_by() 需要 track_location 特性 最佳实践：\n对于实现 PartialEq 的资源，使用 set_if_neq() 避免不必要的变更检测 使用变更检测响应资源变化 注意变更检测的性能影响","资源的设计思想#资源的设计思想":"资源采用数据导向的设计思想，将全局数据（资源）和逻辑（系统）分离。这种设计使得：\n系统可以高效访问全局数据 资源可以在任何系统中访问 资源可以灵活管理全局状态","进阶用法#进阶用法":""},"title":"资源（Resources）"},"/wiki/bevybook/ecs/ecs%E8%BF%9B%E9%98%B6/":{"data":{"":"","ecs-进阶功能概览#ECS 进阶功能概览":"变更检测：检测组件和资源的变化 组件生命周期钩子：在组件添加、插入、替换、移除时执行逻辑 关系系统：建立自定义的实体关系 并行查询：使用并行迭代器提高性能 查询组合：处理实体间的交互 观察者模式：响应组件生命周期事件和自定义事件 消息系统：使用消息实现系统间通信 错误处理：处理系统执行中的错误 动态 ECS：动态创建组件和实体","为什么需要高级-ecs-功能#为什么需要高级 ECS 功能？":"在复杂的游戏开发中，我们需要：\n性能优化：通过并行查询提高系统执行效率 变更响应：检测组件和资源的变化，及时响应 关系管理：建立和维护实体间的复杂关系 生命周期管理：在组件的生命周期关键点执行逻辑 事件驱动：使用消息系统和观察者模式实现事件驱动逻辑","关系系统relationships#关系系统（Relationships）":"关系系统允许建立自定义的实体关系，类似于内置的 ChildOf/Children 关系。\n源代码文件：bevy/examples/ecs/relationships.rs\n代码示例：\nuse bevy::prelude::*; /// 此实体正在瞄准的实体 /// /// 这是关系的真实来源，可以直接修改以改变目标 #[derive(Component, Debug)] #[relationship(relationship_target = TargetedBy)] struct Targeting(Entity); /// 所有正在瞄准此实体的实体 /// /// 此组件使用派生 [`Relationship`] trait 引入的组件钩子进行响应式更新 /// 我们不应该直接修改此组件，但可以安全地读取其字段 #[derive(Component, Debug)] #[relationship_target(relationship = Targeting)] struct TargetedBy(Vec\u003cEntity\u003e); fn spawning_entities_with_relationships(mut commands: Commands) { // 调用 `.id()` 在生成实体后将返回生成实体的 `Entity` 标识符 // 即使实体本身尚未在世界中实例化 let alice = commands.spawn(Name::new(\"Alice\")).id(); // 关系只是组件，所以我们可以将它们添加到正在生成的 bundle 中 let bob = commands.spawn((Name::new(\"Bob\"), Targeting(alice))).id(); // `with_related` 和 `with_related_entities` 辅助方法可以更符合人体工程学地添加关系 let charlie = commands .spawn((Name::new(\"Charlie\"), Targeting(bob))) // `with_related` 方法将生成一个带有 `Targeting` 关系的 bundle .with_related::\u003cTargeting\u003e(Name::new(\"James\")) // `with_related_entities` 方法将自动将 `Targeting` 组件添加到闭包内生成的任何实体 .with_related_entities::\u003cTargeting\u003e(|related_spawner_commands| { // 我们可以在这里生成多个实体，它们都会瞄准 `charlie` related_spawner_commands.spawn(Name::new(\"Devon\")); }) .id(); // 简单地插入 `Targeting` 组件将自动创建并更新目标实体上的 `TargetedBy` 组件 // 我们可以在任何时候这样做；不仅仅是在实体生成时 commands.entity(alice).insert(Targeting(charlie)); } fn mutate_relationships(name_query: Query\u003c(Entity, \u0026Name)\u003e, mut commands: Commands) { // 关系组件是不可变的！我们不能可变地查询 `Targeting` 组件并直接修改它 // 但我们可以插入一个新的 `Targeting` 组件来替换旧的 // 这允许 `Targeting` 组件上的钩子正确更新 `TargetedBy` 组件 // `TargetedBy` 组件将自动更新！ let devon = name_query .iter() .find(|(_entity, name)| name.as_str() == \"Devon\") .unwrap() .0; let alice = name_query .iter() .find(|(_entity, name)| name.as_str() == \"Alice\") .unwrap() .0; println!(\"Making Devon target Alice.\\n\"); commands.entity(devon).insert(Targeting(alice)); } 关键要点：\n使用 #[relationship(relationship_target = TargetedBy)] 定义关系组件 使用 #[relationship_target(relationship = Targeting)] 定义关系目标组件 关系组件是真实来源，可以直接修改 关系目标组件是响应式更新的，不应直接修改 使用 with_related 和 with_related_entities 辅助方法添加关系 插入关系组件会自动更新关系目标组件 说明： 关系系统允许建立自定义的实体关系。Bevy 内置了 ChildOf/Children 关系用于变换和可见性传播，但你可以定义自己的关系。关系组件是真实来源，可以直接修改，而关系目标组件是响应式更新的，不应直接修改。","动态-ecs#动态 ECS":"动态 ECS 允许动态创建组件和实体。\n源代码文件：bevy/examples/ecs/dynamic.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .add_systems(Update, query_dynamic_components) .run(); } fn setup(mut commands: Commands, mut world: \u0026mut World) { // 动态创建组件 let component_id = world.register_component_with_descriptor(ComponentDescriptor::new( \"MyDynamicComponent\", StorageType::Table, )); // 使用动态组件创建实体 let entity = commands.spawn_empty().id(); commands.entity(entity).insert_by_id(component_id, MyData(42)); } fn query_dynamic_components(world: \u0026mut World, component_id: ComponentId) { // 查询动态组件 let query = Query::new((component_id,)); for (data,) in query.iter(world) { // ... } } 关键要点：\n使用 register_component_with_descriptor() 动态创建组件 使用 insert_by_id() 插入动态组件 使用 Query 查询动态组件 动态 ECS 可以用于运行时创建组件 注意事项：\n动态 ECS 允许运行时创建组件 动态 ECS 可以用于插件系统 注意动态 ECS 的性能影响 最佳实践：\n对于需要运行时创建组件的场景，使用动态 ECS 对于插件系统，使用动态 ECS 注意动态 ECS 的性能影响","变更检测change-detection#变更检测（Change Detection）":"变更检测用于检测组件和资源的变化，是响应式编程的基础。\n源代码文件：bevy/examples/ecs/change_detection.rs\n代码示例：\nuse bevy::prelude::*; #[derive(Component, PartialEq, Debug)] struct MyComponent(f32); #[derive(Resource, PartialEq, Debug)] struct MyResource(f32); fn change_component(time: Res\u003cTime\u003e, mut query: Query\u003c(Entity, \u0026mut MyComponent)\u003e) { for (entity, mut component) in \u0026mut query { if rand::rng().random_bool(0.1) { let new_component = MyComponent(time.elapsed_secs().round()); info!(\"New value: {new_component:?} {entity}\"); // 变更检测发生在可变解引用时，不考虑值是否实际相等 // 为了避免在值未实际改变时触发变更检测，可以使用 `set_if_neq` 方法 // 该方法要求组件实现 PartialEq component.set_if_neq(new_component); } } } fn change_detection( changed_components: Query\u003cRef\u003cMyComponent\u003e, Changed\u003cMyComponent\u003e\u003e, my_resource: Res\u003cMyResource\u003e, ) { for component in \u0026changed_components { // 默认情况下，你只能知道组件被改变了 // 但如果有多个系统修改同一个组件，如何知道是哪个系统导致的改变？ warn!( \"Change detected!\\n\\t-\u003e value: {:?}\\n\\t-\u003e added: {}\\n\\t-\u003e changed: {}\\n\\t-\u003e changed by: {}\", component, component.is_added(), component.is_changed(), // 如果启用 `track_location` 特性，可以解锁 `changed_by()` 方法 // 它返回组件或资源被改变的文件和行号 // 不建议在发布的游戏中使用，但对调试很有用！ component.changed_by() ); } if my_resource.is_changed() { warn!( \"Change detected!\\n\\t-\u003e value: {:?}\\n\\t-\u003e added: {}\\n\\t-\u003e changed: {}\\n\\t-\u003e changed by: {}\", my_resource, my_resource.is_added(), my_resource.is_changed(), my_resource.changed_by() // 与组件一样，需要 `track_location` 特性 ); } } 关键要点：\n使用 Changed 过滤器查询已变更的组件 使用 Added 过滤器查询新添加的组件 使用 Ref 系统参数访问变更检测信息，但不过滤查询 使用 set_if_neq() 方法避免不必要的变更检测 使用 is_changed() 和 is_added() 检查变更状态 使用 changed_by() 方法（需要 track_location 特性）获取变更位置 说明： 变更检测是 Bevy ECS 的核心功能之一。当组件或资源被修改时，Bevy 会自动跟踪这些变更。使用 Changed 过滤器可以只查询已变更的组件，这对于性能优化很重要。set_if_neq() 方法可以避免在值未实际改变时触发变更检测，这对于实现 PartialEq 的组件很有用。","在游戏开发中的应用场景#在游戏开发中的应用场景":"ECS 进阶功能在游戏开发中有广泛的应用：\n性能优化：使用并行查询提高系统执行效率 变更响应：使用变更检测和观察者响应组件变化 关系管理：使用关系系统建立实体间的复杂关系 生命周期管理：使用组件钩子管理组件的生命周期 事件驱动：使用消息系统和观察者实现事件驱动逻辑","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：何时使用变更检测，何时使用观察者？\n解决方案：\n变更检测适用于需要查询已变更组件的场景 观察者适用于需要响应组件生命周期事件的场景 对于简单场景，优先使用变更检测 问题 2：并行查询何时更快？\n解决方案：\n并行查询适用于计算密集型操作 对于简单操作，并行查询可能不会更快 需要根据实际情况测试性能 问题 3：如何优化查询组合的性能？\n解决方案：\n使用空间分区减少需要检查的实体对 使用查询过滤器减少查询的实体数量 考虑使用并行查询组合","并行查询parallel-queries#并行查询（Parallel Queries）":"并行查询使用并行迭代器提高系统执行效率。\n源代码文件：bevy/examples/ecs/parallel_query.rs\n代码示例：\nuse bevy::{ecs::batching::BatchingStrategy, prelude::*}; #[derive(Component, Deref)] struct Velocity(Vec2); // 根据速度移动精灵 fn move_system(mut sprites: Query\u003c(\u0026mut Transform, \u0026Velocity)\u003e) { // 在 ComputeTaskPool 上并行计算每个精灵的新位置 // // 此示例仅用于演示目的。对于像加法这样便宜的操作，在只有 128 个元素时 // 使用 ParallelIterator 通常不会比使用普通 Iterator 更快 // 有关何时使用或不使用 ParallelIterator 的更多信息，请参阅 ParallelIterator 文档 sprites .par_iter_mut() .for_each(|(mut transform, velocity)| { transform.translation += velocity.extend(0.0); }); } // 在窗口外反弹精灵 fn bounce_system(window: Query\u003c\u0026Window\u003e, mut sprites: Query\u003c(\u0026Transform, \u0026mut Velocity)\u003e) { let Ok(window) = window.single() else { return; }; let width = window.width(); let height = window.height(); // 也可以覆盖默认批次大小 // 在这种情况下，选择批次大小为 32 以限制 ParallelIterator 的开销 sprites .par_iter_mut() .batching_strategy(BatchingStrategy::fixed(32)) .for_each(|(transform, mut v)| { // ... }); } 关键要点：\n使用 par_iter_mut() 获取并行迭代器 使用 batching_strategy() 自定义批处理策略 并行查询适用于计算密集型操作 对于简单操作，并行查询可能不会更快 注意事项：\n并行查询适用于计算密集型操作 对于简单操作，并行查询可能不会更快 可以使用 batching_strategy() 自定义批处理策略 最佳实践：\n只在计算密集型操作时使用并行查询 对于简单操作，使用普通查询 根据操作复杂度调整批处理策略","性能考虑#性能考虑":"并行查询：只在计算密集型操作时使用 查询组合：注意性能影响，考虑使用空间分区 观察者：考虑性能开销，优先使用变更检测 组件钩子：比观察者开销更小，但灵活性较低","查询组合query-combinations#查询组合（Query Combinations）":"查询组合用于处理实体间的交互，如碰撞检测。\n源代码文件：bevy/examples/ecs/iter_combinations.rs\n代码示例：\nuse bevy::prelude::*; const GRAVITY_CONSTANT: f32 = 0.001; #[derive(Component, Default)] struct Mass(f32); #[derive(Component, Default)] struct Acceleration(Vec3); fn interact_bodies(mut query: Query\u003c(\u0026Mass, \u0026GlobalTransform, \u0026mut Acceleration)\u003e) { let mut iter = query.iter_combinations_mut(); while let Some([(Mass(m1), transform1, mut acc1), (Mass(m2), transform2, mut acc2)]) = iter.fetch_next() { let delta = transform2.translation() - transform1.translation(); let distance_sq: f32 = delta.length_squared(); let f = GRAVITY_CONSTANT / distance_sq; let force_unit_mass = delta * f; acc1.0 += force_unit_mass * *m2; acc2.0 -= force_unit_mass * *m1; } } 关键要点：\n使用 iter_combinations_mut() 获取可变组合迭代器 使用 fetch_next() 获取下一对实体 查询组合会跳过重复的组合（如 (A, B) 和 (B, A)） 查询组合用于处理实体间的成对交互 注意事项：\n查询组合用于处理实体间的成对交互 查询组合会跳过重复的组合 查询组合对于大量实体可能较慢 最佳实践：\n使用查询组合处理碰撞检测、物理交互等场景 注意性能影响，对于大量实体考虑使用空间分区 考虑使用并行查询组合提高性能","核心概念#核心概念":"","概述#概述":"学习目标：\n掌握变更检测（Change Detection）的使用方法 理解组件生命周期钩子（Component Hooks）的应用场景 学会使用关系系统（Relationships）建立实体间的关系 掌握并行查询（Parallel Queries）的性能优化技巧 理解查询组合（Query Combinations）的使用方法 学会使用观察者模式（Observers）响应组件变化 了解消息系统、错误处理、动态 ECS 等高级功能 前置知识要求：\n核心编程框架（ECS） 组件（Components） 实体（Entities） 系统（Systems） 查询（Queries） 资源（Resources） 系统调度（Schedule \u0026 App）","消息系统messages#消息系统（Messages）":"消息系统用于实现系统间通信。\n源代码文件：bevy/examples/ecs/message.rs\n代码示例：\nuse bevy::prelude::*; /// 这是一个 [`Message`]，任何观察它的观察者都会在它被激活时运行 #[derive(Message)] struct MyMessage; fn main() { App::new() .add_plugins(DefaultPlugins) .add_message::\u003cMyMessage\u003e() .add_systems(Startup, setup) .add_systems(Update, send_message) .add_observer(receive_message) .run(); } fn send_message(mut commands: Commands) { // 发送消息 commands.write_message(MyMessage); } fn receive_message(_message: On\u003cMyMessage\u003e) { info!(\"Message received!\"); } 关键要点：\n使用 Message 派生宏定义消息 使用 add_message() 注册消息 使用 write_message() 发送消息 使用观察者接收消息 注意事项：\n消息系统用于实现系统间通信 消息可以用于事件驱动逻辑 注意消息系统的性能影响 最佳实践：\n对于系统间通信，使用消息系统 对于事件驱动逻辑，使用消息系统 注意消息系统的性能影响","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ecs/change_detection.rs - 变更检测示例 bevy/examples/ecs/component_hooks.rs - 组件生命周期钩子示例 bevy/examples/ecs/relationships.rs - 关系系统示例 bevy/examples/ecs/parallel_query.rs - 并行查询示例 bevy/examples/ecs/iter_combinations.rs - 查询组合示例 bevy/examples/ecs/observers.rs - 观察者模式示例 bevy/examples/ecs/removal_detection.rs - 移除检测示例 bevy/examples/ecs/message.rs - 消息系统示例 bevy/examples/ecs/error_handling.rs - 错误处理示例 bevy/examples/ecs/dynamic.rs - 动态 ECS 示例 官方文档链接：\nBevy ECS 官方文档 变更检测文档 关系系统文档 观察者文档 进一步学习建议：\n学习 Bevy 的其他高级功能，如自定义系统参数、系统调度等 阅读 Bevy ECS 源码，深入理解实现原理 实践编写自己的高级 ECS 系统，加深理解 索引：返回上级目录","组件生命周期钩子component-hooks#组件生命周期钩子（Component Hooks）":"组件生命周期钩子允许在组件的生命周期关键点执行逻辑。\n源代码文件：bevy/examples/ecs/component_hooks.rs\n代码示例：\nuse bevy::{ ecs::component::{Mutable, StorageType}, ecs::lifecycle::{ComponentHook, HookContext}, prelude::*, }; use std::collections::HashMap; #[derive(Debug)] struct MyComponent(KeyCode); impl Component for MyComponent { const STORAGE_TYPE: StorageType = StorageType::Table; type Mutability = Mutable; fn on_add() -\u003e Option\u003cComponentHook\u003e { // 如果没有 on_add 钩子，返回 None // 注意这是不实现钩子时的默认行为 None } } fn setup(world: \u0026mut World) { // 为了注册组件钩子，组件必须： // - 当前未被世界中的任何实体使用 // - 尚未注册该类型的钩子 // 这是为了防止覆盖插件和其他 crate 中定义的钩子，并保持性能 world .register_component_hooks::\u003cMyComponent\u003e() // 有 4 种组件生命周期钩子：`on_add`、`on_insert`、`on_replace` 和 `on_remove` // 钩子有 2 个参数： // - 一个 `DeferredWorld`，允许访问资源和组件数据以及 `Commands` // - 一个 `HookContext`，提供以下上下文信息： // - 触发钩子的实体 // - 触发组件的组件 ID，主要用于动态组件 // - 导致钩子触发的代码位置 // // `on_add` 将在组件插入到没有该组件的实体上时触发 .on_add( |mut world, HookContext { entity, component_id, caller, .. }| { // 可以在钩子内访问组件数据 let value = world.get::\u003cMyComponent\u003e(entity).unwrap().0; println!( \"{component_id:?} added to {entity} with value {value:?}{}\", caller .map(|location| format!(\"due to {location}\")) .unwrap_or_default() ); // 或访问资源 world .resource_mut::\u003cMyComponentIndex\u003e() .insert(value, entity); }, ) // `on_insert` 将在组件插入到实体上时触发，无论实体是否已有该组件 // 如果 `on_add` 运行了，则在 `on_add` 之后运行 .on_insert(|world, _| { println!(\"Current Index: {:?}\", world.resource::\u003cMyComponentIndex\u003e()); }) // `on_replace` 将在组件插入到已有该组件的实体上时触发 // 在值被替换之前运行 // 当组件从实体移除时也会触发，在 `on_remove` 之前运行 .on_replace(|mut world, context| { let value = world.get::\u003cMyComponent\u003e(context.entity).unwrap().0; world.resource_mut::\u003cMyComponentIndex\u003e().remove(\u0026value); }) // `on_remove` 将在组件从实体移除时触发 // 由于它在组件移除之前运行，你仍然可以访问组件数据 .on_remove( |mut world, HookContext { entity, component_id, caller, .. }| { let value = world.get::\u003cMyComponent\u003e(entity).unwrap().0; println!( \"{component_id:?} removed from {entity} with value {value:?}{}\", caller .map(|location| format!(\"due to {location}\")) .unwrap_or_default() ); // 也可以通过 `.commands()` 发出命令 world.commands().entity(entity).despawn(); }, ); } 关键要点：\n有 4 种组件生命周期钩子：on_add、on_insert、on_replace、on_remove 钩子可以访问 DeferredWorld 和 HookContext 钩子可以访问组件数据、资源和 Commands 钩子可以发送消息 组件必须未被使用且未注册钩子才能注册钩子 说明： 组件生命周期钩子用于在组件的生命周期关键点执行逻辑。它们对于维护索引、强制执行结构规则等场景很有用。但要注意，尽可能使用 Bevy 的变更检测或事件来响应组件变化，因为事件通常提供更好的性能和更灵活的集成。","观察者模式observers#观察者模式（Observers）":"观察者模式用于响应组件生命周期事件和自定义事件。\n源代码文件：bevy/examples/ecs/observers.rs\n代码示例：\nuse bevy::prelude::*; #[derive(Component)] struct Mine { pos: Vec2, size: f32, } /// 这是一个普通的 [`Event`]。任何观察它的观察者都会在它被触发时运行 #[derive(Event)] struct ExplodeMines { pos: Vec2, radius: f32, } /// [`EntityEvent`] 是一种专门的 [`Event`] 类型，可以针对特定实体 /// 除了在触发时运行正常的\"顶级\"观察者（针对任何爆炸的实体）外 /// 它还会运行针对该事件的特定实体的任何观察者 #[derive(EntityEvent)] struct Explode { entity: Entity, } fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .add_systems(Update, (draw_shapes, handle_click)) // 观察者是在事件被\"触发\"时运行的系统 // 此观察者在 `ExplodeMines` 被触发时运行 .add_observer( |explode_mines: On\u003cExplodeMines\u003e, mines: Query\u003c\u0026Mine\u003e, index: Res\u003cSpatialIndex\u003e, mut commands: Commands| { // 访问资源 for entity in index.get_nearby(explode_mines.pos) { // 运行查询 let mine = mines.get(entity).unwrap(); if mine.pos.distance(explode_mines.pos) \u003c mine.size + explode_mines.radius { // 并排队命令，包括触发其他事件 // 这里我们为实体 `e` 触发 `Explode` 事件 commands.trigger(Explode { entity }); } } }, ) // 此观察者在 `Mine` 组件添加到实体时运行，并将其放置在简单的空间索引中 .add_observer(on_add_mine) // 此观察者在 `Mine` 组件从实体移除时运行（包括销毁它） // 并将其从空间索引中移除 .add_observer(on_remove_mine) .run(); } fn on_add_mine(add: On\u003cAdd, Mine\u003e, query: Query\u003c\u0026Mine\u003e, mut index: ResMut\u003cSpatialIndex\u003e) { let mine = query.get(add.entity).unwrap(); let tile = ( (mine.pos.x / CELL_SIZE).floor() as i32, (mine.pos.y / CELL_SIZE).floor() as i32, ); index.map.entry(tile).or_default().insert(add.entity); } fn on_remove_mine(remove: On\u003cRemove, Mine\u003e, query: Query\u003c\u0026Mine\u003e, mut index: ResMut\u003cSpatialIndex\u003e) { let mine = query.get(remove.entity).unwrap(); let tile = ( (mine.pos.x / CELL_SIZE).floor() as i32, (mine.pos.y / CELL_SIZE).floor() as i32, ); index.map.entry(tile).and_modify(|set| { set.remove(\u0026remove.entity); }); } 关键要点：\n观察者用于响应组件生命周期事件和自定义事件 使用 On 响应组件添加 使用 On 响应组件移除 使用 On 响应自定义事件 观察者可以访问资源、运行查询、发出命令 注意事项：\n观察者用于响应组件生命周期事件和自定义事件 观察者可以访问资源、运行查询、发出命令 观察者比组件钩子更灵活，但开销更大 最佳实践：\n使用观察者响应组件生命周期事件 使用观察者响应自定义事件 考虑性能影响，观察者可能比组件钩子更灵活但开销更大","进阶用法#进阶用法":"","错误处理#错误处理":"系统可以返回 Result 来处理错误。\n源代码文件：bevy/examples/ecs/error_handling.rs\n代码示例：\nuse bevy::ecs::error::warn; fn main() { let mut app = App::new(); // 默认情况下，返回错误的可失败系统会 panic // // 我们可以通过设置自定义错误处理器来改变这一点 // 它适用于整个应用 // 这里我们使用内置错误处理器之一 app.set_error_handler(warn); app.add_plugins(DefaultPlugins); app.add_systems(Startup, setup); // 单个系统也可以通过管道输出结果来处理： app.add_systems( PostStartup, failing_system.pipe(|result: In\u003cResult\u003e| { let _ = result.0.inspect_err(|err| info!(\"captured error: {err}\")); }), ); app.run(); } /// 这个系统总是失败验证，因为我们从未创建同时具有 `Player` 和 `Enemy` 组件的实体 fn failing_system(world: \u0026mut World) -\u003e Result { world // `get_resource` 返回 `Option`，所以我们使用 `ok_or` 将其转换为 `Result` // 然后我们可以调用 `?` 来传播错误 .get_resource::\u003cUninitializedResource\u003e() // 我们可以在这里提供 `str`，因为 `BevyError` 实现了 `From\u003c\u0026str\u003e` .ok_or(\"Resource not initialized\")?; Ok(()) } 关键要点：\n系统可以返回 Result\u003c(), BevyError\u003e 来处理错误 使用 set_error_handler() 设置错误处理器 使用 .pipe() 方法处理系统错误 可失败系统可以用于错误处理 注意事项：\n默认情况下，返回错误的系统会 panic 可以设置自定义错误处理器 系统错误可以通过管道处理 最佳实践：\n对于可能失败的操作，使用可失败系统 设置适当的错误处理器 使用系统管道处理错误"},"title":"ECS 进阶"},"/wiki/bevybook/examples/":{"data":{"":"本部分包含完整的 Bevy 项目示例，展示如何将所学知识应用到实际项目中。","2d-游戏示例#2D 游戏示例":"2D 平台游戏 - 完整的 2D 平台游戏实现 2D 射击游戏 - 2D 射击游戏示例 2D 益智游戏 - 2D 益智游戏示例","3d-游戏示例#3D 游戏示例":"3D 场景漫游 - 3D 场景和相机控制 3D 物理示例 - 3D 物理系统示例 3D 游戏示例 - 完整的 3D 游戏实现","基础示例#基础示例":"Hello World - 最简单的 Bevy 程序 ECS 示例 - ECS 基础用法示例 输入处理示例 - 键盘、鼠标、手柄输入","如何使用#如何使用":"查看示例：浏览示例代码了解实现方式 运行示例：运行示例查看效果 修改示例：尝试修改示例代码 学习实践：参考示例实现自己的项目","示例列表#示例列表":"","综合示例#综合示例":"完整游戏项目 - 包含所有功能的完整游戏 多人游戏示例 - 网络多人游戏实现 插件示例 - 自定义插件示例","贡献示例#贡献示例":"欢迎提交你的示例项目！\n索引：返回主目录"},"title":"Examples（示例）"},"/wiki/bevybook/foundation/":{"data":{"":"","1-快速入门#1. 快速入门":"","2-bevy-与-rust-框架#2. Bevy 与 Rust 框架":"","3-游戏引擎基础#3. 游戏引擎基础":"本部分介绍 Bevy 的基础知识，适合完全新手。\n内容列表 1. 快速入门 Bevy 安装与配置 创建第一个 Bevy 项目 基本项目结构 Hello World 示例 学习目标：能够创建并运行一个基本的 Bevy 项目\n2. Bevy 与 Rust 框架 Bevy 是什么 Bevy 的特点和优势 Rust 基础回顾 Bevy 与 Rust 的关系 为什么选择 Bevy 学习目标：理解 Bevy 的定位和 Rust 在 Bevy 中的作用\n3. 游戏引擎基础 游戏引擎核心概念 游戏循环（Game Loop） 场景图（Scene Graph） 渲染管线（Render Pipeline） 物理引擎基础 资源管理基础 学习目标：理解游戏引擎的基本工作原理","下一步#下一步":"完成本部分学习后，建议继续学习：\nECS（实体组件系统） - Bevy 的核心编程范式 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"按顺序学习：建议按照上述顺序依次学习 动手实践：每学完一个概念，尝试编写代码 理解概念：不要急于求成，确保理解每个概念 查阅文档：遇到问题及时查阅官方文档"},"title":"Foundation（基础）"},"/wiki/bevybook/foundation/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/":{"data":{"":"","bevy-应用是什么#Bevy 应用是什么？":"Bevy 应用是使用 Bevy 游戏引擎创建的程序。每个 Bevy 应用都基于 ECS（Entity Component System）模式构建。\n为什么使用 Bevy？\n数据导向：功能由数据驱动，而非继承层次 高性能：大规模并行执行，缓存友好 易用性：简洁的 API，易于学习和使用 模块化：插件化架构，易于扩展","bevy-应用的基本结构#Bevy 应用的基本结构":"Bevy 应用由以下部分组成：\nApp：应用主入口，管理应用生命周期 System：系统函数，处理游戏逻辑 Schedule：系统调度，控制系统的执行顺序 Plugin：插件，封装相关功能","使用插件#使用插件":"插件是封装相关功能的模块，可以简化应用配置。\n代码示例：\nfn main() { App::new() .add_plugins(DefaultPlugins) // 添加默认插件 .add_systems(Update, hello_world_system) .run(); } 注意事项：\nDefaultPlugins 包含窗口、输入、渲染等基本功能 可以根据需要选择插件 插件可以自定义配置 最佳实践：\n使用 DefaultPlugins 快速开始 根据需要添加或移除插件 创建自定义插件封装功能","创建最简单的-bevy-应用#创建最简单的 Bevy 应用":"创建一个输出 “hello world” 的最简单 Bevy 应用。\n源代码文件：bevy/examples/hello_world.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new().add_systems(Update, hello_world_system).run(); } fn hello_world_system() { println!(\"hello world\"); } 关键要点：\n使用 App::new() 创建应用 使用 add_systems() 注册系统 Update 是系统调度，表示系统在每次更新时运行 使用 run() 启动应用 系统是普通 Rust 函数 说明： 这是最简单的 Bevy 应用。App::new() 创建了一个新的应用实例，add_systems(Update, hello_world_system) 将系统注册到 Update 调度中，run() 启动应用并进入主循环。系统 hello_world_system 在每次应用更新时运行，输出 “hello world”。","在游戏开发中的应用场景#在游戏开发中的应用场景":"快速入门是学习 Bevy 的第一步，为后续学习打下基础：\n项目初始化：创建新的 Bevy 项目 系统注册：注册游戏逻辑系统 应用配置：配置应用的基本设置","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何运行 Bevy 应用？\n解决方案：使用 cargo run 命令运行应用。确保在项目根目录下执行。\n问题 2：系统什么时候运行？\n解决方案：系统在注册的调度阶段运行。Startup 系统运行一次，Update 系统每次更新运行。\n问题 3：如何调试 Bevy 应用？\n解决方案：使用 println! 输出调试信息，或使用 Bevy 的诊断工具。","应用生命周期#应用生命周期":"Bevy 应用有不同的调度阶段，控制系统的执行顺序。\n源代码文件：bevy/examples/hello_world.rs\n代码示例：\nfn main() { App::new() .add_systems(Startup, startup_system) // 启动系统，运行一次 .add_systems(Update, update_system) // 更新系统，每次更新运行 .run(); } fn startup_system() { println!(\"应用启动\"); } fn update_system() { println!(\"应用更新\"); } 关键要点：\nStartup：启动系统，在应用启动时运行一次 Update：更新系统，在每次应用更新时运行 系统按调度顺序执行 启动系统在更新系统之前执行 说明： 启动系统用于初始化应用状态，如创建初始实体、加载资源等。更新系统用于处理游戏逻辑，如处理输入、更新游戏状态等。","性能考虑#性能考虑":"系统优化：尽量减少系统的执行时间 并行执行：系统可以并行执行，提高性能 资源管理：合理管理资源，避免内存泄漏","核心概念#核心概念":"","概述#概述":"学习目标：\n创建第一个 Bevy 应用 理解 Bevy 应用的基本结构 学会定义和注册系统 理解 Bevy 应用的生命周期 前置知识要求：\nRust 基础语法 基本的 Rust 项目结构 Cargo 包管理器使用","相关资源#相关资源":"相关源代码文件：\nbevy/examples/hello_world.rs - Hello World 示例 bevy/examples/app/empty.rs - 空应用示例 bevy/examples/app/empty_defaults.rs - 带默认插件的空应用示例 官方文档链接：\nBevy 快速入门指南 Bevy 官方文档 Bevy 官方示例 进一步学习建议：\n学习 ECS 基础，理解 Bevy 的核心编程范式 学习资源管理，了解如何加载和管理资源 学习输入处理，了解如何处理用户输入 索引：返回上级目录","系统执行顺序#系统执行顺序":"可以通过 .before() 和 .after() 方法控制系统的执行顺序。\n代码示例：\nfn main() { App::new() .add_systems(Update, ( system_a, system_b.after(system_a), // system_b 在 system_a 之后运行 system_c.before(system_b), // system_c 在 system_b 之前运行 )) .run(); } 注意事项：\n系统执行顺序影响游戏逻辑 确保依赖关系正确 避免循环依赖 最佳实践：\n使用 .before() 和 .after() 明确指定顺序 将相关系统组织在一起 避免不必要的顺序依赖","进阶用法#进阶用法":"","配置-bevy-项目#配置 Bevy 项目":"在开始编写 Bevy 应用之前，需要配置项目依赖。\n配置步骤：\n在 Cargo.toml 中添加 Bevy 依赖 [dependencies] bevy = \"0.15\" # 确保这是最新版本 或者使用 Cargo 命令添加 cargo add bevy 关键要点：\n确保使用最新版本的 Bevy Bevy 版本可能会影响 API 使用方式 建议使用 cargo add 命令自动管理依赖 说明： Bevy 是一个快速发展的项目，API 可能会发生变化。使用最新版本可以确保获得最新的功能和修复。"},"title":"快速入门"},"/wiki/bevybook/foundation/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E5%9F%BA%E7%A1%80/":{"data":{"":"","什么是游戏引擎#什么是游戏引擎？":"游戏引擎是一个软件框架，用于开发游戏。它提供了游戏开发所需的核心功能，如渲染、物理、音频、输入处理等。\n为什么使用游戏引擎？\n提高效率：游戏引擎提供了游戏开发所需的核心功能，减少重复工作 跨平台支持：游戏引擎通常支持多个平台，简化跨平台开发 性能优化：游戏引擎经过优化，提供高性能的游戏运行环境 工具支持：游戏引擎通常提供丰富的工具和编辑器","在游戏开发中的应用场景#在游戏开发中的应用场景":"游戏引擎基础是游戏开发的基础，为后续学习打下基础：\n游戏循环：控制游戏的更新和渲染 相机系统：配置游戏视角 资源管理：加载和管理游戏资源 渲染管线：处理图形渲染 物理引擎：处理物理模拟","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：游戏循环是如何工作的？\n解决方案：游戏循环是游戏引擎的核心。它控制游戏的更新和渲染，确保游戏以稳定的帧率运行。Bevy 使用 ECS 模式，通过系统来处理游戏逻辑。\n问题 2：为什么需要相机？\n解决方案：相机负责配置要绘制什么、如何绘制以及在哪里绘制。必须至少有一个相机实体，才能显示任何内容。相机决定了玩家看到的内容。\n问题 3：资源管理是如何工作的？\n解决方案：资源管理负责加载和管理游戏资源。Bevy 使用 AssetServer 来加载资源。资源在并行加载时不会阻塞，可以使用 Assets 集合来访问已加载的资源。","性能考虑#性能考虑":"游戏循环优化：尽量减少游戏循环的执行时间 渲染优化：合理使用渲染管线，减少渲染开销 资源管理优化：合理管理资源，避免内存泄漏","核心概念#核心概念":"","概述#概述":"学习目标：\n理解游戏引擎的核心概念 了解游戏循环的工作原理 理解渲染管线的基本概念 了解资源管理的基础知识 理解相机系统的作用 前置知识要求：\n快速入门 Bevy 与 Rust 框架 Rust 基础语法","渲染管线#渲染管线":"渲染管线是游戏引擎的核心，负责处理图形渲染。\n源代码文件：bevy/examples/shader/compute_shader_game_of_life.rs\n关键信息：\n渲染管线负责处理图形渲染 Bevy 使用现代图形 API（如 WebGPU）进行渲染 渲染管线包括多个阶段，如顶点着色、片段着色等 可以使用自定义着色器来自定义渲染效果 说明： 渲染管线是游戏引擎的核心。它负责将游戏世界转换为屏幕上的图像。Bevy 使用现代图形 API，支持高性能渲染。","游戏引擎的核心组件#游戏引擎的核心组件":"游戏引擎通常包含以下核心组件：\n游戏循环（Game Loop）：控制游戏的更新和渲染 渲染管线（Render Pipeline）：处理图形渲染 物理引擎（Physics Engine）：处理物理模拟 资源管理（Asset Management）：管理游戏资源 输入处理（Input Handling）：处理用户输入 音频系统（Audio System）：处理音频播放","游戏循环#游戏循环":"游戏循环是游戏引擎的核心，控制游戏的更新和渲染。\n源代码文件：bevy/examples/app/custom_loop.rs\n代码示例：\nuse bevy::{app::AppExit, prelude::*}; use std::io; #[derive(Resource)] struct Input(String); fn my_runner(mut app: App) -\u003e AppExit { // 完成插件构建，包括运行任何必要的清理 // 这通常由默认运行器完成 app.finish(); app.cleanup(); println!(\"在控制台中输入内容\"); for line in io::stdin().lines() { { let mut input = app.world_mut().resource_mut::\u003cInput\u003e(); input.0 = line.unwrap(); } app.update(); if let Some(exit) = app.should_exit() { return exit; } } AppExit::Success } fn print_system(input: Res\u003cInput\u003e) { println!(\"你输入了: {}\", input.0); } fn exit_system(input: Res\u003cInput\u003e, mut app_exit_reader: MessageWriter\u003cAppExit\u003e) { if input.0 == \"exit\" { app_exit_reader.write(AppExit::Success); } } fn main() -\u003e AppExit { App::new() .insert_resource(Input(String::new())) .set_runner(my_runner) .add_systems(Update, (print_system, exit_system)) .run() } 关键要点：\n游戏循环控制游戏的更新和渲染 Bevy 使用 app.update() 来更新应用 可以自定义运行器来控制游戏循环 游戏循环通常包括输入处理、更新逻辑、渲染等步骤 说明： 游戏循环是游戏引擎的核心。它控制游戏的更新和渲染，确保游戏以稳定的帧率运行。Bevy 使用 ECS 模式，通过系统来处理游戏逻辑。","物理引擎基础#物理引擎基础":"物理引擎负责处理物理模拟，如碰撞检测、重力等。\n源代码文件：bevy/examples/movement/physics_in_fixed_timestep.rs\n关键信息：\n物理引擎负责处理物理模拟 Bevy 支持固定时间步长物理模拟 物理模拟通常在固定时间步长中运行 可以使用物理引擎来处理碰撞检测、重力等 说明： 物理引擎是游戏引擎的重要组成部分。它负责处理物理模拟，使游戏世界更加真实。Bevy 支持固定时间步长物理模拟，确保物理模拟的稳定性。","相关资源#相关资源":"相关源代码文件：\nbevy/examples/app/custom_loop.rs - 自定义游戏循环示例 bevy/examples/camera/2d_on_ui.rs - 2D 相机示例 bevy/examples/asset/asset_loading.rs - 资源加载示例 bevy/examples/shader/compute_shader_game_of_life.rs - 渲染管线示例 bevy/examples/movement/physics_in_fixed_timestep.rs - 物理引擎示例 官方文档链接：\nBevy 官方文档 Bevy 官方示例 进一步学习建议：\n学习 ECS 基础，理解 Bevy 的核心编程范式 学习资源管理，了解如何加载和管理资源 学习输入处理，了解如何处理用户输入 索引：返回上级目录","相机系统#相机系统":"相机系统负责配置要绘制什么、如何绘制以及在哪里绘制。必须至少有一个相机实体，才能显示任何内容！\n源代码文件：bevy/examples/camera/2d_on_ui.rs\n代码示例：\nuse bevy::{camera::visibility::RenderLayers, color::palettes::tailwind, prelude::*}; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .add_systems(Update, rotate_sprite) .run(); } fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { // 默认相机。`IsDefaultUiCamera` 使这成为渲染 UI 元素的默认相机 commands.spawn((Camera2d, IsDefaultUiCamera)); // 第二个相机。更高的 order 意味着这个相机将在第一个相机之后渲染 // 我们将渲染到这个相机以在 UI 上绘制 commands.spawn(( Camera2d, Camera { order: 1, // 不在背景中绘制任何内容，以查看前一个相机 clear_color: ClearColorConfig::None, ..default() }, // 此相机将只渲染在同一渲染层上的实体 RenderLayers::layer(1), )); } 关键要点：\n相机负责配置要绘制什么、如何绘制以及在哪里绘制 必须至少有一个相机实体，才能显示任何内容 可以使用多个相机来渲染不同的内容 相机的 order 属性控制渲染顺序 说明： 相机是游戏引擎中非常重要的组件。它决定了玩家看到的内容。Bevy 支持 2D 和 3D 相机，可以配置相机的属性，如视野、投影类型等。","资源管理#资源管理":"资源管理是游戏引擎的重要组成部分，负责加载和管理游戏资源。\n源代码文件：bevy/examples/asset/asset_loading.rs\n代码示例：\nuse bevy::{asset::LoadedFolder, prelude::*}; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .run(); } fn setup( mut commands: Commands, asset_server: Res\u003cAssetServer\u003e, meshes: Res\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { // 默认情况下，AssetServer 将从 \"assets\" 文件夹内加载资源 // 例如，下一行将加载 \"ROOT/assets/models/cube/cube.gltf\" // 其中 \"ROOT\" 是应用程序的目录 // // 这可以通过设置 [`AssetPlugin.file_path`] 来覆盖 let cube_handle = asset_server.load( GltfAssetLabel::Primitive { mesh: 0, primitive: 0, } .from_asset(\"models/cube/cube.gltf\"), ); let sphere_handle = asset_server.load( GltfAssetLabel::Primitive { mesh: 0, primitive: 0, } .from_asset(\"models/sphere/sphere.gltf\"), ); // 所有资源在加载完成后都会进入它们的 Assets 集合 if let Some(sphere) = meshes.get(\u0026sphere_handle) { // 你可能会注意到这不会运行！这是因为资源在并行加载时不会阻塞 // 当资源加载完成时，它将出现在相关的 Assets 集合中 info!(\"{:?}\", sphere.primitive_topology()); } else { info!(\"sphere 尚未加载\"); } // 你可以像这样加载文件夹中的所有资源。它们将在不阻塞的情况下并行加载 // LoadedFolder 资源保存文件夹中每个资源的句柄 // 这些都是 LoadedFolder 资源的依赖项，这意味着如果你想要等待文件夹中的所有资源加载 // 可以等待 LoadedFolder 资源触发 AssetEvent::LoadedWithDependencies // 如果你想保持文件夹中的资源存活，请确保存储返回的句柄 } 关键要点：\n资源管理负责加载和管理游戏资源 Bevy 使用 AssetServer 来加载资源 资源在并行加载时不会阻塞 可以使用 Assets 集合来访问已加载的资源 说明： 资源管理是游戏引擎的重要组成部分。游戏需要加载各种资源，如模型、纹理、音频等。Bevy 的资源管理系统支持异步加载，不会阻塞游戏运行。","进阶用法#进阶用法":""},"title":"游戏引擎基础"},"/wiki/bevybook/foundation/bevyrust%E6%A1%86%E6%9E%B6/":{"data":{"":"","bevy-与-rust-的关系#Bevy 与 Rust 的关系":"Bevy 是用 Rust 构建的，充分利用了 Rust 的特性。\n源代码文件：bevy/src/lib.rs\n关键信息：\nBevy 使用 Rust 的所有权系统管理内存 Bevy 利用 Rust 的类型系统确保安全性 Bevy 使用 Rust 的并发特性实现并行执行 Bevy 的模块化架构与 Rust 的模块系统完美契合 说明： Rust 的所有权系统和类型系统使 Bevy 能够在编译时捕获许多错误，同时提供高性能。Rust 的并发特性使 Bevy 能够实现大规模并行执行。","bevy-的-cargo-features#Bevy 的 Cargo Features":"Bevy 支持通过 Cargo features 自定义功能集。\n源代码文件：bevy/docs/cargo_features.md\n关键信息：\n可以通过 Cargo features 启用/禁用功能 默认功能提供完整的引擎体验 可以只启用需要的功能以减少编译时间 某些功能是互斥的 说明： Cargo features 允许开发者根据项目需求自定义 Bevy 功能集。这对于减少编译时间、减小二进制大小或创建特定用途的构建非常有用。","bevy-的-ecs-实现#Bevy 的 ECS 实现":"Bevy 使用 ECS（Entity Component System）作为核心架构。\n源代码文件：bevy/crates/bevy_ecs/README.md\n关键信息：\nBevy 的 ECS 实现是高性能的 支持大规模并行执行 使用数据导向的设计 提供类型安全的查询系统 说明： ECS 是 Bevy 的核心架构模式。它允许开发者以数据导向的方式组织游戏逻辑，实现高性能和可扩展性。","bevy-的插件系统#Bevy 的插件系统":"Bevy 使用插件系统组织功能。\n源代码文件：bevy/src/lib.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .run(); } 关键要点：\n插件是封装相关功能的模块 可以使用 add_plugins() 添加插件 DefaultPlugins 包含窗口、输入、渲染等基本功能 可以创建自定义插件来组织功能 说明： Bevy 的插件系统允许开发者将功能组织成模块。这使得代码更加模块化和可维护。","bevy-的模块化架构#Bevy 的模块化架构":"Bevy 采用模块化架构，每个模块都是独立的 crate。\n源代码文件：bevy/src/lib.rs\n代码示例：\n// bevy crate 是一个容器 crate，使消费 Bevy 子 crate 更容易 // 默认提供\"完整\"的引擎体验，但你可以轻松地在项目的 Cargo.toml 中启用/禁用功能 关键要点：\nBevy 由多个独立的 crate 组成 每个模块都可以单独使用 可以通过 Cargo features 控制功能 可以替换不喜欢的模块 说明： Bevy 的模块化架构允许开发者只使用需要的功能，减少编译时间和二进制大小。每个模块都是独立的 crate，可以在 crates.io 上找到。","bevy-的设计目标#Bevy 的设计目标":"Bevy 有以下几个核心设计目标：\n源代码文件：bevy/README.md\n设计目标：\nCapable（功能完整）：提供完整的 2D 和 3D 功能集 Simple（简单易用）：新手容易上手，但为高级用户提供无限灵活性 Data Focused（数据导向）：使用 ECS 范式的数据导向架构 Modular（模块化）：只使用你需要的功能，替换你不喜欢的部分 Fast（快速）：应用逻辑应该快速运行，尽可能并行执行 Productive（高效）：更改应该快速编译，等待不有趣 说明： 这些设计目标指导了 Bevy 的开发和设计决策。Bevy 试图在简单性和功能完整性之间找到平衡。","什么是-bevy#什么是 Bevy？":"Bevy 是一个用 Rust 构建的简单、数据驱动的游戏引擎。它是免费且开源的。\n源代码文件：bevy/README.md\n关键信息：\nBevy 是一个数据驱动的游戏引擎 Bevy 使用 ECS（Entity Component System）架构 Bevy 是模块化的，可以按需使用功能 Bevy 专注于开发者生产力和性能 说明： Bevy 的设计目标是创建一个简单易用但功能强大的游戏引擎。它使用数据导向的架构，通过 ECS 模式实现高性能的游戏逻辑。","在游戏开发中的应用场景#在游戏开发中的应用场景":"Bevy 适用于各种游戏开发场景：\n2D 游戏开发：Bevy 提供完整的 2D 功能集 3D 游戏开发：Bevy 提供完整的 3D 功能集 原型开发：Bevy 的简单性和快速编译使其适合原型开发 学习游戏开发：Bevy 的简单性和文档使其适合学习游戏开发","实际应用#实际应用":"","常见问题#常见问题":"问题 1：Bevy 适合初学者吗？\n解决方案：是的，Bevy 的设计目标之一是简单易用，新手容易上手。Bevy 的 API 简洁，文档完善，适合初学者学习游戏开发。\n问题 2：Bevy 的性能如何？\n解决方案：Bevy 的性能很好。Bevy 使用数据导向的架构和 ECS 模式，支持大规模并行执行，性能接近 C++ 游戏引擎。\n问题 3：Bevy 的稳定性如何？\n解决方案：Bevy 仍在积极开发中，API 可能会发生变化。Bevy 大约每 3 个月发布一个新版本，可能包含破坏性更改。Bevy 提供迁移指南，但不能保证迁移总是容易的。\n问题 4：Bevy 支持哪些平台？\n解决方案：Bevy 支持多个平台，包括 Windows、macOS、Linux、Android、iOS 和 Web（WebAssembly）。","性能考虑#性能考虑":"编译时间：Bevy 的编译时间可能较长，特别是首次编译。可以通过禁用不需要的 features 来减少编译时间。 运行时性能：Bevy 的运行时性能很好，使用数据导向的架构和 ECS 模式，支持大规模并行执行。 内存使用：Bevy 的内存使用合理，使用 Rust 的所有权系统管理内存，无需垃圾回收。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 是什么以及它的设计目标 了解 Bevy 与 Rust 的关系 理解 Bevy 的模块化架构 了解 Bevy 的 Cargo features 理解 Bevy 的 ECS 实现 了解 Bevy 的插件系统 前置知识要求：\nRust 基础语法 基本的 Rust 项目结构 Cargo 包管理器使用","相关资源#相关资源":"相关源代码文件：\nbevy/README.md - Bevy 主 README bevy/src/lib.rs - Bevy 主库文件 bevy/crates/bevy_ecs/README.md - Bevy ECS README bevy/docs/cargo_features.md - Bevy Cargo Features 文档 官方文档链接：\nBevy 官方网站 Bevy 快速入门指南 Bevy 官方文档 Bevy 官方示例 进一步学习建议：\n学习快速入门，创建第一个 Bevy 应用 学习 ECS 基础，理解 Bevy 的核心编程范式 学习游戏引擎基础，理解游戏引擎的基本工作原理 索引：返回上级目录"},"title":"Bevy——Rust框架"},"/wiki/bevybook/input/":{"data":{"":"","1-输入基础#1. 输入基础":"","2-输入处理#2. 输入处理":"","3-拾取系统picking#3. 拾取系统（Picking）":"本部分介绍如何在 Bevy 中处理各种用户输入。\n内容列表 1. 输入基础 输入系统概述 输入事件类型 输入状态管理 输入处理流程 学习目标：理解 Bevy 的输入系统工作原理\n2. 输入处理 键盘输入\n按键检测 按键状态 按键组合 文本输入 鼠标输入\n鼠标位置 鼠标按钮 鼠标滚轮 鼠标捕获 游戏手柄输入\n手柄检测 手柄按钮 手柄摇杆 手柄震动 触摸输入\n触摸事件 多点触控 手势识别 学习目标：能够处理各种类型的用户输入\n3. 拾取系统（Picking） 拾取系统概述 鼠标拾取 射线拾取 拾取事件处理 学习目标：能够实现对象拾取和交互","下一步#下一步":"完成本部分学习后，建议继续学习：\nGraphics（图形渲染） - 结合输入实现交互 UI \u0026 Audio（界面与音频） - 处理 UI 输入 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"实践为主：多写代码处理不同的输入场景 理解事件：理解输入事件和状态的区别 平台差异：注意不同平台的输入差异 用户体验：考虑输入响应性和用户体验","相关资源#相关资源":"Bevy Input 官方文档 输入处理示例"},"title":"Input（输入处理）"},"/wiki/bevybook/input/%E6%8B%BE%E5%8F%96%E7%B3%BB%E7%BB%9Fpicking/":{"data":{"":"","什么是拾取系统#什么是拾取系统？":"拾取系统是 Bevy 中用于检测鼠标或触摸输入是否与实体交互的功能。拾取系统可以用于实现点击、悬停、拖拽等交互功能。\n为什么需要拾取系统？\n交互检测：拾取系统可以检测鼠标或触摸输入是否与实体交互 点击事件：拾取系统可以触发点击事件 悬停效果：拾取系统可以实现悬停效果 拖拽功能：拾取系统可以实现拖拽功能","在游戏开发中的应用场景#在游戏开发中的应用场景":"拾取系统在游戏开发中有广泛的应用：\n点击交互：实现点击实体触发事件 悬停效果：实现鼠标悬停时的视觉效果 拖拽功能：实现拖拽实体移动 选择功能：实现选择实体的功能 UI 交互：实现 UI 元素的交互","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何启用拾取系统？\n解决方案：\n使用 MeshPickingPlugin 启用网格拾取 使用 Pickable 组件标记实体为可拾取 使用 observe() 注册指针事件观察者 问题 2：如何处理拾取事件？\n解决方案：\n使用 On","性能考虑#性能考虑":"拾取插件：拾取插件是高效的，可以频繁使用 拾取事件：拾取事件处理是高效的，可以大量使用 拾取调试：拾取调试应仅在开发时使用，避免影响性能","拾取事件#拾取事件":"使用拾取事件处理复杂的交互。\n关键信息：\n使用 On","拾取系统的核心组件#拾取系统的核心组件":"Bevy 拾取系统包含以下核心组件：\nPickable：可拾取组件，标记实体为可拾取 MeshPickingPlugin：网格拾取插件，用于 3D 网格拾取 Pointer：指针事件，用于处理鼠标和触摸输入 PointerInteraction：指针交互，用于处理交互状态","拾取调试#拾取调试":"使用拾取调试工具调试拾取问题。\n源代码文件：bevy/examples/picking/debug_picking.rs\n关键信息：\n使用 DebugPickingPlugin 启用拾取调试 使用 DebugPickingMode 控制调试模式 使用 DebugPickingBackend 控制调试后端 说明： 拾取调试是拾取系统的重要功能。通过使用拾取调试，可以调试拾取问题，了解拾取系统的行为。","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 Bevy 拾取系统的基本概念 掌握网格拾取的使用 了解精灵拾取的使用 学会使用拾取事件 前置知识要求：\nBevy 快速入门 ECS 基础 输入处理基础 3D 开发基础（用于网格拾取）","相关资源#相关资源":"相关源代码文件：\nbevy/examples/picking/simple_picking.rs - 简单拾取示例 bevy/examples/picking/mesh_picking.rs - 网格拾取示例 bevy/examples/picking/sprite_picking.rs - 精灵拾取示例 bevy/examples/picking/debug_picking.rs - 拾取调试示例 官方文档链接：\nBevy 拾取系统 Bevy 拾取示例 进一步学习建议：\n学习输入处理，了解输入系统 学习 3D 开发，了解 3D 渲染基础 学习 UI 系统，了解 UI 交互 索引：返回上级目录","简单拾取#简单拾取":"使用拾取系统实现简单的点击和拖拽功能。\n源代码文件：bevy/examples/picking/simple_picking.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins((DefaultPlugins, MeshPickingPlugin)) .add_systems(Startup, setup_scene) .run(); } fn setup_scene( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { commands .spawn(( Text::new(\"Click Me to get a box\\nDrag cubes to rotate\"), Node { position_type: PositionType::Absolute, top: percent(12), left: percent(12), ..default() }, )) .observe(on_click_spawn_cube) .observe(|out: On\u003cPointer\u003cOut\u003e\u003e, mut texts: Query\u003c\u0026mut TextColor\u003e| { let mut text_color = texts.get_mut(out.entity).unwrap(); text_color.0 = Color::WHITE; }) .observe( |over: On\u003cPointer\u003cOver\u003e\u003e, mut texts: Query\u003c\u0026mut TextColor\u003e| { let mut color = texts.get_mut(over.entity).unwrap(); color.0 = bevy::color::palettes::tailwind::CYAN_400.into(); }, ); // 基础 commands.spawn(( Mesh3d(meshes.add(Circle::new(4.0))), MeshMaterial3d(materials.add(Color::WHITE)), Transform::from_rotation(Quat::from_rotation_x(-std::f32::consts::FRAC_PI_2)), )); // 光源 commands.spawn(( PointLight { shadows_enabled: true, ..default() }, Transform::from_xyz(4.0, 8.0, 4.0), )); // 相机 commands.spawn(( Camera3d::default(), Transform::from_xyz(-2.5, 4.5, 9.0).looking_at(Vec3::ZERO, Vec3::Y), )); } fn on_click_spawn_cube( _click: On\u003cPointer\u003cClick\u003e\u003e, mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, mut num: Local\u003cusize\u003e, ) { commands .spawn(( Mesh3d(meshes.add(Cuboid::new(0.5, 0.5, 0.5))), MeshMaterial3d(materials.add(Color::srgb_u8(124, 144, 255))), Transform::from_xyz(0.0, 0.25 + 0.55 * *num as f32, 0.0), )) // 添加 MeshPickingPlugin 后，您可以向网格添加指针事件观察者： .observe(on_drag_rotate); *num += 1; } fn on_drag_rotate(drag: On\u003cPointer\u003cDrag\u003e\u003e, mut transforms: Query\u003c\u0026mut Transform\u003e) { if let Ok(mut transform) = transforms.get_mut(drag.entity) { transform.rotate_y(drag.delta.x * 0.02); transform.rotate_x(drag.delta.y * 0.02); } } 关键要点：\n使用 MeshPickingPlugin 启用网格拾取 使用 observe() 注册指针事件观察者 使用 On","精灵拾取#精灵拾取":"使用精灵拾取实现 2D 精灵的交互。\n源代码文件：bevy/examples/picking/sprite_picking.rs\n代码示例：\nuse bevy::{prelude::*, sprite::Anchor}; fn main() { App::new() .add_plugins(DefaultPlugins.set(ImagePlugin::default_nearest())) .add_systems(Startup, (setup, setup_atlas)) .add_systems(Update, (move_sprite, animate_sprite)) .run(); } fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(Camera2d); let len = 128.0; let sprite_size = Vec2::splat(len / 2.0); commands .spawn((Transform::default(), Visibility::default())) .with_children(|commands| { for (anchor_index, anchor) in [ Anchor::TOP_LEFT, Anchor::TOP_CENTER, Anchor::TOP_RIGHT, Anchor::CENTER_LEFT, Anchor::CENTER, Anchor::CENTER_RIGHT, Anchor::BOTTOM_LEFT, Anchor::BOTTOM_CENTER, Anchor::BOTTOM_RIGHT, ] .iter() .enumerate() { let i = (anchor_index % 3) as f32; let j = (anchor_index / 3) as f32; // 在精灵后面生成黑色方块以显示锚点 commands .spawn(( Sprite::from_color(Color::BLACK, sprite_size), Transform::from_xyz(i * len - len, j * len - len, -1.0), Pickable::default(), )) .observe(recolor_on::\u003cPointer\u003cOver\u003e\u003e(Color::srgb(0.0, 1.0, 1.0))) .observe(recolor_on::\u003cPointer\u003cOut\u003e\u003e(Color::BLACK)) .observe(recolor_on::\u003cPointer\u003cPress\u003e\u003e(Color::srgb(1.0, 1.0, 0.0))) .observe(recolor_on::\u003cPointer\u003cRelease\u003e\u003e(Color::srgb(0.0, 1.0, 1.0))); commands .spawn(( Sprite { image: asset_server.load(\"branding/bevy_bird_dark.png\"), custom_size: Some(sprite_size), color: Color::srgb(1.0, 0.0, 0.0), ..default() }, anchor.to_owned(), // 通过更改变换创建 3x3 锚点示例网格 Transform::from_xyz(i * len - len, j * len - len, 0.0) .with_scale(Vec3::splat(1.0 + (i - 1.0) * 0.2)) .with_rotation(Quat::from_rotation_z((j - 1.0) * 0.2)), Pickable::default(), )) .observe(recolor_on::\u003cPointer\u003cOver\u003e\u003e(Color::srgb(0.0, 1.0, 0.0))) .observe(recolor_on::\u003cPointer\u003cOut\u003e\u003e(Color::srgb(1.0, 0.0, 0.0))) .observe(recolor_on::\u003cPointer\u003cPress\u003e\u003e(Color::srgb(0.0, 0.0, 1.0))) .observe(recolor_on::\u003cPointer\u003cRelease\u003e\u003e(Color::srgb(0.0, 1.0, 0.0))); } }); } 关键要点：\n使用 Pickable 组件标记实体为可拾取 使用 observe() 注册指针事件观察者 使用 On","网格拾取#网格拾取":"使用网格拾取实现 3D 网格的交互。\n源代码文件：bevy/examples/picking/mesh_picking.rs\n代码示例：\nuse bevy::{color::palettes::tailwind::*, picking::pointer::PointerInteraction, prelude::*}; fn main() { App::new() // MeshPickingPlugin 不是默认插件 .add_plugins((DefaultPlugins, MeshPickingPlugin)) .add_systems(Startup, setup_scene) .add_systems(Update, (draw_mesh_intersections, rotate)) .run(); } /// 一个标记组件，用于我们的形状，以便我们可以将它们与地平面分开查询。 #[derive(Component)] struct Shape; fn setup_scene( mut commands: Commands, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { // 设置材质。 let white_matl = materials.add(Color::WHITE); let ground_matl = materials.add(Color::from(GRAY_300)); let hover_matl = materials.add(Color::from(CYAN_300)); let pressed_matl = materials.add(Color::from(YELLOW_300)); let shapes = [ meshes.add(Cuboid::default()), meshes.add(Tetrahedron::default()), meshes.add(Capsule3d::default()), meshes.add(Torus::default()), meshes.add(Cylinder::default()), meshes.add(Cone::default()), meshes.add(ConicalFrustum::default()), meshes.add(Sphere::default().mesh().ico(5).unwrap()), meshes.add(Sphere::default().mesh().uv(32, 18)), ]; // 生成形状。默认情况下，网格是可拾取的。 for (i, shape) in shapes.into_iter().enumerate() { commands .spawn(( Mesh3d(shape), MeshMaterial3d(white_matl.clone()), Transform::from_xyz( -SHAPES_X_EXTENT / 2. + i as f32 / (num_shapes - 1) as f32 * SHAPES_X_EXTENT, 2.0, Z_EXTENT / 2., ) .with_rotation(Quat::from_rotation_x(-PI / 4.)), Shape, )) .observe(update_material_on::\u003cPointer\u003cOver\u003e\u003e(hover_matl.clone())) .observe(update_material_on::\u003cPointer\u003cOut\u003e\u003e(white_matl.clone())) .observe(update_material_on::\u003cPointer\u003cPress\u003e\u003e(pressed_matl.clone())) .observe(update_material_on::\u003cPointer\u003cRelease\u003e\u003e(hover_matl.clone())) .observe(rotate_on_drag); } } 关键要点：\n使用 MeshPickingPlugin 启用网格拾取 使用 observe() 注册指针事件观察者 使用 On","进阶用法#进阶用法":""},"title":"拾取系统（Picking）"},"/wiki/bevybook/input/%E8%BE%93%E5%85%A5%E5%A4%84%E7%90%86/":{"data":{"":"input基础\n本教程基于Bevy官方示例，提供了完整的输入系统开发指南。","1-基础输入处理#1. 基础输入处理":"fn input_system(keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e) { if keyboard_input.pressed(KeyCode::KeyW) { // 处理持续输入 } if keyboard_input.just_pressed(KeyCode::Space) { // 处理单次输入 } }","1-游戏手柄震动#1. 游戏手柄震动":"fn rumble_system( gamepads: Query\u003c(Entity, \u0026Gamepad)\u003e, mut rumble_requests: EventWriter\u003cGamepadRumbleRequest\u003e, ) { for (entity, gamepad) in \u0026gamepads { if gamepad.just_pressed(GamepadButton::North) { rumble_requests.send(GamepadRumbleRequest::Add { gamepad: entity, intensity: GamepadRumbleIntensity::strong_motor(0.5), duration: Duration::from_secs(2), }); } } }","1-输入延迟#1. 输入延迟":"// 使用缓存减少重复检查 let cached_state = input_cache.get_key_state(key); // 使用批处理减少事件处理开销 let batched_events = collect_events(); process_batch(batched_events);","1-输入系统设计#1. 输入系统设计":"使用状态机管理不同的输入上下文 实现输入映射系统支持自定义绑定 使用事件系统处理输入，避免直接修改游戏状态 实现输入缓冲和预测提高响应性","1-输入缓存#1. 输入缓存":"#[derive(Resource)] struct InputCache { keyboard_cache: HashMap\u003cKeyCode, bool\u003e, last_update: f32, cache_duration: f32, } fn optimized_input_system( mut input_cache: ResMut\u003cInputCache\u003e, keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, time: Res\u003cTime\u003e, ) { let current_time = time.elapsed_secs(); if input_cache.needs_update(current_time) { input_cache.update_cache(\u0026keyboard_input, current_time); } // 使用缓存的数据 if input_cache.is_key_pressed(KeyCode::KeyW) { // 处理输入 } }","2-性能优化#2. 性能优化":"缓存输入状态减少重复检查 使用批处理减少事件处理开销 实现输入预测和插值 优化输入事件的分发和处理","2-组合键处理#2. 组合键处理":"fn combo_input_system(input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e) { let ctrl = input.any_pressed([KeyCode::ControlLeft, KeyCode::ControlRight]); let shift = input.any_pressed([KeyCode::ShiftLeft, KeyCode::ShiftRight]); if ctrl \u0026\u0026 shift \u0026\u0026 input.just_pressed(KeyCode::KeyS) { // 处理 Ctrl+Shift+S } }","2-输入冲突#2. 输入冲突":"// 使用状态机管理输入上下文 match current_input_state { InputState::Gameplay =\u003e { // 处理游戏输入 } InputState::UI =\u003e { // 处理UI输入 } }","2-输入批处理#2. 输入批处理":"fn batched_input_system( mut input_events: EventReader\u003cInputEvent\u003e, mut batched_actions: EventWriter\u003cBatchedAction\u003e, ) { let mut actions = Vec::new(); for event in input_events.read() { actions.push(event.action.clone()); } if !actions.is_empty() { batched_actions.send(BatchedAction { actions }); } }","2-输入映射系统#2. 输入映射系统":"#[derive(Resource)] struct InputMapping { keyboard_bindings: HashMap\u003cInputAction, Vec\u003cKeyCode\u003e\u003e, mouse_bindings: HashMap\u003cInputAction, Vec\u003cMouseButton\u003e\u003e, gamepad_bindings: HashMap\u003cInputAction, Vec\u003cGamepadButton\u003e\u003e, } fn input_processing_system( keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, input_mapping: Res\u003cInputMapping\u003e, ) { for (action, keys) in \u0026input_mapping.keyboard_bindings { let is_pressed = keys.iter().any(|key| keyboard_input.pressed(*key)); // 处理映射的输入 } }","3-事件优先级#3. 事件优先级":"fn priority_input_system( mut high_priority: EventReader\u003cHighPriorityEvent\u003e, mut normal_priority: EventReader\u003cNormalPriorityEvent\u003e, ) { // 先处理高优先级事件 for event in high_priority.read() { // 处理紧急输入 } // 再处理正常优先级事件 for event in normal_priority.read() { // 处理常规输入 } }","3-多设备支持#3. 多设备支持":"// 统一输入映射 fn unified_input_system( keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, gamepads: Query\u003c\u0026Gamepad\u003e, input_mapping: Res\u003cInputMapping\u003e, ) { // 检查键盘输入 if keyboard_input.pressed(input_mapping.get_key(InputAction::MoveForward)) { // 处理移动 } // 检查游戏手柄输入 for gamepad in \u0026gamepads { if gamepad.pressed(input_mapping.get_gamepad_button(InputAction::MoveForward)) { // 处理移动 } } }","3-游戏手柄输入#3. 游戏手柄输入":"fn gamepad_system(gamepads: Query\u003c(Entity, \u0026Gamepad)\u003e) { for (entity, gamepad) in \u0026gamepads { if gamepad.just_pressed(GamepadButton::South) { // 处理按钮按下 } let left_stick_x = gamepad.get(GamepadAxis::LeftStickX).unwrap(); if left_stick_x.abs() \u003e 0.01 { // 处理摇杆输入 } } }","3-用户体验#3. 用户体验":"支持多种输入设备 提供输入配置选项 实现输入反馈（震动、音效等） 处理输入冲突和优先级","3-输入状态机#3. 输入状态机":"#[derive(States)] enum InputState { Normal, Menu, Combat, } fn input_state_system( mut input_context: ResMut\u003cInputContext\u003e, keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, ) { match input_context.current_state { InputState::Normal =\u003e { if keyboard_input.just_pressed(KeyCode::Escape) { input_context.current_state = InputState::Menu; } } InputState::Menu =\u003e { if keyboard_input.just_pressed(KeyCode::Escape) { input_context.current_state = InputState::Normal; } } _ =\u003e {} } }","4-触摸输入#4. 触摸输入":"fn touch_system(touches: Res\u003cTouches\u003e) { for touch in touches.iter_just_pressed() { info!(\"触摸按下 - ID: {}, 位置: {}\", touch.id(), touch.position()); } for touch in touches.iter() { if touches.pressed(touch.id()) { // 处理持续触摸 } } }","4-输入验证#4. 输入验证":"// 输入过滤器 fn input_filter_system( keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, input_filter: Res\u003cInputFilter\u003e, mut filtered_events: EventWriter\u003cFilteredInputEvent\u003e, ) { for key_code in KeyCode::iter() { if keyboard_input.just_pressed(key_code) { if !input_filter.is_disabled(key_code) { filtered_events.send(FilteredInputEvent { key: key_code }); } } } }","4-错误处理#4. 错误处理":"验证输入数据的有效性 处理设备连接和断开 提供合理的默认输入配置 记录输入错误便于调试","5-输入事件监听#5. 输入事件监听":"fn event_system(mut events: EventReader\u003cKeyboardInput\u003e) { for event in events.read() { match event.logical_key { Key::Character(c) =\u003e { // 处理字符输入 } Key::Enter =\u003e { // 处理回车键 } _ =\u003e {} } } }","基础教程-bevy_input_基础教程md#基础教程 (\u003ccode\u003eBevy_Input_基础教程.md\u003c/code\u003e)":"键盘输入: 基础按键、事件监听、修饰键、字符输入 鼠标输入: 按钮、移动、滚轮、事件监听、光标控制 触摸输入: 基础触摸、事件监听、多点触摸 游戏手柄输入: 基础手柄、事件监听、连接管理 文本输入: IME支持、多语言输入、特殊键处理","基础输入资源#基础输入资源":"// 键盘输入 Res\u003cButtonInput\u003cKeyCode\u003e\u003e // 鼠标输入 Res\u003cButtonInput\u003cMouseButton\u003e\u003e Res\u003cAccumulatedMouseMotion\u003e Res\u003cAccumulatedMouseScroll\u003e // 触摸输入 Res\u003cTouches\u003e // 游戏手柄 Query\u003c(Entity, \u0026Gamepad)\u003e","学习路径建议#学习路径建议":"初学者: 从基础教程开始，掌握各种输入设备的基本使用 进阶用户: 学习高级教程，了解输入映射、状态管理等 高级用户: 探索自定义输入系统、性能优化、输入预测等","官方文档#官方文档":"Bevy Input Book Bevy Input Examples Bevy Input API Reference","常用模式#常用模式":"","常见问题解决#常见问题解决":"","性能优化技巧#性能优化技巧":"","扩展资源#扩展资源":"","教程结构#教程结构":"","最佳实践#最佳实践":"","核心概念速查#核心概念速查":"","社区资源#社区资源":"Bevy Discord Bevy GitHub Bevy Assets","结语#结语":"Bevy的输入系统提供了强大而灵活的输入处理能力，从基础的键盘鼠标输入到高级的游戏手柄震动和自定义输入类型。通过本教程的学习，您应该能够：\n处理各种输入设备的输入 实现复杂的输入映射和绑定 管理输入状态和上下文 优化输入系统的性能 创建自定义输入类型 实现输入预测和插值 建议在实际项目中逐步应用这些知识，并根据具体需求选择合适的特性组合。Bevy的ECS架构和模块化设计使得输入系统易于扩展和维护，是开发高质量交互体验的优秀选择。","输入事件#输入事件":"// 键盘事件 EventReader\u003cKeyboardInput\u003e // 鼠标事件 EventReader\u003cMouseButtonInput\u003e EventReader\u003cMouseMotion\u003e EventReader\u003cCursorMoved\u003e EventReader\u003cMouseWheel\u003e // 触摸事件 EventReader\u003cTouchInput\u003e // 游戏手柄事件 EventReader\u003cGamepadConnectionEvent\u003e EventReader\u003cGamepadAxisChangedEvent\u003e EventReader\u003cGamepadButtonChangedEvent\u003e","输入状态检查#输入状态检查":"// 按键状态 keyboard_input.pressed(KeyCode::KeyA) // 正在按下 keyboard_input.just_pressed(KeyCode::KeyA) // 刚刚按下 keyboard_input.just_released(KeyCode::KeyA) // 刚刚释放 // 组合键检查 input.any_pressed([KeyCode::ShiftLeft, KeyCode::ShiftRight])","高级功能#高级功能":"","高级教程-bevy_input_高级教程md#高级教程 (\u003ccode\u003eBevy_Input_高级教程.md\u003c/code\u003e)":"游戏手柄震动: 力反馈、自定义震动模式 输入映射和绑定: 动态绑定、配置管理 输入事件处理: 优先级、过滤、转换 输入状态管理: 状态机、上下文管理 自定义输入系统: 扩展输入类型、模拟回放 输入优化: 缓存、批处理、预测插值"},"title":"输入处理"},"/wiki/bevybook/input/input%E5%9F%BA%E7%A1%80/":{"data":{"bevy-input-基础教程#Bevy Input 基础教程":"Bevy Input 基础教程本教程基于Bevy官方示例，按主题组织，提供易于理解的输入系统使用参考。","基础文本输入#基础文本输入":"示例文件: text_input.rs\n处理文本输入和IME（输入法编辑器）：\nuse std::mem; use bevy::{ input::keyboard::{Key, KeyboardInput}, prelude::*, }; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup_scene) .add_systems( Update, ( toggle_ime, listen_ime_events, listen_keyboard_input_events, bubbling_text, ), ) .run(); } fn setup_scene(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(Camera2d); // 使用支持更多字符的字体 let font = asset_server.load(\"fonts/FiraMono-Medium.ttf\"); // 创建UI文本显示 commands.spawn(( Text::default(), Node { position_type: PositionType::Absolute, top: Val::Px(12.0), left: Val::Px(12.0), ..default() }, children![ TextSpan::new(\"点击切换IME。按回车开始新行。\\\\n\\\\n\"), TextSpan::new(\"IME启用: \"), TextSpan::new(\"false\\\\n\"), TextSpan::new(\"IME激活: \"), TextSpan::new(\"false\\\\n\"), TextSpan::new(\"IME缓冲区: \"), ( TextSpan::new(\"\\\\n\"), TextFont { font: font.clone(), ..default() }, ), ], )); // 创建2D文本用于输入 commands.spawn(( Text2d::new(\"\"), TextFont { font, font_size: 100.0, ..default() }, )); } // 切换IME状态 fn toggle_ime( input: Res\u003cButtonInput\u003cMouseButton\u003e\u003e, mut window: Single\u003c\u0026mut Window\u003e, status_text: Single\u003cEntity, (With\u003cNode\u003e, With\u003cText\u003e)\u003e, mut ui_writer: TextUiWriter, ) { if input.just_pressed(MouseButton::Left) { window.ime_position = window.cursor_position().unwrap(); window.ime_enabled = !window.ime_enabled; *ui_writer.text(*status_text, 3) = format!(\"{}\\\\n\", window.ime_enabled); } } // 监听IME事件 fn listen_ime_events( mut events: EventReader\u003cIme\u003e, status_text: Single\u003cEntity, (With\u003cNode\u003e, With\u003cText\u003e)\u003e, mut edit_text: Single\u003c\u0026mut Text2d, (Without\u003cNode\u003e, Without\u003cBubble\u003e)\u003e, mut ui_writer: TextUiWriter, ) { for event in events.read() { match event { Ime::Preedit { value, cursor } =\u003e { *ui_writer.text(*status_text, 5) = format!(\"{}\\\\n\", value); *ui_writer.text(*status_text, 4) = \"true\\\\n\".to_string(); } Ime::Commit { value } =\u003e { edit_text.0 = format!(\"{}{}\", edit_text.0, value); *ui_writer.text(*status_text, 5) = \"\\\\n\".to_string(); *ui_writer.text(*status_text, 4) = \"false\\\\n\".to_string(); } Ime::Enabled { .. } =\u003e { *ui_writer.text(*status_text, 4) = \"true\\\\n\".to_string(); } Ime::Disabled { .. } =\u003e { *ui_writer.text(*status_text, 4) = \"false\\\\n\".to_string(); } } } } // 监听键盘输入事件 fn listen_keyboard_input_events( mut commands: Commands, mut events: EventReader\u003cKeyboardInput\u003e, edit_text: Single\u003c(\u0026mut Text2d, \u0026TextFont), (Without\u003cNode\u003e, Without\u003cBubble\u003e)\u003e, ) { for event in events.read() { if !event.state.is_pressed() { continue; } match \u0026event.logical_key { Key::Character(character) =\u003e { if is_printable_char(*character) { edit_text.0 .0 = format!(\"{}{}\", edit_text.0 .0, character); } } Key::Enter =\u003e { edit_text.0 .0 = format!(\"{}\\\\n\", edit_text.0 .0); } Key::Backspace =\u003e { edit_text.0 .0.pop(); } _ =\u003e {} } } } // 检查是否为可打印字符 fn is_printable_char(chr: char) -\u003e bool { !chr.is_control() || chr == '\\\\n' || chr == '\\\\t' } 关键要点:\nIME支持多语言输入 处理预编辑和提交事件 支持特殊键如回车、退格 需要合适的字体支持多语言字符","基础游戏手柄输入#基础游戏手柄输入":"示例文件: gamepad_input.rs\n处理游戏手柄输入：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, gamepad_system) .run(); } fn gamepad_system(gamepads: Query\u003c(Entity, \u0026Gamepad)\u003e) { for (entity, gamepad) in \u0026gamepads { // 处理按钮输入 if gamepad.just_pressed(GamepadButton::South) { info!(\"手柄 {} 刚刚按下 South 按钮\", entity); } else if gamepad.just_released(GamepadButton::South) { info!(\"手柄 {} 刚刚释放 South 按钮\", entity); } // 处理扳机键（模拟输入） let right_trigger = gamepad.get(GamepadButton::RightTrigger2).unwrap(); if right_trigger.abs() \u003e 0.01 { info!(\"手柄 {} 右扳机值: {}\", entity, right_trigger); } // 处理摇杆输入 let left_stick_x = gamepad.get(GamepadAxis::LeftStickX).unwrap(); let left_stick_y = gamepad.get(GamepadAxis::LeftStickY).unwrap(); if left_stick_x.abs() \u003e 0.01 || left_stick_y.abs() \u003e 0.01 { info!(\"手柄 {} 左摇杆: ({}, {})\", entity, left_stick_x, left_stick_y); } let right_stick_x = gamepad.get(GamepadAxis::RightStickX).unwrap(); let right_stick_y = gamepad.get(GamepadAxis::RightStickY).unwrap(); if right_stick_x.abs() \u003e 0.01 || right_stick_y.abs() \u003e 0.01 { info!(\"手柄 {} 右摇杆: ({}, {})\", entity, right_stick_x, right_stick_y); } // 处理其他按钮 if gamepad.just_pressed(GamepadButton::North) { info!(\"手柄 {} 按下 North 按钮\", entity); } if gamepad.just_pressed(GamepadButton::East) { info!(\"手柄 {} 按下 East 按钮\", entity); } if gamepad.just_pressed(GamepadButton::West) { info!(\"手柄 {} 按下 West 按钮\", entity); } } } 关键要点:\nGamepad 组件提供手柄输入状态 支持多个手柄同时连接 按钮有数字和模拟两种输入 摇杆提供X、Y轴模拟输入","基础触摸输入#基础触摸输入":"示例文件: touch_input.rs\n处理触摸屏输入：\nuse bevy::{input::touch::*, prelude::*}; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, touch_system) .run(); } fn touch_system(touches: Res\u003cTouches\u003e) { // 处理刚刚按下的触摸 for touch in touches.iter_just_pressed() { info!( \"触摸按下 - ID: {}, 位置: {}\", touch.id(), touch.position() ); } // 处理刚刚释放的触摸 for touch in touches.iter_just_released() { info!( \"触摸释放 - ID: {}, 位置: {}\", touch.id(), touch.position() ); } // 处理被取消的触摸 for touch in touches.iter_just_canceled() { info!(\"触摸取消 - ID: {}\", touch.id()); } // 处理所有当前活动的触摸 for touch in touches.iter() { info!(\"活动触摸: {touch:?}\"); info!(\" 是否刚刚按下: {}\", touches.just_pressed(touch.id())); info!(\" 是否正在按下: {}\", touches.pressed(touch.id())); info!(\" 位置: {}\", touch.position()); info!(\" 压力: {}\", touch.force().unwrap_or(0.0)); } // 获取触摸数量 info!(\"当前触摸数量: {}\", touches.count()); } 关键要点:\nTouches 资源提供触摸状态 每个触摸有唯一ID 支持多点触摸 包含位置和压力信息","基础键盘输入#基础键盘输入":"示例文件: keyboard_input.rs\n最基本的键盘输入处理：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, keyboard_input_system) .run(); } /// 处理键盘输入的系统 fn keyboard_input_system(keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e) { // 检查按键是否正在被按下 if keyboard_input.pressed(KeyCode::KeyA) { info!(\"'A' 键正在被按下\"); } // 检查按键是否刚刚被按下 if keyboard_input.just_pressed(KeyCode::KeyA) { info!(\"'A' 键刚刚被按下\"); } // 检查按键是否刚刚被释放 if keyboard_input.just_released(KeyCode::KeyA) { info!(\"'A' 键刚刚被释放\"); } } 关键要点:\n使用 Res","基础鼠标输入#基础鼠标输入":"示例文件: mouse_input.rs\n处理鼠标按钮和移动：\nuse bevy::{ input::mouse::{AccumulatedMouseMotion, AccumulatedMouseScroll}, prelude::*, }; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, (mouse_click_system, mouse_move_system)) .run(); } /// 处理鼠标点击的系统 fn mouse_click_system(mouse_button_input: Res\u003cButtonInput\u003cMouseButton\u003e\u003e) { // 检查左键是否正在被按下 if mouse_button_input.pressed(MouseButton::Left) { info!(\"左键正在被按下\"); } // 检查左键是否刚刚被按下 if mouse_button_input.just_pressed(MouseButton::Left) { info!(\"左键刚刚被按下\"); } // 检查左键是否刚刚被释放 if mouse_button_input.just_released(MouseButton::Left) { info!(\"左键刚刚被释放\"); } // 检查右键 if mouse_button_input.just_pressed(MouseButton::Right) { info!(\"右键刚刚被按下\"); } // 检查中键 if mouse_button_input.just_pressed(MouseButton::Middle) { info!(\"中键刚刚被按下\"); } } /// 处理鼠标移动和滚轮的系统 fn mouse_move_system( accumulated_mouse_motion: Res\u003cAccumulatedMouseMotion\u003e, accumulated_mouse_scroll: Res\u003cAccumulatedMouseScroll\u003e, ) { // 处理鼠标移动 if accumulated_mouse_motion.delta != Vec2::ZERO { let delta = accumulated_mouse_motion.delta; info!(\"鼠标移动了 ({}, {})\", delta.x, delta.y); } // 处理鼠标滚轮 if accumulated_mouse_scroll.delta != Vec2::ZERO { let delta = accumulated_mouse_scroll.delta; info!(\"鼠标滚动了 ({}, {})\", delta.x, delta.y); } } 关键要点:\nButtonInput 处理鼠标按钮 AccumulatedMouseMotion 处理鼠标移动 AccumulatedMouseScroll 处理滚轮滚动 支持左键、右键、中键检测","字符输入#字符输入":"示例文件: char_input_events.rs\n处理字符输入（支持多语言）：\nuse bevy::{ input::keyboard::{Key, KeyboardInput}, prelude::*, }; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, print_char_event_system) .run(); } /// 处理字符输入的系统 fn print_char_event_system(mut char_input_events: EventReader\u003cKeyboardInput\u003e) { for event in char_input_events.read() { // 只处理按键按下事件 if !event.state.is_pressed() { continue; } // 检查是否为字符输入 if let Key::Character(character) = \u0026event.logical_key { info!(\"输入字符: '{}'\", character); } } } 关键要点:\n使用 event.logical_key 获取逻辑键值 Key::Character 表示字符输入 支持多语言字符输入 适合文本输入和聊天功能","总结#总结":"Bevy的输入系统提供了全面的输入处理能力：\n键盘输入: 基础按键、组合键、字符输入 鼠标输入: 按钮、移动、滚轮、光标控制 触摸输入: 多点触摸、手势识别 游戏手柄: 按钮、摇杆、扳机、震动 文本输入: IME支持、多语言输入 这些输入系统可以组合使用，创建丰富的交互体验。建议根据项目需求选择合适的输入方式。","文本输入#文本输入":"","游戏手柄事件监听#游戏手柄事件监听":"示例文件: gamepad_input_events.rs\n监听游戏手柄连接和输入事件：\nuse bevy::{ input::gamepad::{ GamepadAxisChangedEvent, GamepadButtonChangedEvent, GamepadButtonStateChangedEvent, GamepadConnectionEvent, GamepadEvent, }, prelude::*, }; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, (gamepad_events, gamepad_ordered_events)) .run(); } fn gamepad_events( mut connection_events: EventReader\u003cGamepadConnectionEvent\u003e, mut axis_changed_events: EventReader\u003cGamepadAxisChangedEvent\u003e, mut button_changed_events: EventReader\u003cGamepadButtonChangedEvent\u003e, mut button_input_events: EventReader\u003cGamepadButtonStateChangedEvent\u003e, ) { // 处理连接事件 for connection_event in connection_events.read() { info!(\"手柄连接事件: {:?}\", connection_event); } // 处理轴变化事件 for axis_changed_event in axis_changed_events.read() { info!( \"手柄轴变化 - 轴: {:?}, 手柄: {}, 值: {}\", axis_changed_event.axis, axis_changed_event.entity, axis_changed_event.value ); } // 处理按钮变化事件 for button_changed_event in button_changed_events.read() { info!( \"手柄按钮变化 - 按钮: {:?}, 手柄: {}, 值: {}\", button_changed_event.button, button_changed_event.entity, button_changed_event.value ); } // 处理按钮状态变化事件 for button_input_event in button_input_events.read() { info!(\"手柄按钮状态变化: {:?}\", button_input_event); } } // 处理有序的游戏手柄事件 fn gamepad_ordered_events(mut gamepad_events: EventReader\u003cGamepadEvent\u003e) { for gamepad_event in gamepad_events.read() { match gamepad_event { GamepadEvent::Connection(connection_event) =\u003e { info!(\"手柄连接事件: {:?}\", connection_event); } GamepadEvent::Button(button_event) =\u003e { info!(\"手柄按钮事件: {:?}\", button_event); } GamepadEvent::Axis(axis_event) =\u003e { info!(\"手柄轴事件: {:?}\", axis_event); } } } } 关键要点:\n多种事件类型提供不同粒度的手柄信息 连接事件处理手柄插拔 轴和按钮事件提供精确的输入变化 有序事件确保事件处理的正确顺序","游戏手柄输入#游戏手柄输入":"","触摸事件监听#触摸事件监听":"示例文件: touch_input_events.rs\n监听详细的触摸事件：\nuse bevy::{input::touch::*, prelude::*}; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, touch_event_system) .run(); } fn touch_event_system(mut touch_events: EventReader\u003cTouchInput\u003e) { for event in touch_events.read() { info!(\"触摸事件: {:?}\", event); match event.phase { TouchPhase::Started =\u003e { info!(\"触摸开始 - ID: {}, 位置: {}\", event.id, event.position); } TouchPhase::Moved =\u003e { info!(\"触摸移动 - ID: {}, 位置: {}\", event.id, event.position); } TouchPhase::Ended =\u003e { info!(\"触摸结束 - ID: {}, 位置: {}\", event.id, event.position); } TouchPhase::Canceled =\u003e { info!(\"触摸取消 - ID: {}\", event.id); } } } } 关键要点:\nTouchInput 事件提供详细的触摸信息 TouchPhase 表示触摸的不同阶段 适合需要精确触摸控制的场景","触摸输入#触摸输入":"","键盘事件监听#键盘事件监听":"示例文件: keyboard_input_events.rs\n监听所有键盘事件：\nuse bevy::{input::keyboard::KeyboardInput, prelude::*}; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, print_keyboard_event_system) .run(); } /// 打印所有键盘事件的系统 fn print_keyboard_event_system(mut keyboard_input_events: EventReader\u003cKeyboardInput\u003e) { for event in keyboard_input_events.read() { info!(\"键盘事件: {:?}\", event); } } 关键要点:\n使用 EventReader 监听键盘事件 事件包含按键状态、物理键、逻辑键等信息 适合需要详细键盘信息的场景","键盘修饰键#键盘修饰键":"示例文件: keyboard_modifiers.rs\n处理组合键和修饰键：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, keyboard_input_system) .run(); } /// 处理组合键的系统 fn keyboard_input_system(input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e) { // 检查Shift键是否被按下（左Shift或右Shift） let shift = input.any_pressed([KeyCode::ShiftLeft, KeyCode::ShiftRight]); // 检查Ctrl键是否被按下（左Ctrl或右Ctrl） let ctrl = input.any_pressed([KeyCode::ControlLeft, KeyCode::ControlRight]); // 检查组合键 Ctrl + Shift + A if ctrl \u0026\u0026 shift \u0026\u0026 input.just_pressed(KeyCode::KeyA) { info!(\"刚刚按下了 Ctrl + Shift + A!\"); } // 检查其他组合键 if ctrl \u0026\u0026 input.just_pressed(KeyCode::KeyS) { info!(\"保存快捷键被触发\"); } if ctrl \u0026\u0026 input.just_pressed(KeyCode::KeyZ) { info!(\"撤销快捷键被触发\"); } } 关键要点:\nany_pressed() 检查多个按键中是否有任意一个被按下 支持左右修饰键的检测 适合实现快捷键和组合键功能","键盘输入#键盘输入":"","鼠标事件监听#鼠标事件监听":"示例文件: mouse_input_events.rs\n监听详细的鼠标事件：\nuse bevy::{ input::{ gestures::*, mouse::{MouseButtonInput, MouseMotion, MouseWheel}, }, prelude::*, }; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, print_mouse_events_system) .run(); } /// 打印所有鼠标事件的系统 fn print_mouse_events_system( mut mouse_button_input_events: EventReader\u003cMouseButtonInput\u003e, mut mouse_motion_events: EventReader\u003cMouseMotion\u003e, mut cursor_moved_events: EventReader\u003cCursorMoved\u003e, mut mouse_wheel_events: EventReader\u003cMouseWheel\u003e, mut pinch_gesture_events: EventReader\u003cPinchGesture\u003e, mut rotation_gesture_events: EventReader\u003cRotationGesture\u003e, mut double_tap_gesture_events: EventReader\u003cDoubleTapGesture\u003e, ) { // 鼠标按钮事件 for event in mouse_button_input_events.read() { info!(\"鼠标按钮事件: {:?}\", event); } // 鼠标移动事件 for event in mouse_motion_events.read() { info!(\"鼠标移动事件: {:?}\", event); } // 光标移动事件 for event in cursor_moved_events.read() { info!(\"光标移动事件: {:?}\", event); } // 鼠标滚轮事件 for event in mouse_wheel_events.read() { info!(\"鼠标滚轮事件: {:?}\", event); } // 手势事件（仅macOS） for event in pinch_gesture_events.read() { info!(\"捏合手势事件: {:?}\", event); } for event in rotation_gesture_events.read() { info!(\"旋转手势事件: {:?}\", event); } for event in double_tap_gesture_events.read() { info!(\"双击手势事件: {:?}\", event); } } 关键要点:\n多种事件类型提供不同粒度的鼠标信息 手势事件仅在macOS上可用 适合需要精确鼠标控制的场景","鼠标光标控制#鼠标光标控制":"示例文件: mouse_grab.rs\n控制鼠标光标的显示和锁定：\nuse bevy::{prelude::*, window::CursorGrabMode}; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Update, grab_mouse) .run(); } /// 控制鼠标光标抓取的系统 fn grab_mouse( mut window: Single\u003c\u0026mut Window\u003e, mouse: Res\u003cButtonInput\u003cMouseButton\u003e\u003e, key: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, ) { // 左键点击时隐藏光标并锁定鼠标 if mouse.just_pressed(MouseButton::Left) { window.cursor_options.visible = false; window.cursor_options.grab_mode = CursorGrabMode::Locked; info!(\"鼠标已锁定\"); } // ESC键释放鼠标 if key.just_pressed(KeyCode::Escape) { window.cursor_options.visible = true; window.cursor_options.grab_mode = CursorGrabMode::None; info!(\"鼠标已释放\"); } // 其他光标模式示例 if key.just_pressed(KeyCode::Key1) { // 限制光标在窗口内 window.cursor_options.grab_mode = CursorGrabMode::Confined; } if key.just_pressed(KeyCode::Key2) { // 隐藏光标但不锁定 window.cursor_options.visible = false; window.cursor_options.grab_mode = CursorGrabMode::None; } } 关键要点:\nCursorGrabMode::Locked 锁定鼠标到窗口中心 CursorGrabMode::Confined 限制鼠标在窗口内 CursorGrabMode::None 正常模式 适合FPS游戏等需要鼠标控制的场景","鼠标输入#鼠标输入":""},"title":"input基础"},"/wiki/bevybook/learning_path/":{"data":{"":"本指南帮助你根据不同的学习目标选择合适的学习路径。","1-理论与实践结合#1. 理论与实践结合":"理论学习：阅读教程文档，理解概念 实践练习：编写代码，运行示例 项目实践：完成实际项目","2-循序渐进#2. 循序渐进":"不要跳过基础内容 确保理解每个概念再继续 遇到问题及时查阅文档","3-多写代码#3. 多写代码":"每学完一个概念就写代码 修改示例代码 尝试实现自己的想法","4-参与社区#4. 参与社区":"加入 Bevy Discord 阅读其他人的代码 提问和回答问题","5-持续学习#5. 持续学习":"Bevy 在快速发展 关注更新和变化 阅读源码和文档","51-专注于-ecs#5.1 专注于 ECS":"学习内容：\nECS（实体组件系统） - 全部内容 Advanced（高级主题） - 性能优化 Bevy ECS 源码阅读","52-专注于渲染#5.2 专注于渲染":"学习内容：\n2D Graphics（2D 图形） - 全部内容 3D Graphics（3D 图形） - 全部内容 Advanced（高级主题） - 自定义渲染","53-专注于网络#5.3 专注于网络":"学习内容：\nECS（实体组件系统） - 全部内容 Architecture（架构设计） - 全部内容 Advanced（高级主题） - 网络编程","学习建议#学习建议":"","学习目标#学习目标":"","学习计划建议#学习计划建议":"","每日学习计划2-3-小时天#每日学习计划（2-3 小时/天）":"第 1 周：\n第 1-2 天：Foundation + ECS 基础 第 3-4 天：ECS 进阶 + Assets 第 5-6 天：Input + 2D/3D 基础 第 7 天：复习和实践 第 2 周：\n第 8-9 天：2D/3D 开发 第 10-11 天：UI \u0026 Audio 第 12-13 天：Architecture 第 14 天：项目实践 第 3-4 周：\nAdvanced 主题学习 项目开发 源码阅读","相关资源#相关资源":"Bevy 官方文档 Bevy 官方示例 Bevy Cheatbook Bevy Discord 索引：返回主目录","路径-1快速入门1-2-天#路径 1：快速入门（1-2 天）":"目标：快速了解 Bevy，能够创建简单的程序\n学习内容：\nFoundation（基础） - 快速入门 ECS（实体组件系统） - ECS 基础 Assets（资源管理） - 资源加载基础 Input（输入处理） - 输入基础 预计时间：4-6 小时\n成果：能够创建一个简单的交互式程序","路径-22d-游戏开发1-2-周#路径 2：2D 游戏开发（1-2 周）":"目标：掌握 2D 游戏开发，能够创建完整的 2D 游戏\n学习内容：\nFoundation（基础） - 全部内容 ECS（实体组件系统） - 全部内容 Assets（资源管理） - 全部内容 Input（输入处理） - 全部内容 2D Graphics（2D 图形） - 全部内容 UI \u0026 Audio（界面与音频） - UI 部分 Architecture（架构设计） - 代码组织 预计时间：20-30 小时\n成果：能够开发完整的 2D 游戏","路径-33d-游戏开发2-3-周#路径 3：3D 游戏开发（2-3 周）":"目标：掌握 3D 游戏开发，能够创建完整的 3D 游戏\n学习内容：\nFoundation（基础） - 全部内容 ECS（实体组件系统） - 全部内容 Assets（资源管理） - 全部内容 Input（输入处理） - 全部内容 3D Graphics（3D 图形） - 全部内容 UI \u0026 Audio（界面与音频） - 全部内容 Architecture（架构设计） - 全部内容 预计时间：30-40 小时\n成果：能够开发完整的 3D 游戏","路径-4高级开发者1-2-个月#路径 4：高级开发者（1-2 个月）":"目标：深入理解 Bevy，能够进行高级开发和优化\n学习内容：\n路径 2 或路径 3 的全部内容 Advanced（高级主题） - 全部内容 阅读 Bevy 源码 参与 Bevy 社区 预计时间：50-80 小时\n成果：能够进行高级开发、性能优化和插件开发","路径-5特定领域深入学习#路径 5：特定领域深入学习":""},"title":"学习路径指南"},"/wiki/bevybook/readme/":{"data":{"":"","1-2d-基础#1. 2D 基础":"","1-代码组织#1. 代码组织":"","1-动画基础#1. 动画基础":"","1-快速入门#1. 快速入门":"","1-性能优化#1. 性能优化":"","1-核心编程框架ecs#1. 核心编程框架（ECS）":"","1-窗口管理#1. 窗口管理":"","1-资源管理#1. 资源管理":"","1-输入基础#1. 输入基础":"","10-时间系统time#10. 时间系统（Time）":"","11-ecs-进阶#11. ECS 进阶":"","2-2d-开发#2. 2D 开发":"","2-bevy-与-rust-框架#2. Bevy 与 Rust 框架":"","2-动画进阶#2. 动画进阶":"","2-场景系统scene#2. 场景系统（Scene）":"","2-用户界面ui#2. 用户界面（UI）":"","2-组件components#2. 组件（Components）":"","2-自定义渲染#2. 自定义渲染":"","2-输入处理#2. 输入处理":"","2-逻辑-渲染分离#2. 逻辑-渲染分离":"","3-3d-开发#3. 3D 开发":"","3-ui-动画#3. UI 动画":"","3-实体entities#3. 实体（Entities）":"","3-拾取系统picking#3. 拾取系统（Picking）":"","3-插件系统#3. 插件系统":"","3-游戏引擎基础#3. 游戏引擎基础":"","3-网络编程#3. 网络编程":"","3-音频系统#3. 音频系统":"","4-变形目标#4. 变形目标":"","4-拆解学习#4. 拆解学习":"","4-相机系统camera#4. 相机系统（Camera）":"","4-系统systems#4. 系统（Systems）":"","5-查询queries#5. 查询（Queries）":"","6-资源resources#6. 资源（Resources）":"","7-命令commands#7. 命令（Commands）":"","8-系统调度schedule-与-app#8. 系统调度（Schedule 与 App）":"","9-状态管理state#9. 状态管理（State）":"","目录结构#目录结构":"","示例项目索引#示例项目索引":"本文档提供 Bevy 教程的完整索引，方便快速查找和学习。\n目录结构 tutorial_book/ ├── Foundation/ # 基础部分 ├── ECS/ # 实体组件系统 ├── Assets/ # 资源管理 ├── Input/ # 输入处理 ├── Animation/ # 动画系统 ├── 2D_Graphics/ # 2D 图形 ├── 3D_Graphics/ # 3D 图形 ├── UI_Audio_Window/ # UI、音频与窗口 ├── Architecture/ # 架构设计 ├── Advanced/ # 高级主题 └── Examples/ # 示例项目 第一部分：基础（Foundation） 1. 快速入门 安装 Bevy 配置开发环境 第一个 Bevy 程序 项目结构 2. Bevy 与 Rust 框架 Bevy 简介 Rust 基础 Bevy 架构 核心概念 3. 游戏引擎基础 游戏引擎核心概念 游戏循环 资源管理 渲染管线 索引文件：Foundation/README.md\n第二部分：ECS（实体组件系统） 1. 核心编程框架（ECS） ECS 概述 核心概念 设计思想 2. 组件（Components） 组件基础 组件类型 组件存储 组件访问 3. 实体（Entities） 实体基础 实体创建 实体查询 实体删除 4. 系统（Systems） 系统基础 系统定义 系统参数 系统执行 5. 查询（Queries） 查询基础 查询类型 查询过滤 查询优化 6. 资源（Resources） 资源基础 资源访问 资源管理 7. 命令（Commands） 命令系统基础 实体操作 资源修改 8. 系统调度（Schedule 与 App） 调度系统 系统执行顺序 App 结构 9. 状态管理（State） 状态机基础 状态切换 状态与系统 10. 时间系统（Time） 时间步长 定时器 帧率控制 11. ECS 进阶 高级查询 事件系统 性能优化 索引文件：ECS/README.md\n第三部分：资源管理（Assets） 1. 资源管理 资源加载 资源生命周期 异步加载 2. 场景系统（Scene） 场景结构 场景保存与加载 场景中的实体与组件 索引文件：Assets/README.md\n第四部分：输入处理（Input） 1. 输入基础 输入系统概述 键盘输入 鼠标输入 2. 输入处理 输入映射 动作系统 组合输入 3. 拾取系统（Picking） 射线投射 对象拾取 UI 拾取 索引文件：Input/README.md\n第五部分：动画系统（Animation） 1. 动画基础 动画概念 关键帧 插值 2. 动画进阶 动画状态机 复杂动画 3. UI 动画 UI 动画基础 过渡效果 4. 变形目标 形变动画 顶点动画 索引文件：Animation/README.md\n第六部分：图形渲染（Graphics） 1. 2D 基础 2D 渲染概述 2D 相机 精灵系统 2. 2D 开发 2D 游戏基础 Tilemap 碰撞检测 索引文件：2D_Graphics/README.md\n3. 3D 开发 3D 渲染基础 3D 模型 光照与阴影 4. 相机系统（Camera） 相机类型 相机控制 索引文件：3D_Graphics/README.md\n第七部分：UI、音频与窗口（UI \u0026 Audio \u0026 Window） 1. 窗口管理 窗口创建 窗口配置 多窗口支持 2. 用户界面（UI） UI 系统 布局与样式 交互 3. 音频系统 音频播放 音效管理 背景音乐 索引文件：UI_Audio_Window/README.md\n第八部分：架构设计（Architecture） 1. 代码组织 项目结构 模块划分 2. 逻辑-渲染分离 逻辑线程 渲染线程 数据同步 3. 插件系统 插件设计 插件注册 索引文件：Architecture/README.md\n第九部分：高级主题（Advanced） 1. 性能优化 性能分析 优化技巧 2. 自定义渲染 自定义渲染管线 自定义着色器 3. 网络编程 网络架构 同步策略 4. 拆解学习 源码阅读 模块拆解 索引文件：Advanced/README.md\n第十部分：示例项目（Examples） 示例项目索引 完整项目示例列表 示例说明","第一部分基础foundation#第一部分：基础（Foundation）":"","第七部分ui音频与窗口ui--audio--window#第七部分：UI、音频与窗口（UI \u0026amp; Audio \u0026amp; Window）":"","第三部分资源管理assets#第三部分：资源管理（Assets）":"","第九部分高级主题advanced#第九部分：高级主题（Advanced）":"","第二部分ecs实体组件系统#第二部分：ECS（实体组件系统）":"","第五部分动画系统animation#第五部分：动画系统（Animation）":"","第八部分架构设计architecture#第八部分：架构设计（Architecture）":"","第六部分图形渲染graphics#第六部分：图形渲染（Graphics）":"","第十部分示例项目examples#第十部分：示例项目（Examples）":"","第四部分输入处理input#第四部分：输入处理（Input）":"","辅助文档#辅助文档":"主 README - 教程概览 学习路径 - 详细学习路径 架构文档 - 教程架构说明 贡献指南 - 贡献指南"},"title":"Bevy 教程完整索引"},"/wiki/bevybook/ui_audio_window/":{"data":{"":"","1-窗口管理#1. 窗口管理":"","2-用户界面ui#2. 用户界面（UI）":"","3-音频系统#3. 音频系统":"本部分介绍如何在 Bevy 中创建用户界面、处理音频和管理窗口。\n内容列表 1. 窗口管理 窗口创建与配置 窗口属性（大小、标题、全屏） 窗口事件处理 多窗口支持 透明窗口 窗口截图 学习目标：能够创建和管理应用程序窗口\n2. 用户界面（UI） UI 系统概述 UI 组件（Button、Text、Image 等） UI 布局（Flexbox、Grid） UI 样式（Style） UI 交互（点击、悬停） UI 状态管理 学习目标：能够创建完整的用户界面\n3. 音频系统 音频资源加载 背景音乐（BGM） 音效（SFX） 音频控制（播放、暂停、音量、速度） 3D 音频（空间音频） 音频轨道 学习目标：能够创建完整的音频系统","下一步#下一步":"完成本部分学习后，建议继续学习：\nArchitecture（架构设计） - 组织完整的游戏项目 Advanced（高级主题） - 深入高级功能 索引：返回主目录","内容列表#内容列表":"","学习建议#学习建议":"UI 设计：学习现代 UI 设计原则 响应式设计：考虑不同屏幕尺寸的适配 音频设计：理解音频在游戏中的作用 用户体验：关注 UI 和音频的用户体验","相关资源#相关资源":"Bevy UI 官方文档 Bevy Audio 官方文档 UI 示例 音频示例"},"title":"UI \u0026 Audio（界面与音频）"},"/wiki/bevybook/ui_audio_window/%E7%AA%97%E5%8F%A3/":{"data":{"":"","什么是窗口管理#什么是窗口管理？":"窗口管理是 Bevy 中用于创建和管理应用程序窗口的功能。Bevy 支持创建多个窗口、配置窗口属性、处理窗口事件等。\n为什么需要窗口管理？\n用户界面：窗口是应用程序的用户界面 多窗口支持：可以创建多个窗口来显示不同的内容 窗口配置：可以配置窗口的大小、标题、主题等属性 窗口事件：可以处理窗口事件，如关闭、调整大小等","在游戏开发中的应用场景#在游戏开发中的应用场景":"窗口管理在游戏开发中有广泛的应用：\n游戏窗口：创建游戏主窗口 调试窗口：创建调试信息窗口 设置窗口：创建设置界面窗口 多显示器支持：在不同显示器上显示不同内容","基础用法#基础用法":"","多窗口支持#多窗口支持":"创建和管理多个窗口。\n源代码文件：bevy/examples/window/multiple_windows.rs\n代码示例：\nuse bevy::prelude::*; use bevy::window::{RenderTarget, WindowRef}; fn setup_scene(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { // 创建第一个窗口的相机 let first_window_camera = commands .spawn(( Camera3d::default(), Transform::from_xyz(0.0, 0.0, 6.0).looking_at(Vec3::ZERO, Vec3::Y), )) .id(); // 创建第二个窗口 let second_window = commands .spawn(Window { title: \"第二个窗口\".to_owned(), ..default() }) .id(); // 创建第二个窗口的相机 let second_window_camera = commands .spawn(( Camera3d::default(), Transform::from_xyz(6.0, 0.0, 0.0).looking_at(Vec3::ZERO, Vec3::Y), Camera { target: RenderTarget::Window(WindowRef::Entity(second_window)), ..default() }, )) .id(); } 关键要点：\n可以创建多个窗口 每个窗口可以有独立的相机 使用 RenderTarget::Window 来指定相机渲染到哪个窗口 使用 WindowRef::Entity 来引用窗口实体 说明： 多窗口支持允许创建复杂的应用程序界面。例如，可以创建一个主窗口显示游戏内容，另一个窗口显示调试信息。","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何创建全屏窗口？\n解决方案：可以设置窗口的 mode 属性为 WindowMode::Fullscreen。\n问题 2：如何处理窗口关闭事件？\n解决方案：可以监听 WindowCloseRequested 事件，并在事件处理中执行清理操作。\n问题 3：如何在不同窗口之间切换？\n解决方案：可以使用 WindowRef 来引用不同的窗口，并使用 Camera 的 target 属性来指定渲染目标。","性能考虑#性能考虑":"窗口数量：尽量减少窗口数量以提高性能 窗口大小：合理设置窗口大小以平衡性能和视觉效果 VSync：根据需求启用或禁用 VSync 窗口事件：避免在窗口事件处理中执行耗时操作","核心概念#核心概念":"","概述#概述":"学习目标：\n理解窗口管理的基本概念 掌握窗口的创建和配置 了解窗口属性的设置 学会处理多窗口场景 前置知识要求：\nBevy 快速入门 ECS 基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/window/window_settings.rs - 窗口设置示例 bevy/examples/window/multiple_windows.rs - 多窗口示例 bevy/examples/window/transparent_window.rs - 透明窗口示例 bevy/examples/window/window_resizing.rs - 窗口调整大小示例 bevy/examples/window/screenshot.rs - 窗口截图示例 官方文档链接：\nBevy Window 官方文档 窗口示例 进一步学习建议：\n学习 UI，了解如何在窗口中创建用户界面 学习输入处理，了解如何处理窗口输入事件 学习相机系统，了解如何在窗口中渲染内容 索引：返回上级目录","窗口事件处理#窗口事件处理":"处理窗口事件，如关闭、调整大小等。\n源代码文件：bevy/examples/window/window_resizing.rs\n关键信息：\n可以监听窗口关闭事件 可以监听窗口调整大小事件 可以监听窗口焦点变化事件 可以使用 EventReader 来处理窗口事件 说明： 窗口事件处理允许应用程序响应窗口状态的变化。这对于创建响应式应用程序非常重要。","窗口创建和配置#窗口创建和配置":"创建和配置窗口。\n源代码文件：bevy/examples/window/window_settings.rs\n代码示例：\nuse bevy::prelude::*; use bevy::window::{PresentMode, WindowLevel, WindowTheme}; fn main() { App::new() .add_plugins(DefaultPlugins.set(WindowPlugin { primary_window: Some(Window { title: \"我的窗口\".into(), name: Some(\"bevy.app\".into()), resolution: (800, 600).into(), present_mode: PresentMode::AutoVsync, window_theme: Some(WindowTheme::Dark), enabled_buttons: bevy::window::EnabledButtons { maximize: false, ..Default::default() }, visible: false, ..default() }), ..default() })) .add_systems(Update, make_visible) .run(); } fn make_visible(mut window: Single\u003c\u0026mut Window\u003e, frames: Res\u003cFrameCount\u003e) { if frames.0 == 3 { window.visible = true; } } 关键要点：\n可以通过 WindowPlugin 配置主窗口 可以设置窗口的标题、大小、主题等属性 可以控制窗口的可见性 可以禁用窗口按钮（如最大化按钮） 说明： 窗口创建和配置是应用程序的基础。通过配置窗口属性，可以创建符合需求的用户界面。","窗口属性设置#窗口属性设置":"设置窗口的各种属性。\n源代码文件：bevy/examples/window/window_settings.rs\n代码示例：\nuse bevy::prelude::*; use bevy::window::{CursorGrabMode, CursorIcon, PresentMode, WindowLevel}; fn toggle_vsync(input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, mut window: Single\u003c\u0026mut Window\u003e) { if input.just_pressed(KeyCode::KeyV) { window.present_mode = if matches!(window.present_mode, PresentMode::AutoVsync) { PresentMode::AutoNoVsync } else { PresentMode::AutoVsync }; info!(\"PRESENT_MODE: {:?}\", window.present_mode); } } fn switch_level(input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, mut window: Single\u003c\u0026mut Window\u003e) { if input.just_pressed(KeyCode::KeyT) { window.window_level = match window.window_level { WindowLevel::AlwaysOnBottom =\u003e WindowLevel::Normal, WindowLevel::Normal =\u003e WindowLevel::AlwaysOnTop, WindowLevel::AlwaysOnTop =\u003e WindowLevel::AlwaysOnBottom, }; info!(\"WINDOW_LEVEL: {:?}\", window.window_level); } } fn toggle_cursor(input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, mut window: Single\u003c\u0026mut Window\u003e) { if input.just_pressed(KeyCode::KeyC) { window.cursor_options.grab_mode = match window.cursor_options.grab_mode { CursorGrabMode::None =\u003e CursorGrabMode::Locked, CursorGrabMode::Locked =\u003e CursorGrabMode::Confined, CursorGrabMode::Confined =\u003e CursorGrabMode::None, }; info!(\"CURSOR_GRAB_MODE: {:?}\", window.cursor_options.grab_mode); } } 关键要点：\n可以在运行时动态修改窗口属性 可以切换 VSync 模式 可以设置窗口层级 可以控制鼠标光标的抓取模式 说明： 窗口属性设置允许在运行时动态调整窗口行为。这对于创建交互式应用程序非常有用。","窗口截图#窗口截图":"捕获窗口截图。\n源代码文件：bevy/examples/window/screenshot.rs\n关键信息：\n可以捕获窗口截图 可以使用 Window::screenshot() 方法 截图可以保存为文件 可以捕获特定帧的截图 说明： 窗口截图功能可以用于创建游戏截图、调试信息等。","窗口管理的核心组件#窗口管理的核心组件":"Bevy 窗口管理包含以下核心组件：\nWindow：窗口组件，包含窗口的配置信息 WindowPlugin：窗口插件，负责创建和管理窗口 WindowRef：窗口引用，用于引用特定的窗口 WindowLevel：窗口层级，控制窗口的显示顺序","进阶用法#进阶用法":"","透明窗口#透明窗口":"创建透明窗口。\n源代码文件：bevy/examples/window/transparent_window.rs\n关键信息：\n可以创建透明窗口 需要设置窗口的透明度属性 透明窗口可以用于创建特殊效果 某些平台可能不支持透明窗口 说明： 透明窗口可以用于创建特殊的视觉效果，如覆盖层、HUD 等。"},"title":"窗口管理"},"/wiki/bevybook/ui_audio_window/%E9%9F%B3%E9%A2%91/":{"data":{"":"","3d-空间音频#3D 空间音频":"使用 3D 空间音频创建沉浸式音频体验。\n源代码文件：bevy/examples/audio/spatial_audio_3d.rs\n代码示例：\nuse bevy::prelude::*; fn setup( mut commands: Commands, asset_server: Res\u003cAssetServer\u003e, mut meshes: ResMut\u003cAssets\u003cMesh\u003e\u003e, mut materials: ResMut\u003cAssets\u003cStandardMaterial\u003e\u003e, ) { // 创建音频发射器 commands.spawn(( Mesh3d(meshes.add(Sphere::new(0.2).mesh().uv(32, 18))), MeshMaterial3d(materials.add(Color::from(BLUE))), Transform::from_xyz(0.0, 0.0, 0.0), Emitter::default(), AudioPlayer::new(asset_server.load(\"sounds/Windless Slopes.ogg\")), PlaybackSettings::LOOP.with_spatial(true), )); // 创建空间监听器 let listener = SpatialListener::new(4.0); // 4.0 是两耳之间的距离 commands.spawn(( Transform::default(), Visibility::default(), listener, )); } fn update_listener( keyboard: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, mut listener: Query\u003c\u0026mut Transform, With\u003cSpatialListener\u003e\u003e, ) { let Ok(mut transform) = listener.single_mut() else { return; }; let speed = 2.0; if keyboard.pressed(KeyCode::ArrowUp) { transform.translation.z -= speed; } if keyboard.pressed(KeyCode::ArrowDown) { transform.translation.z += speed; } if keyboard.pressed(KeyCode::ArrowLeft) { transform.translation.x -= speed; } if keyboard.pressed(KeyCode::ArrowRight) { transform.translation.x += speed; } } 关键要点：\n使用 SpatialListener 组件创建空间监听器 使用 PlaybackSettings::LOOP.with_spatial(true) 启用空间音频 空间监听器的位置影响音频的感知位置 音频发射器的位置影响音频的来源位置 说明： 3D 空间音频可以创建沉浸式的音频体验。通过设置音频发射器和监听器的位置，可以模拟真实的声音传播效果。","什么是音频系统#什么是音频系统？":"音频系统是 Bevy 中用于播放音频的功能。Bevy 的音频系统支持背景音乐、音效、3D 空间音频等多种音频类型。\n为什么需要音频系统？\n游戏体验：音频可以增强游戏体验 反馈：音频可以提供游戏反馈 氛围：音频可以营造游戏氛围 沉浸感：3D 空间音频可以增强沉浸感","加载和播放音频#加载和播放音频":"加载和播放音频资源。\n源代码文件：bevy/examples/audio/audio.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .add_systems(Startup, setup) .run(); } fn setup(asset_server: Res\u003cAssetServer\u003e, mut commands: Commands) { commands.spawn(AudioPlayer::new( asset_server.load(\"sounds/Windless Slopes.ogg\"), )); } 关键要点：\n使用 AssetServer 加载音频资源 使用 AudioPlayer 组件播放音频 音频资源支持多种格式（OGG、WAV 等） 音频播放是异步的，不会阻塞游戏运行 说明： 音频加载和播放是音频系统的基础。通过加载音频资源并创建音频播放器，可以播放背景音乐和音效。","在游戏开发中的应用场景#在游戏开发中的应用场景":"音频系统在游戏开发中有广泛的应用：\n背景音乐：播放游戏背景音乐 音效：播放游戏音效，如脚步声、爆炸声等 3D 音频：创建沉浸式的 3D 音频体验 音频反馈：提供游戏反馈，如按钮点击声等","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何循环播放音频？\n解决方案：使用 PlaybackSettings::LOOP 设置循环播放。\n问题 2：如何同时播放多个音频？\n解决方案：创建多个 AudioPlayer 实体，每个实体播放不同的音频。\n问题 3：如何实现 3D 空间音频？\n解决方案：使用 SpatialListener 和 PlaybackSettings::LOOP.with_spatial(true) 启用空间音频。","性能考虑#性能考虑":"音频数量：尽量减少同时播放的音频数量 音频格式：选择合适的音频格式以平衡质量和文件大小 音频压缩：使用压缩音频格式以减少内存使用 空间音频：只在需要时启用空间音频以提高性能","核心概念#核心概念":"","概述#概述":"学习目标：\n理解音频系统的基本概念 掌握音频资源的加载和播放 学会控制音频播放（播放、暂停、音量、速度） 了解 3D 空间音频的使用 前置知识要求：\nBevy 快速入门 ECS 基础 资源管理基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/audio/audio.rs - 音频播放示例 bevy/examples/audio/audio_control.rs - 音频控制示例 bevy/examples/audio/spatial_audio_3d.rs - 3D 空间音频示例 bevy/examples/audio/soundtrack.rs - 音频轨道示例 官方文档链接：\nBevy Audio 官方文档 音频示例 进一步学习建议：\n学习资源管理，了解如何加载和管理音频资源 学习输入处理，了解如何通过输入控制音频播放 学习 3D 开发，了解如何将 3D 空间音频与 3D 场景结合 索引：返回上级目录","进阶用法#进阶用法":"","音频控制#音频控制":"控制音频播放（播放、暂停、音量、速度）。\n源代码文件：bevy/examples/audio/audio_control.rs\n代码示例：\nuse bevy::prelude::*; fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(( AudioPlayer::new(asset_server.load(\"sounds/Windless Slopes.ogg\")), MyMusic, )); } #[derive(Component)] struct MyMusic; fn pause( keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, music_controller: Query\u003c\u0026AudioSink, With\u003cMyMusic\u003e\u003e, ) { let Ok(sink) = music_controller.single() else { return; }; if keyboard_input.just_pressed(KeyCode::Space) { sink.toggle_playback(); } } fn mute( keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, mut music_controller: Query\u003c\u0026mut AudioSink, With\u003cMyMusic\u003e\u003e, ) { let Ok(mut sink) = music_controller.single_mut() else { return; }; if keyboard_input.just_pressed(KeyCode::KeyM) { sink.toggle_mute(); } } fn volume( keyboard_input: Res\u003cButtonInput\u003cKeyCode\u003e\u003e, mut music_controller: Query\u003c\u0026mut AudioSink, With\u003cMyMusic\u003e\u003e, ) { let Ok(mut sink) = music_controller.single_mut() else { return; }; if keyboard_input.pressed(KeyCode::Equal) { sink.set_volume((sink.volume() + 0.1).min(1.0)); } if keyboard_input.pressed(KeyCode::Minus) { sink.set_volume((sink.volume() - 0.1).max(0.0)); } } 关键要点：\n使用 AudioSink 组件控制音频播放 可以使用 toggle_playback() 切换播放/暂停 可以使用 toggle_mute() 切换静音 可以使用 set_volume() 设置音量 可以使用 set_speed() 设置播放速度 说明： 音频控制允许在运行时动态调整音频播放。这对于创建音频设置界面、响应游戏状态变化等非常有用。","音频播放设置#音频播放设置":"配置音频播放设置。\n关键信息：\n可以使用 PlaybackSettings 配置播放设置 可以设置循环播放、音量、速度等 可以启用空间音频 可以设置播放延迟 说明： 音频播放设置允许精细控制音频播放行为。这对于创建各种音频效果非常有用。","音频系统的核心组件#音频系统的核心组件":"Bevy 音频系统包含以下核心组件：\nAudioPlayer：音频播放器，用于播放音频 AudioSink：音频接收器，用于控制音频播放 PlaybackSettings：播放设置，用于配置音频播放 SpatialListener：空间监听器，用于 3D 空间音频","音频轨道#音频轨道":"管理多个音频轨道。\n源代码文件：bevy/examples/audio/soundtrack.rs\n关键信息：\n可以创建多个音频轨道 可以在不同轨道之间切换 可以同时播放多个轨道 可以控制每个轨道的音量 说明： 音频轨道允许管理复杂的音频场景。例如，可以创建背景音乐轨道、音效轨道等。"},"title":"音频系统"},"/wiki/bevybook/ui_audio_window/ui/":{"data":{"":"","flexbox-布局#Flexbox 布局":"使用 Flexbox 布局 UI 元素。\n源代码文件：bevy/examples/ui/flex_layout.rs\n代码示例：\nuse bevy::prelude::*; fn spawn_layout(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { let font = asset_server.load(\"fonts/FiraSans-Bold.ttf\"); commands.spawn(Camera2d); commands .spawn(( Node { width: percent(100), height: percent(100), flex_direction: FlexDirection::Column, align_items: AlignItems::Center, padding: UiRect::all(Val::Px(12.0)), row_gap: Val::Px(12.0), ..Default::default() }, BackgroundColor(Color::BLACK), )) .with_children(|builder| { builder .spawn(Node { flex_direction: FlexDirection::Row, ..default() }) .with_children(|builder| { // 添加子元素 }); }); } 关键要点：\n使用 Node 组件创建布局容器 使用 flex_direction 设置布局方向（Column 或 Row） 使用 align_items 设置对齐方式 使用 justify_content 设置内容分布 使用 padding、row_gap、column_gap 设置间距 说明： Flexbox 布局是创建响应式 UI 的重要工具。通过设置不同的布局属性，可以创建各种 UI 布局。","grid-布局#Grid 布局":"使用 Grid 布局 UI 元素。\n源代码文件：bevy/examples/ui/grid.rs\n关键信息：\n可以使用 Grid 组件创建网格布局 可以设置网格的行和列 可以设置网格项的跨行和跨列 可以设置网格间距和对齐方式 说明： Grid 布局适合创建表格、仪表板等复杂的 UI 布局。","ui-交互#UI 交互":"处理 UI 元素的交互。\n关键信息：\n使用 Interaction 组件检测交互状态 可以响应 Pressed、Hovered、None 三种状态 可以使用 InputFocus 资源支持无障碍功能 可以使用 Button 组件的 set_changed() 方法更新状态 说明： UI 交互是创建响应式界面的关键。通过检测交互状态，可以创建各种交互效果。","ui-样式#UI 样式":"设置 UI 元素的样式。\n关键信息：\n可以使用 BackgroundColor 设置背景颜色 可以使用 BorderColor 设置边框颜色 可以使用 BorderRadius 设置圆角 可以使用 TextShadow 设置文本阴影 可以使用 TextLayout 设置文本布局 说明： UI 样式可以让界面更加美观和易用。通过设置不同的样式属性，可以创建各种视觉效果。","ui-系统的核心组件#UI 系统的核心组件":"Bevy UI 系统包含以下核心组件：\nNode：UI 节点，用于布局和样式 Button：按钮组件，用于用户交互 Text：文本组件，用于显示文本 BackgroundColor：背景颜色组件 BorderColor：边框颜色组件 Interaction：交互状态组件","什么是-ui-系统#什么是 UI 系统？":"UI 系统是 Bevy 中用于创建用户界面的功能。Bevy 的 UI 系统支持按钮、文本、布局、样式等多种 UI 元素。\n为什么需要 UI 系统？\n用户交互：UI 系统提供用户交互界面 信息显示：UI 系统可以显示游戏信息 菜单系统：UI 系统可以创建菜单和设置界面 HUD：UI 系统可以创建游戏 HUD","创建按钮#创建按钮":"创建和使用按钮。\n源代码文件：bevy/examples/ui/button.rs\n代码示例：\nuse bevy::prelude::*; fn main() { App::new() .add_plugins(DefaultPlugins) .init_resource::\u003cInputFocus\u003e() .add_systems(Startup, setup) .add_systems(Update, button_system) .run(); } const NORMAL_BUTTON: Color = Color::srgb(0.15, 0.15, 0.15); const HOVERED_BUTTON: Color = Color::srgb(0.25, 0.25, 0.25); const PRESSED_BUTTON: Color = Color::srgb(0.35, 0.75, 0.35); fn button_system( mut input_focus: ResMut\u003cInputFocus\u003e, mut interaction_query: Query\u003c ( Entity, \u0026Interaction, \u0026mut BackgroundColor, \u0026mut BorderColor, \u0026mut Button, \u0026Children, ), Changed\u003cInteraction\u003e, \u003e, mut text_query: Query\u003c\u0026mut Text\u003e, ) { for (entity, interaction, mut color, mut border_color, mut button, children) in \u0026mut interaction_query { let mut text = text_query.get_mut(children[0]).unwrap(); match *interaction { Interaction::Pressed =\u003e { input_focus.set(entity); **text = \"Press\".to_string(); *color = PRESSED_BUTTON.into(); *border_color = BorderColor::all(RED); button.set_changed(); } Interaction::Hovered =\u003e { input_focus.set(entity); **text = \"Hover\".to_string(); *color = HOVERED_BUTTON.into(); *border_color = BorderColor::all(Color::WHITE); button.set_changed(); } Interaction::None =\u003e { input_focus.clear(); **text = \"Button\".to_string(); *color = NORMAL_BUTTON.into(); *border_color = BorderColor::all(Color::BLACK); } } } } fn setup(mut commands: Commands, assets: Res\u003cAssetServer\u003e) { commands.spawn(Camera2d); commands.spawn(button(\u0026assets)); } fn button(asset_server: \u0026AssetServer) -\u003e impl Bundle { ( Node { width: percent(100), height: percent(100), align_items: AlignItems::Center, justify_content: JustifyContent::Center, ..default() }, children![( Button, Node { width: px(150), height: px(65), border: UiRect::all(px(5)), justify_content: JustifyContent::Center, align_items: AlignItems::Center, ..default() }, BorderColor::all(Color::WHITE), BorderRadius::MAX, BackgroundColor(Color::BLACK), children![( Text::new(\"Button\"), TextFont { font: asset_server.load(\"fonts/FiraSans-Bold.ttf\"), font_size: 40.0, ..default() }, )], )], ) } 关键要点：\n使用 Button 组件创建按钮 使用 Interaction 组件检测交互状态 可以响应 Pressed、Hovered、None 三种交互状态 需要设置 InputFocus 资源以支持无障碍功能 说明： 按钮是 UI 系统中最常用的交互元素。通过检测交互状态，可以创建响应式的按钮效果。","创建文本#创建文本":"创建和更新文本。\n源代码文件：bevy/examples/ui/text.rs\n代码示例：\nuse bevy::prelude::*; fn setup(mut commands: Commands, asset_server: Res\u003cAssetServer\u003e) { commands.spawn(Camera2d); // 创建单个文本 commands.spawn(( Text::new(\"hello\\nbevy!\"), TextFont { font: asset_server.load(\"fonts/FiraSans-Bold.ttf\"), font_size: 67.0, ..default() }, TextShadow::default(), TextLayout::new_with_justify(Justify::Center), Node { position_type: PositionType::Absolute, bottom: px(5), right: px(5), ..default() }, )); // 创建多段文本 commands .spawn(( Text::new(\"FPS: \"), TextFont { font: asset_server.load(\"fonts/FiraSans-Bold.ttf\"), font_size: 42.0, ..default() }, )) .with_child(( TextSpan::default(), TextFont { font_size: 33.0, ..default() }, TextColor(GOLD.into()), )); } fn text_update_system( diagnostics: Res\u003cDiagnosticsStore\u003e, mut query: Query\u003c\u0026mut Text, With\u003cFpsText\u003e\u003e, ) { for mut text in \u0026mut query { if let Some(fps) = diagnostics.get(\u0026FrameTimeDiagnosticsPlugin::FPS) { if let Some(value) = fps.smoothed() { text.0 = format!(\"{value:.2}\"); } } } } 关键要点：\n使用 Text 组件创建文本 可以使用 TextFont 设置字体和大小 可以使用 TextColor 设置文本颜色 可以使用 TextSpan 创建多段文本 可以在系统中更新文本内容 说明： 文本是 UI 系统中用于显示信息的重要元素。通过更新文本内容，可以显示游戏状态、分数等信息。","在游戏开发中的应用场景#在游戏开发中的应用场景":"UI 系统在游戏开发中有广泛的应用：\n游戏菜单：创建主菜单、设置菜单等 HUD：创建游戏 HUD，显示分数、生命值等 对话框：创建对话和提示界面 设置界面：创建设置和配置界面","基础用法#基础用法":"","实际应用#实际应用":"","常见问题#常见问题":"问题 1：如何创建响应式布局？\n解决方案：使用 Flexbox 或 Grid 布局，并使用百分比或相对单位设置大小。\n问题 2：如何处理 UI 点击事件？\n解决方案：使用 Interaction 组件检测交互状态，并在系统中处理交互逻辑。\n问题 3：如何更新 UI 文本？\n解决方案：在系统中查询文本组件，并使用 Text 的 set() 方法更新内容。","性能考虑#性能考虑":"UI 元素数量：尽量减少 UI 元素数量以提高性能 文本更新频率：避免频繁更新文本内容 布局计算：合理使用布局属性以减少计算开销 交互检测：只在需要时检测交互状态","核心概念#核心概念":"","概述#概述":"学习目标：\n理解 UI 系统的基本概念 掌握按钮的创建和使用 学会创建和更新文本 了解 Flexbox 和 Grid 布局 掌握 UI 样式和交互 前置知识要求：\nBevy 快速入门 ECS 基础 窗口管理基础","相关资源#相关资源":"相关源代码文件：\nbevy/examples/ui/button.rs - 按钮示例 bevy/examples/ui/text.rs - 文本示例 bevy/examples/ui/flex_layout.rs - Flexbox 布局示例 bevy/examples/ui/grid.rs - Grid 布局示例 bevy/examples/ui/directional_navigation.rs - 方向导航示例 官方文档链接：\nBevy UI 官方文档 UI 示例 进一步学习建议：\n学习窗口管理，了解如何在窗口中创建 UI 学习输入处理，了解如何处理 UI 输入事件 学习动画系统，了解如何对 UI 元素进行动画处理 索引：返回上级目录","进阶用法#进阶用法":""},"title":"用户界面（UI）"},"/wiki/sow/":{"data":{"":"","项目介绍#项目介绍":"SoW 是一个专注于世界建模和仿真的高效平台。"},"title":"项目介绍"},"/wiki/tricktrade/":{"data":{"":"","项目介绍#项目介绍":"TrickTrade 是一个专注于量化交易的高效平台，提供丰富的策略和工具，帮助用户实现自动化交易。无论您是新手还是有经验的交易者，TrickTrade 都能满足您的需求。"},"title":"项目介绍"}}